From 4617be139becec0e5d7823c1d86d12015e0ac5c6 Mon Sep 17 00:00:00 2001
From: Yoshi <yoshijava@gmail.com>
Date: Wed, 16 Dec 2020 12:44:31 +0800
Subject: [PATCH] Patched for gcc bug

---
 builtins.c    |    2 +-
 c-convert.c   |  162 +-
 c-decl.c      |    1 +
 config.h      |    1 +
 expmed.c      |    4 +-
 expr.c        |   38 +-
 fibheap.h     |    2 +-
 graph.c       |    2 +-
 hashtab.h     |    2 +-
 i386.c        |   28 +-
 insn-emit.c   |    3 +-
 insn-output.c | 1088 +++---
 main.c        |   52 +-
 optabs.c      | 8814 ++++++++++++++++++++++++-------------------------
 optabs.h      |   15 +-
 partition.h   |    2 +-
 recog.c       | 5218 ++++++++++++++---------------
 recog.h       |   17 +-
 reload1.c     |    8 +-
 safe-ctype.c  |    2 +-
 splay-tree.h  |    2 +-
 stor-layout.c | 2950 ++++++++---------
 system.h      |    4 +-
 vasprintf.c   |    2 +-
 24 files changed, 9225 insertions(+), 9194 deletions(-)

diff --git a/builtins.c b/builtins.c
index c3d6ae9..aa75846 100644
--- a/builtins.c
+++ b/builtins.c
@@ -1644,7 +1644,7 @@ expand_builtin_strlen (exp, target)
 							    char_mode))
 	char_rtx = copy_to_mode_reg (char_mode, char_rtx);
 
-      pat = GEN_FCN (icode) (result, gen_rtx_MEM (BLKmode, src_reg),
+      pat = GEN_FCN4 (icode) (result, gen_rtx_MEM (BLKmode, src_reg),
 			     char_rtx, GEN_INT (align));
       if (! pat)
 	return 0;
diff --git a/expmed.c b/expmed.c
index ab127ec..812e55a 100644
--- a/expmed.c
+++ b/expmed.c
@@ -444,7 +444,7 @@ store_bit_field (str_rtx, bitsize, bitnum, fieldmode, value, total_size)
 	    abort ();
 	}
 
-      emit_insn (GEN_FCN (icode)
+      emit_insn (GEN_FCN2 (icode)
 		 (gen_rtx_SUBREG (fieldmode, op0,
 				  (bitnum % BITS_PER_WORD) / BITS_PER_UNIT
 				  + (offset * UNITS_PER_WORD)),
@@ -4410,7 +4410,7 @@ emit_store_flag (target, code, op0, op1, mode, unsignedp, normalizep)
 	  || ! (*pred) (subtarget, compare_mode))
 	subtarget = gen_reg_rtx (compare_mode);
 
-      pattern = GEN_FCN (icode) (subtarget);
+      pattern = GEN_FCN1 (icode) (subtarget);
       if (pattern)
 	{
 	  emit_insn (pattern);
diff --git a/expr.c b/expr.c
index a6ec546..f8224ed 100644
--- a/expr.c
+++ b/expr.c
@@ -123,7 +123,7 @@ static rtx enqueue_insn		PARAMS ((rtx, rtx));
 static unsigned HOST_WIDE_INT move_by_pieces_ninsns
 				PARAMS ((unsigned HOST_WIDE_INT,
 					 unsigned int));
-static void move_by_pieces_1	PARAMS ((rtx (*) (rtx, ...), enum machine_mode,
+static void move_by_pieces_1	PARAMS ((rtx (*) (rtx, rtx), enum machine_mode,
 					 struct move_by_pieces *));
 static rtx clear_by_pieces_1	PARAMS ((PTR, HOST_WIDE_INT,
 					 enum machine_mode));
@@ -131,7 +131,7 @@ static void clear_by_pieces	PARAMS ((rtx, unsigned HOST_WIDE_INT,
 					 unsigned int));
 static void store_by_pieces_1	PARAMS ((struct store_by_pieces *,
 					 unsigned int));
-static void store_by_pieces_2	PARAMS ((rtx (*) (rtx, ...),
+static void store_by_pieces_2	PARAMS ((rtx (*) (rtx, rtx),
 					 enum machine_mode,
 					 struct store_by_pieces *));
 static rtx get_subtarget	PARAMS ((rtx));
@@ -1493,7 +1493,7 @@ move_by_pieces (to, from, len, align)
 
       icode = mov_optab->handlers[(int) mode].insn_code;
       if (icode != CODE_FOR_nothing && align >= GET_MODE_ALIGNMENT (mode))
-	move_by_pieces_1 (GEN_FCN (icode), mode, &data);
+	move_by_pieces_1 (GEN_FCN0 (icode), mode, &data);
 
       max_size = GET_MODE_SIZE (mode);
     }
@@ -1549,7 +1549,7 @@ move_by_pieces_ninsns (l, align)
 
 static void
 move_by_pieces_1 (genfun, mode, data)
-     rtx (*genfun) PARAMS ((rtx, ...));
+     rtx (*genfun) PARAMS ((rtx, rtx));
      enum machine_mode mode;
      struct move_by_pieces *data;
 {
@@ -1692,7 +1692,7 @@ emit_block_move (x, y, size)
 	      if (pred != 0 && ! (*pred) (op2, mode))
 		op2 = copy_to_mode_reg (mode, op2);
 
-	      pat = GEN_FCN ((int) code) (x, y, op2, opalign);
+	      pat = GEN_FCN4 ((int) code) (x, y, op2, opalign);
 	      if (pat)
 		{
 		  emit_insn (pat);
@@ -2514,7 +2514,7 @@ store_by_pieces_1 (data, align)
 
       icode = mov_optab->handlers[(int) mode].insn_code;
       if (icode != CODE_FOR_nothing && align >= GET_MODE_ALIGNMENT (mode))
-	store_by_pieces_2 (GEN_FCN (icode), mode, data);
+	store_by_pieces_2 (GEN_FCN2 (icode), mode, data);
 
       max_size = GET_MODE_SIZE (mode);
     }
@@ -2530,7 +2530,7 @@ store_by_pieces_1 (data, align)
 
 static void
 store_by_pieces_2 (genfun, mode, data)
-     rtx (*genfun) PARAMS ((rtx, ...));
+     rtx (*genfun) PARAMS ((rtx, rtx));
      enum machine_mode mode;
      struct store_by_pieces *data;
 {
@@ -2633,7 +2633,7 @@ clear_storage (object, size)
 		  if (pred != 0 && ! (*pred) (op1, mode))
 		    op1 = copy_to_mode_reg (mode, op1);
 
-		  pat = GEN_FCN ((int) code) (object, op1, opalign);
+		  pat = GEN_FCN3 ((int) code) (object, op1, opalign);
 		  if (pat)
 		    {
 		      emit_insn (pat);
@@ -2820,7 +2820,7 @@ emit_move_insn_1 (x, y)
 
   if (mov_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
     return
-      emit_insn (GEN_FCN (mov_optab->handlers[(int) mode].insn_code) (x, y));
+      emit_insn (GEN_FCN2 (mov_optab->handlers[(int) mode].insn_code) (x, y));
 
   /* Expand complex moves by moving real part and imag part, if possible.  */
   else if ((class == MODE_COMPLEX_FLOAT || class == MODE_COMPLEX_INT)
@@ -2894,17 +2894,17 @@ emit_move_insn_1 (x, y)
 	  /* Note that the real part always precedes the imag part in memory
 	     regardless of machine's endianness.  */
 #ifdef STACK_GROWS_DOWNWARD
-	  emit_insn (GEN_FCN (mov_optab->handlers[(int) submode].insn_code)
+	  emit_insn (GEN_FCN2 (mov_optab->handlers[(int) submode].insn_code)
 		     (gen_rtx_MEM (submode, XEXP (x, 0)),
 		      gen_imagpart (submode, y)));
-	  emit_insn (GEN_FCN (mov_optab->handlers[(int) submode].insn_code)
+	  emit_insn (GEN_FCN2 (mov_optab->handlers[(int) submode].insn_code)
 		     (gen_rtx_MEM (submode, XEXP (x, 0)),
 		      gen_realpart (submode, y)));
 #else
-	  emit_insn (GEN_FCN (mov_optab->handlers[(int) submode].insn_code)
+	  emit_insn (GEN_FCN2 (mov_optab->handlers[(int) submode].insn_code)
 		     (gen_rtx_MEM (submode, XEXP (x, 0)),
 		      gen_realpart (submode, y)));
-	  emit_insn (GEN_FCN (mov_optab->handlers[(int) submode].insn_code)
+	  emit_insn (GEN_FCN2 (mov_optab->handlers[(int) submode].insn_code)
 		     (gen_rtx_MEM (submode, XEXP (x, 0)),
 		      gen_imagpart (submode, y)));
 #endif
@@ -2981,9 +2981,9 @@ emit_move_insn_1 (x, y)
 		  || GET_CODE (imagpart_x) == SUBREG))
 	    emit_insn (gen_rtx_CLOBBER (VOIDmode, x));
 
-	  emit_insn (GEN_FCN (mov_optab->handlers[(int) submode].insn_code)
+	  emit_insn (GEN_FCN2 (mov_optab->handlers[(int) submode].insn_code)
 		     (realpart_x, realpart_y));
-	  emit_insn (GEN_FCN (mov_optab->handlers[(int) submode].insn_code)
+	  emit_insn (GEN_FCN2 (mov_optab->handlers[(int) submode].insn_code)
 		     (imagpart_x, imagpart_y));
 	}
 
@@ -3184,7 +3184,7 @@ emit_single_push_insn (mode, x, type)
       if (((pred = insn_data[(int) icode].operand[0].predicate)
 	   && !((*pred) (x, mode))))
 	x = force_reg (mode, x);
-      emit_insn (GEN_FCN (icode) (x));
+      emit_insn (GEN_FCN1 (icode) (x));
       return;
     }
   if (GET_MODE_SIZE (mode) == rounded_size)
@@ -3431,7 +3431,7 @@ emit_push_insn (x, mode, type, size, align, partial, reg, extra,
 		      if (pred != 0 && ! (*pred) (op2, mode))
 			op2 = copy_to_mode_reg (mode, op2);
 
-		      pat = GEN_FCN ((int) code) (target, xinner,
+		      pat = GEN_FCN4 ((int) code) (target, xinner,
 						  op2, opalign);
 		      if (pat)
 			{
@@ -9125,7 +9125,7 @@ expand_increment (exp, post, ignore)
 	  if (! (*insn_data[icode].operand[2].predicate) (op1, mode))
 	    op1 = force_reg (mode, op1);
 
-	  return enqueue_insn (op0, GEN_FCN (icode) (op0, op0, op1));
+	  return enqueue_insn (op0, GEN_FCN3 (icode) (op0, op0, op1));
 	}
       if (icode != (int) CODE_FOR_nothing && GET_CODE (op0) == MEM)
 	{
@@ -9142,7 +9142,7 @@ expand_increment (exp, post, ignore)
 	  /* The increment queue is LIFO, thus we have to `queue'
 	     the instructions in reverse order.  */
 	  enqueue_insn (op0, gen_move_insn (op0, temp));
-	  result = enqueue_insn (temp, GEN_FCN (icode) (temp, temp, op1));
+	  result = enqueue_insn (temp, GEN_FCN3 (icode) (temp, temp, op1));
 	  return result;
 	}
     }
diff --git a/i386.c b/i386.c
index f07ebad..ccefff3 100644
--- a/i386.c
+++ b/i386.c
@@ -11511,7 +11511,7 @@ ix86_expand_binop_builtin (icode, arglist, target)
   if (GET_CODE (op0) == MEM && GET_CODE (op1) == MEM)
     op0 = copy_to_mode_reg (mode0, op0);
 
-  pat = GEN_FCN (icode) (target, op0, op1);
+  pat = GEN_FCN3 (icode) (target, op0, op1);
   if (! pat)
     return 0;
   emit_insn (pat);
@@ -11549,7 +11549,7 @@ ix86_expand_timode_binop_builtin (icode, arglist, target)
   if (GET_CODE (op0) == MEM && GET_CODE (op1) == MEM)
     op0 = copy_to_mode_reg (TImode, op0);
 
-  pat = GEN_FCN (icode) (target, op0, op1);
+  pat = GEN_FCN3 (icode) (target, op0, op1);
   if (! pat)
     return 0;
   emit_insn (pat);
@@ -11580,7 +11580,7 @@ ix86_expand_store_builtin (icode, arglist)
   if (! (*insn_data[icode].operand[1].predicate) (op1, mode1))
     op1 = copy_to_mode_reg (mode1, op1);
 
-  pat = GEN_FCN (icode) (op0, op1);
+  pat = GEN_FCN2 (icode) (op0, op1);
   if (pat)
     emit_insn (pat);
   return 0;
@@ -11616,7 +11616,7 @@ ix86_expand_unop_builtin (icode, arglist, target, do_load)
 	op0 = copy_to_mode_reg (mode0, op0);
     }
 
-  pat = GEN_FCN (icode) (target, op0);
+  pat = GEN_FCN2 (icode) (target, op0);
   if (! pat)
     return 0;
   emit_insn (pat);
@@ -11653,7 +11653,7 @@ ix86_expand_unop1_builtin (icode, arglist, target)
   if (! (*insn_data[icode].operand[2].predicate) (op1, mode0))
     op1 = copy_to_mode_reg (mode0, op1);
   
-  pat = GEN_FCN (icode) (target, op0, op1);
+  pat = GEN_FCN3 (icode) (target, op0, op1);
   if (! pat)
     return 0;
   emit_insn (pat);
@@ -11705,7 +11705,7 @@ ix86_expand_sse_compare (d, arglist, target)
     op1 = copy_to_mode_reg (mode1, op1);
 
   op2 = gen_rtx_fmt_ee (comparison, mode0, op0, op1);
-  pat = GEN_FCN (d->icode) (target, op0, op1, op2);
+  pat = GEN_FCN4 (d->icode) (target, op0, op1, op2);
   if (! pat)
     return 0;
   emit_insn (pat);
@@ -11754,7 +11754,7 @@ ix86_expand_sse_comi (d, arglist, target)
     op1 = copy_to_mode_reg (mode1, op1);
 
   op2 = gen_rtx_fmt_ee (comparison, mode0, op0, op1);
-  pat = GEN_FCN (d->icode) (op0, op1, op2);
+  pat = GEN_FCN3 (d->icode) (op0, op1, op2);
   if (! pat)
     return 0;
   emit_insn (pat);
@@ -11823,7 +11823,7 @@ ix86_expand_builtin (exp, target, subtarget, mode, ignore)
 	  || GET_MODE (target) != tmode
 	  || ! (*insn_data[icode].operand[0].predicate) (target, tmode))
 	target = gen_reg_rtx (tmode);
-      pat = GEN_FCN (icode) (target, op0, op1);
+      pat = GEN_FCN3 (icode) (target, op0, op1);
       if (! pat)
 	return 0;
       emit_insn (pat);
@@ -11856,7 +11856,7 @@ ix86_expand_builtin (exp, target, subtarget, mode, ignore)
 	  || GET_MODE (target) != tmode
 	  || ! (*insn_data[icode].operand[0].predicate) (target, tmode))
 	target = gen_reg_rtx (tmode);
-      pat = GEN_FCN (icode) (target, op0, op1, op2);
+      pat = GEN_FCN4 (icode) (target, op0, op1, op2);
       if (! pat)
 	return 0;
       emit_insn (pat);
@@ -11881,7 +11881,7 @@ ix86_expand_builtin (exp, target, subtarget, mode, ignore)
 	op1 = copy_to_mode_reg (mode1, op1);
       if (! (*insn_data[icode].operand[2].predicate) (op2, mode2))
 	op2 = copy_to_mode_reg (mode2, op2);
-      pat = GEN_FCN (icode) (op0, op1, op2);
+      pat = GEN_FCN3 (icode) (op0, op1, op2);
       if (! pat)
 	return 0;
       emit_insn (pat);
@@ -11943,7 +11943,7 @@ ix86_expand_builtin (exp, target, subtarget, mode, ignore)
 	  || GET_MODE (target) != tmode
 	  || ! (*insn_data[icode].operand[0].predicate) (target, tmode))
 	target = gen_reg_rtx (tmode);
-      pat = GEN_FCN (icode) (target, op0, op1);
+      pat = GEN_FCN3 (icode) (target, op0, op1);
       if (! pat)
 	return 0;
       emit_insn (pat);
@@ -11964,7 +11964,7 @@ ix86_expand_builtin (exp, target, subtarget, mode, ignore)
       if (! (*insn_data[icode].operand[2].predicate) (op1, mode1))
 	op1 = copy_to_mode_reg (mode1, op1);
 
-      pat = GEN_FCN (icode) (op0, op0, op1);
+      pat = GEN_FCN3 (icode) (op0, op0, op1);
       if (! pat)
 	return 0;
       emit_insn (pat);
@@ -12014,7 +12014,7 @@ ix86_expand_builtin (exp, target, subtarget, mode, ignore)
 	  || GET_MODE (target) != tmode
 	  || ! (*insn_data[icode].operand[0].predicate) (target, tmode))
 	target = gen_reg_rtx (tmode);
-      pat = GEN_FCN (icode) (target, op0, op1, op2);
+      pat = GEN_FCN4 (icode) (target, op0, op1, op2);
       if (! pat)
 	return 0;
       emit_insn (pat);
@@ -12042,7 +12042,7 @@ ix86_expand_builtin (exp, target, subtarget, mode, ignore)
 	  || GET_MODE (target) != tmode
 	  || ! (*insn_data[icode].operand[0].predicate) (target, tmode))
 	target = gen_reg_rtx (tmode);
-      pat = GEN_FCN (icode) (target, op0, op1);
+      pat = GEN_FCN3 (icode) (target, op0, op1);
       if (! pat)
 	return 0;
       emit_insn (pat);

diff --git a/insn-output.c b/insn-output.c
index 76fea20..2e291b0 100644
--- a/insn-output.c
+++ b/insn-output.c
@@ -19283,7 +19283,7 @@ const struct insn_data insn_data[] =
   {
     "cmpdi_ccno_1_rex64",
     (const PTR) output_0,
-    (insn_gen_fn) gen_cmpdi_ccno_1_rex64,
+    (void *) gen_cmpdi_ccno_1_rex64,
     &operand_data[1],
     2,
     0,
@@ -19303,7 +19303,7 @@ const struct insn_data insn_data[] =
   {
     "cmpdi_1_insn_rex64",
     "cmp{q}\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_cmpdi_1_insn_rex64,
+    (void *) gen_cmpdi_1_insn_rex64,
     &operand_data[5],
     2,
     0,
@@ -19433,7 +19433,7 @@ const struct insn_data insn_data[] =
   {
     "cmpqi_ext_3_insn",
     "cmp{b}\t{%1, %h0|%h0, %1}",
-    (insn_gen_fn) gen_cmpqi_ext_3_insn,
+    (void *) gen_cmpqi_ext_3_insn,
     &operand_data[24],
     2,
     0,
@@ -19443,7 +19443,7 @@ const struct insn_data insn_data[] =
   {
     "cmpqi_ext_3_insn_rex64",
     "cmp{b}\t{%1, %h0|%h0, %1}",
-    (insn_gen_fn) gen_cmpqi_ext_3_insn_rex64,
+    (void *) gen_cmpqi_ext_3_insn_rex64,
     &operand_data[26],
     2,
     0,
@@ -19583,7 +19583,7 @@ const struct insn_data insn_data[] =
   {
     "x86_fnstsw_1",
     "fnstsw\t%0",
-    (insn_gen_fn) gen_x86_fnstsw_1,
+    (void *) gen_x86_fnstsw_1,
     &operand_data[30],
     1,
     0,
@@ -19593,7 +19593,7 @@ const struct insn_data insn_data[] =
   {
     "x86_sahf_1",
     "sahf",
-    (insn_gen_fn) gen_x86_sahf_1,
+    (void *) gen_x86_sahf_1,
     &operand_data[60],
     1,
     0,
@@ -19703,7 +19703,7 @@ const struct insn_data insn_data[] =
   {
     "popsi1",
     "pop{l}\t%0",
-    (insn_gen_fn) gen_popsi1,
+    (void *) gen_popsi1,
     &operand_data[69],
     1,
     0,
@@ -20013,7 +20013,7 @@ const struct insn_data insn_data[] =
   {
     "movsi_insv_1",
     "mov{b}\t{%b1, %h0|%h0, %b1}",
-    (insn_gen_fn) gen_movsi_insv_1,
+    (void *) gen_movsi_insv_1,
     &operand_data[124],
     2,
     0,
@@ -20053,7 +20053,7 @@ const struct insn_data insn_data[] =
   {
     "pushdi2_rex64",
     (const PTR) output_77,
-    (insn_gen_fn) gen_pushdi2_rex64,
+    (void *) gen_pushdi2_rex64,
     &operand_data[132],
     2,
     0,
@@ -20083,7 +20083,7 @@ const struct insn_data insn_data[] =
   {
     "popdi1",
     "pop{q}\t%0",
-    (insn_gen_fn) gen_popdi1,
+    (void *) gen_popdi1,
     &operand_data[136],
     1,
     0,
@@ -20333,7 +20333,7 @@ const struct insn_data insn_data[] =
   {
     "swapxf",
     (const PTR) output_105,
-    (insn_gen_fn) gen_swapxf,
+    (void *) gen_swapxf,
     &operand_data[185],
     2,
     2,
@@ -20343,7 +20343,7 @@ const struct insn_data insn_data[] =
   {
     "swaptf",
     (const PTR) output_106,
-    (insn_gen_fn) gen_swaptf,
+    (void *) gen_swaptf,
     &operand_data[187],
     2,
     2,
@@ -20353,7 +20353,7 @@ const struct insn_data insn_data[] =
   {
     "zero_extendhisi2_and",
     "#",
-    (insn_gen_fn) gen_zero_extendhisi2_and,
+    (void *) gen_zero_extendhisi2_and,
     &operand_data[189],
     2,
     0,
@@ -20433,7 +20433,7 @@ const struct insn_data insn_data[] =
   {
     "zero_extendsidi2_32",
     "#",
-    (insn_gen_fn) gen_zero_extendsidi2_32,
+    (void *) gen_zero_extendsidi2_32,
     &operand_data[205],
     2,
     0,
@@ -20443,7 +20443,7 @@ const struct insn_data insn_data[] =
   {
     "zero_extendsidi2_rex64",
     (const PTR) output_116,
-    (insn_gen_fn) gen_zero_extendsidi2_rex64,
+    (void *) gen_zero_extendsidi2_rex64,
     &operand_data[207],
     2,
     0,
@@ -20453,7 +20453,7 @@ const struct insn_data insn_data[] =
   {
     "zero_extendhidi2",
     (const PTR) output_117,
-    (insn_gen_fn) gen_zero_extendhidi2,
+    (void *) gen_zero_extendhidi2,
     &operand_data[209],
     2,
     0,
@@ -20463,7 +20463,7 @@ const struct insn_data insn_data[] =
   {
     "zero_extendqidi2",
     (const PTR) output_118,
-    (insn_gen_fn) gen_zero_extendqidi2,
+    (void *) gen_zero_extendqidi2,
     &operand_data[211],
     2,
     0,
@@ -20483,7 +20483,7 @@ const struct insn_data insn_data[] =
   {
     "extendsidi2_rex64",
     (const PTR) output_120,
-    (insn_gen_fn) gen_extendsidi2_rex64,
+    (void *) gen_extendsidi2_rex64,
     &operand_data[216],
     2,
     0,
@@ -20493,7 +20493,7 @@ const struct insn_data insn_data[] =
   {
     "extendhidi2",
     "movs{wq|x}\t{%1,%0|%0, %1}",
-    (insn_gen_fn) gen_extendhidi2,
+    (void *) gen_extendhidi2,
     &operand_data[218],
     2,
     0,
@@ -20503,7 +20503,7 @@ const struct insn_data insn_data[] =
   {
     "extendqidi2",
     "movs{bq|x}\t{%1,%0|%0, %1}",
-    (insn_gen_fn) gen_extendqidi2,
+    (void *) gen_extendqidi2,
     &operand_data[220],
     2,
     0,
@@ -20513,7 +20513,7 @@ const struct insn_data insn_data[] =
   {
     "extendhisi2",
     (const PTR) output_123,
-    (insn_gen_fn) gen_extendhisi2,
+    (void *) gen_extendhisi2,
     &operand_data[222],
     2,
     0,
@@ -20533,7 +20533,7 @@ const struct insn_data insn_data[] =
   {
     "extendqihi2",
     (const PTR) output_125,
-    (insn_gen_fn) gen_extendqihi2,
+    (void *) gen_extendqihi2,
     &operand_data[226],
     2,
     0,
@@ -20543,7 +20543,7 @@ const struct insn_data insn_data[] =
   {
     "extendqisi2",
     "movs{bl|x}\t{%1,%0|%0, %1}",
-    (insn_gen_fn) gen_extendqisi2,
+    (void *) gen_extendqisi2,
     &operand_data[203],
     2,
     0,
@@ -20703,7 +20703,7 @@ const struct insn_data insn_data[] =
   {
     "truncdfsf2_3",
     (const PTR) output_142,
-    (insn_gen_fn) gen_truncdfsf2_3,
+    (void *) gen_truncdfsf2_3,
     &operand_data[258],
     2,
     0,
@@ -20713,7 +20713,7 @@ const struct insn_data insn_data[] =
   {
     "truncdfsf2_sse_only",
     "cvtsd2ss\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_truncdfsf2_sse_only,
+    (void *) gen_truncdfsf2_sse_only,
     &operand_data[260],
     2,
     0,
@@ -20813,7 +20813,7 @@ const struct insn_data insn_data[] =
   {
     "fix_truncdi_nomemory",
     "#",
-    (insn_gen_fn) gen_fix_truncdi_nomemory,
+    (void *) gen_fix_truncdi_nomemory,
     &operand_data[282],
     6,
     0,
@@ -20823,7 +20823,7 @@ const struct insn_data insn_data[] =
   {
     "fix_truncdi_memory",
     (const PTR) output_154,
-    (insn_gen_fn) gen_fix_truncdi_memory,
+    (void *) gen_fix_truncdi_memory,
     &operand_data[288],
     5,
     0,
@@ -20833,7 +20833,7 @@ const struct insn_data insn_data[] =
   {
     "fix_truncsfdi_sse",
     "cvttss2si{q}\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_fix_truncsfdi_sse,
+    (void *) gen_fix_truncsfdi_sse,
     &operand_data[293],
     2,
     0,
@@ -20843,7 +20843,7 @@ const struct insn_data insn_data[] =
   {
     "fix_truncdfdi_sse",
     "cvttsd2si{q}\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_fix_truncdfdi_sse,
+    (void *) gen_fix_truncdfdi_sse,
     &operand_data[295],
     2,
     0,
@@ -20863,7 +20863,7 @@ const struct insn_data insn_data[] =
   {
     "fix_truncsi_nomemory",
     "#",
-    (insn_gen_fn) gen_fix_truncsi_nomemory,
+    (void *) gen_fix_truncsi_nomemory,
     &operand_data[297],
     5,
     0,
@@ -20873,7 +20873,7 @@ const struct insn_data insn_data[] =
   {
     "fix_truncsi_memory",
     (const PTR) output_159,
-    (insn_gen_fn) gen_fix_truncsi_memory,
+    (void *) gen_fix_truncsi_memory,
     &operand_data[302],
     4,
     0,
@@ -20883,7 +20883,7 @@ const struct insn_data insn_data[] =
   {
     "fix_truncsfsi_sse",
     "cvttss2si\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_fix_truncsfsi_sse,
+    (void *) gen_fix_truncsfsi_sse,
     &operand_data[306],
     2,
     0,
@@ -20893,7 +20893,7 @@ const struct insn_data insn_data[] =
   {
     "fix_truncdfsi_sse",
     "cvttsd2si\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_fix_truncdfsi_sse,
+    (void *) gen_fix_truncdfsi_sse,
     &operand_data[308],
     2,
     0,
@@ -20913,7 +20913,7 @@ const struct insn_data insn_data[] =
   {
     "fix_trunchi_nomemory",
     "#",
-    (insn_gen_fn) gen_fix_trunchi_nomemory,
+    (void *) gen_fix_trunchi_nomemory,
     &operand_data[310],
     5,
     0,
@@ -20923,7 +20923,7 @@ const struct insn_data insn_data[] =
   {
     "fix_trunchi_memory",
     (const PTR) output_164,
-    (insn_gen_fn) gen_fix_trunchi_memory,
+    (void *) gen_fix_trunchi_memory,
     &operand_data[315],
     4,
     0,
@@ -20933,7 +20933,7 @@ const struct insn_data insn_data[] =
   {
     "x86_fnstcw_1",
     "fnstcw\t%0",
-    (insn_gen_fn) gen_x86_fnstcw_1,
+    (void *) gen_x86_fnstcw_1,
     &operand_data[315],
     1,
     0,
@@ -20943,7 +20943,7 @@ const struct insn_data insn_data[] =
   {
     "x86_fldcw_1",
     "fldcw\t%0",
-    (insn_gen_fn) gen_x86_fldcw_1,
+    (void *) gen_x86_fldcw_1,
     &operand_data[290],
     1,
     0,
@@ -20953,7 +20953,7 @@ const struct insn_data insn_data[] =
   {
     "floathisf2",
     (const PTR) output_167,
-    (insn_gen_fn) gen_floathisf2,
+    (void *) gen_floathisf2,
     &operand_data[319],
     2,
     0,
@@ -21013,7 +21013,7 @@ const struct insn_data insn_data[] =
   {
     "floathidf2",
     (const PTR) output_173,
-    (insn_gen_fn) gen_floathidf2,
+    (void *) gen_floathidf2,
     &operand_data[331],
     2,
     0,
@@ -21073,7 +21073,7 @@ const struct insn_data insn_data[] =
   {
     "floathixf2",
     (const PTR) output_179,
-    (insn_gen_fn) gen_floathixf2,
+    (void *) gen_floathixf2,
     &operand_data[343],
     2,
     0,
@@ -21083,7 +21083,7 @@ const struct insn_data insn_data[] =
   {
     "floathitf2",
     (const PTR) output_180,
-    (insn_gen_fn) gen_floathitf2,
+    (void *) gen_floathitf2,
     &operand_data[345],
     2,
     0,
@@ -21093,7 +21093,7 @@ const struct insn_data insn_data[] =
   {
     "floatsixf2",
     (const PTR) output_181,
-    (insn_gen_fn) gen_floatsixf2,
+    (void *) gen_floatsixf2,
     &operand_data[347],
     2,
     0,
@@ -21103,7 +21103,7 @@ const struct insn_data insn_data[] =
   {
     "floatsitf2",
     (const PTR) output_182,
-    (insn_gen_fn) gen_floatsitf2,
+    (void *) gen_floatsitf2,
     &operand_data[349],
     2,
     0,
@@ -21113,7 +21113,7 @@ const struct insn_data insn_data[] =
   {
     "floatdixf2",
     (const PTR) output_183,
-    (insn_gen_fn) gen_floatdixf2,
+    (void *) gen_floatdixf2,
     &operand_data[351],
     2,
     0,
@@ -21123,7 +21123,7 @@ const struct insn_data insn_data[] =
   {
     "floatditf2",
     (const PTR) output_184,
-    (insn_gen_fn) gen_floatditf2,
+    (void *) gen_floatditf2,
     &operand_data[353],
     2,
     0,
@@ -21193,7 +21193,7 @@ const struct insn_data insn_data[] =
   {
     "addqi3_cc",
     "add{b}\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_addqi3_cc,
+    (void *) gen_addqi3_cc,
     &operand_data[367],
     3,
     2,
@@ -21363,7 +21363,7 @@ const struct insn_data insn_data[] =
   {
     "addsi_1_zext",
     (const PTR) output_208,
-    (insn_gen_fn) gen_addsi_1_zext,
+    (void *) gen_addsi_1_zext,
     &operand_data[420],
     3,
     0,
@@ -21553,7 +21553,7 @@ const struct insn_data insn_data[] =
   {
     "addqi_ext_1",
     (const PTR) output_227,
-    (insn_gen_fn) gen_addqi_ext_1,
+    (void *) gen_addqi_ext_1,
     &operand_data[465],
     3,
     0,
@@ -21593,7 +21593,7 @@ const struct insn_data insn_data[] =
   {
     "subdi3_carry_rex64",
     "sbb{q}\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_subdi3_carry_rex64,
+    (void *) gen_subdi3_carry_rex64,
     &operand_data[477],
     3,
     0,
@@ -21633,7 +21633,7 @@ const struct insn_data insn_data[] =
   {
     "subsi3_carry",
     "sbb{l}\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_subsi3_carry,
+    (void *) gen_subsi3_carry,
     &operand_data[480],
     3,
     0,
@@ -21643,7 +21643,7 @@ const struct insn_data insn_data[] =
   {
     "subsi3_carry_zext",
     "sbb{l}\t{%2, %k0|%k0, %2}",
-    (insn_gen_fn) gen_subsi3_carry_zext,
+    (void *) gen_subsi3_carry_zext,
     &operand_data[483],
     3,
     0,
@@ -21943,7 +21943,7 @@ const struct insn_data insn_data[] =
   {
     "divqi3",
     "idiv{b}\t%2",
-    (insn_gen_fn) gen_divqi3,
+    (void *) gen_divqi3,
     &operand_data[537],
     3,
     0,
@@ -21953,7 +21953,7 @@ const struct insn_data insn_data[] =
   {
     "udivqi3",
     "div{b}\t%2",
-    (insn_gen_fn) gen_udivqi3,
+    (void *) gen_udivqi3,
     &operand_data[537],
     3,
     0,
@@ -22023,7 +22023,7 @@ const struct insn_data insn_data[] =
   {
     "divmodhi4",
     "cwtd\n\tidiv{w}\t%2",
-    (insn_gen_fn) gen_divmodhi4,
+    (void *) gen_divmodhi4,
     &operand_data[566],
     4,
     2,
@@ -22033,7 +22033,7 @@ const struct insn_data insn_data[] =
   {
     "udivmoddi4",
     "xor{q}\t%3, %3\n\tdiv{q}\t%2",
-    (insn_gen_fn) gen_udivmoddi4,
+    (void *) gen_udivmoddi4,
     &operand_data[570],
     4,
     2,
@@ -22053,7 +22053,7 @@ const struct insn_data insn_data[] =
   {
     "udivmodsi4",
     "xor{l}\t%3, %3\n\tdiv{l}\t%2",
-    (insn_gen_fn) gen_udivmodsi4,
+    (void *) gen_udivmodsi4,
     &operand_data[574],
     4,
     2,
@@ -22093,7 +22093,7 @@ const struct insn_data insn_data[] =
   {
     "testsi_1",
     "test{l}\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_testsi_1,
+    (void *) gen_testsi_1,
     &operand_data[585],
     2,
     0,
@@ -22303,7 +22303,7 @@ const struct insn_data insn_data[] =
   {
     "andqi_ext_0",
     "and{b}\t{%2, %h0|%h0, %2}",
-    (insn_gen_fn) gen_andqi_ext_0,
+    (void *) gen_andqi_ext_0,
     &operand_data[629],
     3,
     0,
@@ -22833,7 +22833,7 @@ const struct insn_data insn_data[] =
   {
     "negsf2_memory",
     "#",
-    (insn_gen_fn) gen_negsf2_memory,
+    (void *) gen_negsf2_memory,
     &operand_data[699],
     2,
     0,
@@ -22843,7 +22843,7 @@ const struct insn_data insn_data[] =
   {
     "negsf2_ifs",
     "#",
-    (insn_gen_fn) gen_negsf2_ifs,
+    (void *) gen_negsf2_ifs,
     &operand_data[701],
     3,
     0,
@@ -22863,7 +22863,7 @@ const struct insn_data insn_data[] =
   {
     "negdf2_memory",
     "#",
-    (insn_gen_fn) gen_negdf2_memory,
+    (void *) gen_negdf2_memory,
     &operand_data[706],
     2,
     0,
@@ -22873,7 +22873,7 @@ const struct insn_data insn_data[] =
   {
     "negdf2_ifs",
     "#",
-    (insn_gen_fn) gen_negdf2_ifs,
+    (void *) gen_negdf2_ifs,
     &operand_data[708],
     3,
     0,
@@ -23023,7 +23023,7 @@ const struct insn_data insn_data[] =
   {
     "abssf2_memory",
     "#",
-    (insn_gen_fn) gen_abssf2_memory,
+    (void *) gen_abssf2_memory,
     &operand_data[699],
     2,
     0,
@@ -23033,7 +23033,7 @@ const struct insn_data insn_data[] =
   {
     "abssf2_ifs",
     "#",
-    (insn_gen_fn) gen_abssf2_ifs,
+    (void *) gen_abssf2_ifs,
     &operand_data[740],
     3,
     0,
@@ -23053,7 +23053,7 @@ const struct insn_data insn_data[] =
   {
     "absdf2_memory",
     "#",
-    (insn_gen_fn) gen_absdf2_memory,
+    (void *) gen_absdf2_memory,
     &operand_data[706],
     2,
     0,
@@ -23063,7 +23063,7 @@ const struct insn_data insn_data[] =
   {
     "absdf2_ifs",
     "#",
-    (insn_gen_fn) gen_absdf2_ifs,
+    (void *) gen_absdf2_ifs,
     &operand_data[743],
     3,
     0,
@@ -23333,7 +23333,7 @@ const struct insn_data insn_data[] =
   {
     "ashldi3_1",
     "#",
-    (insn_gen_fn) gen_ashldi3_1,
+    (void *) gen_ashldi3_1,
     &operand_data[757],
     4,
     0,
@@ -23353,7 +23353,7 @@ const struct insn_data insn_data[] =
   {
     "x86_shld_1",
     (const PTR) output_407,
-    (insn_gen_fn) gen_x86_shld_1,
+    (void *) gen_x86_shld_1,
     &operand_data[761],
     3,
     2,
@@ -23463,7 +23463,7 @@ const struct insn_data insn_data[] =
   {
     "ashrdi3_63_rex64",
     (const PTR) output_418,
-    (insn_gen_fn) gen_ashrdi3_63_rex64,
+    (void *) gen_ashrdi3_63_rex64,
     &operand_data[794],
     3,
     0,
@@ -23513,7 +23513,7 @@ const struct insn_data insn_data[] =
   {
     "ashrdi3_1",
     "#",
-    (insn_gen_fn) gen_ashrdi3_1,
+    (void *) gen_ashrdi3_1,
     &operand_data[757],
     4,
     0,
@@ -23533,7 +23533,7 @@ const struct insn_data insn_data[] =
   {
     "x86_shrd_1",
     (const PTR) output_425,
-    (insn_gen_fn) gen_x86_shrd_1,
+    (void *) gen_x86_shrd_1,
     &operand_data[761],
     3,
     2,
@@ -23543,7 +23543,7 @@ const struct insn_data insn_data[] =
   {
     "ashrsi3_31",
     (const PTR) output_426,
-    (insn_gen_fn) gen_ashrsi3_31,
+    (void *) gen_ashrsi3_31,
     &operand_data[806],
     3,
     0,
@@ -23763,7 +23763,7 @@ const struct insn_data insn_data[] =
   {
     "lshrdi3_1",
     "#",
-    (insn_gen_fn) gen_lshrdi3_1,
+    (void *) gen_lshrdi3_1,
     &operand_data[757],
     4,
     0,
@@ -24153,7 +24153,7 @@ const struct insn_data insn_data[] =
   {
     "setcc_2",
     "set%C1\t%0",
-    (insn_gen_fn) gen_setcc_2,
+    (void *) gen_setcc_2,
     &operand_data[850],
     2,
     0,
@@ -24303,7 +24303,7 @@ const struct insn_data insn_data[] =
   {
     "jump",
     "jmp\t%l0",
-    (insn_gen_fn) gen_jump,
+    (void *) gen_jump,
     &operand_data[860],
     1,
     0,
@@ -24353,7 +24353,7 @@ const struct insn_data insn_data[] =
   {
     "doloop_end_internal",
     (const PTR) output_507,
-    (insn_gen_fn) gen_doloop_end_internal,
+    (void *) gen_doloop_end_internal,
     &operand_data[887],
     4,
     1,
@@ -24413,7 +24413,7 @@ const struct insn_data insn_data[] =
   {
     "blockage",
     "",
-    (insn_gen_fn) gen_blockage,
+    (void *) gen_blockage,
     &operand_data[0],
     0,
     0,
@@ -24423,7 +24423,7 @@ const struct insn_data insn_data[] =
   {
     "return_internal",
     "ret",
-    (insn_gen_fn) gen_return_internal,
+    (void *) gen_return_internal,
     &operand_data[0],
     0,
     0,
@@ -24433,7 +24433,7 @@ const struct insn_data insn_data[] =
   {
     "return_pop_internal",
     "ret\t%0",
-    (insn_gen_fn) gen_return_pop_internal,
+    (void *) gen_return_pop_internal,
     &operand_data[596],
     1,
     0,
@@ -24443,7 +24443,7 @@ const struct insn_data insn_data[] =
   {
     "return_indirect_internal",
     "jmp\t%A0",
-    (insn_gen_fn) gen_return_indirect_internal,
+    (void *) gen_return_indirect_internal,
     &operand_data[381],
     1,
     0,
@@ -24453,7 +24453,7 @@ const struct insn_data insn_data[] =
   {
     "nop",
     "nop",
-    (insn_gen_fn) gen_nop,
+    (void *) gen_nop,
     &operand_data[0],
     0,
     0,
@@ -24463,7 +24463,7 @@ const struct insn_data insn_data[] =
   {
     "prologue_set_got",
     (const PTR) output_518,
-    (insn_gen_fn) gen_prologue_set_got,
+    (void *) gen_prologue_set_got,
     &operand_data[903],
     3,
     1,
@@ -24473,7 +24473,7 @@ const struct insn_data insn_data[] =
   {
     "prologue_get_pc",
     (const PTR) output_519,
-    (insn_gen_fn) gen_prologue_get_pc,
+    (void *) gen_prologue_get_pc,
     &operand_data[906],
     2,
     0,
@@ -24483,7 +24483,7 @@ const struct insn_data insn_data[] =
   {
     "eh_return_si",
     "#",
-    (insn_gen_fn) gen_eh_return_si,
+    (void *) gen_eh_return_si,
     &operand_data[908],
     1,
     0,
@@ -24493,7 +24493,7 @@ const struct insn_data insn_data[] =
   {
     "eh_return_di",
     "#",
-    (insn_gen_fn) gen_eh_return_di,
+    (void *) gen_eh_return_di,
     &operand_data[909],
     1,
     0,
@@ -24503,7 +24503,7 @@ const struct insn_data insn_data[] =
   {
     "leave",
     "leave",
-    (insn_gen_fn) gen_leave,
+    (void *) gen_leave,
     &operand_data[0],
     0,
     0,
@@ -24513,7 +24513,7 @@ const struct insn_data insn_data[] =
   {
     "leave_rex64",
     "leave",
-    (insn_gen_fn) gen_leave_rex64,
+    (void *) gen_leave_rex64,
     &operand_data[0],
     0,
     0,
@@ -24523,7 +24523,7 @@ const struct insn_data insn_data[] =
   {
     "ffssi_1",
     "bsf{l}\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_ffssi_1,
+    (void *) gen_ffssi_1,
     &operand_data[910],
     2,
     1,
@@ -24873,7 +24873,7 @@ const struct insn_data insn_data[] =
   {
     "sqrtsf2_1",
     (const PTR) output_559,
-    (insn_gen_fn) gen_sqrtsf2_1,
+    (void *) gen_sqrtsf2_1,
     &operand_data[1048],
     2,
     0,
@@ -24883,7 +24883,7 @@ const struct insn_data insn_data[] =
   {
     "sqrtsf2_1_sse_only",
     "sqrtss\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_sqrtsf2_1_sse_only,
+    (void *) gen_sqrtsf2_1_sse_only,
     &operand_data[1050],
     2,
     0,
@@ -24893,7 +24893,7 @@ const struct insn_data insn_data[] =
   {
     "sqrtsf2_i387",
     "fsqrt",
-    (insn_gen_fn) gen_sqrtsf2_i387,
+    (void *) gen_sqrtsf2_i387,
     &operand_data[722],
     2,
     0,
@@ -24903,7 +24903,7 @@ const struct insn_data insn_data[] =
   {
     "sqrtdf2_1",
     (const PTR) output_562,
-    (insn_gen_fn) gen_sqrtdf2_1,
+    (void *) gen_sqrtdf2_1,
     &operand_data[1052],
     2,
     0,
@@ -24913,7 +24913,7 @@ const struct insn_data insn_data[] =
   {
     "sqrtdf2_1_sse_only",
     "sqrtsd\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_sqrtdf2_1_sse_only,
+    (void *) gen_sqrtdf2_1_sse_only,
     &operand_data[1054],
     2,
     0,
@@ -24923,7 +24923,7 @@ const struct insn_data insn_data[] =
   {
     "sqrtdf2_i387",
     "fsqrt",
-    (insn_gen_fn) gen_sqrtdf2_i387,
+    (void *) gen_sqrtdf2_i387,
     &operand_data[724],
     2,
     0,
@@ -24943,7 +24943,7 @@ const struct insn_data insn_data[] =
   {
     "sqrtxf2",
     "fsqrt",
-    (insn_gen_fn) gen_sqrtxf2,
+    (void *) gen_sqrtxf2,
     &operand_data[728],
     2,
     0,
@@ -24953,7 +24953,7 @@ const struct insn_data insn_data[] =
   {
     "sqrttf2",
     "fsqrt",
-    (insn_gen_fn) gen_sqrttf2,
+    (void *) gen_sqrttf2,
     &operand_data[734],
     2,
     0,
@@ -25003,7 +25003,7 @@ const struct insn_data insn_data[] =
   {
     "sindf2",
     "fsin",
-    (insn_gen_fn) gen_sindf2,
+    (void *) gen_sindf2,
     &operand_data[724],
     2,
     0,
@@ -25013,7 +25013,7 @@ const struct insn_data insn_data[] =
   {
     "sinsf2",
     "fsin",
-    (insn_gen_fn) gen_sinsf2,
+    (void *) gen_sinsf2,
     &operand_data[722],
     2,
     0,
@@ -25033,7 +25033,7 @@ const struct insn_data insn_data[] =
   {
     "sinxf2",
     "fsin",
-    (insn_gen_fn) gen_sinxf2,
+    (void *) gen_sinxf2,
     &operand_data[728],
     2,
     0,
@@ -25043,7 +25043,7 @@ const struct insn_data insn_data[] =
   {
     "sintf2",
     "fsin",
-    (insn_gen_fn) gen_sintf2,
+    (void *) gen_sintf2,
     &operand_data[734],
     2,
     0,
@@ -25053,7 +25053,7 @@ const struct insn_data insn_data[] =
   {
     "cosdf2",
     "fcos",
-    (insn_gen_fn) gen_cosdf2,
+    (void *) gen_cosdf2,
     &operand_data[724],
     2,
     0,
@@ -25063,7 +25063,7 @@ const struct insn_data insn_data[] =
   {
     "cossf2",
     "fcos",
-    (insn_gen_fn) gen_cossf2,
+    (void *) gen_cossf2,
     &operand_data[722],
     2,
     0,
@@ -25083,7 +25083,7 @@ const struct insn_data insn_data[] =
   {
     "cosxf2",
     "fcos",
-    (insn_gen_fn) gen_cosxf2,
+    (void *) gen_cosxf2,
     &operand_data[728],
     2,
     0,
@@ -25093,7 +25093,7 @@ const struct insn_data insn_data[] =
   {
     "costf2",
     "fcos",
-    (insn_gen_fn) gen_costf2,
+    (void *) gen_costf2,
     &operand_data[734],
     2,
     0,
@@ -25103,7 +25103,7 @@ const struct insn_data insn_data[] =
   {
     "cld",
     "cld",
-    (insn_gen_fn) gen_cld,
+    (void *) gen_cld,
     &operand_data[0],
     0,
     0,
@@ -25113,7 +25113,7 @@ const struct insn_data insn_data[] =
   {
     "strmovdi_rex_1",
     "movsq",
-    (insn_gen_fn) gen_strmovdi_rex_1,
+    (void *) gen_strmovdi_rex_1,
     &operand_data[1056],
     4,
     2,
@@ -25123,7 +25123,7 @@ const struct insn_data insn_data[] =
   {
     "strmovsi_1",
     "{movsl|movsd}",
-    (insn_gen_fn) gen_strmovsi_1,
+    (void *) gen_strmovsi_1,
     &operand_data[1060],
     4,
     2,
@@ -25133,7 +25133,7 @@ const struct insn_data insn_data[] =
   {
     "strmovsi_rex_1",
     "{movsl|movsd}",
-    (insn_gen_fn) gen_strmovsi_rex_1,
+    (void *) gen_strmovsi_rex_1,
     &operand_data[1056],
     4,
     2,
@@ -25143,7 +25143,7 @@ const struct insn_data insn_data[] =
   {
     "strmovhi_1",
     "movsw",
-    (insn_gen_fn) gen_strmovhi_1,
+    (void *) gen_strmovhi_1,
     &operand_data[1060],
     4,
     2,
@@ -25153,7 +25153,7 @@ const struct insn_data insn_data[] =
   {
     "strmovhi_rex_1",
     "movsw",
-    (insn_gen_fn) gen_strmovhi_rex_1,
+    (void *) gen_strmovhi_rex_1,
     &operand_data[1056],
     4,
     2,
@@ -25163,7 +25163,7 @@ const struct insn_data insn_data[] =
   {
     "strmovqi_1",
     "movsb",
-    (insn_gen_fn) gen_strmovqi_1,
+    (void *) gen_strmovqi_1,
     &operand_data[1060],
     4,
     2,
@@ -25173,7 +25173,7 @@ const struct insn_data insn_data[] =
   {
     "strmovqi_rex_1",
     "movsb",
-    (insn_gen_fn) gen_strmovqi_rex_1,
+    (void *) gen_strmovqi_rex_1,
     &operand_data[1056],
     4,
     2,
@@ -25183,7 +25183,7 @@ const struct insn_data insn_data[] =
   {
     "rep_movdi_rex64",
     "{rep\n\tmovsq|rep movsq}",
-    (insn_gen_fn) gen_rep_movdi_rex64,
+    (void *) gen_rep_movdi_rex64,
     &operand_data[1064],
     6,
     4,
@@ -25193,7 +25193,7 @@ const struct insn_data insn_data[] =
   {
     "rep_movsi",
     "{rep\n\tmovsl|rep movsd}",
-    (insn_gen_fn) gen_rep_movsi,
+    (void *) gen_rep_movsi,
     &operand_data[1070],
     6,
     4,
@@ -25203,7 +25203,7 @@ const struct insn_data insn_data[] =
   {
     "rep_movsi_rex64",
     "{rep\n\tmovsl|rep movsd}",
-    (insn_gen_fn) gen_rep_movsi_rex64,
+    (void *) gen_rep_movsi_rex64,
     &operand_data[1064],
     6,
     4,
@@ -25213,7 +25213,7 @@ const struct insn_data insn_data[] =
   {
     "rep_movqi",
     "{rep\n\tmovsb|rep movsb}",
-    (insn_gen_fn) gen_rep_movqi,
+    (void *) gen_rep_movqi,
     &operand_data[1070],
     6,
     4,
@@ -25223,7 +25223,7 @@ const struct insn_data insn_data[] =
   {
     "rep_movqi_rex64",
     "{rep\n\tmovsb|rep movsb}",
-    (insn_gen_fn) gen_rep_movqi_rex64,
+    (void *) gen_rep_movqi_rex64,
     &operand_data[1064],
     6,
     4,
@@ -25233,7 +25233,7 @@ const struct insn_data insn_data[] =
   {
     "strsetdi_rex_1",
     "stosq",
-    (insn_gen_fn) gen_strsetdi_rex_1,
+    (void *) gen_strsetdi_rex_1,
     &operand_data[1076],
     3,
     1,
@@ -25243,7 +25243,7 @@ const struct insn_data insn_data[] =
   {
     "strsetsi_1",
     "{stosl|stosd}",
-    (insn_gen_fn) gen_strsetsi_1,
+    (void *) gen_strsetsi_1,
     &operand_data[1079],
     3,
     1,
@@ -25253,7 +25253,7 @@ const struct insn_data insn_data[] =
   {
     "strsetsi_rex_1",
     "{stosl|stosd}",
-    (insn_gen_fn) gen_strsetsi_rex_1,
+    (void *) gen_strsetsi_rex_1,
     &operand_data[1076],
     3,
     1,
@@ -25263,7 +25263,7 @@ const struct insn_data insn_data[] =
   {
     "strsethi_1",
     "stosw",
-    (insn_gen_fn) gen_strsethi_1,
+    (void *) gen_strsethi_1,
     &operand_data[1082],
     3,
     1,
@@ -25273,7 +25273,7 @@ const struct insn_data insn_data[] =
   {
     "strsethi_rex_1",
     "stosw",
-    (insn_gen_fn) gen_strsethi_rex_1,
+    (void *) gen_strsethi_rex_1,
     &operand_data[1085],
     3,
     1,
@@ -25283,7 +25283,7 @@ const struct insn_data insn_data[] =
   {
     "strsetqi_1",
     "stosb",
-    (insn_gen_fn) gen_strsetqi_1,
+    (void *) gen_strsetqi_1,
     &operand_data[1088],
     3,
     1,
@@ -25293,7 +25293,7 @@ const struct insn_data insn_data[] =
   {
     "strsetqi_rex_1",
     "stosb",
-    (insn_gen_fn) gen_strsetqi_rex_1,
+    (void *) gen_strsetqi_rex_1,
     &operand_data[1091],
     3,
     1,
@@ -25303,7 +25303,7 @@ const struct insn_data insn_data[] =
   {
     "rep_stosdi_rex64",
     "{rep\n\tstosq|rep stosq}",
-    (insn_gen_fn) gen_rep_stosdi_rex64,
+    (void *) gen_rep_stosdi_rex64,
     &operand_data[1094],
     5,
     2,
@@ -25313,7 +25313,7 @@ const struct insn_data insn_data[] =
   {
     "rep_stossi",
     "{rep\n\tstosl|rep stosd}",
-    (insn_gen_fn) gen_rep_stossi,
+    (void *) gen_rep_stossi,
     &operand_data[1099],
     5,
     2,
@@ -25323,7 +25323,7 @@ const struct insn_data insn_data[] =
   {
     "rep_stossi_rex64",
     "{rep\n\tstosl|rep stosd}",
-    (insn_gen_fn) gen_rep_stossi_rex64,
+    (void *) gen_rep_stossi_rex64,
     &operand_data[1104],
     5,
     2,
@@ -25333,7 +25333,7 @@ const struct insn_data insn_data[] =
   {
     "rep_stosqi",
     "{rep\n\tstosb|rep stosb}",
-    (insn_gen_fn) gen_rep_stosqi,
+    (void *) gen_rep_stosqi,
     &operand_data[1109],
     5,
     2,
@@ -25343,7 +25343,7 @@ const struct insn_data insn_data[] =
   {
     "rep_stosqi_rex64",
     "{rep\n\tstosb|rep stosb}",
-    (insn_gen_fn) gen_rep_stosqi_rex64,
+    (void *) gen_rep_stosqi_rex64,
     &operand_data[1114],
     5,
     2,
@@ -25353,7 +25353,7 @@ const struct insn_data insn_data[] =
   {
     "cmpstrqi_nz_1",
     "repz{\n\t| }cmpsb",
-    (insn_gen_fn) gen_cmpstrqi_nz_1,
+    (void *) gen_cmpstrqi_nz_1,
     &operand_data[1119],
     7,
     0,
@@ -25363,7 +25363,7 @@ const struct insn_data insn_data[] =
   {
     "cmpstrqi_nz_rex_1",
     "repz{\n\t| }cmpsb",
-    (insn_gen_fn) gen_cmpstrqi_nz_rex_1,
+    (void *) gen_cmpstrqi_nz_rex_1,
     &operand_data[1126],
     7,
     0,
@@ -25373,7 +25373,7 @@ const struct insn_data insn_data[] =
   {
     "cmpstrqi_1",
     "repz{\n\t| }cmpsb",
-    (insn_gen_fn) gen_cmpstrqi_1,
+    (void *) gen_cmpstrqi_1,
     &operand_data[1119],
     7,
     0,
@@ -25383,7 +25383,7 @@ const struct insn_data insn_data[] =
   {
     "cmpstrqi_rex_1",
     "repz{\n\t| }cmpsb",
-    (insn_gen_fn) gen_cmpstrqi_rex_1,
+    (void *) gen_cmpstrqi_rex_1,
     &operand_data[1126],
     7,
     0,
@@ -25393,7 +25393,7 @@ const struct insn_data insn_data[] =
   {
     "strlenqi_1",
     "repnz{\n\t| }scasb",
-    (insn_gen_fn) gen_strlenqi_1,
+    (void *) gen_strlenqi_1,
     &operand_data[1133],
     6,
     0,
@@ -25403,7 +25403,7 @@ const struct insn_data insn_data[] =
   {
     "strlenqi_rex_1",
     "repnz{\n\t| }scasb",
-    (insn_gen_fn) gen_strlenqi_rex_1,
+    (void *) gen_strlenqi_rex_1,
     &operand_data[1139],
     6,
     0,
@@ -25413,7 +25413,7 @@ const struct insn_data insn_data[] =
   {
     "x86_movdicc_0_m1_rex64",
     "sbb{q}\t%0, %0",
-    (insn_gen_fn) gen_x86_movdicc_0_m1_rex64,
+    (void *) gen_x86_movdicc_0_m1_rex64,
     &operand_data[137],
     1,
     0,
@@ -25433,7 +25433,7 @@ const struct insn_data insn_data[] =
   {
     "x86_movsicc_0_m1",
     "sbb{l}\t%0, %0",
-    (insn_gen_fn) gen_x86_movsicc_0_m1,
+    (void *) gen_x86_movsicc_0_m1,
     &operand_data[70],
     1,
     0,
@@ -25643,7 +25643,7 @@ const struct insn_data insn_data[] =
   {
     "pro_epilogue_adjust_stack_rex64",
     (const PTR) output_636,
-    (insn_gen_fn) gen_pro_epilogue_adjust_stack_rex64,
+    (void *) gen_pro_epilogue_adjust_stack_rex64,
     &operand_data[1188],
     3,
     0,
@@ -25653,7 +25653,7 @@ const struct insn_data insn_data[] =
   {
     "sse_movsfcc",
     "#",
-    (insn_gen_fn) gen_sse_movsfcc,
+    (void *) gen_sse_movsfcc,
     &operand_data[1191],
     7,
     0,
@@ -25663,7 +25663,7 @@ const struct insn_data insn_data[] =
   {
     "sse_movsfcc_eq",
     "#",
-    (insn_gen_fn) gen_sse_movsfcc_eq,
+    (void *) gen_sse_movsfcc_eq,
     &operand_data[1198],
     6,
     0,
@@ -25673,7 +25673,7 @@ const struct insn_data insn_data[] =
   {
     "sse_movdfcc",
     "#",
-    (insn_gen_fn) gen_sse_movdfcc,
+    (void *) gen_sse_movdfcc,
     &operand_data[1204],
     7,
     0,
@@ -25683,7 +25683,7 @@ const struct insn_data insn_data[] =
   {
     "sse_movdfcc_eq",
     "#",
-    (insn_gen_fn) gen_sse_movdfcc_eq,
+    (void *) gen_sse_movdfcc_eq,
     &operand_data[1211],
     6,
     0,
@@ -25773,7 +25773,7 @@ const struct insn_data insn_data[] =
   {
     "allocate_stack_worker_1",
     "call\t__alloca",
-    (insn_gen_fn) gen_allocate_stack_worker_1,
+    (void *) gen_allocate_stack_worker_1,
     &operand_data[559],
     1,
     2,
@@ -25783,7 +25783,7 @@ const struct insn_data insn_data[] =
   {
     "allocate_stack_worker_rex64",
     "call\t__alloca",
-    (insn_gen_fn) gen_allocate_stack_worker_rex64,
+    (void *) gen_allocate_stack_worker_rex64,
     &operand_data[546],
     1,
     2,
@@ -25853,7 +25853,7 @@ const struct insn_data insn_data[] =
   {
     "trap",
     "int\t$5",
-    (insn_gen_fn) gen_trap,
+    (void *) gen_trap,
     &operand_data[0],
     0,
     0,
@@ -25873,7 +25873,7 @@ const struct insn_data insn_data[] =
   {
     "movv4sf_internal",
     "movaps\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_movv4sf_internal,
+    (void *) gen_movv4sf_internal,
     &operand_data[1281],
     2,
     0,
@@ -25883,7 +25883,7 @@ const struct insn_data insn_data[] =
   {
     "movv4si_internal",
     "movaps\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_movv4si_internal,
+    (void *) gen_movv4si_internal,
     &operand_data[1283],
     2,
     0,
@@ -25893,7 +25893,7 @@ const struct insn_data insn_data[] =
   {
     "movv8qi_internal",
     "movq\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_movv8qi_internal,
+    (void *) gen_movv8qi_internal,
     &operand_data[1285],
     2,
     0,
@@ -25903,7 +25903,7 @@ const struct insn_data insn_data[] =
   {
     "movv4hi_internal",
     "movq\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_movv4hi_internal,
+    (void *) gen_movv4hi_internal,
     &operand_data[1287],
     2,
     0,
@@ -25913,7 +25913,7 @@ const struct insn_data insn_data[] =
   {
     "movv2si_internal",
     "movq\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_movv2si_internal,
+    (void *) gen_movv2si_internal,
     &operand_data[1289],
     2,
     0,
@@ -25923,7 +25923,7 @@ const struct insn_data insn_data[] =
   {
     "movv2sf_internal",
     "movq\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_movv2sf_internal,
+    (void *) gen_movv2sf_internal,
     &operand_data[1291],
     2,
     0,
@@ -26003,7 +26003,7 @@ const struct insn_data insn_data[] =
   {
     "movti_internal",
     (const PTR) output_672,
-    (insn_gen_fn) gen_movti_internal,
+    (void *) gen_movti_internal,
     &operand_data[1307],
     2,
     0,
@@ -26023,7 +26023,7 @@ const struct insn_data insn_data[] =
   {
     "sse_movaps",
     (const PTR) output_674,
-    (insn_gen_fn) gen_sse_movaps,
+    (void *) gen_sse_movaps,
     &operand_data[1281],
     2,
     0,
@@ -26033,7 +26033,7 @@ const struct insn_data insn_data[] =
   {
     "sse_movups",
     (const PTR) output_675,
-    (insn_gen_fn) gen_sse_movups,
+    (void *) gen_sse_movups,
     &operand_data[1281],
     2,
     0,
@@ -26043,7 +26043,7 @@ const struct insn_data insn_data[] =
   {
     "sse_movmskps",
     "movmskps\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_sse_movmskps,
+    (void *) gen_sse_movmskps,
     &operand_data[1311],
     2,
     0,
@@ -26053,7 +26053,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_pmovmskb",
     "pmovmskb\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_mmx_pmovmskb,
+    (void *) gen_mmx_pmovmskb,
     &operand_data[1313],
     2,
     0,
@@ -26063,7 +26063,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_maskmovq",
     "maskmovq\t{%2, %1|%1, %2}",
-    (insn_gen_fn) gen_mmx_maskmovq,
+    (void *) gen_mmx_maskmovq,
     &operand_data[1315],
     3,
     0,
@@ -26073,7 +26073,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_maskmovq_rex",
     "maskmovq\t{%2, %1|%1, %2}",
-    (insn_gen_fn) gen_mmx_maskmovq_rex,
+    (void *) gen_mmx_maskmovq_rex,
     &operand_data[1318],
     3,
     0,
@@ -26083,7 +26083,7 @@ const struct insn_data insn_data[] =
   {
     "sse_movntv4sf",
     "movntps\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_sse_movntv4sf,
+    (void *) gen_sse_movntv4sf,
     &operand_data[1321],
     2,
     0,
@@ -26093,7 +26093,7 @@ const struct insn_data insn_data[] =
   {
     "sse_movntdi",
     "movntq\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_sse_movntdi,
+    (void *) gen_sse_movntdi,
     &operand_data[1323],
     2,
     0,
@@ -26103,7 +26103,7 @@ const struct insn_data insn_data[] =
   {
     "sse_movhlps",
     "movhlps\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_sse_movhlps,
+    (void *) gen_sse_movhlps,
     &operand_data[1325],
     3,
     0,
@@ -26113,7 +26113,7 @@ const struct insn_data insn_data[] =
   {
     "sse_movlhps",
     "movlhps\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_sse_movlhps,
+    (void *) gen_sse_movlhps,
     &operand_data[1325],
     3,
     0,
@@ -26123,7 +26123,7 @@ const struct insn_data insn_data[] =
   {
     "sse_movhps",
     "movhps\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_sse_movhps,
+    (void *) gen_sse_movhps,
     &operand_data[1328],
     3,
     0,
@@ -26133,7 +26133,7 @@ const struct insn_data insn_data[] =
   {
     "sse_movlps",
     "movlps\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_sse_movlps,
+    (void *) gen_sse_movlps,
     &operand_data[1328],
     3,
     0,
@@ -26143,7 +26143,7 @@ const struct insn_data insn_data[] =
   {
     "sse_loadss",
     "movss\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_sse_loadss,
+    (void *) gen_sse_loadss,
     &operand_data[1331],
     2,
     0,
@@ -26153,7 +26153,7 @@ const struct insn_data insn_data[] =
   {
     "sse_movss",
     "movss\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_sse_movss,
+    (void *) gen_sse_movss,
     &operand_data[1325],
     3,
     0,
@@ -26163,7 +26163,7 @@ const struct insn_data insn_data[] =
   {
     "sse_storess",
     "movss\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_sse_storess,
+    (void *) gen_sse_storess,
     &operand_data[1333],
     2,
     0,
@@ -26173,7 +26173,7 @@ const struct insn_data insn_data[] =
   {
     "sse_shufps",
     "shufps\t{%3, %2, %0|%0, %2, %3}",
-    (insn_gen_fn) gen_sse_shufps,
+    (void *) gen_sse_shufps,
     &operand_data[1335],
     4,
     0,
@@ -26183,7 +26183,7 @@ const struct insn_data insn_data[] =
   {
     "addv4sf3",
     "addps\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_addv4sf3,
+    (void *) gen_addv4sf3,
     &operand_data[1335],
     3,
     0,
@@ -26193,7 +26193,7 @@ const struct insn_data insn_data[] =
   {
     "vmaddv4sf3",
     "addss\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_vmaddv4sf3,
+    (void *) gen_vmaddv4sf3,
     &operand_data[1335],
     3,
     1,
@@ -26203,7 +26203,7 @@ const struct insn_data insn_data[] =
   {
     "subv4sf3",
     "subps\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_subv4sf3,
+    (void *) gen_subv4sf3,
     &operand_data[1335],
     3,
     0,
@@ -26213,7 +26213,7 @@ const struct insn_data insn_data[] =
   {
     "vmsubv4sf3",
     "subss\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_vmsubv4sf3,
+    (void *) gen_vmsubv4sf3,
     &operand_data[1335],
     3,
     1,
@@ -26223,7 +26223,7 @@ const struct insn_data insn_data[] =
   {
     "mulv4sf3",
     "mulps\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mulv4sf3,
+    (void *) gen_mulv4sf3,
     &operand_data[1335],
     3,
     0,
@@ -26233,7 +26233,7 @@ const struct insn_data insn_data[] =
   {
     "vmmulv4sf3",
     "mulss\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_vmmulv4sf3,
+    (void *) gen_vmmulv4sf3,
     &operand_data[1335],
     3,
     1,
@@ -26243,7 +26243,7 @@ const struct insn_data insn_data[] =
   {
     "divv4sf3",
     "divps\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_divv4sf3,
+    (void *) gen_divv4sf3,
     &operand_data[1335],
     3,
     0,
@@ -26253,7 +26253,7 @@ const struct insn_data insn_data[] =
   {
     "vmdivv4sf3",
     "divss\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_vmdivv4sf3,
+    (void *) gen_vmdivv4sf3,
     &operand_data[1335],
     3,
     1,
@@ -26263,7 +26263,7 @@ const struct insn_data insn_data[] =
   {
     "rcpv4sf2",
     "rcpps\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_rcpv4sf2,
+    (void *) gen_rcpv4sf2,
     &operand_data[1339],
     2,
     0,
@@ -26273,7 +26273,7 @@ const struct insn_data insn_data[] =
   {
     "vmrcpv4sf2",
     "rcpss\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_vmrcpv4sf2,
+    (void *) gen_vmrcpv4sf2,
     &operand_data[1339],
     3,
     0,
@@ -26283,7 +26283,7 @@ const struct insn_data insn_data[] =
   {
     "rsqrtv4sf2",
     "rsqrtps\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_rsqrtv4sf2,
+    (void *) gen_rsqrtv4sf2,
     &operand_data[1339],
     2,
     0,
@@ -26293,7 +26293,7 @@ const struct insn_data insn_data[] =
   {
     "vmrsqrtv4sf2",
     "rsqrtss\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_vmrsqrtv4sf2,
+    (void *) gen_vmrsqrtv4sf2,
     &operand_data[1339],
     3,
     0,
@@ -26303,7 +26303,7 @@ const struct insn_data insn_data[] =
   {
     "sqrtv4sf2",
     "sqrtps\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_sqrtv4sf2,
+    (void *) gen_sqrtv4sf2,
     &operand_data[1339],
     2,
     0,
@@ -26313,7 +26313,7 @@ const struct insn_data insn_data[] =
   {
     "vmsqrtv4sf2",
     "sqrtss\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_vmsqrtv4sf2,
+    (void *) gen_vmsqrtv4sf2,
     &operand_data[1339],
     3,
     0,
@@ -26363,7 +26363,7 @@ const struct insn_data insn_data[] =
   {
     "sse_andti3",
     "andps\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_sse_andti3,
+    (void *) gen_sse_andti3,
     &operand_data[1354],
     3,
     0,
@@ -26403,7 +26403,7 @@ const struct insn_data insn_data[] =
   {
     "sse_nandti3",
     "andnps\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_sse_nandti3,
+    (void *) gen_sse_nandti3,
     &operand_data[1357],
     3,
     0,
@@ -26463,7 +26463,7 @@ const struct insn_data insn_data[] =
   {
     "sse_iorti3",
     "orps\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_sse_iorti3,
+    (void *) gen_sse_iorti3,
     &operand_data[1354],
     3,
     0,
@@ -26523,7 +26523,7 @@ const struct insn_data insn_data[] =
   {
     "sse_xorti3",
     "xorps\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_sse_xorti3,
+    (void *) gen_sse_xorti3,
     &operand_data[1354],
     3,
     0,
@@ -26543,7 +26543,7 @@ const struct insn_data insn_data[] =
   {
     "sse_clrv4sf",
     "xorps\t{%0, %0|%0, %0}",
-    (insn_gen_fn) gen_sse_clrv4sf,
+    (void *) gen_sse_clrv4sf,
     &operand_data[1325],
     1,
     0,
@@ -26553,7 +26553,7 @@ const struct insn_data insn_data[] =
   {
     "maskcmpv4sf3",
     "cmp%D3ps\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_maskcmpv4sf3,
+    (void *) gen_maskcmpv4sf3,
     &operand_data[1360],
     4,
     0,
@@ -26563,7 +26563,7 @@ const struct insn_data insn_data[] =
   {
     "maskncmpv4sf3",
     (const PTR) output_728,
-    (insn_gen_fn) gen_maskncmpv4sf3,
+    (void *) gen_maskncmpv4sf3,
     &operand_data[1360],
     4,
     0,
@@ -26573,7 +26573,7 @@ const struct insn_data insn_data[] =
   {
     "vmmaskcmpv4sf3",
     "cmp%D3ss\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_vmmaskcmpv4sf3,
+    (void *) gen_vmmaskcmpv4sf3,
     &operand_data[1360],
     4,
     1,
@@ -26583,7 +26583,7 @@ const struct insn_data insn_data[] =
   {
     "vmmaskncmpv4sf3",
     (const PTR) output_730,
-    (insn_gen_fn) gen_vmmaskncmpv4sf3,
+    (void *) gen_vmmaskncmpv4sf3,
     &operand_data[1360],
     4,
     1,
@@ -26593,7 +26593,7 @@ const struct insn_data insn_data[] =
   {
     "sse_comi",
     "comiss\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_sse_comi,
+    (void *) gen_sse_comi,
     &operand_data[1364],
     3,
     0,
@@ -26603,7 +26603,7 @@ const struct insn_data insn_data[] =
   {
     "sse_ucomi",
     "ucomiss\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_sse_ucomi,
+    (void *) gen_sse_ucomi,
     &operand_data[1367],
     3,
     0,
@@ -26613,7 +26613,7 @@ const struct insn_data insn_data[] =
   {
     "sse_unpckhps",
     "unpckhps\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_sse_unpckhps,
+    (void *) gen_sse_unpckhps,
     &operand_data[1325],
     3,
     0,
@@ -26623,7 +26623,7 @@ const struct insn_data insn_data[] =
   {
     "sse_unpcklps",
     "unpcklps\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_sse_unpcklps,
+    (void *) gen_sse_unpcklps,
     &operand_data[1325],
     3,
     0,
@@ -26633,7 +26633,7 @@ const struct insn_data insn_data[] =
   {
     "smaxv4sf3",
     "maxps\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_smaxv4sf3,
+    (void *) gen_smaxv4sf3,
     &operand_data[1335],
     3,
     0,
@@ -26643,7 +26643,7 @@ const struct insn_data insn_data[] =
   {
     "vmsmaxv4sf3",
     "maxss\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_vmsmaxv4sf3,
+    (void *) gen_vmsmaxv4sf3,
     &operand_data[1335],
     3,
     1,
@@ -26653,7 +26653,7 @@ const struct insn_data insn_data[] =
   {
     "sminv4sf3",
     "minps\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_sminv4sf3,
+    (void *) gen_sminv4sf3,
     &operand_data[1335],
     3,
     0,
@@ -26663,7 +26663,7 @@ const struct insn_data insn_data[] =
   {
     "vmsminv4sf3",
     "minss\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_vmsminv4sf3,
+    (void *) gen_vmsminv4sf3,
     &operand_data[1335],
     3,
     1,
@@ -26673,7 +26673,7 @@ const struct insn_data insn_data[] =
   {
     "cvtpi2ps",
     "cvtpi2ps\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_cvtpi2ps,
+    (void *) gen_cvtpi2ps,
     &operand_data[1370],
     3,
     0,
@@ -26683,7 +26683,7 @@ const struct insn_data insn_data[] =
   {
     "cvtps2pi",
     "cvtps2pi\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_cvtps2pi,
+    (void *) gen_cvtps2pi,
     &operand_data[1373],
     2,
     0,
@@ -26693,7 +26693,7 @@ const struct insn_data insn_data[] =
   {
     "cvttps2pi",
     "cvttps2pi\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_cvttps2pi,
+    (void *) gen_cvttps2pi,
     &operand_data[1373],
     2,
     0,
@@ -26703,7 +26703,7 @@ const struct insn_data insn_data[] =
   {
     "cvtsi2ss",
     "cvtsi2ss\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_cvtsi2ss,
+    (void *) gen_cvtsi2ss,
     &operand_data[1375],
     3,
     0,
@@ -26713,7 +26713,7 @@ const struct insn_data insn_data[] =
   {
     "cvtss2si",
     "cvtss2si\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_cvtss2si,
+    (void *) gen_cvtss2si,
     &operand_data[1378],
     2,
     0,
@@ -26723,7 +26723,7 @@ const struct insn_data insn_data[] =
   {
     "cvttss2si",
     "cvttss2si\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_cvttss2si,
+    (void *) gen_cvttss2si,
     &operand_data[1378],
     2,
     0,
@@ -26733,7 +26733,7 @@ const struct insn_data insn_data[] =
   {
     "addv8qi3",
     "paddb\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_addv8qi3,
+    (void *) gen_addv8qi3,
     &operand_data[1380],
     3,
     0,
@@ -26743,7 +26743,7 @@ const struct insn_data insn_data[] =
   {
     "addv4hi3",
     "paddw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_addv4hi3,
+    (void *) gen_addv4hi3,
     &operand_data[1383],
     3,
     0,
@@ -26753,7 +26753,7 @@ const struct insn_data insn_data[] =
   {
     "addv2si3",
     "paddd\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_addv2si3,
+    (void *) gen_addv2si3,
     &operand_data[1386],
     3,
     0,
@@ -26763,7 +26763,7 @@ const struct insn_data insn_data[] =
   {
     "ssaddv8qi3",
     "paddsb\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_ssaddv8qi3,
+    (void *) gen_ssaddv8qi3,
     &operand_data[1380],
     3,
     0,
@@ -26773,7 +26773,7 @@ const struct insn_data insn_data[] =
   {
     "ssaddv4hi3",
     "paddsw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_ssaddv4hi3,
+    (void *) gen_ssaddv4hi3,
     &operand_data[1383],
     3,
     0,
@@ -26783,7 +26783,7 @@ const struct insn_data insn_data[] =
   {
     "usaddv8qi3",
     "paddusb\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_usaddv8qi3,
+    (void *) gen_usaddv8qi3,
     &operand_data[1380],
     3,
     0,
@@ -26793,7 +26793,7 @@ const struct insn_data insn_data[] =
   {
     "usaddv4hi3",
     "paddusw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_usaddv4hi3,
+    (void *) gen_usaddv4hi3,
     &operand_data[1383],
     3,
     0,
@@ -26803,7 +26803,7 @@ const struct insn_data insn_data[] =
   {
     "subv8qi3",
     "psubb\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_subv8qi3,
+    (void *) gen_subv8qi3,
     &operand_data[1380],
     3,
     0,
@@ -26813,7 +26813,7 @@ const struct insn_data insn_data[] =
   {
     "subv4hi3",
     "psubw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_subv4hi3,
+    (void *) gen_subv4hi3,
     &operand_data[1383],
     3,
     0,
@@ -26823,7 +26823,7 @@ const struct insn_data insn_data[] =
   {
     "subv2si3",
     "psubd\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_subv2si3,
+    (void *) gen_subv2si3,
     &operand_data[1386],
     3,
     0,
@@ -26833,7 +26833,7 @@ const struct insn_data insn_data[] =
   {
     "sssubv8qi3",
     "psubsb\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_sssubv8qi3,
+    (void *) gen_sssubv8qi3,
     &operand_data[1380],
     3,
     0,
@@ -26843,7 +26843,7 @@ const struct insn_data insn_data[] =
   {
     "sssubv4hi3",
     "psubsw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_sssubv4hi3,
+    (void *) gen_sssubv4hi3,
     &operand_data[1383],
     3,
     0,
@@ -26853,7 +26853,7 @@ const struct insn_data insn_data[] =
   {
     "ussubv8qi3",
     "psubusb\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_ussubv8qi3,
+    (void *) gen_ussubv8qi3,
     &operand_data[1380],
     3,
     0,
@@ -26863,7 +26863,7 @@ const struct insn_data insn_data[] =
   {
     "ussubv4hi3",
     "psubusw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_ussubv4hi3,
+    (void *) gen_ussubv4hi3,
     &operand_data[1383],
     3,
     0,
@@ -26873,7 +26873,7 @@ const struct insn_data insn_data[] =
   {
     "mulv4hi3",
     "pmullw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mulv4hi3,
+    (void *) gen_mulv4hi3,
     &operand_data[1383],
     3,
     0,
@@ -26883,7 +26883,7 @@ const struct insn_data insn_data[] =
   {
     "smulv4hi3_highpart",
     "pmulhw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_smulv4hi3_highpart,
+    (void *) gen_smulv4hi3_highpart,
     &operand_data[1383],
     3,
     0,
@@ -26893,7 +26893,7 @@ const struct insn_data insn_data[] =
   {
     "umulv4hi3_highpart",
     "pmulhuw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_umulv4hi3_highpart,
+    (void *) gen_umulv4hi3_highpart,
     &operand_data[1383],
     3,
     0,
@@ -26903,7 +26903,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_pmaddwd",
     "pmaddwd\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mmx_pmaddwd,
+    (void *) gen_mmx_pmaddwd,
     &operand_data[1389],
     3,
     2,
@@ -26913,7 +26913,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_iordi3",
     "por\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mmx_iordi3,
+    (void *) gen_mmx_iordi3,
     &operand_data[1392],
     3,
     0,
@@ -26923,7 +26923,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_xordi3",
     "pxor\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mmx_xordi3,
+    (void *) gen_mmx_xordi3,
     &operand_data[1392],
     3,
     0,
@@ -26933,7 +26933,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_clrdi",
     "pxor\t{%0, %0|%0, %0}",
-    (insn_gen_fn) gen_mmx_clrdi,
+    (void *) gen_mmx_clrdi,
     &operand_data[1392],
     1,
     0,
@@ -26943,7 +26943,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_anddi3",
     "pand\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mmx_anddi3,
+    (void *) gen_mmx_anddi3,
     &operand_data[1392],
     3,
     0,
@@ -26953,7 +26953,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_nanddi3",
     "pandn\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mmx_nanddi3,
+    (void *) gen_mmx_nanddi3,
     &operand_data[1392],
     3,
     0,
@@ -26963,7 +26963,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_uavgv8qi3",
     "pavgb\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mmx_uavgv8qi3,
+    (void *) gen_mmx_uavgv8qi3,
     &operand_data[1380],
     3,
     0,
@@ -26973,7 +26973,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_uavgv4hi3",
     "pavgw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mmx_uavgv4hi3,
+    (void *) gen_mmx_uavgv4hi3,
     &operand_data[1383],
     3,
     0,
@@ -26983,7 +26983,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_psadbw",
     "psadbw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mmx_psadbw,
+    (void *) gen_mmx_psadbw,
     &operand_data[1380],
     3,
     0,
@@ -26993,7 +26993,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_pinsrw",
     "pinsrw\t{%3, %2, %0|%0, %2, %3}",
-    (insn_gen_fn) gen_mmx_pinsrw,
+    (void *) gen_mmx_pinsrw,
     &operand_data[1395],
     4,
     0,
@@ -27003,7 +27003,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_pextrw",
     "pextrw\t{%2, %1, %0|%0, %1, %2}",
-    (insn_gen_fn) gen_mmx_pextrw,
+    (void *) gen_mmx_pextrw,
     &operand_data[1399],
     3,
     0,
@@ -27013,7 +27013,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_pshufw",
     "pshufw\t{%2, %1, %0|%0, %1, %2}",
-    (insn_gen_fn) gen_mmx_pshufw,
+    (void *) gen_mmx_pshufw,
     &operand_data[1402],
     3,
     0,
@@ -27023,7 +27023,7 @@ const struct insn_data insn_data[] =
   {
     "eqv8qi3",
     "pcmpeqb\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_eqv8qi3,
+    (void *) gen_eqv8qi3,
     &operand_data[1380],
     3,
     0,
@@ -27033,7 +27033,7 @@ const struct insn_data insn_data[] =
   {
     "eqv4hi3",
     "pcmpeqw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_eqv4hi3,
+    (void *) gen_eqv4hi3,
     &operand_data[1383],
     3,
     0,
@@ -27043,7 +27043,7 @@ const struct insn_data insn_data[] =
   {
     "eqv2si3",
     "pcmpeqd\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_eqv2si3,
+    (void *) gen_eqv2si3,
     &operand_data[1386],
     3,
     0,
@@ -27053,7 +27053,7 @@ const struct insn_data insn_data[] =
   {
     "gtv8qi3",
     "pcmpgtb\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_gtv8qi3,
+    (void *) gen_gtv8qi3,
     &operand_data[1380],
     3,
     0,
@@ -27063,7 +27063,7 @@ const struct insn_data insn_data[] =
   {
     "gtv4hi3",
     "pcmpgtw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_gtv4hi3,
+    (void *) gen_gtv4hi3,
     &operand_data[1383],
     3,
     0,
@@ -27073,7 +27073,7 @@ const struct insn_data insn_data[] =
   {
     "gtv2si3",
     "pcmpgtd\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_gtv2si3,
+    (void *) gen_gtv2si3,
     &operand_data[1386],
     3,
     0,
@@ -27083,7 +27083,7 @@ const struct insn_data insn_data[] =
   {
     "umaxv8qi3",
     "pmaxub\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_umaxv8qi3,
+    (void *) gen_umaxv8qi3,
     &operand_data[1380],
     3,
     0,
@@ -27093,7 +27093,7 @@ const struct insn_data insn_data[] =
   {
     "smaxv4hi3",
     "pmaxsw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_smaxv4hi3,
+    (void *) gen_smaxv4hi3,
     &operand_data[1383],
     3,
     0,
@@ -27103,7 +27103,7 @@ const struct insn_data insn_data[] =
   {
     "uminv8qi3",
     "pminub\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_uminv8qi3,
+    (void *) gen_uminv8qi3,
     &operand_data[1380],
     3,
     0,
@@ -27113,7 +27113,7 @@ const struct insn_data insn_data[] =
   {
     "sminv4hi3",
     "pminsw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_sminv4hi3,
+    (void *) gen_sminv4hi3,
     &operand_data[1383],
     3,
     0,
@@ -27123,7 +27123,7 @@ const struct insn_data insn_data[] =
   {
     "ashrv4hi3",
     "psraw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_ashrv4hi3,
+    (void *) gen_ashrv4hi3,
     &operand_data[1405],
     3,
     0,
@@ -27133,7 +27133,7 @@ const struct insn_data insn_data[] =
   {
     "ashrv2si3",
     "psrad\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_ashrv2si3,
+    (void *) gen_ashrv2si3,
     &operand_data[1408],
     3,
     0,
@@ -27143,7 +27143,7 @@ const struct insn_data insn_data[] =
   {
     "lshrv4hi3",
     "psrlw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_lshrv4hi3,
+    (void *) gen_lshrv4hi3,
     &operand_data[1405],
     3,
     0,
@@ -27153,7 +27153,7 @@ const struct insn_data insn_data[] =
   {
     "lshrv2si3",
     "psrld\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_lshrv2si3,
+    (void *) gen_lshrv2si3,
     &operand_data[1408],
     3,
     0,
@@ -27163,7 +27163,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_lshrdi3",
     "psrlq\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mmx_lshrdi3,
+    (void *) gen_mmx_lshrdi3,
     &operand_data[1411],
     3,
     0,
@@ -27173,7 +27173,7 @@ const struct insn_data insn_data[] =
   {
     "ashlv4hi3",
     "psllw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_ashlv4hi3,
+    (void *) gen_ashlv4hi3,
     &operand_data[1405],
     3,
     0,
@@ -27183,7 +27183,7 @@ const struct insn_data insn_data[] =
   {
     "ashlv2si3",
     "pslld\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_ashlv2si3,
+    (void *) gen_ashlv2si3,
     &operand_data[1408],
     3,
     0,
@@ -27193,7 +27193,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_ashldi3",
     "psllq\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mmx_ashldi3,
+    (void *) gen_mmx_ashldi3,
     &operand_data[1411],
     3,
     0,
@@ -27203,7 +27203,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_packsswb",
     "packsswb\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mmx_packsswb,
+    (void *) gen_mmx_packsswb,
     &operand_data[1414],
     3,
     0,
@@ -27213,7 +27213,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_packssdw",
     "packssdw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mmx_packssdw,
+    (void *) gen_mmx_packssdw,
     &operand_data[1417],
     3,
     0,
@@ -27223,7 +27223,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_packuswb",
     "packuswb\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mmx_packuswb,
+    (void *) gen_mmx_packuswb,
     &operand_data[1414],
     3,
     0,
@@ -27233,7 +27233,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_punpckhbw",
     "punpckhbw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mmx_punpckhbw,
+    (void *) gen_mmx_punpckhbw,
     &operand_data[1420],
     3,
     0,
@@ -27243,7 +27243,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_punpckhwd",
     "punpckhwd\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mmx_punpckhwd,
+    (void *) gen_mmx_punpckhwd,
     &operand_data[1423],
     3,
     0,
@@ -27253,7 +27253,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_punpckhdq",
     "punpckhdq\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mmx_punpckhdq,
+    (void *) gen_mmx_punpckhdq,
     &operand_data[1426],
     3,
     0,
@@ -27263,7 +27263,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_punpcklbw",
     "punpcklbw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mmx_punpcklbw,
+    (void *) gen_mmx_punpcklbw,
     &operand_data[1420],
     3,
     0,
@@ -27273,7 +27273,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_punpcklwd",
     "punpcklwd\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mmx_punpcklwd,
+    (void *) gen_mmx_punpcklwd,
     &operand_data[1423],
     3,
     0,
@@ -27283,7 +27283,7 @@ const struct insn_data insn_data[] =
   {
     "mmx_punpckldq",
     "punpckldq\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mmx_punpckldq,
+    (void *) gen_mmx_punpckldq,
     &operand_data[1426],
     3,
     0,
@@ -27293,7 +27293,7 @@ const struct insn_data insn_data[] =
   {
     "emms",
     "emms",
-    (insn_gen_fn) gen_emms,
+    (void *) gen_emms,
     &operand_data[0],
     0,
     0,
@@ -27303,7 +27303,7 @@ const struct insn_data insn_data[] =
   {
     "ldmxcsr",
     "ldmxcsr\t%0",
-    (insn_gen_fn) gen_ldmxcsr,
+    (void *) gen_ldmxcsr,
     &operand_data[1429],
     1,
     0,
@@ -27313,7 +27313,7 @@ const struct insn_data insn_data[] =
   {
     "stmxcsr",
     "stmxcsr\t%0",
-    (insn_gen_fn) gen_stmxcsr,
+    (void *) gen_stmxcsr,
     &operand_data[302],
     1,
     0,
@@ -27343,7 +27343,7 @@ const struct insn_data insn_data[] =
   {
     "addv2sf3",
     "pfadd\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_addv2sf3,
+    (void *) gen_addv2sf3,
     &operand_data[1436],
     3,
     0,
@@ -27353,7 +27353,7 @@ const struct insn_data insn_data[] =
   {
     "subv2sf3",
     "pfsub\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_subv2sf3,
+    (void *) gen_subv2sf3,
     &operand_data[1436],
     3,
     0,
@@ -27363,7 +27363,7 @@ const struct insn_data insn_data[] =
   {
     "subrv2sf3",
     "pfsubr\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_subrv2sf3,
+    (void *) gen_subrv2sf3,
     &operand_data[1436],
     3,
     0,
@@ -27373,7 +27373,7 @@ const struct insn_data insn_data[] =
   {
     "gtv2sf3",
     "pfcmpgt\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_gtv2sf3,
+    (void *) gen_gtv2sf3,
     &operand_data[1439],
     3,
     0,
@@ -27383,7 +27383,7 @@ const struct insn_data insn_data[] =
   {
     "gev2sf3",
     "pfcmpge\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_gev2sf3,
+    (void *) gen_gev2sf3,
     &operand_data[1439],
     3,
     0,
@@ -27393,7 +27393,7 @@ const struct insn_data insn_data[] =
   {
     "eqv2sf3",
     "pfcmpeq\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_eqv2sf3,
+    (void *) gen_eqv2sf3,
     &operand_data[1439],
     3,
     0,
@@ -27403,7 +27403,7 @@ const struct insn_data insn_data[] =
   {
     "pfmaxv2sf3",
     "pfmax\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_pfmaxv2sf3,
+    (void *) gen_pfmaxv2sf3,
     &operand_data[1436],
     3,
     0,
@@ -27413,7 +27413,7 @@ const struct insn_data insn_data[] =
   {
     "pfminv2sf3",
     "pfmin\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_pfminv2sf3,
+    (void *) gen_pfminv2sf3,
     &operand_data[1436],
     3,
     0,
@@ -27423,7 +27423,7 @@ const struct insn_data insn_data[] =
   {
     "mulv2sf3",
     "pfmul\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_mulv2sf3,
+    (void *) gen_mulv2sf3,
     &operand_data[1436],
     3,
     0,
@@ -27433,7 +27433,7 @@ const struct insn_data insn_data[] =
   {
     "femms",
     "femms",
-    (insn_gen_fn) gen_femms,
+    (void *) gen_femms,
     &operand_data[0],
     0,
     0,
@@ -27443,7 +27443,7 @@ const struct insn_data insn_data[] =
   {
     "pf2id",
     "pf2id\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_pf2id,
+    (void *) gen_pf2id,
     &operand_data[1442],
     2,
     0,
@@ -27453,7 +27453,7 @@ const struct insn_data insn_data[] =
   {
     "pf2iw",
     "pf2iw\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_pf2iw,
+    (void *) gen_pf2iw,
     &operand_data[1442],
     2,
     0,
@@ -27463,7 +27463,7 @@ const struct insn_data insn_data[] =
   {
     "pfacc",
     "pfacc\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_pfacc,
+    (void *) gen_pfacc,
     &operand_data[1444],
     3,
     2,
@@ -27473,7 +27473,7 @@ const struct insn_data insn_data[] =
   {
     "pfnacc",
     "pfnacc\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_pfnacc,
+    (void *) gen_pfnacc,
     &operand_data[1444],
     3,
     2,
@@ -27483,7 +27483,7 @@ const struct insn_data insn_data[] =
   {
     "pfpnacc",
     "pfpnacc\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_pfpnacc,
+    (void *) gen_pfpnacc,
     &operand_data[1444],
     3,
     2,
@@ -27493,7 +27493,7 @@ const struct insn_data insn_data[] =
   {
     "pi2fw",
     "pi2fw\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_pi2fw,
+    (void *) gen_pi2fw,
     &operand_data[1447],
     2,
     1,
@@ -27503,7 +27503,7 @@ const struct insn_data insn_data[] =
   {
     "floatv2si2",
     "pi2fd\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_floatv2si2,
+    (void *) gen_floatv2si2,
     &operand_data[1447],
     2,
     0,
@@ -27513,7 +27513,7 @@ const struct insn_data insn_data[] =
   {
     "pavgusb",
     "pavgusb\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_pavgusb,
+    (void *) gen_pavgusb,
     &operand_data[1380],
     3,
     0,
@@ -27523,7 +27523,7 @@ const struct insn_data insn_data[] =
   {
     "pfrcpv2sf2",
     "pfrcp\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_pfrcpv2sf2,
+    (void *) gen_pfrcpv2sf2,
     &operand_data[1449],
     2,
     0,
@@ -27533,7 +27533,7 @@ const struct insn_data insn_data[] =
   {
     "pfrcpit1v2sf3",
     "pfrcpit1\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_pfrcpit1v2sf3,
+    (void *) gen_pfrcpit1v2sf3,
     &operand_data[1436],
     3,
     0,
@@ -27543,7 +27543,7 @@ const struct insn_data insn_data[] =
   {
     "pfrcpit2v2sf3",
     "pfrcpit2\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_pfrcpit2v2sf3,
+    (void *) gen_pfrcpit2v2sf3,
     &operand_data[1436],
     3,
     0,
@@ -27553,7 +27553,7 @@ const struct insn_data insn_data[] =
   {
     "pfrsqrtv2sf2",
     "pfrsqrt\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_pfrsqrtv2sf2,
+    (void *) gen_pfrsqrtv2sf2,
     &operand_data[1449],
     2,
     0,
@@ -27563,7 +27563,7 @@ const struct insn_data insn_data[] =
   {
     "pfrsqit1v2sf3",
     "pfrsqit1\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_pfrsqit1v2sf3,
+    (void *) gen_pfrsqit1v2sf3,
     &operand_data[1436],
     3,
     0,
@@ -27573,7 +27573,7 @@ const struct insn_data insn_data[] =
   {
     "pmulhrwv4hi3",
     "pmulhrw\t{%2, %0|%0, %2}",
-    (insn_gen_fn) gen_pmulhrwv4hi3,
+    (void *) gen_pmulhrwv4hi3,
     &operand_data[1383],
     3,
     0,
@@ -27583,7 +27583,7 @@ const struct insn_data insn_data[] =
   {
     "pswapdv2si2",
     "pswapd\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_pswapdv2si2,
+    (void *) gen_pswapdv2si2,
     &operand_data[1451],
     2,
     0,
@@ -27593,7 +27593,7 @@ const struct insn_data insn_data[] =
   {
     "pswapdv2sf2",
     "pswapd\t{%1, %0|%0, %1}",
-    (insn_gen_fn) gen_pswapdv2sf2,
+    (void *) gen_pswapdv2sf2,
     &operand_data[1449],
     2,
     0,
@@ -27623,7 +27623,7 @@ const struct insn_data insn_data[] =
   {
     "cmpdi",
     0,
-    (insn_gen_fn) gen_cmpdi,
+    (void *) gen_cmpdi,
     &operand_data[1457],
     2,
     0,
@@ -27633,7 +27633,7 @@ const struct insn_data insn_data[] =
   {
     "cmpsi",
     0,
-    (insn_gen_fn) gen_cmpsi,
+    (void *) gen_cmpsi,
     &operand_data[1459],
     2,
     0,
@@ -27643,7 +27643,7 @@ const struct insn_data insn_data[] =
   {
     "cmphi",
     0,
-    (insn_gen_fn) gen_cmphi,
+    (void *) gen_cmphi,
     &operand_data[1461],
     2,
     0,
@@ -27653,7 +27653,7 @@ const struct insn_data insn_data[] =
   {
     "cmpqi",
     0,
-    (insn_gen_fn) gen_cmpqi,
+    (void *) gen_cmpqi,
     &operand_data[1463],
     2,
     0,
@@ -27663,7 +27663,7 @@ const struct insn_data insn_data[] =
   {
     "cmpdi_1_rex64",
     0,
-    (insn_gen_fn) gen_cmpdi_1_rex64,
+    (void *) gen_cmpdi_1_rex64,
     &operand_data[1465],
     2,
     0,
@@ -27673,7 +27673,7 @@ const struct insn_data insn_data[] =
   {
     "cmpsi_1",
     0,
-    (insn_gen_fn) gen_cmpsi_1,
+    (void *) gen_cmpsi_1,
     &operand_data[9],
     2,
     0,
@@ -27683,7 +27683,7 @@ const struct insn_data insn_data[] =
   {
     "cmpqi_ext_3",
     0,
-    (insn_gen_fn) gen_cmpqi_ext_3,
+    (void *) gen_cmpqi_ext_3,
     &operand_data[1467],
     2,
     0,
@@ -27693,7 +27693,7 @@ const struct insn_data insn_data[] =
   {
     "cmpxf",
     0,
-    (insn_gen_fn) gen_cmpxf,
+    (void *) gen_cmpxf,
     &operand_data[1469],
     2,
     0,
@@ -27703,7 +27703,7 @@ const struct insn_data insn_data[] =
   {
     "cmptf",
     0,
-    (insn_gen_fn) gen_cmptf,
+    (void *) gen_cmptf,
     &operand_data[1471],
     2,
     0,
@@ -27713,7 +27713,7 @@ const struct insn_data insn_data[] =
   {
     "cmpdf",
     0,
-    (insn_gen_fn) gen_cmpdf,
+    (void *) gen_cmpdf,
     &operand_data[1473],
     2,
     0,
@@ -27723,7 +27723,7 @@ const struct insn_data insn_data[] =
   {
     "cmpsf",
     0,
-    (insn_gen_fn) gen_cmpsf,
+    (void *) gen_cmpsf,
     &operand_data[1475],
     2,
     0,
@@ -27743,7 +27743,7 @@ const struct insn_data insn_data[] =
   {
     "movsi",
     0,
-    (insn_gen_fn) gen_movsi,
+    (void *) gen_movsi,
     &operand_data[1479],
     2,
     0,
@@ -27753,7 +27753,7 @@ const struct insn_data insn_data[] =
   {
     "movhi",
     0,
-    (insn_gen_fn) gen_movhi,
+    (void *) gen_movhi,
     &operand_data[1461],
     2,
     0,
@@ -27763,7 +27763,7 @@ const struct insn_data insn_data[] =
   {
     "movstricthi",
     0,
-    (insn_gen_fn) gen_movstricthi,
+    (void *) gen_movstricthi,
     &operand_data[1481],
     2,
     0,
@@ -27773,7 +27773,7 @@ const struct insn_data insn_data[] =
   {
     "movqi",
     0,
-    (insn_gen_fn) gen_movqi,
+    (void *) gen_movqi,
     &operand_data[1463],
     2,
     0,
@@ -27783,7 +27783,7 @@ const struct insn_data insn_data[] =
   {
     "reload_outqi",
     0,
-    (insn_gen_fn) gen_reload_outqi,
+    (void *) gen_reload_outqi,
     &operand_data[1483],
     3,
     0,
@@ -27793,7 +27793,7 @@ const struct insn_data insn_data[] =
   {
     "movstrictqi",
     0,
-    (insn_gen_fn) gen_movstrictqi,
+    (void *) gen_movstrictqi,
     &operand_data[1486],
     2,
     0,
@@ -27803,7 +27803,7 @@ const struct insn_data insn_data[] =
   {
     "movdi",
     0,
-    (insn_gen_fn) gen_movdi,
+    (void *) gen_movdi,
     &operand_data[1465],
     2,
     0,
@@ -27893,7 +27893,7 @@ const struct insn_data insn_data[] =
   {
     "movsf",
     0,
-    (insn_gen_fn) gen_movsf,
+    (void *) gen_movsf,
     &operand_data[1496],
     2,
     0,
@@ -27933,7 +27933,7 @@ const struct insn_data insn_data[] =
   {
     "movdf",
     0,
-    (insn_gen_fn) gen_movdf,
+    (void *) gen_movdf,
     &operand_data[1502],
     2,
     0,
@@ -27983,7 +27983,7 @@ const struct insn_data insn_data[] =
   {
     "movxf",
     0,
-    (insn_gen_fn) gen_movxf,
+    (void *) gen_movxf,
     &operand_data[1508],
     2,
     0,
@@ -27993,7 +27993,7 @@ const struct insn_data insn_data[] =
   {
     "movtf",
     0,
-    (insn_gen_fn) gen_movtf,
+    (void *) gen_movtf,
     &operand_data[1510],
     2,
     0,
@@ -28063,7 +28063,7 @@ const struct insn_data insn_data[] =
   {
     "zero_extendhisi2",
     0,
-    (insn_gen_fn) gen_zero_extendhisi2,
+    (void *) gen_zero_extendhisi2,
     &operand_data[1522],
     2,
     0,
@@ -28083,7 +28083,7 @@ const struct insn_data insn_data[] =
   {
     "zero_extendqihi2",
     0,
-    (insn_gen_fn) gen_zero_extendqihi2,
+    (void *) gen_zero_extendqihi2,
     &operand_data[1525],
     2,
     0,
@@ -28123,7 +28123,7 @@ const struct insn_data insn_data[] =
   {
     "zero_extendqisi2",
     0,
-    (insn_gen_fn) gen_zero_extendqisi2,
+    (void *) gen_zero_extendqisi2,
     &operand_data[1529],
     2,
     0,
@@ -28163,7 +28163,7 @@ const struct insn_data insn_data[] =
   {
     "zero_extendsidi2",
     0,
-    (insn_gen_fn) gen_zero_extendsidi2,
+    (void *) gen_zero_extendsidi2,
     &operand_data[1533],
     2,
     0,
@@ -28203,7 +28203,7 @@ const struct insn_data insn_data[] =
   {
     "extendsidi2",
     0,
-    (insn_gen_fn) gen_extendsidi2,
+    (void *) gen_extendsidi2,
     &operand_data[1539],
     3,
     0,
@@ -28323,7 +28323,7 @@ const struct insn_data insn_data[] =
   {
     "extendsfdf2",
     0,
-    (insn_gen_fn) gen_extendsfdf2,
+    (void *) gen_extendsfdf2,
     &operand_data[1555],
     2,
     0,
@@ -28333,7 +28333,7 @@ const struct insn_data insn_data[] =
   {
     "extendsfxf2",
     0,
-    (insn_gen_fn) gen_extendsfxf2,
+    (void *) gen_extendsfxf2,
     &operand_data[1557],
     2,
     0,
@@ -28343,7 +28343,7 @@ const struct insn_data insn_data[] =
   {
     "extendsftf2",
     0,
-    (insn_gen_fn) gen_extendsftf2,
+    (void *) gen_extendsftf2,
     &operand_data[1559],
     2,
     0,
@@ -28353,7 +28353,7 @@ const struct insn_data insn_data[] =
   {
     "extenddfxf2",
     0,
-    (insn_gen_fn) gen_extenddfxf2,
+    (void *) gen_extenddfxf2,
     &operand_data[1561],
     2,
     0,
@@ -28363,7 +28363,7 @@ const struct insn_data insn_data[] =
   {
     "extenddftf2",
     0,
-    (insn_gen_fn) gen_extenddftf2,
+    (void *) gen_extenddftf2,
     &operand_data[1563],
     2,
     0,
@@ -28373,7 +28373,7 @@ const struct insn_data insn_data[] =
   {
     "truncdfsf2",
     0,
-    (insn_gen_fn) gen_truncdfsf2,
+    (void *) gen_truncdfsf2,
     &operand_data[1565],
     2,
     1,
@@ -28413,7 +28413,7 @@ const struct insn_data insn_data[] =
   {
     "truncxfsf2",
     0,
-    (insn_gen_fn) gen_truncxfsf2,
+    (void *) gen_truncxfsf2,
     &operand_data[1576],
     2,
     1,
@@ -28443,7 +28443,7 @@ const struct insn_data insn_data[] =
   {
     "trunctfsf2",
     0,
-    (insn_gen_fn) gen_trunctfsf2,
+    (void *) gen_trunctfsf2,
     &operand_data[1584],
     2,
     1,
@@ -28473,7 +28473,7 @@ const struct insn_data insn_data[] =
   {
     "truncxfdf2",
     0,
-    (insn_gen_fn) gen_truncxfdf2,
+    (void *) gen_truncxfdf2,
     &operand_data[1592],
     2,
     1,
@@ -28503,7 +28503,7 @@ const struct insn_data insn_data[] =
   {
     "trunctfdf2",
     0,
-    (insn_gen_fn) gen_trunctfdf2,
+    (void *) gen_trunctfdf2,
     &operand_data[1600],
     2,
     1,
@@ -28533,7 +28533,7 @@ const struct insn_data insn_data[] =
   {
     "fix_truncxfdi2",
     0,
-    (insn_gen_fn) gen_fix_truncxfdi2,
+    (void *) gen_fix_truncxfdi2,
     &operand_data[1608],
     2,
     0,
@@ -28543,7 +28543,7 @@ const struct insn_data insn_data[] =
   {
     "fix_trunctfdi2",
     0,
-    (insn_gen_fn) gen_fix_trunctfdi2,
+    (void *) gen_fix_trunctfdi2,
     &operand_data[1610],
     2,
     0,
@@ -28553,7 +28553,7 @@ const struct insn_data insn_data[] =
   {
     "fix_truncdfdi2",
     0,
-    (insn_gen_fn) gen_fix_truncdfdi2,
+    (void *) gen_fix_truncdfdi2,
     &operand_data[1612],
     2,
     0,
@@ -28563,7 +28563,7 @@ const struct insn_data insn_data[] =
   {
     "fix_truncsfdi2",
     0,
-    (insn_gen_fn) gen_fix_truncsfdi2,
+    (void *) gen_fix_truncsfdi2,
     &operand_data[1614],
     2,
     0,
@@ -28603,7 +28603,7 @@ const struct insn_data insn_data[] =
   {
     "fix_truncxfsi2",
     0,
-    (insn_gen_fn) gen_fix_truncxfsi2,
+    (void *) gen_fix_truncxfsi2,
     &operand_data[1630],
     2,
     0,
@@ -28613,7 +28613,7 @@ const struct insn_data insn_data[] =
   {
     "fix_trunctfsi2",
     0,
-    (insn_gen_fn) gen_fix_trunctfsi2,
+    (void *) gen_fix_trunctfsi2,
     &operand_data[1632],
     2,
     0,
@@ -28623,7 +28623,7 @@ const struct insn_data insn_data[] =
   {
     "fix_truncdfsi2",
     0,
-    (insn_gen_fn) gen_fix_truncdfsi2,
+    (void *) gen_fix_truncdfsi2,
     &operand_data[1634],
     2,
     0,
@@ -28633,7 +28633,7 @@ const struct insn_data insn_data[] =
   {
     "fix_truncsfsi2",
     0,
-    (insn_gen_fn) gen_fix_truncsfsi2,
+    (void *) gen_fix_truncsfsi2,
     &operand_data[1636],
     2,
     0,
@@ -28673,7 +28673,7 @@ const struct insn_data insn_data[] =
   {
     "fix_truncxfhi2",
     0,
-    (insn_gen_fn) gen_fix_truncxfhi2,
+    (void *) gen_fix_truncxfhi2,
     &operand_data[1649],
     2,
     0,
@@ -28683,7 +28683,7 @@ const struct insn_data insn_data[] =
   {
     "fix_trunctfhi2",
     0,
-    (insn_gen_fn) gen_fix_trunctfhi2,
+    (void *) gen_fix_trunctfhi2,
     &operand_data[1651],
     2,
     0,
@@ -28693,7 +28693,7 @@ const struct insn_data insn_data[] =
   {
     "fix_truncdfhi2",
     0,
-    (insn_gen_fn) gen_fix_truncdfhi2,
+    (void *) gen_fix_truncdfhi2,
     &operand_data[1653],
     2,
     0,
@@ -28703,7 +28703,7 @@ const struct insn_data insn_data[] =
   {
     "fix_truncsfhi2",
     0,
-    (insn_gen_fn) gen_fix_truncsfhi2,
+    (void *) gen_fix_truncsfhi2,
     &operand_data[1655],
     2,
     0,
@@ -28743,7 +28743,7 @@ const struct insn_data insn_data[] =
   {
     "floatsisf2",
     0,
-    (insn_gen_fn) gen_floatsisf2,
+    (void *) gen_floatsisf2,
     &operand_data[1637],
     2,
     0,
@@ -28753,7 +28753,7 @@ const struct insn_data insn_data[] =
   {
     "floatdisf2",
     0,
-    (insn_gen_fn) gen_floatdisf2,
+    (void *) gen_floatdisf2,
     &operand_data[1615],
     2,
     0,
@@ -28763,7 +28763,7 @@ const struct insn_data insn_data[] =
   {
     "floatsidf2",
     0,
-    (insn_gen_fn) gen_floatsidf2,
+    (void *) gen_floatsidf2,
     &operand_data[1635],
     2,
     0,
@@ -28773,7 +28773,7 @@ const struct insn_data insn_data[] =
   {
     "floatdidf2",
     0,
-    (insn_gen_fn) gen_floatdidf2,
+    (void *) gen_floatdidf2,
     &operand_data[1613],
     2,
     0,
@@ -28793,7 +28793,7 @@ const struct insn_data insn_data[] =
   {
     "adddi3",
     0,
-    (insn_gen_fn) gen_adddi3,
+    (void *) gen_adddi3,
     &operand_data[1671],
     3,
     0,
@@ -28813,7 +28813,7 @@ const struct insn_data insn_data[] =
   {
     "addsi3",
     0,
-    (insn_gen_fn) gen_addsi3,
+    (void *) gen_addsi3,
     &operand_data[1677],
     3,
     0,
@@ -28913,7 +28913,7 @@ const struct insn_data insn_data[] =
   {
     "addhi3",
     0,
-    (insn_gen_fn) gen_addhi3,
+    (void *) gen_addhi3,
     &operand_data[1715],
     3,
     0,
@@ -28923,7 +28923,7 @@ const struct insn_data insn_data[] =
   {
     "addqi3",
     0,
-    (insn_gen_fn) gen_addqi3,
+    (void *) gen_addqi3,
     &operand_data[1718],
     3,
     0,
@@ -28933,7 +28933,7 @@ const struct insn_data insn_data[] =
   {
     "addxf3",
     0,
-    (insn_gen_fn) gen_addxf3,
+    (void *) gen_addxf3,
     &operand_data[1721],
     3,
     0,
@@ -28943,7 +28943,7 @@ const struct insn_data insn_data[] =
   {
     "addtf3",
     0,
-    (insn_gen_fn) gen_addtf3,
+    (void *) gen_addtf3,
     &operand_data[1724],
     3,
     0,
@@ -28953,7 +28953,7 @@ const struct insn_data insn_data[] =
   {
     "adddf3",
     0,
-    (insn_gen_fn) gen_adddf3,
+    (void *) gen_adddf3,
     &operand_data[1727],
     3,
     0,
@@ -28963,7 +28963,7 @@ const struct insn_data insn_data[] =
   {
     "addsf3",
     0,
-    (insn_gen_fn) gen_addsf3,
+    (void *) gen_addsf3,
     &operand_data[1730],
     3,
     0,
@@ -28973,7 +28973,7 @@ const struct insn_data insn_data[] =
   {
     "subdi3",
     0,
-    (insn_gen_fn) gen_subdi3,
+    (void *) gen_subdi3,
     &operand_data[1671],
     3,
     0,
@@ -28993,7 +28993,7 @@ const struct insn_data insn_data[] =
   {
     "subsi3",
     0,
-    (insn_gen_fn) gen_subsi3,
+    (void *) gen_subsi3,
     &operand_data[1677],
     3,
     0,
@@ -29003,7 +29003,7 @@ const struct insn_data insn_data[] =
   {
     "subhi3",
     0,
-    (insn_gen_fn) gen_subhi3,
+    (void *) gen_subhi3,
     &operand_data[1715],
     3,
     0,
@@ -29013,7 +29013,7 @@ const struct insn_data insn_data[] =
   {
     "subqi3",
     0,
-    (insn_gen_fn) gen_subqi3,
+    (void *) gen_subqi3,
     &operand_data[1718],
     3,
     0,
@@ -29023,7 +29023,7 @@ const struct insn_data insn_data[] =
   {
     "subxf3",
     0,
-    (insn_gen_fn) gen_subxf3,
+    (void *) gen_subxf3,
     &operand_data[1721],
     3,
     0,
@@ -29033,7 +29033,7 @@ const struct insn_data insn_data[] =
   {
     "subtf3",
     0,
-    (insn_gen_fn) gen_subtf3,
+    (void *) gen_subtf3,
     &operand_data[1724],
     3,
     0,
@@ -29043,7 +29043,7 @@ const struct insn_data insn_data[] =
   {
     "subdf3",
     0,
-    (insn_gen_fn) gen_subdf3,
+    (void *) gen_subdf3,
     &operand_data[1727],
     3,
     0,
@@ -29053,7 +29053,7 @@ const struct insn_data insn_data[] =
   {
     "subsf3",
     0,
-    (insn_gen_fn) gen_subsf3,
+    (void *) gen_subsf3,
     &operand_data[1730],
     3,
     0,
@@ -29063,7 +29063,7 @@ const struct insn_data insn_data[] =
   {
     "muldi3",
     0,
-    (insn_gen_fn) gen_muldi3,
+    (void *) gen_muldi3,
     &operand_data[1733],
     3,
     0,
@@ -29073,7 +29073,7 @@ const struct insn_data insn_data[] =
   {
     "mulsi3",
     0,
-    (insn_gen_fn) gen_mulsi3,
+    (void *) gen_mulsi3,
     &operand_data[1736],
     3,
     0,
@@ -29083,7 +29083,7 @@ const struct insn_data insn_data[] =
   {
     "mulhi3",
     0,
-    (insn_gen_fn) gen_mulhi3,
+    (void *) gen_mulhi3,
     &operand_data[1739],
     3,
     0,
@@ -29093,7 +29093,7 @@ const struct insn_data insn_data[] =
   {
     "mulqi3",
     0,
-    (insn_gen_fn) gen_mulqi3,
+    (void *) gen_mulqi3,
     &operand_data[1742],
     3,
     0,
@@ -29103,7 +29103,7 @@ const struct insn_data insn_data[] =
   {
     "umulqihi3",
     0,
-    (insn_gen_fn) gen_umulqihi3,
+    (void *) gen_umulqihi3,
     &operand_data[1745],
     3,
     0,
@@ -29113,7 +29113,7 @@ const struct insn_data insn_data[] =
   {
     "mulqihi3",
     0,
-    (insn_gen_fn) gen_mulqihi3,
+    (void *) gen_mulqihi3,
     &operand_data[1745],
     3,
     0,
@@ -29123,7 +29123,7 @@ const struct insn_data insn_data[] =
   {
     "umulditi3",
     0,
-    (insn_gen_fn) gen_umulditi3,
+    (void *) gen_umulditi3,
     &operand_data[1748],
     3,
     0,
@@ -29133,7 +29133,7 @@ const struct insn_data insn_data[] =
   {
     "umulsidi3",
     0,
-    (insn_gen_fn) gen_umulsidi3,
+    (void *) gen_umulsidi3,
     &operand_data[1750],
     3,
     0,
@@ -29143,7 +29143,7 @@ const struct insn_data insn_data[] =
   {
     "mulditi3",
     0,
-    (insn_gen_fn) gen_mulditi3,
+    (void *) gen_mulditi3,
     &operand_data[1748],
     3,
     0,
@@ -29153,7 +29153,7 @@ const struct insn_data insn_data[] =
   {
     "mulsidi3",
     0,
-    (insn_gen_fn) gen_mulsidi3,
+    (void *) gen_mulsidi3,
     &operand_data[1750],
     3,
     0,
@@ -29163,7 +29163,7 @@ const struct insn_data insn_data[] =
   {
     "umuldi3_highpart",
     0,
-    (insn_gen_fn) gen_umuldi3_highpart,
+    (void *) gen_umuldi3_highpart,
     &operand_data[1753],
     4,
     0,
@@ -29173,7 +29173,7 @@ const struct insn_data insn_data[] =
   {
     "umulsi3_highpart",
     0,
-    (insn_gen_fn) gen_umulsi3_highpart,
+    (void *) gen_umulsi3_highpart,
     &operand_data[1757],
     4,
     0,
@@ -29183,7 +29183,7 @@ const struct insn_data insn_data[] =
   {
     "smuldi3_highpart",
     0,
-    (insn_gen_fn) gen_smuldi3_highpart,
+    (void *) gen_smuldi3_highpart,
     &operand_data[1761],
     4,
     0,
@@ -29193,7 +29193,7 @@ const struct insn_data insn_data[] =
   {
     "smulsi3_highpart",
     0,
-    (insn_gen_fn) gen_smulsi3_highpart,
+    (void *) gen_smulsi3_highpart,
     &operand_data[1757],
     4,
     0,
@@ -29203,7 +29203,7 @@ const struct insn_data insn_data[] =
   {
     "mulxf3",
     0,
-    (insn_gen_fn) gen_mulxf3,
+    (void *) gen_mulxf3,
     &operand_data[1721],
     3,
     0,
@@ -29213,7 +29213,7 @@ const struct insn_data insn_data[] =
   {
     "multf3",
     0,
-    (insn_gen_fn) gen_multf3,
+    (void *) gen_multf3,
     &operand_data[1724],
     3,
     0,
@@ -29223,7 +29223,7 @@ const struct insn_data insn_data[] =
   {
     "muldf3",
     0,
-    (insn_gen_fn) gen_muldf3,
+    (void *) gen_muldf3,
     &operand_data[1727],
     3,
     0,
@@ -29233,7 +29233,7 @@ const struct insn_data insn_data[] =
   {
     "mulsf3",
     0,
-    (insn_gen_fn) gen_mulsf3,
+    (void *) gen_mulsf3,
     &operand_data[1730],
     3,
     0,
@@ -29243,7 +29243,7 @@ const struct insn_data insn_data[] =
   {
     "divxf3",
     0,
-    (insn_gen_fn) gen_divxf3,
+    (void *) gen_divxf3,
     &operand_data[1721],
     3,
     0,
@@ -29253,7 +29253,7 @@ const struct insn_data insn_data[] =
   {
     "divtf3",
     0,
-    (insn_gen_fn) gen_divtf3,
+    (void *) gen_divtf3,
     &operand_data[1724],
     3,
     0,
@@ -29263,7 +29263,7 @@ const struct insn_data insn_data[] =
   {
     "divdf3",
     0,
-    (insn_gen_fn) gen_divdf3,
+    (void *) gen_divdf3,
     &operand_data[1727],
     3,
     0,
@@ -29273,7 +29273,7 @@ const struct insn_data insn_data[] =
   {
     "divsf3",
     0,
-    (insn_gen_fn) gen_divsf3,
+    (void *) gen_divsf3,
     &operand_data[1730],
     3,
     0,
@@ -29283,7 +29283,7 @@ const struct insn_data insn_data[] =
   {
     "divmoddi4",
     0,
-    (insn_gen_fn) gen_divmoddi4,
+    (void *) gen_divmoddi4,
     &operand_data[1765],
     4,
     2,
@@ -29303,7 +29303,7 @@ const struct insn_data insn_data[] =
   {
     "divmodsi4",
     0,
-    (insn_gen_fn) gen_divmodsi4,
+    (void *) gen_divmodsi4,
     &operand_data[1769],
     4,
     2,
@@ -29343,7 +29343,7 @@ const struct insn_data insn_data[] =
   {
     "udivmodhi4",
     0,
-    (insn_gen_fn) gen_udivmodhi4,
+    (void *) gen_udivmodhi4,
     &operand_data[1773],
     4,
     4,
@@ -29353,7 +29353,7 @@ const struct insn_data insn_data[] =
   {
     "testsi_ccno_1",
     0,
-    (insn_gen_fn) gen_testsi_ccno_1,
+    (void *) gen_testsi_ccno_1,
     &operand_data[1777],
     2,
     0,
@@ -29363,7 +29363,7 @@ const struct insn_data insn_data[] =
   {
     "testqi_ccz_1",
     0,
-    (insn_gen_fn) gen_testqi_ccz_1,
+    (void *) gen_testqi_ccz_1,
     &operand_data[1779],
     2,
     0,
@@ -29373,7 +29373,7 @@ const struct insn_data insn_data[] =
   {
     "testqi_ext_ccno_0",
     0,
-    (insn_gen_fn) gen_testqi_ext_ccno_0,
+    (void *) gen_testqi_ext_ccno_0,
     &operand_data[1781],
     2,
     0,
@@ -29393,7 +29393,7 @@ const struct insn_data insn_data[] =
   {
     "anddi3",
     0,
-    (insn_gen_fn) gen_anddi3,
+    (void *) gen_anddi3,
     &operand_data[1786],
     3,
     0,
@@ -29403,7 +29403,7 @@ const struct insn_data insn_data[] =
   {
     "andsi3",
     0,
-    (insn_gen_fn) gen_andsi3,
+    (void *) gen_andsi3,
     &operand_data[1677],
     3,
     0,
@@ -29443,7 +29443,7 @@ const struct insn_data insn_data[] =
   {
     "andhi3",
     0,
-    (insn_gen_fn) gen_andhi3,
+    (void *) gen_andhi3,
     &operand_data[1715],
     3,
     0,
@@ -29453,7 +29453,7 @@ const struct insn_data insn_data[] =
   {
     "andqi3",
     0,
-    (insn_gen_fn) gen_andqi3,
+    (void *) gen_andqi3,
     &operand_data[1718],
     3,
     0,
@@ -29463,7 +29463,7 @@ const struct insn_data insn_data[] =
   {
     "iordi3",
     0,
-    (insn_gen_fn) gen_iordi3,
+    (void *) gen_iordi3,
     &operand_data[1671],
     3,
     0,
@@ -29473,7 +29473,7 @@ const struct insn_data insn_data[] =
   {
     "iorsi3",
     0,
-    (insn_gen_fn) gen_iorsi3,
+    (void *) gen_iorsi3,
     &operand_data[1677],
     3,
     0,
@@ -29483,7 +29483,7 @@ const struct insn_data insn_data[] =
   {
     "iorhi3",
     0,
-    (insn_gen_fn) gen_iorhi3,
+    (void *) gen_iorhi3,
     &operand_data[1715],
     3,
     0,
@@ -29493,7 +29493,7 @@ const struct insn_data insn_data[] =
   {
     "iorqi3",
     0,
-    (insn_gen_fn) gen_iorqi3,
+    (void *) gen_iorqi3,
     &operand_data[1718],
     3,
     0,
@@ -29503,7 +29503,7 @@ const struct insn_data insn_data[] =
   {
     "xordi3",
     0,
-    (insn_gen_fn) gen_xordi3,
+    (void *) gen_xordi3,
     &operand_data[1671],
     3,
     0,
@@ -29513,7 +29513,7 @@ const struct insn_data insn_data[] =
   {
     "xorsi3",
     0,
-    (insn_gen_fn) gen_xorsi3,
+    (void *) gen_xorsi3,
     &operand_data[1677],
     3,
     0,
@@ -29523,7 +29523,7 @@ const struct insn_data insn_data[] =
   {
     "xorhi3",
     0,
-    (insn_gen_fn) gen_xorhi3,
+    (void *) gen_xorhi3,
     &operand_data[1715],
     3,
     0,
@@ -29533,7 +29533,7 @@ const struct insn_data insn_data[] =
   {
     "xorqi3",
     0,
-    (insn_gen_fn) gen_xorqi3,
+    (void *) gen_xorqi3,
     &operand_data[1718],
     3,
     0,
@@ -29543,7 +29543,7 @@ const struct insn_data insn_data[] =
   {
     "xorqi_cc_ext_1",
     0,
-    (insn_gen_fn) gen_xorqi_cc_ext_1,
+    (void *) gen_xorqi_cc_ext_1,
     &operand_data[1789],
     3,
     2,
@@ -29553,7 +29553,7 @@ const struct insn_data insn_data[] =
   {
     "negdi2",
     0,
-    (insn_gen_fn) gen_negdi2,
+    (void *) gen_negdi2,
     &operand_data[1671],
     2,
     0,
@@ -29573,7 +29573,7 @@ const struct insn_data insn_data[] =
   {
     "negsi2",
     0,
-    (insn_gen_fn) gen_negsi2,
+    (void *) gen_negsi2,
     &operand_data[1677],
     2,
     0,
@@ -29583,7 +29583,7 @@ const struct insn_data insn_data[] =
   {
     "neghi2",
     0,
-    (insn_gen_fn) gen_neghi2,
+    (void *) gen_neghi2,
     &operand_data[1715],
     2,
     0,
@@ -29593,7 +29593,7 @@ const struct insn_data insn_data[] =
   {
     "negqi2",
     0,
-    (insn_gen_fn) gen_negqi2,
+    (void *) gen_negqi2,
     &operand_data[1718],
     2,
     0,
@@ -29603,7 +29603,7 @@ const struct insn_data insn_data[] =
   {
     "negsf2",
     0,
-    (insn_gen_fn) gen_negsf2,
+    (void *) gen_negsf2,
     &operand_data[1792],
     2,
     0,
@@ -29673,7 +29673,7 @@ const struct insn_data insn_data[] =
   {
     "negdf2",
     0,
-    (insn_gen_fn) gen_negdf2,
+    (void *) gen_negdf2,
     &operand_data[1805],
     2,
     0,
@@ -29743,7 +29743,7 @@ const struct insn_data insn_data[] =
   {
     "negxf2",
     0,
-    (insn_gen_fn) gen_negxf2,
+    (void *) gen_negxf2,
     &operand_data[1816],
     2,
     0,
@@ -29753,7 +29753,7 @@ const struct insn_data insn_data[] =
   {
     "negtf2",
     0,
-    (insn_gen_fn) gen_negtf2,
+    (void *) gen_negtf2,
     &operand_data[1818],
     2,
     0,
@@ -29803,7 +29803,7 @@ const struct insn_data insn_data[] =
   {
     "abssf2",
     0,
-    (insn_gen_fn) gen_abssf2,
+    (void *) gen_abssf2,
     &operand_data[1792],
     2,
     0,
@@ -29873,7 +29873,7 @@ const struct insn_data insn_data[] =
   {
     "absdf2",
     0,
-    (insn_gen_fn) gen_absdf2,
+    (void *) gen_absdf2,
     &operand_data[1805],
     2,
     0,
@@ -29933,7 +29933,7 @@ const struct insn_data insn_data[] =
   {
     "absxf2",
     0,
-    (insn_gen_fn) gen_absxf2,
+    (void *) gen_absxf2,
     &operand_data[1816],
     2,
     0,
@@ -29943,7 +29943,7 @@ const struct insn_data insn_data[] =
   {
     "abstf2",
     0,
-    (insn_gen_fn) gen_abstf2,
+    (void *) gen_abstf2,
     &operand_data[1818],
     2,
     0,
@@ -29993,7 +29993,7 @@ const struct insn_data insn_data[] =
   {
     "one_cmpldi2",
     0,
-    (insn_gen_fn) gen_one_cmpldi2,
+    (void *) gen_one_cmpldi2,
     &operand_data[1671],
     2,
     0,
@@ -30013,7 +30013,7 @@ const struct insn_data insn_data[] =
   {
     "one_cmplsi2",
     0,
-    (insn_gen_fn) gen_one_cmplsi2,
+    (void *) gen_one_cmplsi2,
     &operand_data[1677],
     2,
     0,
@@ -30043,7 +30043,7 @@ const struct insn_data insn_data[] =
   {
     "one_cmplhi2",
     0,
-    (insn_gen_fn) gen_one_cmplhi2,
+    (void *) gen_one_cmplhi2,
     &operand_data[1715],
     2,
     0,
@@ -30063,7 +30063,7 @@ const struct insn_data insn_data[] =
   {
     "one_cmplqi2",
     0,
-    (insn_gen_fn) gen_one_cmplqi2,
+    (void *) gen_one_cmplqi2,
     &operand_data[1718],
     2,
     0,
@@ -30083,7 +30083,7 @@ const struct insn_data insn_data[] =
   {
     "ashldi3",
     0,
-    (insn_gen_fn) gen_ashldi3,
+    (void *) gen_ashldi3,
     &operand_data[1820],
     3,
     0,
@@ -30123,7 +30123,7 @@ const struct insn_data insn_data[] =
   {
     "x86_shift_adj_1",
     0,
-    (insn_gen_fn) gen_x86_shift_adj_1,
+    (void *) gen_x86_shift_adj_1,
     &operand_data[1830],
     4,
     3,
@@ -30133,7 +30133,7 @@ const struct insn_data insn_data[] =
   {
     "x86_shift_adj_2",
     0,
-    (insn_gen_fn) gen_x86_shift_adj_2,
+    (void *) gen_x86_shift_adj_2,
     &operand_data[1830],
     3,
     0,
@@ -30143,7 +30143,7 @@ const struct insn_data insn_data[] =
   {
     "ashlsi3",
     0,
-    (insn_gen_fn) gen_ashlsi3,
+    (void *) gen_ashlsi3,
     &operand_data[1834],
     3,
     0,
@@ -30173,7 +30173,7 @@ const struct insn_data insn_data[] =
   {
     "ashlhi3",
     0,
-    (insn_gen_fn) gen_ashlhi3,
+    (void *) gen_ashlhi3,
     &operand_data[1843],
     3,
     0,
@@ -30183,7 +30183,7 @@ const struct insn_data insn_data[] =
   {
     "ashlqi3",
     0,
-    (insn_gen_fn) gen_ashlqi3,
+    (void *) gen_ashlqi3,
     &operand_data[1846],
     3,
     0,
@@ -30193,7 +30193,7 @@ const struct insn_data insn_data[] =
   {
     "ashrdi3",
     0,
-    (insn_gen_fn) gen_ashrdi3,
+    (void *) gen_ashrdi3,
     &operand_data[1820],
     3,
     0,
@@ -30223,7 +30223,7 @@ const struct insn_data insn_data[] =
   {
     "x86_shift_adj_3",
     0,
-    (insn_gen_fn) gen_x86_shift_adj_3,
+    (void *) gen_x86_shift_adj_3,
     &operand_data[1830],
     3,
     0,
@@ -30233,7 +30233,7 @@ const struct insn_data insn_data[] =
   {
     "ashrsi3",
     0,
-    (insn_gen_fn) gen_ashrsi3,
+    (void *) gen_ashrsi3,
     &operand_data[1834],
     3,
     0,
@@ -30243,7 +30243,7 @@ const struct insn_data insn_data[] =
   {
     "ashrhi3",
     0,
-    (insn_gen_fn) gen_ashrhi3,
+    (void *) gen_ashrhi3,
     &operand_data[1843],
     3,
     0,
@@ -30253,7 +30253,7 @@ const struct insn_data insn_data[] =
   {
     "ashrqi3",
     0,
-    (insn_gen_fn) gen_ashrqi3,
+    (void *) gen_ashrqi3,
     &operand_data[1846],
     3,
     0,
@@ -30263,7 +30263,7 @@ const struct insn_data insn_data[] =
   {
     "lshrdi3",
     0,
-    (insn_gen_fn) gen_lshrdi3,
+    (void *) gen_lshrdi3,
     &operand_data[1820],
     3,
     0,
@@ -30293,7 +30293,7 @@ const struct insn_data insn_data[] =
   {
     "lshrsi3",
     0,
-    (insn_gen_fn) gen_lshrsi3,
+    (void *) gen_lshrsi3,
     &operand_data[1834],
     3,
     0,
@@ -30303,7 +30303,7 @@ const struct insn_data insn_data[] =
   {
     "lshrhi3",
     0,
-    (insn_gen_fn) gen_lshrhi3,
+    (void *) gen_lshrhi3,
     &operand_data[1843],
     3,
     0,
@@ -30313,7 +30313,7 @@ const struct insn_data insn_data[] =
   {
     "lshrqi3",
     0,
-    (insn_gen_fn) gen_lshrqi3,
+    (void *) gen_lshrqi3,
     &operand_data[1846],
     3,
     0,
@@ -30323,7 +30323,7 @@ const struct insn_data insn_data[] =
   {
     "rotldi3",
     0,
-    (insn_gen_fn) gen_rotldi3,
+    (void *) gen_rotldi3,
     &operand_data[1849],
     3,
     0,
@@ -30333,7 +30333,7 @@ const struct insn_data insn_data[] =
   {
     "rotlsi3",
     0,
-    (insn_gen_fn) gen_rotlsi3,
+    (void *) gen_rotlsi3,
     &operand_data[1834],
     3,
     0,
@@ -30343,7 +30343,7 @@ const struct insn_data insn_data[] =
   {
     "rotlhi3",
     0,
-    (insn_gen_fn) gen_rotlhi3,
+    (void *) gen_rotlhi3,
     &operand_data[1843],
     3,
     0,
@@ -30353,7 +30353,7 @@ const struct insn_data insn_data[] =
   {
     "rotlqi3",
     0,
-    (insn_gen_fn) gen_rotlqi3,
+    (void *) gen_rotlqi3,
     &operand_data[1846],
     3,
     0,
@@ -30363,7 +30363,7 @@ const struct insn_data insn_data[] =
   {
     "rotrdi3",
     0,
-    (insn_gen_fn) gen_rotrdi3,
+    (void *) gen_rotrdi3,
     &operand_data[1849],
     3,
     0,
@@ -30373,7 +30373,7 @@ const struct insn_data insn_data[] =
   {
     "rotrsi3",
     0,
-    (insn_gen_fn) gen_rotrsi3,
+    (void *) gen_rotrsi3,
     &operand_data[1834],
     3,
     0,
@@ -30383,7 +30383,7 @@ const struct insn_data insn_data[] =
   {
     "rotrhi3",
     0,
-    (insn_gen_fn) gen_rotrhi3,
+    (void *) gen_rotrhi3,
     &operand_data[1843],
     3,
     0,
@@ -30393,7 +30393,7 @@ const struct insn_data insn_data[] =
   {
     "rotrqi3",
     0,
-    (insn_gen_fn) gen_rotrqi3,
+    (void *) gen_rotrqi3,
     &operand_data[1846],
     3,
     0,
@@ -30403,7 +30403,7 @@ const struct insn_data insn_data[] =
   {
     "extv",
     0,
-    (insn_gen_fn) gen_extv,
+    (void *) gen_extv,
     &operand_data[1852],
     4,
     0,
@@ -30413,7 +30413,7 @@ const struct insn_data insn_data[] =
   {
     "extzv",
     0,
-    (insn_gen_fn) gen_extzv,
+    (void *) gen_extzv,
     &operand_data[1856],
     4,
     0,
@@ -30423,7 +30423,7 @@ const struct insn_data insn_data[] =
   {
     "insv",
     0,
-    (insn_gen_fn) gen_insv,
+    (void *) gen_insv,
     &operand_data[1857],
     4,
     0,
@@ -30433,7 +30433,7 @@ const struct insn_data insn_data[] =
   {
     "seq",
     0,
-    (insn_gen_fn) gen_seq,
+    (void *) gen_seq,
     &operand_data[1528],
     1,
     0,
@@ -30443,7 +30443,7 @@ const struct insn_data insn_data[] =
   {
     "sne",
     0,
-    (insn_gen_fn) gen_sne,
+    (void *) gen_sne,
     &operand_data[1528],
     1,
     0,
@@ -30453,7 +30453,7 @@ const struct insn_data insn_data[] =
   {
     "sgt",
     0,
-    (insn_gen_fn) gen_sgt,
+    (void *) gen_sgt,
     &operand_data[1528],
     1,
     0,
@@ -30463,7 +30463,7 @@ const struct insn_data insn_data[] =
   {
     "sgtu",
     0,
-    (insn_gen_fn) gen_sgtu,
+    (void *) gen_sgtu,
     &operand_data[1528],
     1,
     0,
@@ -30473,7 +30473,7 @@ const struct insn_data insn_data[] =
   {
     "slt",
     0,
-    (insn_gen_fn) gen_slt,
+    (void *) gen_slt,
     &operand_data[1528],
     1,
     0,
@@ -30483,7 +30483,7 @@ const struct insn_data insn_data[] =
   {
     "sltu",
     0,
-    (insn_gen_fn) gen_sltu,
+    (void *) gen_sltu,
     &operand_data[1528],
     1,
     0,
@@ -30493,7 +30493,7 @@ const struct insn_data insn_data[] =
   {
     "sge",
     0,
-    (insn_gen_fn) gen_sge,
+    (void *) gen_sge,
     &operand_data[1528],
     1,
     0,
@@ -30503,7 +30503,7 @@ const struct insn_data insn_data[] =
   {
     "sgeu",
     0,
-    (insn_gen_fn) gen_sgeu,
+    (void *) gen_sgeu,
     &operand_data[1528],
     1,
     0,
@@ -30513,7 +30513,7 @@ const struct insn_data insn_data[] =
   {
     "sle",
     0,
-    (insn_gen_fn) gen_sle,
+    (void *) gen_sle,
     &operand_data[1528],
     1,
     0,
@@ -30523,7 +30523,7 @@ const struct insn_data insn_data[] =
   {
     "sleu",
     0,
-    (insn_gen_fn) gen_sleu,
+    (void *) gen_sleu,
     &operand_data[1528],
     1,
     0,
@@ -30533,7 +30533,7 @@ const struct insn_data insn_data[] =
   {
     "sunordered",
     0,
-    (insn_gen_fn) gen_sunordered,
+    (void *) gen_sunordered,
     &operand_data[1528],
     1,
     0,
@@ -30543,7 +30543,7 @@ const struct insn_data insn_data[] =
   {
     "sordered",
     0,
-    (insn_gen_fn) gen_sordered,
+    (void *) gen_sordered,
     &operand_data[1528],
     1,
     0,
@@ -30553,7 +30553,7 @@ const struct insn_data insn_data[] =
   {
     "suneq",
     0,
-    (insn_gen_fn) gen_suneq,
+    (void *) gen_suneq,
     &operand_data[1528],
     1,
     0,
@@ -30563,7 +30563,7 @@ const struct insn_data insn_data[] =
   {
     "sunge",
     0,
-    (insn_gen_fn) gen_sunge,
+    (void *) gen_sunge,
     &operand_data[1528],
     1,
     0,
@@ -30573,7 +30573,7 @@ const struct insn_data insn_data[] =
   {
     "sungt",
     0,
-    (insn_gen_fn) gen_sungt,
+    (void *) gen_sungt,
     &operand_data[1528],
     1,
     0,
@@ -30583,7 +30583,7 @@ const struct insn_data insn_data[] =
   {
     "sunle",
     0,
-    (insn_gen_fn) gen_sunle,
+    (void *) gen_sunle,
     &operand_data[1528],
     1,
     0,
@@ -30593,7 +30593,7 @@ const struct insn_data insn_data[] =
   {
     "sunlt",
     0,
-    (insn_gen_fn) gen_sunlt,
+    (void *) gen_sunlt,
     &operand_data[1528],
     1,
     0,
@@ -30603,7 +30603,7 @@ const struct insn_data insn_data[] =
   {
     "sltgt",
     0,
-    (insn_gen_fn) gen_sltgt,
+    (void *) gen_sltgt,
     &operand_data[1528],
     1,
     0,
@@ -30653,7 +30653,7 @@ const struct insn_data insn_data[] =
   {
     "beq",
     0,
-    (insn_gen_fn) gen_beq,
+    (void *) gen_beq,
     &operand_data[860],
     1,
     1,
@@ -30663,7 +30663,7 @@ const struct insn_data insn_data[] =
   {
     "bne",
     0,
-    (insn_gen_fn) gen_bne,
+    (void *) gen_bne,
     &operand_data[860],
     1,
     1,
@@ -30673,7 +30673,7 @@ const struct insn_data insn_data[] =
   {
     "bgt",
     0,
-    (insn_gen_fn) gen_bgt,
+    (void *) gen_bgt,
     &operand_data[860],
     1,
     1,
@@ -30683,7 +30683,7 @@ const struct insn_data insn_data[] =
   {
     "bgtu",
     0,
-    (insn_gen_fn) gen_bgtu,
+    (void *) gen_bgtu,
     &operand_data[860],
     1,
     1,
@@ -30693,7 +30693,7 @@ const struct insn_data insn_data[] =
   {
     "blt",
     0,
-    (insn_gen_fn) gen_blt,
+    (void *) gen_blt,
     &operand_data[860],
     1,
     1,
@@ -30703,7 +30703,7 @@ const struct insn_data insn_data[] =
   {
     "bltu",
     0,
-    (insn_gen_fn) gen_bltu,
+    (void *) gen_bltu,
     &operand_data[860],
     1,
     1,
@@ -30713,7 +30713,7 @@ const struct insn_data insn_data[] =
   {
     "bge",
     0,
-    (insn_gen_fn) gen_bge,
+    (void *) gen_bge,
     &operand_data[860],
     1,
     1,
@@ -30723,7 +30723,7 @@ const struct insn_data insn_data[] =
   {
     "bgeu",
     0,
-    (insn_gen_fn) gen_bgeu,
+    (void *) gen_bgeu,
     &operand_data[860],
     1,
     1,
@@ -30733,7 +30733,7 @@ const struct insn_data insn_data[] =
   {
     "ble",
     0,
-    (insn_gen_fn) gen_ble,
+    (void *) gen_ble,
     &operand_data[860],
     1,
     1,
@@ -30743,7 +30743,7 @@ const struct insn_data insn_data[] =
   {
     "bleu",
     0,
-    (insn_gen_fn) gen_bleu,
+    (void *) gen_bleu,
     &operand_data[860],
     1,
     1,
@@ -30753,7 +30753,7 @@ const struct insn_data insn_data[] =
   {
     "bunordered",
     0,
-    (insn_gen_fn) gen_bunordered,
+    (void *) gen_bunordered,
     &operand_data[860],
     1,
     1,
@@ -30763,7 +30763,7 @@ const struct insn_data insn_data[] =
   {
     "bordered",
     0,
-    (insn_gen_fn) gen_bordered,
+    (void *) gen_bordered,
     &operand_data[860],
     1,
     1,
@@ -30773,7 +30773,7 @@ const struct insn_data insn_data[] =
   {
     "buneq",
     0,
-    (insn_gen_fn) gen_buneq,
+    (void *) gen_buneq,
     &operand_data[860],
     1,
     1,
@@ -30783,7 +30783,7 @@ const struct insn_data insn_data[] =
   {
     "bunge",
     0,
-    (insn_gen_fn) gen_bunge,
+    (void *) gen_bunge,
     &operand_data[860],
     1,
     1,
@@ -30793,7 +30793,7 @@ const struct insn_data insn_data[] =
   {
     "bungt",
     0,
-    (insn_gen_fn) gen_bungt,
+    (void *) gen_bungt,
     &operand_data[860],
     1,
     1,
@@ -30803,7 +30803,7 @@ const struct insn_data insn_data[] =
   {
     "bunle",
     0,
-    (insn_gen_fn) gen_bunle,
+    (void *) gen_bunle,
     &operand_data[860],
     1,
     1,
@@ -30813,7 +30813,7 @@ const struct insn_data insn_data[] =
   {
     "bunlt",
     0,
-    (insn_gen_fn) gen_bunlt,
+    (void *) gen_bunlt,
     &operand_data[860],
     1,
     1,
@@ -30823,7 +30823,7 @@ const struct insn_data insn_data[] =
   {
     "bltgt",
     0,
-    (insn_gen_fn) gen_bltgt,
+    (void *) gen_bltgt,
     &operand_data[860],
     1,
     1,
@@ -30873,7 +30873,7 @@ const struct insn_data insn_data[] =
   {
     "indirect_jump",
     0,
-    (insn_gen_fn) gen_indirect_jump,
+    (void *) gen_indirect_jump,
     &operand_data[595],
     1,
     0,
@@ -30883,7 +30883,7 @@ const struct insn_data insn_data[] =
   {
     "tablejump",
     0,
-    (insn_gen_fn) gen_tablejump,
+    (void *) gen_tablejump,
     &operand_data[1872],
     2,
     0,
@@ -30893,7 +30893,7 @@ const struct insn_data insn_data[] =
   {
     "doloop_end",
     0,
-    (insn_gen_fn) gen_doloop_end,
+    (void *) gen_doloop_end,
     &operand_data[1873],
     5,
     0,
@@ -30943,7 +30943,7 @@ const struct insn_data insn_data[] =
   {
     "call_pop",
     0,
-    (insn_gen_fn) gen_call_pop,
+    (void *) gen_call_pop,
     &operand_data[1888],
     4,
     0,
@@ -30953,7 +30953,7 @@ const struct insn_data insn_data[] =
   {
     "call",
     0,
-    (insn_gen_fn) gen_call,
+    (void *) gen_call,
     &operand_data[1892],
     3,
     0,
@@ -30963,7 +30963,7 @@ const struct insn_data insn_data[] =
   {
     "call_exp",
     0,
-    (insn_gen_fn) gen_call_exp,
+    (void *) gen_call_exp,
     &operand_data[1892],
     2,
     0,
@@ -30973,7 +30973,7 @@ const struct insn_data insn_data[] =
   {
     "call_value_pop",
     0,
-    (insn_gen_fn) gen_call_value_pop,
+    (void *) gen_call_value_pop,
     &operand_data[1894],
     5,
     0,
@@ -30983,7 +30983,7 @@ const struct insn_data insn_data[] =
   {
     "call_value",
     0,
-    (insn_gen_fn) gen_call_value,
+    (void *) gen_call_value,
     &operand_data[1899],
     4,
     0,
@@ -30993,7 +30993,7 @@ const struct insn_data insn_data[] =
   {
     "call_value_exp",
     0,
-    (insn_gen_fn) gen_call_value_exp,
+    (void *) gen_call_value_exp,
     &operand_data[1894],
     3,
     0,
@@ -31003,7 +31003,7 @@ const struct insn_data insn_data[] =
   {
     "untyped_call",
     0,
-    (insn_gen_fn) gen_untyped_call,
+    (void *) gen_untyped_call,
     &operand_data[1873],
     3,
     0,
@@ -31013,7 +31013,7 @@ const struct insn_data insn_data[] =
   {
     "return",
     0,
-    (insn_gen_fn) gen_return,
+    (void *) gen_return,
     &operand_data[0],
     0,
     0,
@@ -31023,7 +31023,7 @@ const struct insn_data insn_data[] =
   {
     "prologue",
     0,
-    (insn_gen_fn) gen_prologue,
+    (void *) gen_prologue,
     &operand_data[0],
     0,
     0,
@@ -31033,7 +31033,7 @@ const struct insn_data insn_data[] =
   {
     "epilogue",
     0,
-    (insn_gen_fn) gen_epilogue,
+    (void *) gen_epilogue,
     &operand_data[0],
     0,
     0,
@@ -31043,7 +31043,7 @@ const struct insn_data insn_data[] =
   {
     "sibcall_epilogue",
     0,
-    (insn_gen_fn) gen_sibcall_epilogue,
+    (void *) gen_sibcall_epilogue,
     &operand_data[0],
     0,
     0,
@@ -31053,7 +31053,7 @@ const struct insn_data insn_data[] =
   {
     "eh_return",
     0,
-    (insn_gen_fn) gen_eh_return,
+    (void *) gen_eh_return,
     &operand_data[1669],
     2,
     0,
@@ -31083,7 +31083,7 @@ const struct insn_data insn_data[] =
   {
     "ffssi2",
     0,
-    (insn_gen_fn) gen_ffssi2,
+    (void *) gen_ffssi2,
     &operand_data[1479],
     2,
     0,
@@ -31113,7 +31113,7 @@ const struct insn_data insn_data[] =
   {
     "sqrtsf2",
     0,
-    (insn_gen_fn) gen_sqrtsf2,
+    (void *) gen_sqrtsf2,
     &operand_data[1731],
     2,
     0,
@@ -31123,7 +31123,7 @@ const struct insn_data insn_data[] =
   {
     "sqrtdf2",
     0,
-    (insn_gen_fn) gen_sqrtdf2,
+    (void *) gen_sqrtdf2,
     &operand_data[1554],
     2,
     0,
@@ -31133,7 +31133,7 @@ const struct insn_data insn_data[] =
   {
     "movstrsi",
     0,
-    (insn_gen_fn) gen_movstrsi,
+    (void *) gen_movstrsi,
     &operand_data[1911],
     4,
     0,
@@ -31143,7 +31143,7 @@ const struct insn_data insn_data[] =
   {
     "movstrdi",
     0,
-    (insn_gen_fn) gen_movstrdi,
+    (void *) gen_movstrdi,
     &operand_data[1915],
     4,
     0,
@@ -31153,7 +31153,7 @@ const struct insn_data insn_data[] =
   {
     "strmovdi_rex64",
     0,
-    (insn_gen_fn) gen_strmovdi_rex64,
+    (void *) gen_strmovdi_rex64,
     &operand_data[1706],
     2,
     6,
@@ -31163,7 +31163,7 @@ const struct insn_data insn_data[] =
   {
     "strmovsi",
     0,
-    (insn_gen_fn) gen_strmovsi,
+    (void *) gen_strmovsi,
     &operand_data[1543],
     2,
     6,
@@ -31173,7 +31173,7 @@ const struct insn_data insn_data[] =
   {
     "strmovsi_rex64",
     0,
-    (insn_gen_fn) gen_strmovsi_rex64,
+    (void *) gen_strmovsi_rex64,
     &operand_data[1706],
     2,
     6,
@@ -31183,7 +31183,7 @@ const struct insn_data insn_data[] =
   {
     "strmovhi",
     0,
-    (insn_gen_fn) gen_strmovhi,
+    (void *) gen_strmovhi,
     &operand_data[1543],
     2,
     6,
@@ -31193,7 +31193,7 @@ const struct insn_data insn_data[] =
   {
     "strmovhi_rex64",
     0,
-    (insn_gen_fn) gen_strmovhi_rex64,
+    (void *) gen_strmovhi_rex64,
     &operand_data[1706],
     2,
     6,
@@ -31203,7 +31203,7 @@ const struct insn_data insn_data[] =
   {
     "strmovqi",
     0,
-    (insn_gen_fn) gen_strmovqi,
+    (void *) gen_strmovqi,
     &operand_data[1543],
     2,
     6,
@@ -31213,7 +31213,7 @@ const struct insn_data insn_data[] =
   {
     "strmovqi_rex64",
     0,
-    (insn_gen_fn) gen_strmovqi_rex64,
+    (void *) gen_strmovqi_rex64,
     &operand_data[1706],
     2,
     6,
@@ -31223,7 +31223,7 @@ const struct insn_data insn_data[] =
   {
     "clrstrsi",
     0,
-    (insn_gen_fn) gen_clrstrsi,
+    (void *) gen_clrstrsi,
     &operand_data[1919],
     3,
     0,
@@ -31233,7 +31233,7 @@ const struct insn_data insn_data[] =
   {
     "clrstrdi",
     0,
-    (insn_gen_fn) gen_clrstrdi,
+    (void *) gen_clrstrdi,
     &operand_data[1922],
     3,
     0,
@@ -31243,7 +31243,7 @@ const struct insn_data insn_data[] =
   {
     "strsetdi_rex64",
     0,
-    (insn_gen_fn) gen_strsetdi_rex64,
+    (void *) gen_strsetdi_rex64,
     &operand_data[1706],
     2,
     2,
@@ -31253,7 +31253,7 @@ const struct insn_data insn_data[] =
   {
     "strsetsi",
     0,
-    (insn_gen_fn) gen_strsetsi,
+    (void *) gen_strsetsi,
     &operand_data[1543],
     2,
     2,
@@ -31263,7 +31263,7 @@ const struct insn_data insn_data[] =
   {
     "strsetsi_rex64",
     0,
-    (insn_gen_fn) gen_strsetsi_rex64,
+    (void *) gen_strsetsi_rex64,
     &operand_data[1535],
     2,
     2,
@@ -31273,7 +31273,7 @@ const struct insn_data insn_data[] =
   {
     "strsethi",
     0,
-    (insn_gen_fn) gen_strsethi,
+    (void *) gen_strsethi,
     &operand_data[1524],
     2,
     2,
@@ -31283,7 +31283,7 @@ const struct insn_data insn_data[] =
   {
     "strsethi_rex64",
     0,
-    (insn_gen_fn) gen_strsethi_rex64,
+    (void *) gen_strsethi_rex64,
     &operand_data[1925],
     2,
     2,
@@ -31293,7 +31293,7 @@ const struct insn_data insn_data[] =
   {
     "strsetqi",
     0,
-    (insn_gen_fn) gen_strsetqi,
+    (void *) gen_strsetqi,
     &operand_data[1531],
     2,
     2,
@@ -31303,7 +31303,7 @@ const struct insn_data insn_data[] =
   {
     "strsetqi_rex64",
     0,
-    (insn_gen_fn) gen_strsetqi_rex64,
+    (void *) gen_strsetqi_rex64,
     &operand_data[1927],
     2,
     2,
@@ -31313,7 +31313,7 @@ const struct insn_data insn_data[] =
   {
     "cmpstrsi",
     0,
-    (insn_gen_fn) gen_cmpstrsi,
+    (void *) gen_cmpstrsi,
     &operand_data[1929],
     5,
     0,
@@ -31323,7 +31323,7 @@ const struct insn_data insn_data[] =
   {
     "cmpintqi",
     0,
-    (insn_gen_fn) gen_cmpintqi,
+    (void *) gen_cmpintqi,
     &operand_data[1528],
     1,
     4,
@@ -31333,7 +31333,7 @@ const struct insn_data insn_data[] =
   {
     "strlensi",
     0,
-    (insn_gen_fn) gen_strlensi,
+    (void *) gen_strlensi,
     &operand_data[1934],
     4,
     0,
@@ -31343,7 +31343,7 @@ const struct insn_data insn_data[] =
   {
     "strlendi",
     0,
-    (insn_gen_fn) gen_strlendi,
+    (void *) gen_strlendi,
     &operand_data[1938],
     4,
     0,
@@ -31373,7 +31373,7 @@ const struct insn_data insn_data[] =
   {
     "movdicc",
     0,
-    (insn_gen_fn) gen_movdicc,
+    (void *) gen_movdicc,
     &operand_data[1951],
     4,
     0,
@@ -31383,7 +31383,7 @@ const struct insn_data insn_data[] =
   {
     "movsicc",
     0,
-    (insn_gen_fn) gen_movsicc,
+    (void *) gen_movsicc,
     &operand_data[1955],
     4,
     0,
@@ -31393,7 +31393,7 @@ const struct insn_data insn_data[] =
   {
     "movhicc",
     0,
-    (insn_gen_fn) gen_movhicc,
+    (void *) gen_movhicc,
     &operand_data[1959],
     4,
     0,
@@ -31403,7 +31403,7 @@ const struct insn_data insn_data[] =
   {
     "movsfcc",
     0,
-    (insn_gen_fn) gen_movsfcc,
+    (void *) gen_movsfcc,
     &operand_data[1963],
     4,
     0,
@@ -31413,7 +31413,7 @@ const struct insn_data insn_data[] =
   {
     "movdfcc",
     0,
-    (insn_gen_fn) gen_movdfcc,
+    (void *) gen_movdfcc,
     &operand_data[1967],
     4,
     0,
@@ -31433,7 +31433,7 @@ const struct insn_data insn_data[] =
   {
     "movxfcc",
     0,
-    (insn_gen_fn) gen_movxfcc,
+    (void *) gen_movxfcc,
     &operand_data[1975],
     4,
     0,
@@ -31443,7 +31443,7 @@ const struct insn_data insn_data[] =
   {
     "movtfcc",
     0,
-    (insn_gen_fn) gen_movtfcc,
+    (void *) gen_movtfcc,
     &operand_data[1979],
     4,
     0,
@@ -31453,7 +31453,7 @@ const struct insn_data insn_data[] =
   {
     "minsf3",
     0,
-    (insn_gen_fn) gen_minsf3,
+    (void *) gen_minsf3,
     &operand_data[1730],
     3,
     2,
@@ -31483,7 +31483,7 @@ const struct insn_data insn_data[] =
   {
     "mindf3",
     0,
-    (insn_gen_fn) gen_mindf3,
+    (void *) gen_mindf3,
     &operand_data[1727],
     3,
     2,
@@ -31513,7 +31513,7 @@ const struct insn_data insn_data[] =
   {
     "maxsf3",
     0,
-    (insn_gen_fn) gen_maxsf3,
+    (void *) gen_maxsf3,
     &operand_data[1730],
     3,
     2,
@@ -31543,7 +31543,7 @@ const struct insn_data insn_data[] =
   {
     "maxdf3",
     0,
-    (insn_gen_fn) gen_maxdf3,
+    (void *) gen_maxdf3,
     &operand_data[1727],
     3,
     2,
@@ -31573,7 +31573,7 @@ const struct insn_data insn_data[] =
   {
     "pro_epilogue_adjust_stack",
     0,
-    (insn_gen_fn) gen_pro_epilogue_adjust_stack,
+    (void *) gen_pro_epilogue_adjust_stack,
     &operand_data[1185],
     3,
     0,
@@ -31613,7 +31613,7 @@ const struct insn_data insn_data[] =
   {
     "allocate_stack_worker",
     0,
-    (insn_gen_fn) gen_allocate_stack_worker,
+    (void *) gen_allocate_stack_worker,
     &operand_data[1478],
     1,
     0,
@@ -31623,7 +31623,7 @@ const struct insn_data insn_data[] =
   {
     "allocate_stack",
     0,
-    (insn_gen_fn) gen_allocate_stack,
+    (void *) gen_allocate_stack,
     &operand_data[2023],
     2,
     1,
@@ -31633,7 +31633,7 @@ const struct insn_data insn_data[] =
   {
     "builtin_setjmp_receiver",
     0,
-    (insn_gen_fn) gen_builtin_setjmp_receiver,
+    (void *) gen_builtin_setjmp_receiver,
     &operand_data[860],
     1,
     0,
@@ -32263,7 +32263,7 @@ const struct insn_data insn_data[] =
   {
     "conditional_trap",
     0,
-    (insn_gen_fn) gen_conditional_trap,
+    (void *) gen_conditional_trap,
     &operand_data[1279],
     2,
     1,
@@ -32273,7 +32273,7 @@ const struct insn_data insn_data[] =
   {
     "movti",
     0,
-    (insn_gen_fn) gen_movti,
+    (void *) gen_movti,
     &operand_data[2095],
     2,
     0,
@@ -32283,7 +32283,7 @@ const struct insn_data insn_data[] =
   {
     "movv4sf",
     0,
-    (insn_gen_fn) gen_movv4sf,
+    (void *) gen_movv4sf,
     &operand_data[2097],
     2,
     0,
@@ -32293,7 +32293,7 @@ const struct insn_data insn_data[] =
   {
     "movv4si",
     0,
-    (insn_gen_fn) gen_movv4si,
+    (void *) gen_movv4si,
     &operand_data[2099],
     2,
     0,
@@ -32303,7 +32303,7 @@ const struct insn_data insn_data[] =
   {
     "movv2si",
     0,
-    (insn_gen_fn) gen_movv2si,
+    (void *) gen_movv2si,
     &operand_data[2101],
     2,
     0,
@@ -32313,7 +32313,7 @@ const struct insn_data insn_data[] =
   {
     "movv4hi",
     0,
-    (insn_gen_fn) gen_movv4hi,
+    (void *) gen_movv4hi,
     &operand_data[2103],
     2,
     0,
@@ -32323,7 +32323,7 @@ const struct insn_data insn_data[] =
   {
     "movv8qi",
     0,
-    (insn_gen_fn) gen_movv8qi,
+    (void *) gen_movv8qi,
     &operand_data[2105],
     2,
     0,
@@ -32333,7 +32333,7 @@ const struct insn_data insn_data[] =
   {
     "movv2sf",
     0,
-    (insn_gen_fn) gen_movv2sf,
+    (void *) gen_movv2sf,
     &operand_data[2107],
     2,
     0,
@@ -32423,7 +32423,7 @@ const struct insn_data insn_data[] =
   {
     "sfence",
     0,
-    (insn_gen_fn) gen_sfence,
+    (void *) gen_sfence,
     &operand_data[0],
     0,
     2,
@@ -32433,7 +32433,7 @@ const struct insn_data insn_data[] =
   {
     "sse_prologue_save",
     0,
-    (insn_gen_fn) gen_sse_prologue_save,
+    (void *) gen_sse_prologue_save,
     &operand_data[2125],
     4,
     0,
@@ -32443,7 +32443,7 @@ const struct insn_data insn_data[] =
   {
     "prefetch",
     0,
-    (insn_gen_fn) gen_prefetch,
+    (void *) gen_prefetch,
     &operand_data[2129],
     3,
     0,

diff --git a/optabs.c b/optabs.c
index 7249ffa..7780843 100644
--- a/optabs.c
+++ b/optabs.c
@@ -1,23 +1,23 @@
 /* Expand the basic unary and binary arithmetic operations, for GNU compiler.
-   Copyright (C) 1987, 1988, 1992, 1993, 1994, 1995, 1996, 1997, 1998,
-   1999, 2000, 2001 Free Software Foundation, Inc.
-
-This file is part of GCC.
-
-GCC is free software; you can redistribute it and/or modify it under
-the terms of the GNU General Public License as published by the Free
-Software Foundation; either version 2, or (at your option) any later
-version.
-
-GCC is distributed in the hope that it will be useful, but WITHOUT ANY
-WARRANTY; without even the implied warranty of MERCHANTABILITY or
-FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
-for more details.
-
-You should have received a copy of the GNU General Public License
-along with GCC; see the file COPYING.  If not, write to the Free
-Software Foundation, 59 Temple Place - Suite 330, Boston, MA
-02111-1307, USA.  */
+ Copyright (C) 1987, 1988, 1992, 1993, 1994, 1995, 1996, 1997, 1998,
+ 1999, 2000, 2001 Free Software Foundation, Inc.
+ 
+ This file is part of GCC.
+ 
+ GCC is free software; you can redistribute it and/or modify it under
+ the terms of the GNU General Public License as published by the Free
+ Software Foundation; either version 2, or (at your option) any later
+ version.
+ 
+ GCC is distributed in the hope that it will be useful, but WITHOUT ANY
+ WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ for more details.
+ 
+ You should have received a copy of the GNU General Public License
+ along with GCC; see the file COPYING.  If not, write to the Free
+ Software Foundation, 59 Temple Place - Suite 330, Boston, MA
+ 02111-1307, USA.  */
 
 
 #include "config.h"
@@ -25,7 +25,7 @@ Software Foundation, 59 Temple Place - Suite 330, Boston, MA
 #include "toplev.h"
 
 /* Include insn-config.h before expr.h so that HAVE_conditional_move
-   is properly defined.  */
+ is properly defined.  */
 #include "insn-config.h"
 #include "rtl.h"
 #include "tree.h"
@@ -42,13 +42,13 @@ Software Foundation, 59 Temple Place - Suite 330, Boston, MA
 #include "real.h"
 
 /* Each optab contains info on how this target machine
-   can perform a particular operation
-   for all sizes and kinds of operands.
-
-   The operation to be performed is often specified
-   by passing one of these optabs as an argument.
-
-   See expr.h for documentation of these optabs.  */
+ can perform a particular operation
+ for all sizes and kinds of operands.
+ 
+ The operation to be performed is often specified
+ by passing one of these optabs as an argument.
+ 
+ See expr.h for documentation of these optabs.  */
 
 optab optab_table[OTI_MAX];
 
@@ -66,44 +66,44 @@ enum insn_code floattab[NUM_MACHINE_MODES][NUM_MACHINE_MODES][2];
 optab code_to_optab[NUM_RTX_CODE + 1];
 
 /* Indexed by the rtx-code for a conditional (eg. EQ, LT,...)
-   gives the gen_function to make a branch to test that condition.  */
+ gives the gen_function to make a branch to test that condition.  */
 
 rtxfun bcc_gen_fctn[NUM_RTX_CODE];
 
 /* Indexed by the rtx-code for a conditional (eg. EQ, LT,...)
-   gives the insn code to make a store-condition insn
-   to test that condition.  */
+ gives the insn code to make a store-condition insn
+ to test that condition.  */
 
 enum insn_code setcc_gen_code[NUM_RTX_CODE];
 
 #ifdef HAVE_conditional_move
 /* Indexed by the machine mode, gives the insn code to make a conditional
-   move insn.  This is not indexed by the rtx-code like bcc_gen_fctn and
-   setcc_gen_code to cut down on the number of named patterns.  Consider a day
-   when a lot more rtx codes are conditional (eg: for the ARM).  */
+ move insn.  This is not indexed by the rtx-code like bcc_gen_fctn and
+ setcc_gen_code to cut down on the number of named patterns.  Consider a day
+ when a lot more rtx codes are conditional (eg: for the ARM).  */
 
 enum insn_code movcc_gen_code[NUM_MACHINE_MODES];
 #endif
 
 static int add_equal_note	PARAMS ((rtx, rtx, enum rtx_code, rtx, rtx));
 static rtx widen_operand	PARAMS ((rtx, enum machine_mode,
-				       enum machine_mode, int, int));
+                                     enum machine_mode, int, int));
 static int expand_cmplxdiv_straight PARAMS ((rtx, rtx, rtx, rtx,
-					   rtx, rtx, enum machine_mode,
-					   int, enum optab_methods,
-					   enum mode_class, optab));
+                                             rtx, rtx, enum machine_mode,
+                                             int, enum optab_methods,
+                                             enum mode_class, optab));
 static int expand_cmplxdiv_wide PARAMS ((rtx, rtx, rtx, rtx,
-				       rtx, rtx, enum machine_mode,
-				       int, enum optab_methods,
-				       enum mode_class, optab));
+                                         rtx, rtx, enum machine_mode,
+                                         int, enum optab_methods,
+                                         enum mode_class, optab));
 static void prepare_cmp_insn PARAMS ((rtx *, rtx *, enum rtx_code *, rtx,
-				      enum machine_mode *, int *,
-				      enum can_compare_purpose));
+                                      enum machine_mode *, int *,
+                                      enum can_compare_purpose));
 static enum insn_code can_fix_p	PARAMS ((enum machine_mode, enum machine_mode,
-				       int, int *));
+                                         int, int *));
 static enum insn_code can_float_p PARAMS ((enum machine_mode,
-					   enum machine_mode,
-					   int));
+                                           enum machine_mode,
+                                           int));
 static rtx ftruncify	PARAMS ((rtx));
 static optab new_optab	PARAMS ((void));
 static inline optab init_optab	PARAMS ((enum rtx_code));
@@ -115,2876 +115,2876 @@ static void init_floating_libfuncs PARAMS ((optab, const char *, int));
 static void init_traps PARAMS ((void));
 #endif
 static void emit_cmp_and_jump_insn_1 PARAMS ((rtx, rtx, enum machine_mode,
-					    enum rtx_code, int, rtx));
+                                              enum rtx_code, int, rtx));
 static void prepare_float_lib_cmp PARAMS ((rtx *, rtx *, enum rtx_code *,
-					 enum machine_mode *, int *));
+                                           enum machine_mode *, int *));
 
 /* Add a REG_EQUAL note to the last insn in SEQ.  TARGET is being set to
-   the result of operation CODE applied to OP0 (and OP1 if it is a binary
-   operation).
-
-   If the last insn does not set TARGET, don't do anything, but return 1.
-
-   If a previous insn sets TARGET and TARGET is one of OP0 or OP1,
-   don't add the REG_EQUAL note but return 0.  Our caller can then try
-   again, ensuring that TARGET is not one of the operands.  */
+ the result of operation CODE applied to OP0 (and OP1 if it is a binary
+ operation).
+ 
+ If the last insn does not set TARGET, don't do anything, but return 1.
+ 
+ If a previous insn sets TARGET and TARGET is one of OP0 or OP1,
+ don't add the REG_EQUAL note but return 0.  Our caller can then try
+ again, ensuring that TARGET is not one of the operands.  */
 
 static int
 add_equal_note (seq, target, code, op0, op1)
-     rtx seq;
-     rtx target;
-     enum rtx_code code;
-     rtx op0, op1;
+rtx seq;
+rtx target;
+enum rtx_code code;
+rtx op0, op1;
 {
-  rtx set;
-  int i;
-  rtx note;
-
-  if ((GET_RTX_CLASS (code) != '1' && GET_RTX_CLASS (code) != '2'
-       && GET_RTX_CLASS (code) != 'c' && GET_RTX_CLASS (code) != '<')
-      || GET_CODE (seq) != SEQUENCE
-      || (set = single_set (XVECEXP (seq, 0, XVECLEN (seq, 0) - 1))) == 0
-      || GET_CODE (target) == ZERO_EXTRACT
-      || (! rtx_equal_p (SET_DEST (set), target)
-	  /* For a STRICT_LOW_PART, the REG_NOTE applies to what is inside the
-	     SUBREG.  */
-	  && (GET_CODE (SET_DEST (set)) != STRICT_LOW_PART
-	      || ! rtx_equal_p (SUBREG_REG (XEXP (SET_DEST (set), 0)),
-				target))))
-    return 1;
-
-  /* If TARGET is in OP0 or OP1, check if anything in SEQ sets TARGET
+    rtx set;
+    int i;
+    rtx note;
+    
+    if ((GET_RTX_CLASS (code) != '1' && GET_RTX_CLASS (code) != '2'
+         && GET_RTX_CLASS (code) != 'c' && GET_RTX_CLASS (code) != '<')
+        || GET_CODE (seq) != SEQUENCE
+        || (set = single_set (XVECEXP (seq, 0, XVECLEN (seq, 0) - 1))) == 0
+        || GET_CODE (target) == ZERO_EXTRACT
+        || (! rtx_equal_p (SET_DEST (set), target)
+            /* For a STRICT_LOW_PART, the REG_NOTE applies to what is inside the
+             SUBREG.  */
+            && (GET_CODE (SET_DEST (set)) != STRICT_LOW_PART
+                || ! rtx_equal_p (SUBREG_REG (XEXP (SET_DEST (set), 0)),
+                                  target))))
+        return 1;
+    
+    /* If TARGET is in OP0 or OP1, check if anything in SEQ sets TARGET
      besides the last insn.  */
-  if (reg_overlap_mentioned_p (target, op0)
-      || (op1 && reg_overlap_mentioned_p (target, op1)))
-    for (i = XVECLEN (seq, 0) - 2; i >= 0; i--)
-      if (reg_set_p (target, XVECEXP (seq, 0, i)))
-	return 0;
-
-  if (GET_RTX_CLASS (code) == '1')
-    note = gen_rtx_fmt_e (code, GET_MODE (target), copy_rtx (op0));
-  else
-    note = gen_rtx_fmt_ee (code, GET_MODE (target), copy_rtx (op0), copy_rtx (op1));
-
-  set_unique_reg_note (XVECEXP (seq, 0, XVECLEN (seq, 0) - 1), REG_EQUAL, note);
-
-  return 1;
+    if (reg_overlap_mentioned_p (target, op0)
+        || (op1 && reg_overlap_mentioned_p (target, op1)))
+        for (i = XVECLEN (seq, 0) - 2; i >= 0; i--)
+    if (reg_set_p (target, XVECEXP (seq, 0, i)))
+        return 0;
+    
+    if (GET_RTX_CLASS (code) == '1')
+        note = gen_rtx_fmt_e (code, GET_MODE (target), copy_rtx (op0));
+    else
+        note = gen_rtx_fmt_ee (code, GET_MODE (target), copy_rtx (op0), copy_rtx (op1));
+    
+    set_unique_reg_note (XVECEXP (seq, 0, XVECLEN (seq, 0) - 1), REG_EQUAL, note);
+    
+    return 1;
 }
 
 /* Widen OP to MODE and return the rtx for the widened operand.  UNSIGNEDP
-   says whether OP is signed or unsigned.  NO_EXTEND is nonzero if we need
-   not actually do a sign-extend or zero-extend, but can leave the 
-   higher-order bits of the result rtx undefined, for example, in the case
-   of logical operations, but not right shifts.  */
+ says whether OP is signed or unsigned.  NO_EXTEND is nonzero if we need
+ not actually do a sign-extend or zero-extend, but can leave the
+ higher-order bits of the result rtx undefined, for example, in the case
+ of logical operations, but not right shifts.  */
 
 static rtx
 widen_operand (op, mode, oldmode, unsignedp, no_extend)
-     rtx op;
-     enum machine_mode mode, oldmode;
-     int unsignedp;
-     int no_extend;
+rtx op;
+enum machine_mode mode, oldmode;
+int unsignedp;
+int no_extend;
 {
-  rtx result;
-
-  /* If we don't have to extend and this is a constant, return it.  */
-  if (no_extend && GET_MODE (op) == VOIDmode)
-    return op;
-
-  /* If we must extend do so.  If OP is a SUBREG for a promoted object, also
+    rtx result;
+    
+    /* If we don't have to extend and this is a constant, return it.  */
+    if (no_extend && GET_MODE (op) == VOIDmode)
+        return op;
+    
+    /* If we must extend do so.  If OP is a SUBREG for a promoted object, also
      extend since it will be more efficient to do so unless the signedness of
      a promoted object differs from our extension.  */
-  if (! no_extend
-      || (GET_CODE (op) == SUBREG && SUBREG_PROMOTED_VAR_P (op)
-	  && SUBREG_PROMOTED_UNSIGNED_P (op) == unsignedp))
-    return convert_modes (mode, oldmode, op, unsignedp);
-
-  /* If MODE is no wider than a single word, we return a paradoxical
+    if (! no_extend
+        || (GET_CODE (op) == SUBREG && SUBREG_PROMOTED_VAR_P (op)
+            && SUBREG_PROMOTED_UNSIGNED_P (op) == unsignedp))
+        return convert_modes (mode, oldmode, op, unsignedp);
+    
+    /* If MODE is no wider than a single word, we return a paradoxical
      SUBREG.  */
-  if (GET_MODE_SIZE (mode) <= UNITS_PER_WORD)
-    return gen_rtx_SUBREG (mode, force_reg (GET_MODE (op), op), 0);
-
-  /* Otherwise, get an object of MODE, clobber it, and set the low-order
+    if (GET_MODE_SIZE (mode) <= UNITS_PER_WORD)
+        return gen_rtx_SUBREG (mode, force_reg (GET_MODE (op), op), 0);
+    
+    /* Otherwise, get an object of MODE, clobber it, and set the low-order
      part to OP.  */
-
-  result = gen_reg_rtx (mode);
-  emit_insn (gen_rtx_CLOBBER (VOIDmode, result));
-  emit_move_insn (gen_lowpart (GET_MODE (op), result), op);
-  return result;
+    
+    result = gen_reg_rtx (mode);
+    emit_insn (gen_rtx_CLOBBER (VOIDmode, result));
+    emit_move_insn (gen_lowpart (GET_MODE (op), result), op);
+    return result;
 }
 
 /* Generate code to perform a straightforward complex divide.  */
 
 static int
 expand_cmplxdiv_straight (real0, real1, imag0, imag1, realr, imagr, submode,
-			  unsignedp, methods, class, binoptab)
-  rtx real0, real1, imag0, imag1, realr, imagr;
-  enum machine_mode submode;
-  int unsignedp;
-  enum optab_methods methods;
-  enum mode_class class;
-  optab binoptab;
+                          unsignedp, methods, class, binoptab)
+rtx real0, real1, imag0, imag1, realr, imagr;
+enum machine_mode submode;
+int unsignedp;
+enum optab_methods methods;
+enum mode_class class;
+optab binoptab;
 {
-  rtx divisor;
-  rtx real_t, imag_t;
-  rtx temp1, temp2;
-  rtx res;
-  optab this_add_optab = add_optab;
-  optab this_sub_optab = sub_optab;
-  optab this_neg_optab = neg_optab;
-  optab this_mul_optab = smul_optab;
-	      
-  if (binoptab == sdivv_optab)
+    rtx divisor;
+    rtx real_t, imag_t;
+    rtx temp1, temp2;
+    rtx res;
+    optab this_add_optab = add_optab;
+    optab this_sub_optab = sub_optab;
+    optab this_neg_optab = neg_optab;
+    optab this_mul_optab = smul_optab;
+    
+    if (binoptab == sdivv_optab)
     {
-      this_add_optab = addv_optab;
-      this_sub_optab = subv_optab;
-      this_neg_optab = negv_optab;
-      this_mul_optab = smulv_optab;
+        this_add_optab = addv_optab;
+        this_sub_optab = subv_optab;
+        this_neg_optab = negv_optab;
+        this_mul_optab = smulv_optab;
     }
-
-  /* Don't fetch these from memory more than once.  */
-  real0 = force_reg (submode, real0);
-  real1 = force_reg (submode, real1);
-
-  if (imag0 != 0)
-    imag0 = force_reg (submode, imag0);
-
-  imag1 = force_reg (submode, imag1);
-
-  /* Divisor: c*c + d*d.  */
-  temp1 = expand_binop (submode, this_mul_optab, real1, real1,
-			NULL_RTX, unsignedp, methods);
-
-  temp2 = expand_binop (submode, this_mul_optab, imag1, imag1,
-			NULL_RTX, unsignedp, methods);
-
-  if (temp1 == 0 || temp2 == 0)
-    return 0;
-
-  divisor = expand_binop (submode, this_add_optab, temp1, temp2,
-			  NULL_RTX, unsignedp, methods);
-  if (divisor == 0)
-    return 0;
-
-  if (imag0 == 0)
+    
+    /* Don't fetch these from memory more than once.  */
+    real0 = force_reg (submode, real0);
+    real1 = force_reg (submode, real1);
+    
+    if (imag0 != 0)
+        imag0 = force_reg (submode, imag0);
+    
+    imag1 = force_reg (submode, imag1);
+    
+    /* Divisor: c*c + d*d.  */
+    temp1 = expand_binop (submode, this_mul_optab, real1, real1,
+                          NULL_RTX, unsignedp, methods);
+    
+    temp2 = expand_binop (submode, this_mul_optab, imag1, imag1,
+                          NULL_RTX, unsignedp, methods);
+    
+    if (temp1 == 0 || temp2 == 0)
+        return 0;
+    
+    divisor = expand_binop (submode, this_add_optab, temp1, temp2,
+                            NULL_RTX, unsignedp, methods);
+    if (divisor == 0)
+        return 0;
+    
+    if (imag0 == 0)
     {
-      /* Mathematically, ((a)(c-id))/divisor.  */
-      /* Computationally, (a+i0) / (c+id) = (ac/(cc+dd)) + i(-ad/(cc+dd)).  */
-
-      /* Calculate the dividend.  */
-      real_t = expand_binop (submode, this_mul_optab, real0, real1,
-			     NULL_RTX, unsignedp, methods);
-		  
-      imag_t = expand_binop (submode, this_mul_optab, real0, imag1,
-			     NULL_RTX, unsignedp, methods);
-
-      if (real_t == 0 || imag_t == 0)
-	return 0;
-
-      imag_t = expand_unop (submode, this_neg_optab, imag_t,
-			    NULL_RTX, unsignedp);
+        /* Mathematically, ((a)(c-id))/divisor.  */
+        /* Computationally, (a+i0) / (c+id) = (ac/(cc+dd)) + i(-ad/(cc+dd)).  */
+        
+        /* Calculate the dividend.  */
+        real_t = expand_binop (submode, this_mul_optab, real0, real1,
+                               NULL_RTX, unsignedp, methods);
+        
+        imag_t = expand_binop (submode, this_mul_optab, real0, imag1,
+                               NULL_RTX, unsignedp, methods);
+        
+        if (real_t == 0 || imag_t == 0)
+            return 0;
+        
+        imag_t = expand_unop (submode, this_neg_optab, imag_t,
+                              NULL_RTX, unsignedp);
     }
-  else
+    else
     {
-      /* Mathematically, ((a+ib)(c-id))/divider.  */
-      /* Calculate the dividend.  */
-      temp1 = expand_binop (submode, this_mul_optab, real0, real1,
-			    NULL_RTX, unsignedp, methods);
-
-      temp2 = expand_binop (submode, this_mul_optab, imag0, imag1,
-			    NULL_RTX, unsignedp, methods);
-
-      if (temp1 == 0 || temp2 == 0)
-	return 0;
-
-      real_t = expand_binop (submode, this_add_optab, temp1, temp2,
-			     NULL_RTX, unsignedp, methods);
-		  
-      temp1 = expand_binop (submode, this_mul_optab, imag0, real1,
-			    NULL_RTX, unsignedp, methods);
-
-      temp2 = expand_binop (submode, this_mul_optab, real0, imag1,
-			    NULL_RTX, unsignedp, methods);
-
-      if (temp1 == 0 || temp2 == 0)
-	return 0;
-
-      imag_t = expand_binop (submode, this_sub_optab, temp1, temp2,
-			     NULL_RTX, unsignedp, methods);
-
-      if (real_t == 0 || imag_t == 0)
-	return 0;
+        /* Mathematically, ((a+ib)(c-id))/divider.  */
+        /* Calculate the dividend.  */
+        temp1 = expand_binop (submode, this_mul_optab, real0, real1,
+                              NULL_RTX, unsignedp, methods);
+        
+        temp2 = expand_binop (submode, this_mul_optab, imag0, imag1,
+                              NULL_RTX, unsignedp, methods);
+        
+        if (temp1 == 0 || temp2 == 0)
+            return 0;
+        
+        real_t = expand_binop (submode, this_add_optab, temp1, temp2,
+                               NULL_RTX, unsignedp, methods);
+        
+        temp1 = expand_binop (submode, this_mul_optab, imag0, real1,
+                              NULL_RTX, unsignedp, methods);
+        
+        temp2 = expand_binop (submode, this_mul_optab, real0, imag1,
+                              NULL_RTX, unsignedp, methods);
+        
+        if (temp1 == 0 || temp2 == 0)
+            return 0;
+        
+        imag_t = expand_binop (submode, this_sub_optab, temp1, temp2,
+                               NULL_RTX, unsignedp, methods);
+        
+        if (real_t == 0 || imag_t == 0)
+            return 0;
     }
-
-  if (class == MODE_COMPLEX_FLOAT)
-    res = expand_binop (submode, binoptab, real_t, divisor,
-			realr, unsignedp, methods);
-  else
-    res = expand_divmod (0, TRUNC_DIV_EXPR, submode,
-			 real_t, divisor, realr, unsignedp);
-
-  if (res == 0)
-    return 0;
-
-  if (res != realr)
-    emit_move_insn (realr, res);
-
-  if (class == MODE_COMPLEX_FLOAT)
-    res = expand_binop (submode, binoptab, imag_t, divisor,
-			imagr, unsignedp, methods);
-  else
-    res = expand_divmod (0, TRUNC_DIV_EXPR, submode,
-			 imag_t, divisor, imagr, unsignedp);
-
-  if (res == 0)
-    return 0;
-
-  if (res != imagr)
-    emit_move_insn (imagr, res);
-
-  return 1;
+    
+    if (class == MODE_COMPLEX_FLOAT)
+        res = expand_binop (submode, binoptab, real_t, divisor,
+                            realr, unsignedp, methods);
+    else
+        res = expand_divmod (0, TRUNC_DIV_EXPR, submode,
+                             real_t, divisor, realr, unsignedp);
+    
+    if (res == 0)
+        return 0;
+    
+    if (res != realr)
+        emit_move_insn (realr, res);
+    
+    if (class == MODE_COMPLEX_FLOAT)
+        res = expand_binop (submode, binoptab, imag_t, divisor,
+                            imagr, unsignedp, methods);
+    else
+        res = expand_divmod (0, TRUNC_DIV_EXPR, submode,
+                             imag_t, divisor, imagr, unsignedp);
+    
+    if (res == 0)
+        return 0;
+    
+    if (res != imagr)
+        emit_move_insn (imagr, res);
+    
+    return 1;
 }
 
 /* Generate code to perform a wide-input-range-acceptable complex divide.  */
 
 static int
 expand_cmplxdiv_wide (real0, real1, imag0, imag1, realr, imagr, submode,
-		      unsignedp, methods, class, binoptab)
-  rtx real0, real1, imag0, imag1, realr, imagr;
-  enum machine_mode submode;
-  int unsignedp;
-  enum optab_methods methods;
-  enum mode_class class;
-  optab binoptab;
+                      unsignedp, methods, class, binoptab)
+rtx real0, real1, imag0, imag1, realr, imagr;
+enum machine_mode submode;
+int unsignedp;
+enum optab_methods methods;
+enum mode_class class;
+optab binoptab;
 {
-  rtx ratio, divisor;
-  rtx real_t, imag_t;
-  rtx temp1, temp2, lab1, lab2;
-  enum machine_mode mode;
-  rtx res;
-  optab this_add_optab = add_optab;
-  optab this_sub_optab = sub_optab;
-  optab this_neg_optab = neg_optab;
-  optab this_mul_optab = smul_optab;
-
-  if (binoptab == sdivv_optab)
+    rtx ratio, divisor;
+    rtx real_t, imag_t;
+    rtx temp1, temp2, lab1, lab2;
+    enum machine_mode mode;
+    rtx res;
+    optab this_add_optab = add_optab;
+    optab this_sub_optab = sub_optab;
+    optab this_neg_optab = neg_optab;
+    optab this_mul_optab = smul_optab;
+    
+    if (binoptab == sdivv_optab)
     {
-      this_add_optab = addv_optab;
-      this_sub_optab = subv_optab;
-      this_neg_optab = negv_optab;
-      this_mul_optab = smulv_optab;
+        this_add_optab = addv_optab;
+        this_sub_optab = subv_optab;
+        this_neg_optab = negv_optab;
+        this_mul_optab = smulv_optab;
     }
-	      
-  /* Don't fetch these from memory more than once.  */
-  real0 = force_reg (submode, real0);
-  real1 = force_reg (submode, real1);
-
-  if (imag0 != 0)
-    imag0 = force_reg (submode, imag0);
-
-  imag1 = force_reg (submode, imag1);
-
-  /* XXX What's an "unsigned" complex number?  */
-  if (unsignedp)
+    
+    /* Don't fetch these from memory more than once.  */
+    real0 = force_reg (submode, real0);
+    real1 = force_reg (submode, real1);
+    
+    if (imag0 != 0)
+        imag0 = force_reg (submode, imag0);
+    
+    imag1 = force_reg (submode, imag1);
+    
+    /* XXX What's an "unsigned" complex number?  */
+    if (unsignedp)
     {
-      temp1 = real1;
-      temp2 = imag1;
+        temp1 = real1;
+        temp2 = imag1;
     }
-  else
+    else
     {
-      temp1 = expand_abs (submode, real1, NULL_RTX, unsignedp, 1);
-      temp2 = expand_abs (submode, imag1, NULL_RTX, unsignedp, 1);
+        temp1 = expand_abs (submode, real1, NULL_RTX, unsignedp, 1);
+        temp2 = expand_abs (submode, imag1, NULL_RTX, unsignedp, 1);
     }
-
-  if (temp1 == 0 || temp2 == 0)
-    return 0;
-
-  mode = GET_MODE (temp1);
-  lab1 = gen_label_rtx ();
-  emit_cmp_and_jump_insns (temp1, temp2, LT, NULL_RTX,
-			   mode, unsignedp, lab1);
-
-  /* |c| >= |d|; use ratio d/c to scale dividend and divisor.  */
-
-  if (class == MODE_COMPLEX_FLOAT)
-    ratio = expand_binop (submode, binoptab, imag1, real1,
-			  NULL_RTX, unsignedp, methods);
-  else
-    ratio = expand_divmod (0, TRUNC_DIV_EXPR, submode,
-			   imag1, real1, NULL_RTX, unsignedp);
-
-  if (ratio == 0)
-    return 0;
-
-  /* Calculate divisor.  */
-
-  temp1 = expand_binop (submode, this_mul_optab, imag1, ratio,
-			NULL_RTX, unsignedp, methods);
-
-  if (temp1 == 0)
-    return 0;
-
-  divisor = expand_binop (submode, this_add_optab, temp1, real1,
-			  NULL_RTX, unsignedp, methods);
-
-  if (divisor == 0)
-    return 0;
-
-  /* Calculate dividend.  */
-
-  if (imag0 == 0)
+    
+    if (temp1 == 0 || temp2 == 0)
+        return 0;
+    
+    mode = GET_MODE (temp1);
+    lab1 = gen_label_rtx ();
+    emit_cmp_and_jump_insns (temp1, temp2, LT, NULL_RTX,
+                             mode, unsignedp, lab1);
+    
+    /* |c| >= |d|; use ratio d/c to scale dividend and divisor.  */
+    
+    if (class == MODE_COMPLEX_FLOAT)
+        ratio = expand_binop (submode, binoptab, imag1, real1,
+                              NULL_RTX, unsignedp, methods);
+    else
+        ratio = expand_divmod (0, TRUNC_DIV_EXPR, submode,
+                               imag1, real1, NULL_RTX, unsignedp);
+    
+    if (ratio == 0)
+        return 0;
+    
+    /* Calculate divisor.  */
+    
+    temp1 = expand_binop (submode, this_mul_optab, imag1, ratio,
+                          NULL_RTX, unsignedp, methods);
+    
+    if (temp1 == 0)
+        return 0;
+    
+    divisor = expand_binop (submode, this_add_optab, temp1, real1,
+                            NULL_RTX, unsignedp, methods);
+    
+    if (divisor == 0)
+        return 0;
+    
+    /* Calculate dividend.  */
+    
+    if (imag0 == 0)
     {
-      real_t = real0;
-
-      /* Compute a / (c+id) as a / (c+d(d/c)) + i (-a(d/c)) / (c+d(d/c)).  */
-
-      imag_t = expand_binop (submode, this_mul_optab, real0, ratio,
-			     NULL_RTX, unsignedp, methods);
-
-      if (imag_t == 0)
-	return 0;
-
-      imag_t = expand_unop (submode, this_neg_optab, imag_t,
-			    NULL_RTX, unsignedp);
-
-      if (real_t == 0 || imag_t == 0)
-	return 0;
+        real_t = real0;
+        
+        /* Compute a / (c+id) as a / (c+d(d/c)) + i (-a(d/c)) / (c+d(d/c)).  */
+        
+        imag_t = expand_binop (submode, this_mul_optab, real0, ratio,
+                               NULL_RTX, unsignedp, methods);
+        
+        if (imag_t == 0)
+            return 0;
+        
+        imag_t = expand_unop (submode, this_neg_optab, imag_t,
+                              NULL_RTX, unsignedp);
+        
+        if (real_t == 0 || imag_t == 0)
+            return 0;
     }
-  else
+    else
     {
-      /* Compute (a+ib)/(c+id) as
-	 (a+b(d/c))/(c+d(d/c) + i(b-a(d/c))/(c+d(d/c)).  */
-
-      temp1 = expand_binop (submode, this_mul_optab, imag0, ratio,
-			    NULL_RTX, unsignedp, methods);
-
-      if (temp1 == 0)
-	return 0;
-
-      real_t = expand_binop (submode, this_add_optab, temp1, real0,
-			     NULL_RTX, unsignedp, methods);
-
-      temp1 = expand_binop (submode, this_mul_optab, real0, ratio,
-			    NULL_RTX, unsignedp, methods);
-
-      if (temp1 == 0)
-	return 0;
-
-      imag_t = expand_binop (submode, this_sub_optab, imag0, temp1,
-			     NULL_RTX, unsignedp, methods);
-
-      if (real_t == 0 || imag_t == 0)
-	return 0;
+        /* Compute (a+ib)/(c+id) as
+         (a+b(d/c))/(c+d(d/c) + i(b-a(d/c))/(c+d(d/c)).  */
+        
+        temp1 = expand_binop (submode, this_mul_optab, imag0, ratio,
+                              NULL_RTX, unsignedp, methods);
+        
+        if (temp1 == 0)
+            return 0;
+        
+        real_t = expand_binop (submode, this_add_optab, temp1, real0,
+                               NULL_RTX, unsignedp, methods);
+        
+        temp1 = expand_binop (submode, this_mul_optab, real0, ratio,
+                              NULL_RTX, unsignedp, methods);
+        
+        if (temp1 == 0)
+            return 0;
+        
+        imag_t = expand_binop (submode, this_sub_optab, imag0, temp1,
+                               NULL_RTX, unsignedp, methods);
+        
+        if (real_t == 0 || imag_t == 0)
+            return 0;
     }
-
-  if (class == MODE_COMPLEX_FLOAT)
-    res = expand_binop (submode, binoptab, real_t, divisor,
-			realr, unsignedp, methods);
-  else
-    res = expand_divmod (0, TRUNC_DIV_EXPR, submode,
-			 real_t, divisor, realr, unsignedp);
-
-  if (res == 0)
-    return 0;
-
-  if (res != realr)
-    emit_move_insn (realr, res);
-
-  if (class == MODE_COMPLEX_FLOAT)
-    res = expand_binop (submode, binoptab, imag_t, divisor,
-			imagr, unsignedp, methods);
-  else
-    res = expand_divmod (0, TRUNC_DIV_EXPR, submode,
-			 imag_t, divisor, imagr, unsignedp);
-
-  if (res == 0)
-    return 0;
-
-  if (res != imagr)
-    emit_move_insn (imagr, res);
-
-  lab2 = gen_label_rtx ();
-  emit_jump_insn (gen_jump (lab2));
-  emit_barrier ();
-
-  emit_label (lab1);
-
-  /* |d| > |c|; use ratio c/d to scale dividend and divisor.  */
-
-  if (class == MODE_COMPLEX_FLOAT)
-    ratio = expand_binop (submode, binoptab, real1, imag1,
-			  NULL_RTX, unsignedp, methods);
-  else
-    ratio = expand_divmod (0, TRUNC_DIV_EXPR, submode,
-			   real1, imag1, NULL_RTX, unsignedp);
-
-  if (ratio == 0)
-    return 0;
-
-  /* Calculate divisor.  */
-
-  temp1 = expand_binop (submode, this_mul_optab, real1, ratio,
-			NULL_RTX, unsignedp, methods);
-
-  if (temp1 == 0)
-    return 0;
-
-  divisor = expand_binop (submode, this_add_optab, temp1, imag1,
-			  NULL_RTX, unsignedp, methods);
-
-  if (divisor == 0)
-    return 0;
-
-  /* Calculate dividend.  */
-
-  if (imag0 == 0)
+    
+    if (class == MODE_COMPLEX_FLOAT)
+        res = expand_binop (submode, binoptab, real_t, divisor,
+                            realr, unsignedp, methods);
+    else
+        res = expand_divmod (0, TRUNC_DIV_EXPR, submode,
+                             real_t, divisor, realr, unsignedp);
+    
+    if (res == 0)
+        return 0;
+    
+    if (res != realr)
+        emit_move_insn (realr, res);
+    
+    if (class == MODE_COMPLEX_FLOAT)
+        res = expand_binop (submode, binoptab, imag_t, divisor,
+                            imagr, unsignedp, methods);
+    else
+        res = expand_divmod (0, TRUNC_DIV_EXPR, submode,
+                             imag_t, divisor, imagr, unsignedp);
+    
+    if (res == 0)
+        return 0;
+    
+    if (res != imagr)
+        emit_move_insn (imagr, res);
+    
+    lab2 = gen_label_rtx ();
+    emit_jump_insn (gen_jump (lab2));
+    emit_barrier ();
+    
+    emit_label (lab1);
+    
+    /* |d| > |c|; use ratio c/d to scale dividend and divisor.  */
+    
+    if (class == MODE_COMPLEX_FLOAT)
+        ratio = expand_binop (submode, binoptab, real1, imag1,
+                              NULL_RTX, unsignedp, methods);
+    else
+        ratio = expand_divmod (0, TRUNC_DIV_EXPR, submode,
+                               real1, imag1, NULL_RTX, unsignedp);
+    
+    if (ratio == 0)
+        return 0;
+    
+    /* Calculate divisor.  */
+    
+    temp1 = expand_binop (submode, this_mul_optab, real1, ratio,
+                          NULL_RTX, unsignedp, methods);
+    
+    if (temp1 == 0)
+        return 0;
+    
+    divisor = expand_binop (submode, this_add_optab, temp1, imag1,
+                            NULL_RTX, unsignedp, methods);
+    
+    if (divisor == 0)
+        return 0;
+    
+    /* Calculate dividend.  */
+    
+    if (imag0 == 0)
     {
-      /* Compute a / (c+id) as a(c/d) / (c(c/d)+d) + i (-a) / (c(c/d)+d).  */
-
-      real_t = expand_binop (submode, this_mul_optab, real0, ratio,
-			     NULL_RTX, unsignedp, methods);
-
-      imag_t = expand_unop (submode, this_neg_optab, real0,
-			    NULL_RTX, unsignedp);
-
-      if (real_t == 0 || imag_t == 0)
-	return 0;
+        /* Compute a / (c+id) as a(c/d) / (c(c/d)+d) + i (-a) / (c(c/d)+d).  */
+        
+        real_t = expand_binop (submode, this_mul_optab, real0, ratio,
+                               NULL_RTX, unsignedp, methods);
+        
+        imag_t = expand_unop (submode, this_neg_optab, real0,
+                              NULL_RTX, unsignedp);
+        
+        if (real_t == 0 || imag_t == 0)
+            return 0;
     }
-  else
+    else
     {
-      /* Compute (a+ib)/(c+id) as
-	 (a(c/d)+b)/(c(c/d)+d) + i (b(c/d)-a)/(c(c/d)+d).  */
-
-      temp1 = expand_binop (submode, this_mul_optab, real0, ratio,
-			    NULL_RTX, unsignedp, methods);
-
-      if (temp1 == 0)
-	return 0;
-
-      real_t = expand_binop (submode, this_add_optab, temp1, imag0,
-			     NULL_RTX, unsignedp, methods);
-
-      temp1 = expand_binop (submode, this_mul_optab, imag0, ratio,
-			    NULL_RTX, unsignedp, methods);
-
-      if (temp1 == 0)
-	return 0;
-
-      imag_t = expand_binop (submode, this_sub_optab, temp1, real0,
-			     NULL_RTX, unsignedp, methods);
-
-      if (real_t == 0 || imag_t == 0)
-	return 0;
+        /* Compute (a+ib)/(c+id) as
+         (a(c/d)+b)/(c(c/d)+d) + i (b(c/d)-a)/(c(c/d)+d).  */
+        
+        temp1 = expand_binop (submode, this_mul_optab, real0, ratio,
+                              NULL_RTX, unsignedp, methods);
+        
+        if (temp1 == 0)
+            return 0;
+        
+        real_t = expand_binop (submode, this_add_optab, temp1, imag0,
+                               NULL_RTX, unsignedp, methods);
+        
+        temp1 = expand_binop (submode, this_mul_optab, imag0, ratio,
+                              NULL_RTX, unsignedp, methods);
+        
+        if (temp1 == 0)
+            return 0;
+        
+        imag_t = expand_binop (submode, this_sub_optab, temp1, real0,
+                               NULL_RTX, unsignedp, methods);
+        
+        if (real_t == 0 || imag_t == 0)
+            return 0;
     }
-
-  if (class == MODE_COMPLEX_FLOAT)
-    res = expand_binop (submode, binoptab, real_t, divisor,
-			realr, unsignedp, methods);
-  else
-    res = expand_divmod (0, TRUNC_DIV_EXPR, submode,
-			 real_t, divisor, realr, unsignedp);
-
-  if (res == 0)
-    return 0;
-
-  if (res != realr)
-    emit_move_insn (realr, res);
-
-  if (class == MODE_COMPLEX_FLOAT)
-    res = expand_binop (submode, binoptab, imag_t, divisor,
-			imagr, unsignedp, methods);
-  else
-    res = expand_divmod (0, TRUNC_DIV_EXPR, submode,
-			 imag_t, divisor, imagr, unsignedp);
-
-  if (res == 0)
-    return 0;
-
-  if (res != imagr)
-    emit_move_insn (imagr, res);
-
-  emit_label (lab2);
-
-  return 1;
+    
+    if (class == MODE_COMPLEX_FLOAT)
+        res = expand_binop (submode, binoptab, real_t, divisor,
+                            realr, unsignedp, methods);
+    else
+        res = expand_divmod (0, TRUNC_DIV_EXPR, submode,
+                             real_t, divisor, realr, unsignedp);
+    
+    if (res == 0)
+        return 0;
+    
+    if (res != realr)
+        emit_move_insn (realr, res);
+    
+    if (class == MODE_COMPLEX_FLOAT)
+        res = expand_binop (submode, binoptab, imag_t, divisor,
+                            imagr, unsignedp, methods);
+    else
+        res = expand_divmod (0, TRUNC_DIV_EXPR, submode,
+                             imag_t, divisor, imagr, unsignedp);
+    
+    if (res == 0)
+        return 0;
+    
+    if (res != imagr)
+        emit_move_insn (imagr, res);
+    
+    emit_label (lab2);
+    
+    return 1;
 }
 
 /* Wrapper around expand_binop which takes an rtx code to specify
-   the operation to perform, not an optab pointer.  All other
-   arguments are the same.  */
+ the operation to perform, not an optab pointer.  All other
+ arguments are the same.  */
 rtx
 expand_simple_binop (mode, code, op0, op1, target, unsignedp, methods)
-     enum machine_mode mode;
-     enum rtx_code code;
-     rtx op0, op1;
-     rtx target;
-     int unsignedp;
-     enum optab_methods methods;
+enum machine_mode mode;
+enum rtx_code code;
+rtx op0, op1;
+rtx target;
+int unsignedp;
+enum optab_methods methods;
 {
-  optab binop = code_to_optab [(int) code];
-  if (binop == 0)
-    abort ();
-
-  return expand_binop (mode, binop, op0, op1, target, unsignedp, methods);
+    optab binop = code_to_optab [(int) code];
+    if (binop == 0)
+        abort ();
+    
+    return expand_binop (mode, binop, op0, op1, target, unsignedp, methods);
 }
 
 /* Generate code to perform an operation specified by BINOPTAB
-   on operands OP0 and OP1, with result having machine-mode MODE.
-
-   UNSIGNEDP is for the case where we have to widen the operands
-   to perform the operation.  It says to use zero-extension.
-
-   If TARGET is nonzero, the value
-   is generated there, if it is convenient to do so.
-   In all cases an rtx is returned for the locus of the value;
-   this may or may not be TARGET.  */
+ on operands OP0 and OP1, with result having machine-mode MODE.
+ 
+ UNSIGNEDP is for the case where we have to widen the operands
+ to perform the operation.  It says to use zero-extension.
+ 
+ If TARGET is nonzero, the value
+ is generated there, if it is convenient to do so.
+ In all cases an rtx is returned for the locus of the value;
+ this may or may not be TARGET.  */
 
 rtx
 expand_binop (mode, binoptab, op0, op1, target, unsignedp, methods)
-     enum machine_mode mode;
-     optab binoptab;
-     rtx op0, op1;
-     rtx target;
-     int unsignedp;
-     enum optab_methods methods;
+enum machine_mode mode;
+optab binoptab;
+rtx op0, op1;
+rtx target;
+int unsignedp;
+enum optab_methods methods;
 {
-  enum optab_methods next_methods
+    enum optab_methods next_methods
     = (methods == OPTAB_LIB || methods == OPTAB_LIB_WIDEN
        ? OPTAB_WIDEN : methods);
-  enum mode_class class;
-  enum machine_mode wider_mode;
-  rtx temp;
-  int commutative_op = 0;
-  int shift_op = (binoptab->code ==  ASHIFT
-		  || binoptab->code == ASHIFTRT
-		  || binoptab->code == LSHIFTRT
-		  || binoptab->code == ROTATE
-		  || binoptab->code == ROTATERT);
-  rtx entry_last = get_last_insn ();
-  rtx last;
-
-  class = GET_MODE_CLASS (mode);
-
-  op0 = protect_from_queue (op0, 0);
-  op1 = protect_from_queue (op1, 0);
-  if (target)
-    target = protect_from_queue (target, 1);
-
-  if (flag_force_mem)
+    enum mode_class class;
+    enum machine_mode wider_mode;
+    rtx temp;
+    int commutative_op = 0;
+    int shift_op = (binoptab->code ==  ASHIFT
+                    || binoptab->code == ASHIFTRT
+                    || binoptab->code == LSHIFTRT
+                    || binoptab->code == ROTATE
+                    || binoptab->code == ROTATERT);
+    rtx entry_last = get_last_insn ();
+    rtx last;
+    
+    class = GET_MODE_CLASS (mode);
+    
+    op0 = protect_from_queue (op0, 0);
+    op1 = protect_from_queue (op1, 0);
+    if (target)
+        target = protect_from_queue (target, 1);
+    
+    if (flag_force_mem)
     {
-      op0 = force_not_mem (op0);
-      op1 = force_not_mem (op1);
+        op0 = force_not_mem (op0);
+        op1 = force_not_mem (op1);
     }
-
-  /* If subtracting an integer constant, convert this into an addition of
+    
+    /* If subtracting an integer constant, convert this into an addition of
      the negated constant.  */
-
-  if (binoptab == sub_optab && GET_CODE (op1) == CONST_INT)
+    
+    if (binoptab == sub_optab && GET_CODE (op1) == CONST_INT)
     {
-      op1 = negate_rtx (mode, op1);
-      binoptab = add_optab;
+        op1 = negate_rtx (mode, op1);
+        binoptab = add_optab;
     }
-
-  /* If we are inside an appropriately-short loop and one operand is an
+    
+    /* If we are inside an appropriately-short loop and one operand is an
      expensive constant, force it into a register.  */
-  if (CONSTANT_P (op0) && preserve_subexpressions_p ()
-      && rtx_cost (op0, binoptab->code) > COSTS_N_INSNS (1))
-    op0 = force_reg (mode, op0);
-
-  if (CONSTANT_P (op1) && preserve_subexpressions_p ()
-      && ! shift_op && rtx_cost (op1, binoptab->code) > COSTS_N_INSNS (1))
-    op1 = force_reg (mode, op1);
-
-  /* Record where to delete back to if we backtrack.  */
-  last = get_last_insn ();
-
-  /* If operation is commutative,
+    if (CONSTANT_P (op0) && preserve_subexpressions_p ()
+        && rtx_cost (op0, binoptab->code) > COSTS_N_INSNS (1))
+        op0 = force_reg (mode, op0);
+    
+    if (CONSTANT_P (op1) && preserve_subexpressions_p ()
+        && ! shift_op && rtx_cost (op1, binoptab->code) > COSTS_N_INSNS (1))
+        op1 = force_reg (mode, op1);
+    
+    /* Record where to delete back to if we backtrack.  */
+    last = get_last_insn ();
+    
+    /* If operation is commutative,
      try to make the first operand a register.
      Even better, try to make it the same as the target.
      Also try to make the last operand a constant.  */
-  if (GET_RTX_CLASS (binoptab->code) == 'c'
-      || binoptab == smul_widen_optab
-      || binoptab == umul_widen_optab
-      || binoptab == smul_highpart_optab
-      || binoptab == umul_highpart_optab)
+    if (GET_RTX_CLASS (binoptab->code) == 'c'
+        || binoptab == smul_widen_optab
+        || binoptab == umul_widen_optab
+        || binoptab == smul_highpart_optab
+        || binoptab == umul_highpart_optab)
     {
-      commutative_op = 1;
-
-      if (((target == 0 || GET_CODE (target) == REG)
-	   ? ((GET_CODE (op1) == REG
-	       && GET_CODE (op0) != REG)
-	      || target == op1)
-	   : rtx_equal_p (op1, target))
-	  || GET_CODE (op0) == CONST_INT)
-	{
-	  temp = op1;
-	  op1 = op0;
-	  op0 = temp;
-	}
+        commutative_op = 1;
+        
+        if (((target == 0 || GET_CODE (target) == REG)
+             ? ((GET_CODE (op1) == REG
+                 && GET_CODE (op0) != REG)
+                || target == op1)
+             : rtx_equal_p (op1, target))
+            || GET_CODE (op0) == CONST_INT)
+        {
+            temp = op1;
+            op1 = op0;
+            op0 = temp;
+        }
     }
-
-  /* If we can do it with a three-operand insn, do so.  */
-
-  if (methods != OPTAB_MUST_WIDEN
-      && binoptab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
+    
+    /* If we can do it with a three-operand insn, do so.  */
+    
+    if (methods != OPTAB_MUST_WIDEN
+        && binoptab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
     {
-      int icode = (int) binoptab->handlers[(int) mode].insn_code;
-      enum machine_mode mode0 = insn_data[icode].operand[1].mode;
-      enum machine_mode mode1 = insn_data[icode].operand[2].mode;
-      rtx pat;
-      rtx xop0 = op0, xop1 = op1;
-
-      if (target)
-	temp = target;
-      else
-	temp = gen_reg_rtx (mode);
-
-      /* If it is a commutative operator and the modes would match
-	 if we would swap the operands, we can save the conversions.  */
-      if (commutative_op)
-	{
-	  if (GET_MODE (op0) != mode0 && GET_MODE (op1) != mode1
-	      && GET_MODE (op0) == mode1 && GET_MODE (op1) == mode0)
-	    {
-	      rtx tmp;
-
-	      tmp = op0; op0 = op1; op1 = tmp;
-	      tmp = xop0; xop0 = xop1; xop1 = tmp;
-	    }
-	}
-
-      /* In case the insn wants input operands in modes different from
-	 the result, convert the operands.  It would seem that we
-	 don't need to convert CONST_INTs, but we do, so that they're
-	 a properly sign-extended for their modes; we choose the
-	 widest mode between mode and mode[01], so that, in a widening
-	 operation, we call convert_modes with different FROM and TO
-	 modes, which ensures the value is sign-extended.  Shift
-	 operations are an exception, because the second operand needs
-	 not be extended to the mode of the result.  */
-
-      if (GET_MODE (op0) != mode0
-	  && mode0 != VOIDmode)
-	xop0 = convert_modes (mode0,
-			      GET_MODE (op0) != VOIDmode
-			      ? GET_MODE (op0)
-			      : GET_MODE_SIZE (mode) > GET_MODE_SIZE (mode0)
-			      ? mode
-			      : mode0,
-			      xop0, unsignedp);
-
-      if (GET_MODE (xop1) != mode1
-	  && mode1 != VOIDmode)
-	xop1 = convert_modes (mode1,
-			      GET_MODE (op1) != VOIDmode
-			      ? GET_MODE (op1)
-			      : (GET_MODE_SIZE (mode) > GET_MODE_SIZE (mode1)
-				 && ! shift_op)
-			      ? mode
-			      : mode1,
-			      xop1, unsignedp);
-
-      /* Now, if insn's predicates don't allow our operands, put them into
-	 pseudo regs.  */
-
-      if (! (*insn_data[icode].operand[1].predicate) (xop0, mode0)
-	  && mode0 != VOIDmode)
-	xop0 = copy_to_mode_reg (mode0, xop0);
-
-      if (! (*insn_data[icode].operand[2].predicate) (xop1, mode1)
-	  && mode1 != VOIDmode)
-	xop1 = copy_to_mode_reg (mode1, xop1);
-
-      if (! (*insn_data[icode].operand[0].predicate) (temp, mode))
-	temp = gen_reg_rtx (mode);
-
-      pat = GEN_FCN (icode) (temp, xop0, xop1);
-      if (pat)
-	{
-	  /* If PAT is a multi-insn sequence, try to add an appropriate
-	     REG_EQUAL note to it.  If we can't because TEMP conflicts with an
-	     operand, call ourselves again, this time without a target.  */
-	  if (GET_CODE (pat) == SEQUENCE
-	      && ! add_equal_note (pat, temp, binoptab->code, xop0, xop1))
-	    {
-	      delete_insns_since (last);
-	      return expand_binop (mode, binoptab, op0, op1, NULL_RTX,
-				   unsignedp, methods);
-	    }
-
-	  emit_insn (pat);
-	  return temp;
-	}
-      else
-	delete_insns_since (last);
+        int icode = (int) binoptab->handlers[(int) mode].insn_code;
+        enum machine_mode mode0 = insn_data[icode].operand[1].mode;
+        enum machine_mode mode1 = insn_data[icode].operand[2].mode;
+        rtx pat;
+        rtx xop0 = op0, xop1 = op1;
+        
+        if (target)
+            temp = target;
+        else
+            temp = gen_reg_rtx (mode);
+        
+        /* If it is a commutative operator and the modes would match
+         if we would swap the operands, we can save the conversions.  */
+        if (commutative_op)
+        {
+            if (GET_MODE (op0) != mode0 && GET_MODE (op1) != mode1
+                && GET_MODE (op0) == mode1 && GET_MODE (op1) == mode0)
+            {
+                rtx tmp;
+                
+                tmp = op0; op0 = op1; op1 = tmp;
+                tmp = xop0; xop0 = xop1; xop1 = tmp;
+            }
+        }
+        
+        /* In case the insn wants input operands in modes different from
+         the result, convert the operands.  It would seem that we
+         don't need to convert CONST_INTs, but we do, so that they're
+         a properly sign-extended for their modes; we choose the
+         widest mode between mode and mode[01], so that, in a widening
+         operation, we call convert_modes with different FROM and TO
+         modes, which ensures the value is sign-extended.  Shift
+         operations are an exception, because the second operand needs
+         not be extended to the mode of the result.  */
+        
+        if (GET_MODE (op0) != mode0
+            && mode0 != VOIDmode)
+            xop0 = convert_modes (mode0,
+                                    GET_MODE (op0) != VOIDmode
+                                    ? GET_MODE (op0)
+                                    : GET_MODE_SIZE (mode) > GET_MODE_SIZE (mode0)
+                                    ? mode
+                                    : mode0,
+                                    xop0, unsignedp);
+        
+        if (GET_MODE (xop1) != mode1
+            && mode1 != VOIDmode)
+            xop1 = convert_modes (mode1,
+                                    GET_MODE (op1) != VOIDmode
+                                    ? GET_MODE (op1)
+                                    : (GET_MODE_SIZE (mode) > GET_MODE_SIZE (mode1)
+                                       && ! shift_op)
+                                    ? mode
+                                    : mode1,
+                                    xop1, unsignedp);
+        
+        /* Now, if insn's predicates don't allow our operands, put them into
+         pseudo regs.  */
+        
+        if (! (*insn_data[icode].operand[1].predicate) (xop0, mode0)
+            && mode0 != VOIDmode)
+            xop0 = copy_to_mode_reg (mode0, xop0);
+        
+        if (! (*insn_data[icode].operand[2].predicate) (xop1, mode1)
+            && mode1 != VOIDmode)
+            xop1 = copy_to_mode_reg (mode1, xop1);
+        
+        if (! (*insn_data[icode].operand[0].predicate) (temp, mode))
+            temp = gen_reg_rtx (mode);
+        
+        pat = GEN_FCN3 (icode) (temp, xop0, xop1);
+        if (pat)
+        {
+            /* If PAT is a multi-insn sequence, try to add an appropriate
+             REG_EQUAL note to it.  If we can't because TEMP conflicts with an
+             operand, call ourselves again, this time without a target.  */
+            if (GET_CODE (pat) == SEQUENCE
+                && ! add_equal_note (pat, temp, binoptab->code, xop0, xop1))
+            {
+                delete_insns_since (last);
+                return expand_binop (mode, binoptab, op0, op1, NULL_RTX,
+                                     unsignedp, methods);
+            }
+            
+            emit_insn (pat);
+            return temp;
+        }
+        else
+            delete_insns_since (last);
     }
-
-  /* If this is a multiply, see if we can do a widening operation that
+    
+    /* If this is a multiply, see if we can do a widening operation that
      takes operands of this mode and makes a wider mode.  */
-
-  if (binoptab == smul_optab && GET_MODE_WIDER_MODE (mode) != VOIDmode
-      && (((unsignedp ? umul_widen_optab : smul_widen_optab)
-	   ->handlers[(int) GET_MODE_WIDER_MODE (mode)].insn_code)
-	  != CODE_FOR_nothing))
+    
+    if (binoptab == smul_optab && GET_MODE_WIDER_MODE (mode) != VOIDmode
+        && (((unsignedp ? umul_widen_optab : smul_widen_optab)
+             ->handlers[(int) GET_MODE_WIDER_MODE (mode)].insn_code)
+            != CODE_FOR_nothing))
     {
-      temp = expand_binop (GET_MODE_WIDER_MODE (mode),
-			   unsignedp ? umul_widen_optab : smul_widen_optab,
-			   op0, op1, NULL_RTX, unsignedp, OPTAB_DIRECT);
-
-      if (temp != 0)
-	{
-	  if (GET_MODE_CLASS (mode) == MODE_INT)
-	    return gen_lowpart (mode, temp);
-	  else
-	    return convert_to_mode (mode, temp, unsignedp);
-	}
+        temp = expand_binop (GET_MODE_WIDER_MODE (mode),
+                             unsignedp ? umul_widen_optab : smul_widen_optab,
+                             op0, op1, NULL_RTX, unsignedp, OPTAB_DIRECT);
+        
+        if (temp != 0)
+        {
+            if (GET_MODE_CLASS (mode) == MODE_INT)
+                return gen_lowpart (mode, temp);
+            else
+                return convert_to_mode (mode, temp, unsignedp);
+        }
     }
-
-  /* Look for a wider mode of the same class for which we think we
+    
+    /* Look for a wider mode of the same class for which we think we
      can open-code the operation.  Check for a widening multiply at the
      wider mode as well.  */
-
-  if ((class == MODE_INT || class == MODE_FLOAT || class == MODE_COMPLEX_FLOAT)
-      && methods != OPTAB_DIRECT && methods != OPTAB_LIB)
-    for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
-	 wider_mode = GET_MODE_WIDER_MODE (wider_mode))
-      {
-	if (binoptab->handlers[(int) wider_mode].insn_code != CODE_FOR_nothing
-	    || (binoptab == smul_optab
-		&& GET_MODE_WIDER_MODE (wider_mode) != VOIDmode
-		&& (((unsignedp ? umul_widen_optab : smul_widen_optab)
-		     ->handlers[(int) GET_MODE_WIDER_MODE (wider_mode)].insn_code)
-		    != CODE_FOR_nothing)))
-	  {
-	    rtx xop0 = op0, xop1 = op1;
-	    int no_extend = 0;
-
-	    /* For certain integer operations, we need not actually extend
-	       the narrow operands, as long as we will truncate
-	       the results to the same narrowness.  */
-
-	    if ((binoptab == ior_optab || binoptab == and_optab
-		 || binoptab == xor_optab
-		 || binoptab == add_optab || binoptab == sub_optab
-		 || binoptab == smul_optab || binoptab == ashl_optab)
-		&& class == MODE_INT)
-	      no_extend = 1;
-
-	    xop0 = widen_operand (xop0, wider_mode, mode, unsignedp, no_extend);
-
-	    /* The second operand of a shift must always be extended.  */
-	    xop1 = widen_operand (xop1, wider_mode, mode, unsignedp,
-				  no_extend && binoptab != ashl_optab);
-
-	    temp = expand_binop (wider_mode, binoptab, xop0, xop1, NULL_RTX,
-				 unsignedp, OPTAB_DIRECT);
-	    if (temp)
-	      {
-		if (class != MODE_INT)
-		  {
-		    if (target == 0)
-		      target = gen_reg_rtx (mode);
-		    convert_move (target, temp, 0);
-		    return target;
-		  }
-		else
-		  return gen_lowpart (mode, temp);
-	      }
-	    else
-	      delete_insns_since (last);
-	  }
-      }
-
-  /* These can be done a word at a time.  */
-  if ((binoptab == and_optab || binoptab == ior_optab || binoptab == xor_optab)
-      && class == MODE_INT
-      && GET_MODE_SIZE (mode) > UNITS_PER_WORD
-      && binoptab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing)
+    
+    if ((class == MODE_INT || class == MODE_FLOAT || class == MODE_COMPLEX_FLOAT)
+        && methods != OPTAB_DIRECT && methods != OPTAB_LIB)
+        for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
+             wider_mode = GET_MODE_WIDER_MODE (wider_mode))
     {
-      int i;
-      rtx insns;
-      rtx equiv_value;
-
-      /* If TARGET is the same as one of the operands, the REG_EQUAL note
-	 won't be accurate, so use a new target.  */
-      if (target == 0 || target == op0 || target == op1)
-	target = gen_reg_rtx (mode);
-
-      start_sequence ();
-
-      /* Do the actual arithmetic.  */
-      for (i = 0; i < GET_MODE_BITSIZE (mode) / BITS_PER_WORD; i++)
-	{
-	  rtx target_piece = operand_subword (target, i, 1, mode);
-	  rtx x = expand_binop (word_mode, binoptab,
-				operand_subword_force (op0, i, mode),
-				operand_subword_force (op1, i, mode),
-				target_piece, unsignedp, next_methods);
-
-	  if (x == 0)
-	    break;
-
-	  if (target_piece != x)
-	    emit_move_insn (target_piece, x);
-	}
-
-      insns = get_insns ();
-      end_sequence ();
-
-      if (i == GET_MODE_BITSIZE (mode) / BITS_PER_WORD)
-	{
-	  if (binoptab->code != UNKNOWN)
-	    equiv_value
-	      = gen_rtx_fmt_ee (binoptab->code, mode,
-				copy_rtx (op0), copy_rtx (op1));
-	  else
-	    equiv_value = 0;
-
-	  emit_no_conflict_block (insns, target, op0, op1, equiv_value);
-	  return target;
-	}
+        if (binoptab->handlers[(int) wider_mode].insn_code != CODE_FOR_nothing
+            || (binoptab == smul_optab
+                && GET_MODE_WIDER_MODE (wider_mode) != VOIDmode
+                && (((unsignedp ? umul_widen_optab : smul_widen_optab)
+                     ->handlers[(int) GET_MODE_WIDER_MODE (wider_mode)].insn_code)
+                    != CODE_FOR_nothing)))
+        {
+            rtx xop0 = op0, xop1 = op1;
+            int no_extend = 0;
+            
+            /* For certain integer operations, we need not actually extend
+             the narrow operands, as long as we will truncate
+             the results to the same narrowness.  */
+            
+            if ((binoptab == ior_optab || binoptab == and_optab
+                 || binoptab == xor_optab
+                 || binoptab == add_optab || binoptab == sub_optab
+                 || binoptab == smul_optab || binoptab == ashl_optab)
+                && class == MODE_INT)
+                no_extend = 1;
+            
+            xop0 = widen_operand (xop0, wider_mode, mode, unsignedp, no_extend);
+            
+            /* The second operand of a shift must always be extended.  */
+            xop1 = widen_operand (xop1, wider_mode, mode, unsignedp,
+                                  no_extend && binoptab != ashl_optab);
+            
+            temp = expand_binop (wider_mode, binoptab, xop0, xop1, NULL_RTX,
+                                 unsignedp, OPTAB_DIRECT);
+            if (temp)
+            {
+                if (class != MODE_INT)
+                {
+                    if (target == 0)
+                        target = gen_reg_rtx (mode);
+                    convert_move (target, temp, 0);
+                    return target;
+                }
+                else
+                    return gen_lowpart (mode, temp);
+            }
+            else
+                delete_insns_since (last);
+        }
     }
-
-  /* Synthesize double word shifts from single word shifts.  */
-  if ((binoptab == lshr_optab || binoptab == ashl_optab
-       || binoptab == ashr_optab)
-      && class == MODE_INT
-      && GET_CODE (op1) == CONST_INT
-      && GET_MODE_SIZE (mode) == 2 * UNITS_PER_WORD
-      && binoptab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing
-      && ashl_optab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing
-      && lshr_optab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing)
+    
+    /* These can be done a word at a time.  */
+    if ((binoptab == and_optab || binoptab == ior_optab || binoptab == xor_optab)
+        && class == MODE_INT
+        && GET_MODE_SIZE (mode) > UNITS_PER_WORD
+        && binoptab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing)
     {
-      rtx insns, inter, equiv_value;
-      rtx into_target, outof_target;
-      rtx into_input, outof_input;
-      int shift_count, left_shift, outof_word;
-
-      /* If TARGET is the same as one of the operands, the REG_EQUAL note
-	 won't be accurate, so use a new target.  */
-      if (target == 0 || target == op0 || target == op1)
-	target = gen_reg_rtx (mode);
-
-      start_sequence ();
-
-      shift_count = INTVAL (op1);
-
-      /* OUTOF_* is the word we are shifting bits away from, and
-	 INTO_* is the word that we are shifting bits towards, thus
-	 they differ depending on the direction of the shift and
-	 WORDS_BIG_ENDIAN.  */
-
-      left_shift = binoptab == ashl_optab;
-      outof_word = left_shift ^ ! WORDS_BIG_ENDIAN;
-
-      outof_target = operand_subword (target, outof_word, 1, mode);
-      into_target = operand_subword (target, 1 - outof_word, 1, mode);
-
-      outof_input = operand_subword_force (op0, outof_word, mode);
-      into_input = operand_subword_force (op0, 1 - outof_word, mode);
-
-      if (shift_count >= BITS_PER_WORD)
-	{
-	  inter = expand_binop (word_mode, binoptab,
-			       outof_input,
-			       GEN_INT (shift_count - BITS_PER_WORD),
-			       into_target, unsignedp, next_methods);
-
-	  if (inter != 0 && inter != into_target)
-	    emit_move_insn (into_target, inter);
-
-	  /* For a signed right shift, we must fill the word we are shifting
-	     out of with copies of the sign bit.  Otherwise it is zeroed.  */
-	  if (inter != 0 && binoptab != ashr_optab)
-	    inter = CONST0_RTX (word_mode);
-	  else if (inter != 0)
-	    inter = expand_binop (word_mode, binoptab,
-				  outof_input,
-				  GEN_INT (BITS_PER_WORD - 1),
-				  outof_target, unsignedp, next_methods);
-
-	  if (inter != 0 && inter != outof_target)
-	    emit_move_insn (outof_target, inter);
-	}
-      else
-	{
-	  rtx carries;
-	  optab reverse_unsigned_shift, unsigned_shift;
-
-	  /* For a shift of less then BITS_PER_WORD, to compute the carry,
-	     we must do a logical shift in the opposite direction of the
-	     desired shift.  */
-
-	  reverse_unsigned_shift = (left_shift ? lshr_optab : ashl_optab);
-
-	  /* For a shift of less than BITS_PER_WORD, to compute the word
-	     shifted towards, we need to unsigned shift the orig value of
-	     that word.  */
-
-	  unsigned_shift = (left_shift ? ashl_optab : lshr_optab);
-
-	  carries = expand_binop (word_mode, reverse_unsigned_shift,
-				  outof_input,
-				  GEN_INT (BITS_PER_WORD - shift_count),
-				  0, unsignedp, next_methods);
-
-	  if (carries == 0)
-	    inter = 0;
-	  else
-	    inter = expand_binop (word_mode, unsigned_shift, into_input,
-				  op1, 0, unsignedp, next_methods);
-
-	  if (inter != 0)
-	    inter = expand_binop (word_mode, ior_optab, carries, inter,
-				  into_target, unsignedp, next_methods);
-
-	  if (inter != 0 && inter != into_target)
-	    emit_move_insn (into_target, inter);
-
-	  if (inter != 0)
-	    inter = expand_binop (word_mode, binoptab, outof_input,
-				  op1, outof_target, unsignedp, next_methods);
-	  
-	  if (inter != 0 && inter != outof_target)
-	    emit_move_insn (outof_target, inter);
-	}
-
-      insns = get_insns ();
-      end_sequence ();
-
-      if (inter != 0)
-	{
-	  if (binoptab->code != UNKNOWN)
-	    equiv_value = gen_rtx_fmt_ee (binoptab->code, mode, op0, op1);
-	  else
-	    equiv_value = 0;
-
-	  emit_no_conflict_block (insns, target, op0, op1, equiv_value);
-	  return target;
-	}
+        int i;
+        rtx insns;
+        rtx equiv_value;
+        
+        /* If TARGET is the same as one of the operands, the REG_EQUAL note
+         won't be accurate, so use a new target.  */
+        if (target == 0 || target == op0 || target == op1)
+            target = gen_reg_rtx (mode);
+        
+        start_sequence ();
+        
+        /* Do the actual arithmetic.  */
+        for (i = 0; i < GET_MODE_BITSIZE (mode) / BITS_PER_WORD; i++)
+        {
+            rtx target_piece = operand_subword (target, i, 1, mode);
+            rtx x = expand_binop (word_mode, binoptab,
+                                  operand_subword_force (op0, i, mode),
+                                  operand_subword_force (op1, i, mode),
+                                  target_piece, unsignedp, next_methods);
+            
+            if (x == 0)
+                break;
+            
+            if (target_piece != x)
+                emit_move_insn (target_piece, x);
+        }
+        
+        insns = get_insns ();
+        end_sequence ();
+        
+        if (i == GET_MODE_BITSIZE (mode) / BITS_PER_WORD)
+        {
+            if (binoptab->code != UNKNOWN)
+                equiv_value
+                = gen_rtx_fmt_ee (binoptab->code, mode,
+                                  copy_rtx (op0), copy_rtx (op1));
+            else
+                equiv_value = 0;
+            
+            emit_no_conflict_block (insns, target, op0, op1, equiv_value);
+            return target;
+        }
     }
-
-  /* Synthesize double word rotates from single word shifts.  */
-  if ((binoptab == rotl_optab || binoptab == rotr_optab)
-      && class == MODE_INT
-      && GET_CODE (op1) == CONST_INT
-      && GET_MODE_SIZE (mode) == 2 * UNITS_PER_WORD
-      && ashl_optab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing
-      && lshr_optab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing)
+    
+    /* Synthesize double word shifts from single word shifts.  */
+    if ((binoptab == lshr_optab || binoptab == ashl_optab
+         || binoptab == ashr_optab)
+        && class == MODE_INT
+        && GET_CODE (op1) == CONST_INT
+        && GET_MODE_SIZE (mode) == 2 * UNITS_PER_WORD
+        && binoptab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing
+        && ashl_optab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing
+        && lshr_optab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing)
     {
-      rtx insns, equiv_value;
-      rtx into_target, outof_target;
-      rtx into_input, outof_input;
-      rtx inter;
-      int shift_count, left_shift, outof_word;
-
-      /* If TARGET is the same as one of the operands, the REG_EQUAL note
-	 won't be accurate, so use a new target.  */
-      if (target == 0 || target == op0 || target == op1)
-	target = gen_reg_rtx (mode);
-
-      start_sequence ();
-
-      shift_count = INTVAL (op1);
-
-      /* OUTOF_* is the word we are shifting bits away from, and
-	 INTO_* is the word that we are shifting bits towards, thus
-	 they differ depending on the direction of the shift and
-	 WORDS_BIG_ENDIAN.  */
-
-      left_shift = (binoptab == rotl_optab);
-      outof_word = left_shift ^ ! WORDS_BIG_ENDIAN;
-
-      outof_target = operand_subword (target, outof_word, 1, mode);
-      into_target = operand_subword (target, 1 - outof_word, 1, mode);
-
-      outof_input = operand_subword_force (op0, outof_word, mode);
-      into_input = operand_subword_force (op0, 1 - outof_word, mode);
-
-      if (shift_count == BITS_PER_WORD)
-	{
-	  /* This is just a word swap.  */
-	  emit_move_insn (outof_target, into_input);
-	  emit_move_insn (into_target, outof_input);
-	  inter = const0_rtx;
-	}
-      else
-	{
-	  rtx into_temp1, into_temp2, outof_temp1, outof_temp2;
-	  rtx first_shift_count, second_shift_count;
-	  optab reverse_unsigned_shift, unsigned_shift;
-
-	  reverse_unsigned_shift = (left_shift ^ (shift_count < BITS_PER_WORD)
-				    ? lshr_optab : ashl_optab);
-
-	  unsigned_shift = (left_shift ^ (shift_count < BITS_PER_WORD)
-			    ? ashl_optab : lshr_optab);
-
-	  if (shift_count > BITS_PER_WORD)
-	    {
-	      first_shift_count = GEN_INT (shift_count - BITS_PER_WORD);
-	      second_shift_count = GEN_INT (2*BITS_PER_WORD - shift_count);
-	    }
-	  else
-	    {
-	      first_shift_count = GEN_INT (BITS_PER_WORD - shift_count);
-	      second_shift_count = GEN_INT (shift_count);
-	    }
-
-	  into_temp1 = expand_binop (word_mode, unsigned_shift,
-				     outof_input, first_shift_count,
-				     NULL_RTX, unsignedp, next_methods);
-	  into_temp2 = expand_binop (word_mode, reverse_unsigned_shift,
-				     into_input, second_shift_count,
-				     into_target, unsignedp, next_methods);
-
-	  if (into_temp1 != 0 && into_temp2 != 0)
-	    inter = expand_binop (word_mode, ior_optab, into_temp1, into_temp2,
-				  into_target, unsignedp, next_methods);
-	  else
-	    inter = 0;
-
-	  if (inter != 0 && inter != into_target)
-	    emit_move_insn (into_target, inter);
-
-	  outof_temp1 = expand_binop (word_mode, unsigned_shift,
-				      into_input, first_shift_count,
-				      NULL_RTX, unsignedp, next_methods);
-	  outof_temp2 = expand_binop (word_mode, reverse_unsigned_shift,
-				      outof_input, second_shift_count,
-				      outof_target, unsignedp, next_methods);
-
-	  if (inter != 0 && outof_temp1 != 0 && outof_temp2 != 0)
-	    inter = expand_binop (word_mode, ior_optab,
-				  outof_temp1, outof_temp2,
-				  outof_target, unsignedp, next_methods);
-
-	  if (inter != 0 && inter != outof_target)
-	    emit_move_insn (outof_target, inter);
-	}
-
-      insns = get_insns ();
-      end_sequence ();
-
-      if (inter != 0)
-	{
-	  if (binoptab->code != UNKNOWN)
-	    equiv_value = gen_rtx_fmt_ee (binoptab->code, mode, op0, op1);
-	  else
-	    equiv_value = 0;
-
-	  /* We can't make this a no conflict block if this is a word swap,
-	     because the word swap case fails if the input and output values
-	     are in the same register.  */
-	  if (shift_count != BITS_PER_WORD)
-	    emit_no_conflict_block (insns, target, op0, op1, equiv_value);
-	  else
-	    emit_insns (insns);
-
-
-	  return target;
-	}
+        rtx insns, inter, equiv_value;
+        rtx into_target, outof_target;
+        rtx into_input, outof_input;
+        int shift_count, left_shift, outof_word;
+        
+        /* If TARGET is the same as one of the operands, the REG_EQUAL note
+         won't be accurate, so use a new target.  */
+        if (target == 0 || target == op0 || target == op1)
+            target = gen_reg_rtx (mode);
+        
+        start_sequence ();
+        
+        shift_count = INTVAL (op1);
+        
+        /* OUTOF_* is the word we are shifting bits away from, and
+         INTO_* is the word that we are shifting bits towards, thus
+         they differ depending on the direction of the shift and
+         WORDS_BIG_ENDIAN.  */
+        
+        left_shift = binoptab == ashl_optab;
+        outof_word = left_shift ^ ! WORDS_BIG_ENDIAN;
+        
+        outof_target = operand_subword (target, outof_word, 1, mode);
+        into_target = operand_subword (target, 1 - outof_word, 1, mode);
+        
+        outof_input = operand_subword_force (op0, outof_word, mode);
+        into_input = operand_subword_force (op0, 1 - outof_word, mode);
+        
+        if (shift_count >= BITS_PER_WORD)
+        {
+            inter = expand_binop (word_mode, binoptab,
+                                  outof_input,
+                                  GEN_INT (shift_count - BITS_PER_WORD),
+                                  into_target, unsignedp, next_methods);
+            
+            if (inter != 0 && inter != into_target)
+                emit_move_insn (into_target, inter);
+            
+            /* For a signed right shift, we must fill the word we are shifting
+             out of with copies of the sign bit.  Otherwise it is zeroed.  */
+            if (inter != 0 && binoptab != ashr_optab)
+                inter = CONST0_RTX (word_mode);
+            else if (inter != 0)
+                inter = expand_binop (word_mode, binoptab,
+                                      outof_input,
+                                      GEN_INT (BITS_PER_WORD - 1),
+                                      outof_target, unsignedp, next_methods);
+            
+            if (inter != 0 && inter != outof_target)
+                emit_move_insn (outof_target, inter);
+        }
+        else
+        {
+            rtx carries;
+            optab reverse_unsigned_shift, unsigned_shift;
+            
+            /* For a shift of less then BITS_PER_WORD, to compute the carry,
+             we must do a logical shift in the opposite direction of the
+             desired shift.  */
+            
+            reverse_unsigned_shift = (left_shift ? lshr_optab : ashl_optab);
+            
+            /* For a shift of less than BITS_PER_WORD, to compute the word
+             shifted towards, we need to unsigned shift the orig value of
+             that word.  */
+            
+            unsigned_shift = (left_shift ? ashl_optab : lshr_optab);
+            
+            carries = expand_binop (word_mode, reverse_unsigned_shift,
+                                    outof_input,
+                                    GEN_INT (BITS_PER_WORD - shift_count),
+                                    0, unsignedp, next_methods);
+            
+            if (carries == 0)
+                inter = 0;
+            else
+                inter = expand_binop (word_mode, unsigned_shift, into_input,
+                                      op1, 0, unsignedp, next_methods);
+            
+            if (inter != 0)
+                inter = expand_binop (word_mode, ior_optab, carries, inter,
+                                      into_target, unsignedp, next_methods);
+            
+            if (inter != 0 && inter != into_target)
+                emit_move_insn (into_target, inter);
+            
+            if (inter != 0)
+                inter = expand_binop (word_mode, binoptab, outof_input,
+                                      op1, outof_target, unsignedp, next_methods);
+            
+            if (inter != 0 && inter != outof_target)
+                emit_move_insn (outof_target, inter);
+        }
+        
+        insns = get_insns ();
+        end_sequence ();
+        
+        if (inter != 0)
+        {
+            if (binoptab->code != UNKNOWN)
+                equiv_value = gen_rtx_fmt_ee (binoptab->code, mode, op0, op1);
+            else
+                equiv_value = 0;
+            
+            emit_no_conflict_block (insns, target, op0, op1, equiv_value);
+            return target;
+        }
     }
-
-  /* These can be done a word at a time by propagating carries.  */
-  if ((binoptab == add_optab || binoptab == sub_optab)
-      && class == MODE_INT
-      && GET_MODE_SIZE (mode) >= 2 * UNITS_PER_WORD
-      && binoptab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing)
+    
+    /* Synthesize double word rotates from single word shifts.  */
+    if ((binoptab == rotl_optab || binoptab == rotr_optab)
+        && class == MODE_INT
+        && GET_CODE (op1) == CONST_INT
+        && GET_MODE_SIZE (mode) == 2 * UNITS_PER_WORD
+        && ashl_optab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing
+        && lshr_optab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing)
     {
-      int i;
-      optab otheroptab = binoptab == add_optab ? sub_optab : add_optab;
-      unsigned int nwords = GET_MODE_BITSIZE (mode) / BITS_PER_WORD;
-      rtx carry_in = NULL_RTX, carry_out = NULL_RTX;
-      rtx xop0, xop1;
-
-      /* We can handle either a 1 or -1 value for the carry.  If STORE_FLAG
-	 value is one of those, use it.  Otherwise, use 1 since it is the
-	 one easiest to get.  */
+        rtx insns, equiv_value;
+        rtx into_target, outof_target;
+        rtx into_input, outof_input;
+        rtx inter;
+        int shift_count, left_shift, outof_word;
+        
+        /* If TARGET is the same as one of the operands, the REG_EQUAL note
+         won't be accurate, so use a new target.  */
+        if (target == 0 || target == op0 || target == op1)
+            target = gen_reg_rtx (mode);
+        
+        start_sequence ();
+        
+        shift_count = INTVAL (op1);
+        
+        /* OUTOF_* is the word we are shifting bits away from, and
+         INTO_* is the word that we are shifting bits towards, thus
+         they differ depending on the direction of the shift and
+         WORDS_BIG_ENDIAN.  */
+        
+        left_shift = (binoptab == rotl_optab);
+        outof_word = left_shift ^ ! WORDS_BIG_ENDIAN;
+        
+        outof_target = operand_subword (target, outof_word, 1, mode);
+        into_target = operand_subword (target, 1 - outof_word, 1, mode);
+        
+        outof_input = operand_subword_force (op0, outof_word, mode);
+        into_input = operand_subword_force (op0, 1 - outof_word, mode);
+        
+        if (shift_count == BITS_PER_WORD)
+        {
+            /* This is just a word swap.  */
+            emit_move_insn (outof_target, into_input);
+            emit_move_insn (into_target, outof_input);
+            inter = const0_rtx;
+        }
+        else
+        {
+            rtx into_temp1, into_temp2, outof_temp1, outof_temp2;
+            rtx first_shift_count, second_shift_count;
+            optab reverse_unsigned_shift, unsigned_shift;
+            
+            reverse_unsigned_shift = (left_shift ^ (shift_count < BITS_PER_WORD)
+                                      ? lshr_optab : ashl_optab);
+            
+            unsigned_shift = (left_shift ^ (shift_count < BITS_PER_WORD)
+                              ? ashl_optab : lshr_optab);
+            
+            if (shift_count > BITS_PER_WORD)
+            {
+                first_shift_count = GEN_INT (shift_count - BITS_PER_WORD);
+                second_shift_count = GEN_INT (2*BITS_PER_WORD - shift_count);
+            }
+            else
+            {
+                first_shift_count = GEN_INT (BITS_PER_WORD - shift_count);
+                second_shift_count = GEN_INT (shift_count);
+            }
+            
+            into_temp1 = expand_binop (word_mode, unsigned_shift,
+                                       outof_input, first_shift_count,
+                                       NULL_RTX, unsignedp, next_methods);
+            into_temp2 = expand_binop (word_mode, reverse_unsigned_shift,
+                                       into_input, second_shift_count,
+                                       into_target, unsignedp, next_methods);
+            
+            if (into_temp1 != 0 && into_temp2 != 0)
+                inter = expand_binop (word_mode, ior_optab, into_temp1, into_temp2,
+                                      into_target, unsignedp, next_methods);
+            else
+                inter = 0;
+            
+            if (inter != 0 && inter != into_target)
+                emit_move_insn (into_target, inter);
+            
+            outof_temp1 = expand_binop (word_mode, unsigned_shift,
+                                        into_input, first_shift_count,
+                                        NULL_RTX, unsignedp, next_methods);
+            outof_temp2 = expand_binop (word_mode, reverse_unsigned_shift,
+                                        outof_input, second_shift_count,
+                                        outof_target, unsignedp, next_methods);
+            
+            if (inter != 0 && outof_temp1 != 0 && outof_temp2 != 0)
+                inter = expand_binop (word_mode, ior_optab,
+                                      outof_temp1, outof_temp2,
+                                      outof_target, unsignedp, next_methods);
+            
+            if (inter != 0 && inter != outof_target)
+                emit_move_insn (outof_target, inter);
+        }
+        
+        insns = get_insns ();
+        end_sequence ();
+        
+        if (inter != 0)
+        {
+            if (binoptab->code != UNKNOWN)
+                equiv_value = gen_rtx_fmt_ee (binoptab->code, mode, op0, op1);
+            else
+                equiv_value = 0;
+            
+            /* We can't make this a no conflict block if this is a word swap,
+             because the word swap case fails if the input and output values
+             are in the same register.  */
+            if (shift_count != BITS_PER_WORD)
+                emit_no_conflict_block (insns, target, op0, op1, equiv_value);
+            else
+                emit_insns (insns);
+            
+            
+            return target;
+        }
+    }
+    
+    /* These can be done a word at a time by propagating carries.  */
+    if ((binoptab == add_optab || binoptab == sub_optab)
+        && class == MODE_INT
+        && GET_MODE_SIZE (mode) >= 2 * UNITS_PER_WORD
+        && binoptab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing)
+    {
+        int i;
+        optab otheroptab = binoptab == add_optab ? sub_optab : add_optab;
+        unsigned int nwords = GET_MODE_BITSIZE (mode) / BITS_PER_WORD;
+        rtx carry_in = NULL_RTX, carry_out = NULL_RTX;
+        rtx xop0, xop1;
+        
+        /* We can handle either a 1 or -1 value for the carry.  If STORE_FLAG
+         value is one of those, use it.  Otherwise, use 1 since it is the
+         one easiest to get.  */
 #if STORE_FLAG_VALUE == 1 || STORE_FLAG_VALUE == -1
-      int normalizep = STORE_FLAG_VALUE;
+        int normalizep = STORE_FLAG_VALUE;
 #else
-      int normalizep = 1;
+        int normalizep = 1;
 #endif
-
-      /* Prepare the operands.  */
-      xop0 = force_reg (mode, op0);
-      xop1 = force_reg (mode, op1);
-
-      if (target == 0 || GET_CODE (target) != REG
-	  || target == xop0 || target == xop1)
-	target = gen_reg_rtx (mode);
-
-      /* Indicate for flow that the entire target reg is being set.  */
-      if (GET_CODE (target) == REG)
-	emit_insn (gen_rtx_CLOBBER (VOIDmode, target));
-
-      /* Do the actual arithmetic.  */
-      for (i = 0; i < nwords; i++)
-	{
-	  int index = (WORDS_BIG_ENDIAN ? nwords - i - 1 : i);
-	  rtx target_piece = operand_subword (target, index, 1, mode);
-	  rtx op0_piece = operand_subword_force (xop0, index, mode);
-	  rtx op1_piece = operand_subword_force (xop1, index, mode);
-	  rtx x;
-
-	  /* Main add/subtract of the input operands.  */
-	  x = expand_binop (word_mode, binoptab,
-			    op0_piece, op1_piece,
-			    target_piece, unsignedp, next_methods);
-	  if (x == 0)
-	    break;
-
-	  if (i + 1 < nwords)
-	    {
-	      /* Store carry from main add/subtract.  */
-	      carry_out = gen_reg_rtx (word_mode);
-	      carry_out = emit_store_flag_force (carry_out,
-						 (binoptab == add_optab
-						  ? LT : GT),
-						 x, op0_piece,
-						 word_mode, 1, normalizep);
-	    }
-
-	  if (i > 0)
-	    {
-	      rtx newx;
-	      
-	      /* Add/subtract previous carry to main result.  */
-	      newx = expand_binop (word_mode,
-				   normalizep == 1 ? binoptab : otheroptab,
-				   x, carry_in,
-				   NULL_RTX, 1, next_methods);
-
-	      if (i + 1 < nwords)
-		{
-		  /* Get out carry from adding/subtracting carry in.  */
-		  rtx carry_tmp = gen_reg_rtx (word_mode);
-		  carry_tmp = emit_store_flag_force (carry_tmp,
-						     (binoptab == add_optab
-						      ? LT : GT),
-						     newx, x,
-						     word_mode, 1, normalizep);
-
-		  /* Logical-ior the two poss. carry together.  */
-		  carry_out = expand_binop (word_mode, ior_optab,
-					    carry_out, carry_tmp,
-					    carry_out, 0, next_methods);
-		  if (carry_out == 0)
-		    break;
-		}
-	      emit_move_insn (target_piece, newx);
-	    }
-
-	  carry_in = carry_out;
-	}	
-
-      if (i == GET_MODE_BITSIZE (mode) / BITS_PER_WORD)
-	{
-	  if (mov_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
-	    {
-	      rtx temp = emit_move_insn (target, target);
-
-	      set_unique_reg_note (temp,
-	      			   REG_EQUAL,
-				   gen_rtx_fmt_ee (binoptab->code, mode,
-						   copy_rtx (xop0),
-						   copy_rtx (xop1)));
-	    }
-
-	  return target;
-	}
-
-      else
-	delete_insns_since (last);
+        
+        /* Prepare the operands.  */
+        xop0 = force_reg (mode, op0);
+        xop1 = force_reg (mode, op1);
+        
+        if (target == 0 || GET_CODE (target) != REG
+            || target == xop0 || target == xop1)
+            target = gen_reg_rtx (mode);
+        
+        /* Indicate for flow that the entire target reg is being set.  */
+        if (GET_CODE (target) == REG)
+            emit_insn (gen_rtx_CLOBBER (VOIDmode, target));
+        
+        /* Do the actual arithmetic.  */
+        for (i = 0; i < nwords; i++)
+        {
+            int index = (WORDS_BIG_ENDIAN ? nwords - i - 1 : i);
+            rtx target_piece = operand_subword (target, index, 1, mode);
+            rtx op0_piece = operand_subword_force (xop0, index, mode);
+            rtx op1_piece = operand_subword_force (xop1, index, mode);
+            rtx x;
+            
+            /* Main add/subtract of the input operands.  */
+            x = expand_binop (word_mode, binoptab,
+                              op0_piece, op1_piece,
+                              target_piece, unsignedp, next_methods);
+            if (x == 0)
+                break;
+            
+            if (i + 1 < nwords)
+            {
+                /* Store carry from main add/subtract.  */
+                carry_out = gen_reg_rtx (word_mode);
+                carry_out = emit_store_flag_force (carry_out,
+                                                   (binoptab == add_optab
+                                                    ? LT : GT),
+                                                   x, op0_piece,
+                                                   word_mode, 1, normalizep);
+            }
+            
+            if (i > 0)
+            {
+                rtx newx;
+                
+                /* Add/subtract previous carry to main result.  */
+                newx = expand_binop (word_mode,
+                                     normalizep == 1 ? binoptab : otheroptab,
+                                     x, carry_in,
+                                     NULL_RTX, 1, next_methods);
+                
+                if (i + 1 < nwords)
+                {
+                    /* Get out carry from adding/subtracting carry in.  */
+                    rtx carry_tmp = gen_reg_rtx (word_mode);
+                    carry_tmp = emit_store_flag_force (carry_tmp,
+                                                       (binoptab == add_optab
+                                                        ? LT : GT),
+                                                       newx, x,
+                                                       word_mode, 1, normalizep);
+                    
+                    /* Logical-ior the two poss. carry together.  */
+                    carry_out = expand_binop (word_mode, ior_optab,
+                                              carry_out, carry_tmp,
+                                              carry_out, 0, next_methods);
+                    if (carry_out == 0)
+                        break;
+                }
+                emit_move_insn (target_piece, newx);
+            }
+            
+            carry_in = carry_out;
+        }
+        
+        if (i == GET_MODE_BITSIZE (mode) / BITS_PER_WORD)
+        {
+            if (mov_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
+            {
+                rtx temp = emit_move_insn (target, target);
+                
+                set_unique_reg_note (temp,
+                                     REG_EQUAL,
+                                     gen_rtx_fmt_ee (binoptab->code, mode,
+                                                     copy_rtx (xop0),
+                                                     copy_rtx (xop1)));
+            }
+            
+            return target;
+        }
+        
+        else
+            delete_insns_since (last);
     }
-
-  /* If we want to multiply two two-word values and have normal and widening
+    
+    /* If we want to multiply two two-word values and have normal and widening
      multiplies of single-word values, we can do this with three smaller
      multiplications.  Note that we do not make a REG_NO_CONFLICT block here
-     because we are not operating on one word at a time. 
-
+     because we are not operating on one word at a time.
+     
      The multiplication proceeds as follows:
-			         _______________________
-			        [__op0_high_|__op0_low__]
-			         _______________________
-        *			[__op1_high_|__op1_low__]
-        _______________________________________________
-			         _______________________
-    (1)				[__op0_low__*__op1_low__]
-		     _______________________
-    (2a)	    [__op0_low__*__op1_high_]
-		     _______________________
-    (2b)	    [__op0_high_*__op1_low__]
-         _______________________
-    (3) [__op0_high_*__op1_high_]
-
-
-    This gives a 4-word result.  Since we are only interested in the
-    lower 2 words, partial result (3) and the upper words of (2a) and
-    (2b) don't need to be calculated.  Hence (2a) and (2b) can be
-    calculated using non-widening multiplication.
-
-    (1), however, needs to be calculated with an unsigned widening
-    multiplication.  If this operation is not directly supported we
-    try using a signed widening multiplication and adjust the result.
-    This adjustment works as follows:
-
-      If both operands are positive then no adjustment is needed.
-
-      If the operands have different signs, for example op0_low < 0 and
-      op1_low >= 0, the instruction treats the most significant bit of
-      op0_low as a sign bit instead of a bit with significance
-      2**(BITS_PER_WORD-1), i.e. the instruction multiplies op1_low
-      with 2**BITS_PER_WORD - op0_low, and two's complements the
-      result.  Conclusion: We need to add op1_low * 2**BITS_PER_WORD to
-      the result.
-
-      Similarly, if both operands are negative, we need to add
-      (op0_low + op1_low) * 2**BITS_PER_WORD.
-
-      We use a trick to adjust quickly.  We logically shift op0_low right
-      (op1_low) BITS_PER_WORD-1 steps to get 0 or 1, and add this to
-      op0_high (op1_high) before it is used to calculate 2b (2a).  If no
-      logical shift exists, we do an arithmetic right shift and subtract
-      the 0 or -1.  */
-
-  if (binoptab == smul_optab
-      && class == MODE_INT
-      && GET_MODE_SIZE (mode) == 2 * UNITS_PER_WORD
-      && smul_optab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing
-      && add_optab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing
-      && ((umul_widen_optab->handlers[(int) mode].insn_code
-	   != CODE_FOR_nothing)
-	  || (smul_widen_optab->handlers[(int) mode].insn_code
-	      != CODE_FOR_nothing)))
+     _______________________
+     [__op0_high_|__op0_low__]
+     _______________________
+     *			[__op1_high_|__op1_low__]
+     _______________________________________________
+     _______________________
+     (1)				[__op0_low__*__op1_low__]
+     _______________________
+     (2a)	    [__op0_low__*__op1_high_]
+     _______________________
+     (2b)	    [__op0_high_*__op1_low__]
+     _______________________
+     (3) [__op0_high_*__op1_high_]
+     
+     
+     This gives a 4-word result.  Since we are only interested in the
+     lower 2 words, partial result (3) and the upper words of (2a) and
+     (2b) don't need to be calculated.  Hence (2a) and (2b) can be
+     calculated using non-widening multiplication.
+     
+     (1), however, needs to be calculated with an unsigned widening
+     multiplication.  If this operation is not directly supported we
+     try using a signed widening multiplication and adjust the result.
+     This adjustment works as follows:
+     
+     If both operands are positive then no adjustment is needed.
+     
+     If the operands have different signs, for example op0_low < 0 and
+     op1_low >= 0, the instruction treats the most significant bit of
+     op0_low as a sign bit instead of a bit with significance
+     2**(BITS_PER_WORD-1), i.e. the instruction multiplies op1_low
+     with 2**BITS_PER_WORD - op0_low, and two's complements the
+     result.  Conclusion: We need to add op1_low * 2**BITS_PER_WORD to
+     the result.
+     
+     Similarly, if both operands are negative, we need to add
+     (op0_low + op1_low) * 2**BITS_PER_WORD.
+     
+     We use a trick to adjust quickly.  We logically shift op0_low right
+     (op1_low) BITS_PER_WORD-1 steps to get 0 or 1, and add this to
+     op0_high (op1_high) before it is used to calculate 2b (2a).  If no
+     logical shift exists, we do an arithmetic right shift and subtract
+     the 0 or -1.  */
+    
+    if (binoptab == smul_optab
+        && class == MODE_INT
+        && GET_MODE_SIZE (mode) == 2 * UNITS_PER_WORD
+        && smul_optab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing
+        && add_optab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing
+        && ((umul_widen_optab->handlers[(int) mode].insn_code
+             != CODE_FOR_nothing)
+            || (smul_widen_optab->handlers[(int) mode].insn_code
+                != CODE_FOR_nothing)))
     {
-      int low = (WORDS_BIG_ENDIAN ? 1 : 0);
-      int high = (WORDS_BIG_ENDIAN ? 0 : 1);
-      rtx op0_high = operand_subword_force (op0, high, mode);
-      rtx op0_low = operand_subword_force (op0, low, mode);
-      rtx op1_high = operand_subword_force (op1, high, mode);
-      rtx op1_low = operand_subword_force (op1, low, mode);
-      rtx product = 0;
-      rtx op0_xhigh = NULL_RTX;
-      rtx op1_xhigh = NULL_RTX;
-
-      /* If the target is the same as one of the inputs, don't use it.  This
-	 prevents problems with the REG_EQUAL note.  */
-      if (target == op0 || target == op1
-	  || (target != 0 && GET_CODE (target) != REG))
-	target = 0;
-
-      /* Multiply the two lower words to get a double-word product.
-	 If unsigned widening multiplication is available, use that;
-	 otherwise use the signed form and compensate.  */
-
-      if (umul_widen_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
-	{
-	  product = expand_binop (mode, umul_widen_optab, op0_low, op1_low,
-				  target, 1, OPTAB_DIRECT);
-
-	  /* If we didn't succeed, delete everything we did so far.  */
-	  if (product == 0)
-	    delete_insns_since (last);
-	  else
-	    op0_xhigh = op0_high, op1_xhigh = op1_high;
-	}
-
-      if (product == 0
-	  && smul_widen_optab->handlers[(int) mode].insn_code
-	       != CODE_FOR_nothing)
-	{
-	  rtx wordm1 = GEN_INT (BITS_PER_WORD - 1);
-	  product = expand_binop (mode, smul_widen_optab, op0_low, op1_low,
-				  target, 1, OPTAB_DIRECT);
-	  op0_xhigh = expand_binop (word_mode, lshr_optab, op0_low, wordm1,
-				    NULL_RTX, 1, next_methods);
-	  if (op0_xhigh)
-	    op0_xhigh = expand_binop (word_mode, add_optab, op0_high,
-				      op0_xhigh, op0_xhigh, 0, next_methods);
-	  else
-	    {
-	      op0_xhigh = expand_binop (word_mode, ashr_optab, op0_low, wordm1,
-					NULL_RTX, 0, next_methods);
-	      if (op0_xhigh)
-		op0_xhigh = expand_binop (word_mode, sub_optab, op0_high,
-					  op0_xhigh, op0_xhigh, 0,
-					  next_methods);
-	    }
-
-	  op1_xhigh = expand_binop (word_mode, lshr_optab, op1_low, wordm1,
-				    NULL_RTX, 1, next_methods);
-	  if (op1_xhigh)
-	    op1_xhigh = expand_binop (word_mode, add_optab, op1_high,
-				      op1_xhigh, op1_xhigh, 0, next_methods);
-	  else
-	    {
-	      op1_xhigh = expand_binop (word_mode, ashr_optab, op1_low, wordm1,
-					NULL_RTX, 0, next_methods);
-	      if (op1_xhigh)
-		op1_xhigh = expand_binop (word_mode, sub_optab, op1_high,
-					  op1_xhigh, op1_xhigh, 0,
-					  next_methods);
-	    }
-	}
-
-      /* If we have been able to directly compute the product of the
-	 low-order words of the operands and perform any required adjustments
-	 of the operands, we proceed by trying two more multiplications
-	 and then computing the appropriate sum.
-
-	 We have checked above that the required addition is provided.
-	 Full-word addition will normally always succeed, especially if
-	 it is provided at all, so we don't worry about its failure.  The
-	 multiplication may well fail, however, so we do handle that.  */
-
-      if (product && op0_xhigh && op1_xhigh)
-	{
-	  rtx product_high = operand_subword (product, high, 1, mode);
-	  rtx temp = expand_binop (word_mode, binoptab, op0_low, op1_xhigh,
-				   NULL_RTX, 0, OPTAB_DIRECT);
-
-	  if (temp != 0)
-	    temp = expand_binop (word_mode, add_optab, temp, product_high,
-				 product_high, 0, next_methods);
-
-	  if (temp != 0 && temp != product_high)
-	    emit_move_insn (product_high, temp);
-
-	  if (temp != 0)
-	    temp = expand_binop (word_mode, binoptab, op1_low, op0_xhigh, 
-				 NULL_RTX, 0, OPTAB_DIRECT);
-
-	  if (temp != 0)
-	    temp = expand_binop (word_mode, add_optab, temp,
-				 product_high, product_high,
-				 0, next_methods);
-
-	  if (temp != 0 && temp != product_high)
-	    emit_move_insn (product_high, temp);
-
-	  if (temp != 0)
-	    {
-	      if (mov_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
-		{
-		  temp = emit_move_insn (product, product);
-		  set_unique_reg_note (temp,
-		  		       REG_EQUAL,
-				       gen_rtx_fmt_ee (MULT, mode,
-						       copy_rtx (op0),
-						       copy_rtx (op1)));
-		}
-
-	      return product;
-	    }
-	}
-
-      /* If we get here, we couldn't do it for some reason even though we
-	 originally thought we could.  Delete anything we've emitted in
-	 trying to do it.  */
-
-      delete_insns_since (last);
+        int low = (WORDS_BIG_ENDIAN ? 1 : 0);
+        int high = (WORDS_BIG_ENDIAN ? 0 : 1);
+        rtx op0_high = operand_subword_force (op0, high, mode);
+        rtx op0_low = operand_subword_force (op0, low, mode);
+        rtx op1_high = operand_subword_force (op1, high, mode);
+        rtx op1_low = operand_subword_force (op1, low, mode);
+        rtx product = 0;
+        rtx op0_xhigh = NULL_RTX;
+        rtx op1_xhigh = NULL_RTX;
+        
+        /* If the target is the same as one of the inputs, don't use it.  This
+         prevents problems with the REG_EQUAL note.  */
+        if (target == op0 || target == op1
+            || (target != 0 && GET_CODE (target) != REG))
+            target = 0;
+        
+        /* Multiply the two lower words to get a double-word product.
+         If unsigned widening multiplication is available, use that;
+         otherwise use the signed form and compensate.  */
+        
+        if (umul_widen_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
+        {
+            product = expand_binop (mode, umul_widen_optab, op0_low, op1_low,
+                                    target, 1, OPTAB_DIRECT);
+            
+            /* If we didn't succeed, delete everything we did so far.  */
+            if (product == 0)
+                delete_insns_since (last);
+            else
+                op0_xhigh = op0_high, op1_xhigh = op1_high;
+        }
+        
+        if (product == 0
+            && smul_widen_optab->handlers[(int) mode].insn_code
+            != CODE_FOR_nothing)
+        {
+            rtx wordm1 = GEN_INT (BITS_PER_WORD - 1);
+            product = expand_binop (mode, smul_widen_optab, op0_low, op1_low,
+                                    target, 1, OPTAB_DIRECT);
+            op0_xhigh = expand_binop (word_mode, lshr_optab, op0_low, wordm1,
+                                      NULL_RTX, 1, next_methods);
+            if (op0_xhigh)
+                op0_xhigh = expand_binop (word_mode, add_optab, op0_high,
+                                          op0_xhigh, op0_xhigh, 0, next_methods);
+            else
+            {
+                op0_xhigh = expand_binop (word_mode, ashr_optab, op0_low, wordm1,
+                                          NULL_RTX, 0, next_methods);
+                if (op0_xhigh)
+                    op0_xhigh = expand_binop (word_mode, sub_optab, op0_high,
+                                              op0_xhigh, op0_xhigh, 0,
+                                              next_methods);
+            }
+            
+            op1_xhigh = expand_binop (word_mode, lshr_optab, op1_low, wordm1,
+                                      NULL_RTX, 1, next_methods);
+            if (op1_xhigh)
+                op1_xhigh = expand_binop (word_mode, add_optab, op1_high,
+                                          op1_xhigh, op1_xhigh, 0, next_methods);
+            else
+            {
+                op1_xhigh = expand_binop (word_mode, ashr_optab, op1_low, wordm1,
+                                          NULL_RTX, 0, next_methods);
+                if (op1_xhigh)
+                    op1_xhigh = expand_binop (word_mode, sub_optab, op1_high,
+                                              op1_xhigh, op1_xhigh, 0,
+                                              next_methods);
+            }
+        }
+        
+        /* If we have been able to directly compute the product of the
+         low-order words of the operands and perform any required adjustments
+         of the operands, we proceed by trying two more multiplications
+         and then computing the appropriate sum.
+         
+         We have checked above that the required addition is provided.
+         Full-word addition will normally always succeed, especially if
+         it is provided at all, so we don't worry about its failure.  The
+         multiplication may well fail, however, so we do handle that.  */
+        
+        if (product && op0_xhigh && op1_xhigh)
+        {
+            rtx product_high = operand_subword (product, high, 1, mode);
+            rtx temp = expand_binop (word_mode, binoptab, op0_low, op1_xhigh,
+                                     NULL_RTX, 0, OPTAB_DIRECT);
+            
+            if (temp != 0)
+                temp = expand_binop (word_mode, add_optab, temp, product_high,
+                                     product_high, 0, next_methods);
+            
+            if (temp != 0 && temp != product_high)
+                emit_move_insn (product_high, temp);
+            
+            if (temp != 0)
+                temp = expand_binop (word_mode, binoptab, op1_low, op0_xhigh,
+                                     NULL_RTX, 0, OPTAB_DIRECT);
+            
+            if (temp != 0)
+                temp = expand_binop (word_mode, add_optab, temp,
+                                     product_high, product_high,
+                                     0, next_methods);
+            
+            if (temp != 0 && temp != product_high)
+                emit_move_insn (product_high, temp);
+            
+            if (temp != 0)
+            {
+                if (mov_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
+                {
+                    temp = emit_move_insn (product, product);
+                    set_unique_reg_note (temp,
+                                         REG_EQUAL,
+                                         gen_rtx_fmt_ee (MULT, mode,
+                                                         copy_rtx (op0),
+                                                         copy_rtx (op1)));
+                }
+                
+                return product;
+            }
+        }
+        
+        /* If we get here, we couldn't do it for some reason even though we
+         originally thought we could.  Delete anything we've emitted in
+         trying to do it.  */
+        
+        delete_insns_since (last);
     }
-
-  /* We need to open-code the complex type operations: '+, -, * and /' */
-
-  /* At this point we allow operations between two similar complex
+    
+    /* We need to open-code the complex type operations: '+, -, * and /' */
+    
+    /* At this point we allow operations between two similar complex
      numbers, and also if one of the operands is not a complex number
      but rather of MODE_FLOAT or MODE_INT. However, the caller
      must make sure that the MODE of the non-complex operand matches
      the SUBMODE of the complex operand.  */
-
-  if (class == MODE_COMPLEX_FLOAT || class == MODE_COMPLEX_INT)
+    
+    if (class == MODE_COMPLEX_FLOAT || class == MODE_COMPLEX_INT)
     {
-      rtx real0 = 0, imag0 = 0;
-      rtx real1 = 0, imag1 = 0;
-      rtx realr, imagr, res;
-      rtx seq;
-      rtx equiv_value;
-      int ok = 0;
-
-      /* Find the correct mode for the real and imaginary parts */
-      enum machine_mode submode
-	= mode_for_size (GET_MODE_UNIT_SIZE (mode) * BITS_PER_UNIT,
-			 class == MODE_COMPLEX_INT ? MODE_INT : MODE_FLOAT,
-			 0);
-
-      if (submode == BLKmode)
-	abort ();
-
-      if (! target)
-	target = gen_reg_rtx (mode);
-
-      start_sequence ();
-
-      realr = gen_realpart (submode, target);
-      imagr = gen_imagpart (submode, target);
-
-      if (GET_MODE (op0) == mode)
-	{
-	  real0 = gen_realpart (submode, op0);
-	  imag0 = gen_imagpart (submode, op0);
-	}
-      else
-	real0 = op0;
-
-      if (GET_MODE (op1) == mode)
-	{
-	  real1 = gen_realpart (submode, op1);
-	  imag1 = gen_imagpart (submode, op1);
-	}
-      else
-	real1 = op1;
-
-      if (real0 == 0 || real1 == 0 || ! (imag0 != 0|| imag1 != 0))
-	abort ();
-
-      switch (binoptab->code)
-	{
-	case PLUS:
-	  /* (a+ib) + (c+id) = (a+c) + i(b+d) */
-	case MINUS:
-	  /* (a+ib) - (c+id) = (a-c) + i(b-d) */
-	  res = expand_binop (submode, binoptab, real0, real1,
-			      realr, unsignedp, methods);
-
-	  if (res == 0)
-	    break;
-	  else if (res != realr)
-	    emit_move_insn (realr, res);
-
-	  if (imag0 && imag1)
-	    res = expand_binop (submode, binoptab, imag0, imag1,
-				imagr, unsignedp, methods);
-	  else if (imag0)
-	    res = imag0;
-	  else if (binoptab->code == MINUS)
-            res = expand_unop (submode,
-                                binoptab == subv_optab ? negv_optab : neg_optab,
-                                imag1, imagr, unsignedp);
-	  else
-	    res = imag1;
-
-	  if (res == 0)
-	    break;
-	  else if (res != imagr)
-	    emit_move_insn (imagr, res);
-
-	  ok = 1;
-	  break;
-
-	case MULT:
-	  /* (a+ib) * (c+id) = (ac-bd) + i(ad+cb) */
-
-	  if (imag0 && imag1)
-	    {
-	      rtx temp1, temp2;
-
-	      /* Don't fetch these from memory more than once.  */
-	      real0 = force_reg (submode, real0);
-	      real1 = force_reg (submode, real1);
-	      imag0 = force_reg (submode, imag0);
-	      imag1 = force_reg (submode, imag1);
-
-	      temp1 = expand_binop (submode, binoptab, real0, real1, NULL_RTX,
-				    unsignedp, methods);
-
-	      temp2 = expand_binop (submode, binoptab, imag0, imag1, NULL_RTX,
-				    unsignedp, methods);
-
-	      if (temp1 == 0 || temp2 == 0)
-		break;
-
-	      res = (expand_binop
-                     (submode,
-                      binoptab == smulv_optab ? subv_optab : sub_optab,
-                      temp1, temp2, realr, unsignedp, methods));
-
-	      if (res == 0)
-		break;
-	      else if (res != realr)
-		emit_move_insn (realr, res);
-
-	      temp1 = expand_binop (submode, binoptab, real0, imag1,
-				    NULL_RTX, unsignedp, methods);
-
-	      temp2 = expand_binop (submode, binoptab, real1, imag0,
-				    NULL_RTX, unsignedp, methods);
-
-	      if (temp1 == 0 || temp2 == 0)
-		  break;
-
-	      res = (expand_binop
-                     (submode,
-                      binoptab == smulv_optab ? addv_optab : add_optab,
-                      temp1, temp2, imagr, unsignedp, methods));
-
-	      if (res == 0)
-		break;
-	      else if (res != imagr)
-		emit_move_insn (imagr, res);
-
-	      ok = 1;
-	    }
-	  else
-	    {
-	      /* Don't fetch these from memory more than once.  */
-	      real0 = force_reg (submode, real0);
-	      real1 = force_reg (submode, real1);
-
-	      res = expand_binop (submode, binoptab, real0, real1,
-				  realr, unsignedp, methods);
-	      if (res == 0)
-		break;
-	      else if (res != realr)
-		emit_move_insn (realr, res);
-
-	      if (imag0 != 0)
-		res = expand_binop (submode, binoptab,
-				    real1, imag0, imagr, unsignedp, methods);
-	      else
-		res = expand_binop (submode, binoptab,
-				    real0, imag1, imagr, unsignedp, methods);
-
-	      if (res == 0)
-		break;
-	      else if (res != imagr)
-		emit_move_insn (imagr, res);
-
-	      ok = 1;
-	    }
-	  break;
-
-	case DIV:
-	  /* (a+ib) / (c+id) = ((ac+bd)/(cc+dd)) + i((bc-ad)/(cc+dd)) */
-	  
-	  if (imag1 == 0)
-	    {
-	      /* (a+ib) / (c+i0) = (a/c) + i(b/c) */
-
-	      /* Don't fetch these from memory more than once.  */
-	      real1 = force_reg (submode, real1);
-
-	      /* Simply divide the real and imaginary parts by `c' */
-	      if (class == MODE_COMPLEX_FLOAT)
-		res = expand_binop (submode, binoptab, real0, real1,
-				    realr, unsignedp, methods);
-	      else
-		res = expand_divmod (0, TRUNC_DIV_EXPR, submode,
-				     real0, real1, realr, unsignedp);
-
-	      if (res == 0)
-		break;
-	      else if (res != realr)
-		emit_move_insn (realr, res);
-
-	      if (class == MODE_COMPLEX_FLOAT)
-		res = expand_binop (submode, binoptab, imag0, real1,
-				    imagr, unsignedp, methods);
-	      else
-		res = expand_divmod (0, TRUNC_DIV_EXPR, submode,
-				     imag0, real1, imagr, unsignedp);
-
-	      if (res == 0)
-		break;
-	      else if (res != imagr)
-		emit_move_insn (imagr, res);
-
-	      ok = 1;
-	    }
-	  else
-	    {
-	      switch (flag_complex_divide_method)
-		{
-		case 0:
-		  ok = expand_cmplxdiv_straight (real0, real1, imag0, imag1,
-						 realr, imagr, submode,
-						 unsignedp, methods,
-						 class, binoptab);
-		  break;
-
-		case 1:
-		  ok = expand_cmplxdiv_wide (real0, real1, imag0, imag1,
-					     realr, imagr, submode,
-					     unsignedp, methods,
-					     class, binoptab);
-		  break;
-
-		default:
-		  abort ();
-		}
-	    }
-	  break;
-	  
-	default:
-	  abort ();
-	}
-
-      seq = get_insns ();
-      end_sequence ();
-
-      if (ok)
-	{
-	  if (binoptab->code != UNKNOWN)
-	    equiv_value
-	      = gen_rtx_fmt_ee (binoptab->code, mode,
-				copy_rtx (op0), copy_rtx (op1));
-	  else
-	    equiv_value = 0;
-	  
-	  emit_no_conflict_block (seq, target, op0, op1, equiv_value);
-      
-	  return target;
-	}
+        rtx real0 = 0, imag0 = 0;
+        rtx real1 = 0, imag1 = 0;
+        rtx realr, imagr, res;
+        rtx seq;
+        rtx equiv_value;
+        int ok = 0;
+        
+        /* Find the correct mode for the real and imaginary parts */
+        enum machine_mode submode
+        = mode_for_size (GET_MODE_UNIT_SIZE (mode) * BITS_PER_UNIT,
+                         class == MODE_COMPLEX_INT ? MODE_INT : MODE_FLOAT,
+                         0);
+        
+        if (submode == BLKmode)
+            abort ();
+        
+        if (! target)
+            target = gen_reg_rtx (mode);
+        
+        start_sequence ();
+        
+        realr = gen_realpart (submode, target);
+        imagr = gen_imagpart (submode, target);
+        
+        if (GET_MODE (op0) == mode)
+        {
+            real0 = gen_realpart (submode, op0);
+            imag0 = gen_imagpart (submode, op0);
+        }
+        else
+            real0 = op0;
+        
+        if (GET_MODE (op1) == mode)
+        {
+            real1 = gen_realpart (submode, op1);
+            imag1 = gen_imagpart (submode, op1);
+        }
+        else
+            real1 = op1;
+        
+        if (real0 == 0 || real1 == 0 || ! (imag0 != 0|| imag1 != 0))
+            abort ();
+        
+        switch (binoptab->code)
+        {
+            case PLUS:
+                /* (a+ib) + (c+id) = (a+c) + i(b+d) */
+            case MINUS:
+                /* (a+ib) - (c+id) = (a-c) + i(b-d) */
+                res = expand_binop (submode, binoptab, real0, real1,
+                                    realr, unsignedp, methods);
+                
+                if (res == 0)
+                    break;
+                else if (res != realr)
+                    emit_move_insn (realr, res);
+                
+                if (imag0 && imag1)
+                    res = expand_binop (submode, binoptab, imag0, imag1,
+                                        imagr, unsignedp, methods);
+                else if (imag0)
+                    res = imag0;
+                else if (binoptab->code == MINUS)
+                    res = expand_unop (submode,
+                                       binoptab == subv_optab ? negv_optab : neg_optab,
+                                       imag1, imagr, unsignedp);
+                else
+                    res = imag1;
+                
+                if (res == 0)
+                    break;
+                else if (res != imagr)
+                    emit_move_insn (imagr, res);
+                
+                ok = 1;
+                break;
+                
+            case MULT:
+                /* (a+ib) * (c+id) = (ac-bd) + i(ad+cb) */
+                
+                if (imag0 && imag1)
+                {
+                    rtx temp1, temp2;
+                    
+                    /* Don't fetch these from memory more than once.  */
+                    real0 = force_reg (submode, real0);
+                    real1 = force_reg (submode, real1);
+                    imag0 = force_reg (submode, imag0);
+                    imag1 = force_reg (submode, imag1);
+                    
+                    temp1 = expand_binop (submode, binoptab, real0, real1, NULL_RTX,
+                                          unsignedp, methods);
+                    
+                    temp2 = expand_binop (submode, binoptab, imag0, imag1, NULL_RTX,
+                                          unsignedp, methods);
+                    
+                    if (temp1 == 0 || temp2 == 0)
+                        break;
+                    
+                    res = (expand_binop
+                           (submode,
+                            binoptab == smulv_optab ? subv_optab : sub_optab,
+                            temp1, temp2, realr, unsignedp, methods));
+                    
+                    if (res == 0)
+                        break;
+                    else if (res != realr)
+                        emit_move_insn (realr, res);
+                    
+                    temp1 = expand_binop (submode, binoptab, real0, imag1,
+                                          NULL_RTX, unsignedp, methods);
+                    
+                    temp2 = expand_binop (submode, binoptab, real1, imag0,
+                                          NULL_RTX, unsignedp, methods);
+                    
+                    if (temp1 == 0 || temp2 == 0)
+                        break;
+                    
+                    res = (expand_binop
+                           (submode,
+                            binoptab == smulv_optab ? addv_optab : add_optab,
+                            temp1, temp2, imagr, unsignedp, methods));
+                    
+                    if (res == 0)
+                        break;
+                    else if (res != imagr)
+                        emit_move_insn (imagr, res);
+                    
+                    ok = 1;
+                }
+                else
+                {
+                    /* Don't fetch these from memory more than once.  */
+                    real0 = force_reg (submode, real0);
+                    real1 = force_reg (submode, real1);
+                    
+                    res = expand_binop (submode, binoptab, real0, real1,
+                                        realr, unsignedp, methods);
+                    if (res == 0)
+                        break;
+                    else if (res != realr)
+                        emit_move_insn (realr, res);
+                    
+                    if (imag0 != 0)
+                        res = expand_binop (submode, binoptab,
+                                            real1, imag0, imagr, unsignedp, methods);
+                    else
+                        res = expand_binop (submode, binoptab,
+                                            real0, imag1, imagr, unsignedp, methods);
+                    
+                    if (res == 0)
+                        break;
+                    else if (res != imagr)
+                        emit_move_insn (imagr, res);
+                    
+                    ok = 1;
+                }
+                break;
+                
+            case DIV:
+                /* (a+ib) / (c+id) = ((ac+bd)/(cc+dd)) + i((bc-ad)/(cc+dd)) */
+                
+                if (imag1 == 0)
+                {
+                    /* (a+ib) / (c+i0) = (a/c) + i(b/c) */
+                    
+                    /* Don't fetch these from memory more than once.  */
+                    real1 = force_reg (submode, real1);
+                    
+                    /* Simply divide the real and imaginary parts by `c' */
+                    if (class == MODE_COMPLEX_FLOAT)
+                        res = expand_binop (submode, binoptab, real0, real1,
+                                            realr, unsignedp, methods);
+                    else
+                        res = expand_divmod (0, TRUNC_DIV_EXPR, submode,
+                                             real0, real1, realr, unsignedp);
+                    
+                    if (res == 0)
+                        break;
+                    else if (res != realr)
+                        emit_move_insn (realr, res);
+                    
+                    if (class == MODE_COMPLEX_FLOAT)
+                        res = expand_binop (submode, binoptab, imag0, real1,
+                                            imagr, unsignedp, methods);
+                    else
+                        res = expand_divmod (0, TRUNC_DIV_EXPR, submode,
+                                             imag0, real1, imagr, unsignedp);
+                    
+                    if (res == 0)
+                        break;
+                    else if (res != imagr)
+                        emit_move_insn (imagr, res);
+                    
+                    ok = 1;
+                }
+                else
+                {
+                    switch (flag_complex_divide_method)
+                    {
+                        case 0:
+                            ok = expand_cmplxdiv_straight (real0, real1, imag0, imag1,
+                                                           realr, imagr, submode,
+                                                           unsignedp, methods,
+                                                           class, binoptab);
+                            break;
+                            
+                        case 1:
+                            ok = expand_cmplxdiv_wide (real0, real1, imag0, imag1,
+                                                       realr, imagr, submode,
+                                                       unsignedp, methods,
+                                                       class, binoptab);
+                            break;
+                            
+                        default:
+                            abort ();
+                    }
+                }
+                break;
+                
+            default:
+                abort ();
+        }
+        
+        seq = get_insns ();
+        end_sequence ();
+        
+        if (ok)
+        {
+            if (binoptab->code != UNKNOWN)
+                equiv_value
+                = gen_rtx_fmt_ee (binoptab->code, mode,
+                                  copy_rtx (op0), copy_rtx (op1));
+            else
+                equiv_value = 0;
+            
+            emit_no_conflict_block (seq, target, op0, op1, equiv_value);
+            
+            return target;
+        }
     }
-
-  /* It can't be open-coded in this mode.
+    
+    /* It can't be open-coded in this mode.
      Use a library call if one is available and caller says that's ok.  */
-
-  if (binoptab->handlers[(int) mode].libfunc
-      && (methods == OPTAB_LIB || methods == OPTAB_LIB_WIDEN))
+    
+    if (binoptab->handlers[(int) mode].libfunc
+        && (methods == OPTAB_LIB || methods == OPTAB_LIB_WIDEN))
     {
-      rtx insns;
-      rtx op1x = op1;
-      enum machine_mode op1_mode = mode;
-      rtx value;
-
-      start_sequence ();
-
-      if (shift_op)
-	{
-	  op1_mode = word_mode;
-	  /* Specify unsigned here,
-	     since negative shift counts are meaningless.  */
-	  op1x = convert_to_mode (word_mode, op1, 1);
-	}
-
-      if (GET_MODE (op0) != VOIDmode
-	  && GET_MODE (op0) != mode)
-	op0 = convert_to_mode (mode, op0, unsignedp);
-
-      /* Pass 1 for NO_QUEUE so we don't lose any increments
-	 if the libcall is cse'd or moved.  */
-      value = emit_library_call_value (binoptab->handlers[(int) mode].libfunc,
-				       NULL_RTX, LCT_CONST, mode, 2,
-				       op0, mode, op1x, op1_mode);
-
-      insns = get_insns ();
-      end_sequence ();
-
-      target = gen_reg_rtx (mode);
-      emit_libcall_block (insns, target, value,
-			  gen_rtx_fmt_ee (binoptab->code, mode, op0, op1));
-
-      return target;
+        rtx insns;
+        rtx op1x = op1;
+        enum machine_mode op1_mode = mode;
+        rtx value;
+        
+        start_sequence ();
+        
+        if (shift_op)
+        {
+            op1_mode = word_mode;
+            /* Specify unsigned here,
+             since negative shift counts are meaningless.  */
+            op1x = convert_to_mode (word_mode, op1, 1);
+        }
+        
+        if (GET_MODE (op0) != VOIDmode
+            && GET_MODE (op0) != mode)
+            op0 = convert_to_mode (mode, op0, unsignedp);
+        
+        /* Pass 1 for NO_QUEUE so we don't lose any increments
+         if the libcall is cse'd or moved.  */
+        value = emit_library_call_value (binoptab->handlers[(int) mode].libfunc,
+                                         NULL_RTX, LCT_CONST, mode, 2,
+                                         op0, mode, op1x, op1_mode);
+        
+        insns = get_insns ();
+        end_sequence ();
+        
+        target = gen_reg_rtx (mode);
+        emit_libcall_block (insns, target, value,
+                            gen_rtx_fmt_ee (binoptab->code, mode, op0, op1));
+        
+        return target;
     }
-
-  delete_insns_since (last);
-
-  /* It can't be done in this mode.  Can we do it in a wider mode?  */
-
-  if (! (methods == OPTAB_WIDEN || methods == OPTAB_LIB_WIDEN
-	 || methods == OPTAB_MUST_WIDEN))
+    
+    delete_insns_since (last);
+    
+    /* It can't be done in this mode.  Can we do it in a wider mode?  */
+    
+    if (! (methods == OPTAB_WIDEN || methods == OPTAB_LIB_WIDEN
+           || methods == OPTAB_MUST_WIDEN))
     {
-      /* Caller says, don't even try.  */
-      delete_insns_since (entry_last);
-      return 0;
+        /* Caller says, don't even try.  */
+        delete_insns_since (entry_last);
+        return 0;
     }
-
-  /* Compute the value of METHODS to pass to recursive calls.
+    
+    /* Compute the value of METHODS to pass to recursive calls.
      Don't allow widening to be tried recursively.  */
-
-  methods = (methods == OPTAB_LIB_WIDEN ? OPTAB_LIB : OPTAB_DIRECT);
-
-  /* Look for a wider mode of the same class for which it appears we can do
+    
+    methods = (methods == OPTAB_LIB_WIDEN ? OPTAB_LIB : OPTAB_DIRECT);
+    
+    /* Look for a wider mode of the same class for which it appears we can do
      the operation.  */
-
-  if (class == MODE_INT || class == MODE_FLOAT || class == MODE_COMPLEX_FLOAT)
+    
+    if (class == MODE_INT || class == MODE_FLOAT || class == MODE_COMPLEX_FLOAT)
     {
-      for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
-	   wider_mode = GET_MODE_WIDER_MODE (wider_mode))
-	{
-	  if ((binoptab->handlers[(int) wider_mode].insn_code
-	       != CODE_FOR_nothing)
-	      || (methods == OPTAB_LIB
-		  && binoptab->handlers[(int) wider_mode].libfunc))
-	    {
-	      rtx xop0 = op0, xop1 = op1;
-	      int no_extend = 0;
-
-	      /* For certain integer operations, we need not actually extend
-		 the narrow operands, as long as we will truncate
-		 the results to the same narrowness.  */
-
-	      if ((binoptab == ior_optab || binoptab == and_optab
-		   || binoptab == xor_optab
-		   || binoptab == add_optab || binoptab == sub_optab
-		   || binoptab == smul_optab || binoptab == ashl_optab)
-		  && class == MODE_INT)
-		no_extend = 1;
-
-	      xop0 = widen_operand (xop0, wider_mode, mode,
-				    unsignedp, no_extend);
-
-	      /* The second operand of a shift must always be extended.  */
-	      xop1 = widen_operand (xop1, wider_mode, mode, unsignedp,
-				    no_extend && binoptab != ashl_optab);
-
-	      temp = expand_binop (wider_mode, binoptab, xop0, xop1, NULL_RTX,
-				   unsignedp, methods);
-	      if (temp)
-		{
-		  if (class != MODE_INT)
-		    {
-		      if (target == 0)
-			target = gen_reg_rtx (mode);
-		      convert_move (target, temp, 0);
-		      return target;
-		    }
-		  else
-		    return gen_lowpart (mode, temp);
-		}
-	      else
-		delete_insns_since (last);
-	    }
-	}
+        for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
+             wider_mode = GET_MODE_WIDER_MODE (wider_mode))
+        {
+            if ((binoptab->handlers[(int) wider_mode].insn_code
+                 != CODE_FOR_nothing)
+                || (methods == OPTAB_LIB
+                    && binoptab->handlers[(int) wider_mode].libfunc))
+            {
+                rtx xop0 = op0, xop1 = op1;
+                int no_extend = 0;
+                
+                /* For certain integer operations, we need not actually extend
+                 the narrow operands, as long as we will truncate
+                 the results to the same narrowness.  */
+                
+                if ((binoptab == ior_optab || binoptab == and_optab
+                     || binoptab == xor_optab
+                     || binoptab == add_optab || binoptab == sub_optab
+                     || binoptab == smul_optab || binoptab == ashl_optab)
+                    && class == MODE_INT)
+                    no_extend = 1;
+                
+                xop0 = widen_operand (xop0, wider_mode, mode,
+                                      unsignedp, no_extend);
+                
+                /* The second operand of a shift must always be extended.  */
+                xop1 = widen_operand (xop1, wider_mode, mode, unsignedp,
+                                      no_extend && binoptab != ashl_optab);
+                
+                temp = expand_binop (wider_mode, binoptab, xop0, xop1, NULL_RTX,
+                                     unsignedp, methods);
+                if (temp)
+                {
+                    if (class != MODE_INT)
+                    {
+                        if (target == 0)
+                            target = gen_reg_rtx (mode);
+                        convert_move (target, temp, 0);
+                        return target;
+                    }
+                    else
+                        return gen_lowpart (mode, temp);
+                }
+                else
+                    delete_insns_since (last);
+            }
+        }
     }
-
-  delete_insns_since (entry_last);
-  return 0;
+    
+    delete_insns_since (entry_last);
+    return 0;
 }
 
 /* Expand a binary operator which has both signed and unsigned forms.
-   UOPTAB is the optab for unsigned operations, and SOPTAB is for
-   signed operations.
-
-   If we widen unsigned operands, we may use a signed wider operation instead
-   of an unsigned wider operation, since the result would be the same.  */
+ UOPTAB is the optab for unsigned operations, and SOPTAB is for
+ signed operations.
+ 
+ If we widen unsigned operands, we may use a signed wider operation instead
+ of an unsigned wider operation, since the result would be the same.  */
 
 rtx
 sign_expand_binop (mode, uoptab, soptab, op0, op1, target, unsignedp, methods)
-    enum machine_mode mode;
-    optab uoptab, soptab;
-    rtx op0, op1, target;
-    int unsignedp;
-    enum optab_methods methods;
+enum machine_mode mode;
+optab uoptab, soptab;
+rtx op0, op1, target;
+int unsignedp;
+enum optab_methods methods;
 {
-  rtx temp;
-  optab direct_optab = unsignedp ? uoptab : soptab;
-  struct optab wide_soptab;
-
-  /* Do it without widening, if possible.  */
-  temp = expand_binop (mode, direct_optab, op0, op1, target,
-		       unsignedp, OPTAB_DIRECT);
-  if (temp || methods == OPTAB_DIRECT)
-    return temp;
-
-  /* Try widening to a signed int.  Make a fake signed optab that
+    rtx temp;
+    optab direct_optab = unsignedp ? uoptab : soptab;
+    struct optab wide_soptab;
+    
+    /* Do it without widening, if possible.  */
+    temp = expand_binop (mode, direct_optab, op0, op1, target,
+                         unsignedp, OPTAB_DIRECT);
+    if (temp || methods == OPTAB_DIRECT)
+        return temp;
+    
+    /* Try widening to a signed int.  Make a fake signed optab that
      hides any signed insn for direct use.  */
-  wide_soptab = *soptab;
-  wide_soptab.handlers[(int) mode].insn_code = CODE_FOR_nothing;
-  wide_soptab.handlers[(int) mode].libfunc = 0;
-
-  temp = expand_binop (mode, &wide_soptab, op0, op1, target,
-		       unsignedp, OPTAB_WIDEN);
-
-  /* For unsigned operands, try widening to an unsigned int.  */
-  if (temp == 0 && unsignedp)
-    temp = expand_binop (mode, uoptab, op0, op1, target,
-			 unsignedp, OPTAB_WIDEN);
-  if (temp || methods == OPTAB_WIDEN)
-    return temp;
-
-  /* Use the right width lib call if that exists.  */
-  temp = expand_binop (mode, direct_optab, op0, op1, target, unsignedp, OPTAB_LIB);
-  if (temp || methods == OPTAB_LIB)
-    return temp;
-
-  /* Must widen and use a lib call, use either signed or unsigned.  */
-  temp = expand_binop (mode, &wide_soptab, op0, op1, target,
-		       unsignedp, methods);
-  if (temp != 0)
-    return temp;
-  if (unsignedp)
-    return expand_binop (mode, uoptab, op0, op1, target,
-			 unsignedp, methods);
-  return 0;
+    wide_soptab = *soptab;
+    wide_soptab.handlers[(int) mode].insn_code = CODE_FOR_nothing;
+    wide_soptab.handlers[(int) mode].libfunc = 0;
+    
+    temp = expand_binop (mode, &wide_soptab, op0, op1, target,
+                         unsignedp, OPTAB_WIDEN);
+    
+    /* For unsigned operands, try widening to an unsigned int.  */
+    if (temp == 0 && unsignedp)
+        temp = expand_binop (mode, uoptab, op0, op1, target,
+                             unsignedp, OPTAB_WIDEN);
+    if (temp || methods == OPTAB_WIDEN)
+        return temp;
+    
+    /* Use the right width lib call if that exists.  */
+    temp = expand_binop (mode, direct_optab, op0, op1, target, unsignedp, OPTAB_LIB);
+    if (temp || methods == OPTAB_LIB)
+        return temp;
+    
+    /* Must widen and use a lib call, use either signed or unsigned.  */
+    temp = expand_binop (mode, &wide_soptab, op0, op1, target,
+                         unsignedp, methods);
+    if (temp != 0)
+        return temp;
+    if (unsignedp)
+        return expand_binop (mode, uoptab, op0, op1, target,
+                             unsignedp, methods);
+    return 0;
 }
 
 /* Generate code to perform an operation specified by BINOPTAB
-   on operands OP0 and OP1, with two results to TARG1 and TARG2.
-   We assume that the order of the operands for the instruction
-   is TARG0, OP0, OP1, TARG1, which would fit a pattern like
-   [(set TARG0 (operate OP0 OP1)) (set TARG1 (operate ...))].
-
-   Either TARG0 or TARG1 may be zero, but what that means is that
-   the result is not actually wanted.  We will generate it into
-   a dummy pseudo-reg and discard it.  They may not both be zero.
-
-   Returns 1 if this operation can be performed; 0 if not.  */
+ on operands OP0 and OP1, with two results to TARG1 and TARG2.
+ We assume that the order of the operands for the instruction
+ is TARG0, OP0, OP1, TARG1, which would fit a pattern like
+ [(set TARG0 (operate OP0 OP1)) (set TARG1 (operate ...))].
+ 
+ Either TARG0 or TARG1 may be zero, but what that means is that
+ the result is not actually wanted.  We will generate it into
+ a dummy pseudo-reg and discard it.  They may not both be zero.
+ 
+ Returns 1 if this operation can be performed; 0 if not.  */
 
 int
 expand_twoval_binop (binoptab, op0, op1, targ0, targ1, unsignedp)
-     optab binoptab;
-     rtx op0, op1;
-     rtx targ0, targ1;
-     int unsignedp;
+optab binoptab;
+rtx op0, op1;
+rtx targ0, targ1;
+int unsignedp;
 {
-  enum machine_mode mode = GET_MODE (targ0 ? targ0 : targ1);
-  enum mode_class class;
-  enum machine_mode wider_mode;
-  rtx entry_last = get_last_insn ();
-  rtx last;
-
-  class = GET_MODE_CLASS (mode);
-
-  op0 = protect_from_queue (op0, 0);
-  op1 = protect_from_queue (op1, 0);
-
-  if (flag_force_mem)
+    enum machine_mode mode = GET_MODE (targ0 ? targ0 : targ1);
+    enum mode_class class;
+    enum machine_mode wider_mode;
+    rtx entry_last = get_last_insn ();
+    rtx last;
+    
+    class = GET_MODE_CLASS (mode);
+    
+    op0 = protect_from_queue (op0, 0);
+    op1 = protect_from_queue (op1, 0);
+    
+    if (flag_force_mem)
     {
-      op0 = force_not_mem (op0);
-      op1 = force_not_mem (op1);
+        op0 = force_not_mem (op0);
+        op1 = force_not_mem (op1);
     }
-
-  /* If we are inside an appropriately-short loop and one operand is an
+    
+    /* If we are inside an appropriately-short loop and one operand is an
      expensive constant, force it into a register.  */
-  if (CONSTANT_P (op0) && preserve_subexpressions_p ()
-      && rtx_cost (op0, binoptab->code) > COSTS_N_INSNS (1))
-    op0 = force_reg (mode, op0);
-
-  if (CONSTANT_P (op1) && preserve_subexpressions_p ()
-      && rtx_cost (op1, binoptab->code) > COSTS_N_INSNS (1))
-    op1 = force_reg (mode, op1);
-
-  if (targ0)
-    targ0 = protect_from_queue (targ0, 1);
-  else
-    targ0 = gen_reg_rtx (mode);
-  if (targ1)
-    targ1 = protect_from_queue (targ1, 1);
-  else
-    targ1 = gen_reg_rtx (mode);
-
-  /* Record where to go back to if we fail.  */
-  last = get_last_insn ();
-
-  if (binoptab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
+    if (CONSTANT_P (op0) && preserve_subexpressions_p ()
+        && rtx_cost (op0, binoptab->code) > COSTS_N_INSNS (1))
+        op0 = force_reg (mode, op0);
+    
+    if (CONSTANT_P (op1) && preserve_subexpressions_p ()
+        && rtx_cost (op1, binoptab->code) > COSTS_N_INSNS (1))
+        op1 = force_reg (mode, op1);
+    
+    if (targ0)
+        targ0 = protect_from_queue (targ0, 1);
+    else
+        targ0 = gen_reg_rtx (mode);
+    if (targ1)
+        targ1 = protect_from_queue (targ1, 1);
+    else
+        targ1 = gen_reg_rtx (mode);
+    
+    /* Record where to go back to if we fail.  */
+    last = get_last_insn ();
+    
+    if (binoptab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
     {
-      int icode = (int) binoptab->handlers[(int) mode].insn_code;
-      enum machine_mode mode0 = insn_data[icode].operand[1].mode;
-      enum machine_mode mode1 = insn_data[icode].operand[2].mode;
-      rtx pat;
-      rtx xop0 = op0, xop1 = op1;
-
-      /* In case this insn wants input operands in modes different from the
-	 result, convert the operands.  */
-      if (GET_MODE (op0) != VOIDmode && GET_MODE (op0) != mode0)
-	xop0 = convert_to_mode (mode0, xop0, unsignedp);
-
-      if (GET_MODE (op1) != VOIDmode && GET_MODE (op1) != mode1)
-	xop1 = convert_to_mode (mode1, xop1, unsignedp);
-
-      /* Now, if insn doesn't accept these operands, put them into pseudos.  */
-      if (! (*insn_data[icode].operand[1].predicate) (xop0, mode0))
-	xop0 = copy_to_mode_reg (mode0, xop0);
-
-      if (! (*insn_data[icode].operand[2].predicate) (xop1, mode1))
-	xop1 = copy_to_mode_reg (mode1, xop1);
-
-      /* We could handle this, but we should always be called with a pseudo
-	 for our targets and all insns should take them as outputs.  */
-      if (! (*insn_data[icode].operand[0].predicate) (targ0, mode)
-	  || ! (*insn_data[icode].operand[3].predicate) (targ1, mode))
-	abort ();
-	
-      pat = GEN_FCN (icode) (targ0, xop0, xop1, targ1);
-      if (pat)
-	{
-	  emit_insn (pat);
-	  return 1;
-	}
-      else
-	delete_insns_since (last);
+        int icode = (int) binoptab->handlers[(int) mode].insn_code;
+        enum machine_mode mode0 = insn_data[icode].operand[1].mode;
+        enum machine_mode mode1 = insn_data[icode].operand[2].mode;
+        rtx pat;
+        rtx xop0 = op0, xop1 = op1;
+        
+        /* In case this insn wants input operands in modes different from the
+         result, convert the operands.  */
+        if (GET_MODE (op0) != VOIDmode && GET_MODE (op0) != mode0)
+            xop0 = convert_to_mode (mode0, xop0, unsignedp);
+        
+        if (GET_MODE (op1) != VOIDmode && GET_MODE (op1) != mode1)
+            xop1 = convert_to_mode (mode1, xop1, unsignedp);
+        
+        /* Now, if insn doesn't accept these operands, put them into pseudos.  */
+        if (! (*insn_data[icode].operand[1].predicate) (xop0, mode0))
+            xop0 = copy_to_mode_reg (mode0, xop0);
+        
+        if (! (*insn_data[icode].operand[2].predicate) (xop1, mode1))
+            xop1 = copy_to_mode_reg (mode1, xop1);
+        
+        /* We could handle this, but we should always be called with a pseudo
+         for our targets and all insns should take them as outputs.  */
+        if (! (*insn_data[icode].operand[0].predicate) (targ0, mode)
+            || ! (*insn_data[icode].operand[3].predicate) (targ1, mode))
+            abort ();
+        
+        pat = GEN_FCN4 (icode) (targ0, xop0, xop1, targ1);
+        if (pat)
+        {
+            emit_insn (pat);
+            return 1;
+        }
+        else
+            delete_insns_since (last);
     }
-
-  /* It can't be done in this mode.  Can we do it in a wider mode?  */
-
-  if (class == MODE_INT || class == MODE_FLOAT || class == MODE_COMPLEX_FLOAT)
+    
+    /* It can't be done in this mode.  Can we do it in a wider mode?  */
+    
+    if (class == MODE_INT || class == MODE_FLOAT || class == MODE_COMPLEX_FLOAT)
     {
-      for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
-	   wider_mode = GET_MODE_WIDER_MODE (wider_mode))
-	{
-	  if (binoptab->handlers[(int) wider_mode].insn_code
-	      != CODE_FOR_nothing)
-	    {
-	      rtx t0 = gen_reg_rtx (wider_mode);
-	      rtx t1 = gen_reg_rtx (wider_mode);
-	      rtx cop0 = convert_modes (wider_mode, mode, op0, unsignedp);
-	      rtx cop1 = convert_modes (wider_mode, mode, op1, unsignedp);
-
-	      if (expand_twoval_binop (binoptab, cop0, cop1,
-				       t0, t1, unsignedp))
-		{
-		  convert_move (targ0, t0, unsignedp);
-		  convert_move (targ1, t1, unsignedp);
-		  return 1;
-		}
-	      else
-		delete_insns_since (last);
-	    }
-	}
+        for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
+             wider_mode = GET_MODE_WIDER_MODE (wider_mode))
+        {
+            if (binoptab->handlers[(int) wider_mode].insn_code
+                != CODE_FOR_nothing)
+            {
+                rtx t0 = gen_reg_rtx (wider_mode);
+                rtx t1 = gen_reg_rtx (wider_mode);
+                rtx cop0 = convert_modes (wider_mode, mode, op0, unsignedp);
+                rtx cop1 = convert_modes (wider_mode, mode, op1, unsignedp);
+                
+                if (expand_twoval_binop (binoptab, cop0, cop1,
+                                         t0, t1, unsignedp))
+                {
+                    convert_move (targ0, t0, unsignedp);
+                    convert_move (targ1, t1, unsignedp);
+                    return 1;
+                }
+                else
+                    delete_insns_since (last);
+            }
+        }
     }
-
-  delete_insns_since (entry_last);
-  return 0;
+    
+    delete_insns_since (entry_last);
+    return 0;
 }
 
 /* Wrapper around expand_unop which takes an rtx code to specify
-   the operation to perform, not an optab pointer.  All other
-   arguments are the same.  */
+ the operation to perform, not an optab pointer.  All other
+ arguments are the same.  */
 rtx
 expand_simple_unop (mode, code, op0, target, unsignedp)
-     enum machine_mode mode;
-     enum rtx_code code;
-     rtx op0;
-     rtx target;
-     int unsignedp;
+enum machine_mode mode;
+enum rtx_code code;
+rtx op0;
+rtx target;
+int unsignedp;
 {
-  optab unop = code_to_optab [(int) code];
-  if (unop == 0)
-    abort ();
-
-  return expand_unop (mode, unop, op0, target, unsignedp);
+    optab unop = code_to_optab [(int) code];
+    if (unop == 0)
+        abort ();
+    
+    return expand_unop (mode, unop, op0, target, unsignedp);
 }
 
 /* Generate code to perform an operation specified by UNOPTAB
-   on operand OP0, with result having machine-mode MODE.
-
-   UNSIGNEDP is for the case where we have to widen the operands
-   to perform the operation.  It says to use zero-extension.
-
-   If TARGET is nonzero, the value
-   is generated there, if it is convenient to do so.
-   In all cases an rtx is returned for the locus of the value;
-   this may or may not be TARGET.  */
+ on operand OP0, with result having machine-mode MODE.
+ 
+ UNSIGNEDP is for the case where we have to widen the operands
+ to perform the operation.  It says to use zero-extension.
+ 
+ If TARGET is nonzero, the value
+ is generated there, if it is convenient to do so.
+ In all cases an rtx is returned for the locus of the value;
+ this may or may not be TARGET.  */
 
 rtx
 expand_unop (mode, unoptab, op0, target, unsignedp)
-     enum machine_mode mode;
-     optab unoptab;
-     rtx op0;
-     rtx target;
-     int unsignedp;
+enum machine_mode mode;
+optab unoptab;
+rtx op0;
+rtx target;
+int unsignedp;
 {
-  enum mode_class class;
-  enum machine_mode wider_mode;
-  rtx temp;
-  rtx last = get_last_insn ();
-  rtx pat;
-
-  class = GET_MODE_CLASS (mode);
-
-  op0 = protect_from_queue (op0, 0);
-
-  if (flag_force_mem)
+    enum mode_class class;
+    enum machine_mode wider_mode;
+    rtx temp;
+    rtx last = get_last_insn ();
+    rtx pat;
+    
+    class = GET_MODE_CLASS (mode);
+    
+    op0 = protect_from_queue (op0, 0);
+    
+    if (flag_force_mem)
     {
-      op0 = force_not_mem (op0);
+        op0 = force_not_mem (op0);
     }
-
-  if (target)
-    target = protect_from_queue (target, 1);
-
-  if (unoptab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
+    
+    if (target)
+        target = protect_from_queue (target, 1);
+    
+    if (unoptab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
     {
-      int icode = (int) unoptab->handlers[(int) mode].insn_code;
-      enum machine_mode mode0 = insn_data[icode].operand[1].mode;
-      rtx xop0 = op0;
-
-      if (target)
-	temp = target;
-      else
-	temp = gen_reg_rtx (mode);
-
-      if (GET_MODE (xop0) != VOIDmode
-	  && GET_MODE (xop0) != mode0)
-	xop0 = convert_to_mode (mode0, xop0, unsignedp);
-
-      /* Now, if insn doesn't accept our operand, put it into a pseudo.  */
-
-      if (! (*insn_data[icode].operand[1].predicate) (xop0, mode0))
-	xop0 = copy_to_mode_reg (mode0, xop0);
-
-      if (! (*insn_data[icode].operand[0].predicate) (temp, mode))
-	temp = gen_reg_rtx (mode);
-
-      pat = GEN_FCN (icode) (temp, xop0);
-      if (pat)
-	{
-	  if (GET_CODE (pat) == SEQUENCE
-	      && ! add_equal_note (pat, temp, unoptab->code, xop0, NULL_RTX))
-	    {
-	      delete_insns_since (last);
-	      return expand_unop (mode, unoptab, op0, NULL_RTX, unsignedp);
-	    }
-
-	  emit_insn (pat);
-	  
-	  return temp;
-	}
-      else
-	delete_insns_since (last);
+        int icode = (int) unoptab->handlers[(int) mode].insn_code;
+        enum machine_mode mode0 = insn_data[icode].operand[1].mode;
+        rtx xop0 = op0;
+        
+        if (target)
+            temp = target;
+        else
+            temp = gen_reg_rtx (mode);
+        
+        if (GET_MODE (xop0) != VOIDmode
+            && GET_MODE (xop0) != mode0)
+            xop0 = convert_to_mode (mode0, xop0, unsignedp);
+        
+        /* Now, if insn doesn't accept our operand, put it into a pseudo.  */
+        
+        if (! (*insn_data[icode].operand[1].predicate) (xop0, mode0))
+            xop0 = copy_to_mode_reg (mode0, xop0);
+        
+        if (! (*insn_data[icode].operand[0].predicate) (temp, mode))
+            temp = gen_reg_rtx (mode);
+        
+        pat = GEN_FCN2 (icode) (temp, xop0);
+        if (pat)
+        {
+            if (GET_CODE (pat) == SEQUENCE
+                && ! add_equal_note (pat, temp, unoptab->code, xop0, NULL_RTX))
+            {
+                delete_insns_since (last);
+                return expand_unop (mode, unoptab, op0, NULL_RTX, unsignedp);
+            }
+            
+            emit_insn (pat);
+            
+            return temp;
+        }
+        else
+            delete_insns_since (last);
     }
-
-  /* It can't be done in this mode.  Can we open-code it in a wider mode?  */
-
-  if (class == MODE_INT || class == MODE_FLOAT || class == MODE_COMPLEX_FLOAT)
-    for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
-	 wider_mode = GET_MODE_WIDER_MODE (wider_mode))
-      {
-	if (unoptab->handlers[(int) wider_mode].insn_code != CODE_FOR_nothing)
-	  {
-	    rtx xop0 = op0;
-
-	    /* For certain operations, we need not actually extend
-	       the narrow operand, as long as we will truncate the
-	       results to the same narrowness.  */
-
-	    xop0 = widen_operand (xop0, wider_mode, mode, unsignedp,
-				  (unoptab == neg_optab
-				   || unoptab == one_cmpl_optab)
-				  && class == MODE_INT);
-	      
-	    temp = expand_unop (wider_mode, unoptab, xop0, NULL_RTX,
-				unsignedp);
-
-	    if (temp)
-	      {
-		if (class != MODE_INT)
-		  {
-		    if (target == 0)
-		      target = gen_reg_rtx (mode);
-		    convert_move (target, temp, 0);
-		    return target;
-		  }
-		else
-		  return gen_lowpart (mode, temp);
-	      }
-	    else
-	      delete_insns_since (last);
-	  }
-      }
-
-  /* These can be done a word at a time.  */
-  if (unoptab == one_cmpl_optab
-      && class == MODE_INT
-      && GET_MODE_SIZE (mode) > UNITS_PER_WORD
-      && unoptab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing)
+    
+    /* It can't be done in this mode.  Can we open-code it in a wider mode?  */
+    
+    if (class == MODE_INT || class == MODE_FLOAT || class == MODE_COMPLEX_FLOAT)
+        for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
+             wider_mode = GET_MODE_WIDER_MODE (wider_mode))
     {
-      int i;
-      rtx insns;
-
-      if (target == 0 || target == op0)
-	target = gen_reg_rtx (mode);
-
-      start_sequence ();
-
-      /* Do the actual arithmetic.  */
-      for (i = 0; i < GET_MODE_BITSIZE (mode) / BITS_PER_WORD; i++)
-	{
-	  rtx target_piece = operand_subword (target, i, 1, mode);
-	  rtx x = expand_unop (word_mode, unoptab,
-			       operand_subword_force (op0, i, mode),
-			       target_piece, unsignedp);
-
-	  if (target_piece != x)
-	    emit_move_insn (target_piece, x);
-	}
-
-      insns = get_insns ();
-      end_sequence ();
-
-      emit_no_conflict_block (insns, target, op0, NULL_RTX,
-			      gen_rtx_fmt_e (unoptab->code, mode,
-					     copy_rtx (op0)));
-      return target;
+        if (unoptab->handlers[(int) wider_mode].insn_code != CODE_FOR_nothing)
+        {
+            rtx xop0 = op0;
+            
+            /* For certain operations, we need not actually extend
+             the narrow operand, as long as we will truncate the
+             results to the same narrowness.  */
+            
+            xop0 = widen_operand (xop0, wider_mode, mode, unsignedp,
+                                  (unoptab == neg_optab
+                                   || unoptab == one_cmpl_optab)
+                                  && class == MODE_INT);
+            
+            temp = expand_unop (wider_mode, unoptab, xop0, NULL_RTX,
+                                unsignedp);
+            
+            if (temp)
+            {
+                if (class != MODE_INT)
+                {
+                    if (target == 0)
+                        target = gen_reg_rtx (mode);
+                    convert_move (target, temp, 0);
+                    return target;
+                }
+                else
+                    return gen_lowpart (mode, temp);
+            }
+            else
+                delete_insns_since (last);
+        }
     }
-
-  /* Open-code the complex negation operation.  */
-  else if (unoptab->code == NEG
-	   && (class == MODE_COMPLEX_FLOAT || class == MODE_COMPLEX_INT))
+    
+    /* These can be done a word at a time.  */
+    if (unoptab == one_cmpl_optab
+        && class == MODE_INT
+        && GET_MODE_SIZE (mode) > UNITS_PER_WORD
+        && unoptab->handlers[(int) word_mode].insn_code != CODE_FOR_nothing)
     {
-      rtx target_piece;
-      rtx x;
-      rtx seq;
-
-      /* Find the correct mode for the real and imaginary parts */
-      enum machine_mode submode
-	= mode_for_size (GET_MODE_UNIT_SIZE (mode) * BITS_PER_UNIT,
-			 class == MODE_COMPLEX_INT ? MODE_INT : MODE_FLOAT,
-			 0);
-
-      if (submode == BLKmode)
-	abort ();
-
-      if (target == 0)
-	target = gen_reg_rtx (mode);
-      
-      start_sequence ();
-
-      target_piece = gen_imagpart (submode, target);
-      x = expand_unop (submode, unoptab,
-		       gen_imagpart (submode, op0),
-		       target_piece, unsignedp);
-      if (target_piece != x)
-	emit_move_insn (target_piece, x);
-
-      target_piece = gen_realpart (submode, target);
-      x = expand_unop (submode, unoptab,
-		       gen_realpart (submode, op0),
-		       target_piece, unsignedp);
-      if (target_piece != x)
-	emit_move_insn (target_piece, x);
-
-      seq = get_insns ();
-      end_sequence ();
-
-      emit_no_conflict_block (seq, target, op0, 0,
-			      gen_rtx_fmt_e (unoptab->code, mode,
-					     copy_rtx (op0)));
-      return target;
+        int i;
+        rtx insns;
+        
+        if (target == 0 || target == op0)
+            target = gen_reg_rtx (mode);
+        
+        start_sequence ();
+        
+        /* Do the actual arithmetic.  */
+        for (i = 0; i < GET_MODE_BITSIZE (mode) / BITS_PER_WORD; i++)
+        {
+            rtx target_piece = operand_subword (target, i, 1, mode);
+            rtx x = expand_unop (word_mode, unoptab,
+                                 operand_subword_force (op0, i, mode),
+                                 target_piece, unsignedp);
+            
+            if (target_piece != x)
+                emit_move_insn (target_piece, x);
+        }
+        
+        insns = get_insns ();
+        end_sequence ();
+        
+        emit_no_conflict_block (insns, target, op0, NULL_RTX,
+                                gen_rtx_fmt_e (unoptab->code, mode,
+                                               copy_rtx (op0)));
+        return target;
     }
-
-  /* Now try a library call in this mode.  */
-  if (unoptab->handlers[(int) mode].libfunc)
+    
+    /* Open-code the complex negation operation.  */
+    else if (unoptab->code == NEG
+             && (class == MODE_COMPLEX_FLOAT || class == MODE_COMPLEX_INT))
     {
-      rtx insns;
-      rtx value;
-
-      start_sequence ();
-
-      /* Pass 1 for NO_QUEUE so we don't lose any increments
-	 if the libcall is cse'd or moved.  */
-      value = emit_library_call_value (unoptab->handlers[(int) mode].libfunc,
-				       NULL_RTX, LCT_CONST, mode, 1, op0, mode);
-      insns = get_insns ();
-      end_sequence ();
-
-      target = gen_reg_rtx (mode);
-      emit_libcall_block (insns, target, value,
-			  gen_rtx_fmt_e (unoptab->code, mode, op0));
-
-      return target;
+        rtx target_piece;
+        rtx x;
+        rtx seq;
+        
+        /* Find the correct mode for the real and imaginary parts */
+        enum machine_mode submode
+        = mode_for_size (GET_MODE_UNIT_SIZE (mode) * BITS_PER_UNIT,
+                         class == MODE_COMPLEX_INT ? MODE_INT : MODE_FLOAT,
+                         0);
+        
+        if (submode == BLKmode)
+            abort ();
+        
+        if (target == 0)
+            target = gen_reg_rtx (mode);
+        
+        start_sequence ();
+        
+        target_piece = gen_imagpart (submode, target);
+        x = expand_unop (submode, unoptab,
+                         gen_imagpart (submode, op0),
+                         target_piece, unsignedp);
+        if (target_piece != x)
+            emit_move_insn (target_piece, x);
+        
+        target_piece = gen_realpart (submode, target);
+        x = expand_unop (submode, unoptab,
+                         gen_realpart (submode, op0),
+                         target_piece, unsignedp);
+        if (target_piece != x)
+            emit_move_insn (target_piece, x);
+        
+        seq = get_insns ();
+        end_sequence ();
+        
+        emit_no_conflict_block (seq, target, op0, 0,
+                                gen_rtx_fmt_e (unoptab->code, mode,
+                                               copy_rtx (op0)));
+        return target;
     }
-
-  /* It can't be done in this mode.  Can we do it in a wider mode?  */
-
-  if (class == MODE_INT || class == MODE_FLOAT || class == MODE_COMPLEX_FLOAT)
+    
+    /* Now try a library call in this mode.  */
+    if (unoptab->handlers[(int) mode].libfunc)
     {
-      for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
-	   wider_mode = GET_MODE_WIDER_MODE (wider_mode))
-	{
-	  if ((unoptab->handlers[(int) wider_mode].insn_code
-	       != CODE_FOR_nothing)
-	      || unoptab->handlers[(int) wider_mode].libfunc)
-	    {
-	      rtx xop0 = op0;
-
-	      /* For certain operations, we need not actually extend
-		 the narrow operand, as long as we will truncate the
-		 results to the same narrowness.  */
-
-	      xop0 = widen_operand (xop0, wider_mode, mode, unsignedp,
-				    (unoptab == neg_optab
-				     || unoptab == one_cmpl_optab)
-				    && class == MODE_INT);
-	      
-	      temp = expand_unop (wider_mode, unoptab, xop0, NULL_RTX,
-				  unsignedp);
-
-	      if (temp)
-		{
-		  if (class != MODE_INT)
-		    {
-		      if (target == 0)
-			target = gen_reg_rtx (mode);
-		      convert_move (target, temp, 0);
-		      return target;
-		    }
-		  else
-		    return gen_lowpart (mode, temp);
-		}
-	      else
-		delete_insns_since (last);
-	    }
-	}
+        rtx insns;
+        rtx value;
+        
+        start_sequence ();
+        
+        /* Pass 1 for NO_QUEUE so we don't lose any increments
+         if the libcall is cse'd or moved.  */
+        value = emit_library_call_value (unoptab->handlers[(int) mode].libfunc,
+                                         NULL_RTX, LCT_CONST, mode, 1, op0, mode);
+        insns = get_insns ();
+        end_sequence ();
+        
+        target = gen_reg_rtx (mode);
+        emit_libcall_block (insns, target, value,
+                            gen_rtx_fmt_e (unoptab->code, mode, op0));
+        
+        return target;
     }
-
-  /* If there is no negate operation, try doing a subtract from zero.
+    
+    /* It can't be done in this mode.  Can we do it in a wider mode?  */
+    
+    if (class == MODE_INT || class == MODE_FLOAT || class == MODE_COMPLEX_FLOAT)
+    {
+        for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
+             wider_mode = GET_MODE_WIDER_MODE (wider_mode))
+        {
+            if ((unoptab->handlers[(int) wider_mode].insn_code
+                 != CODE_FOR_nothing)
+                || unoptab->handlers[(int) wider_mode].libfunc)
+            {
+                rtx xop0 = op0;
+                
+                /* For certain operations, we need not actually extend
+                 the narrow operand, as long as we will truncate the
+                 results to the same narrowness.  */
+                
+                xop0 = widen_operand (xop0, wider_mode, mode, unsignedp,
+                                      (unoptab == neg_optab
+                                       || unoptab == one_cmpl_optab)
+                                      && class == MODE_INT);
+                
+                temp = expand_unop (wider_mode, unoptab, xop0, NULL_RTX,
+                                    unsignedp);
+                
+                if (temp)
+                {
+                    if (class != MODE_INT)
+                    {
+                        if (target == 0)
+                            target = gen_reg_rtx (mode);
+                        convert_move (target, temp, 0);
+                        return target;
+                    }
+                    else
+                        return gen_lowpart (mode, temp);
+                }
+                else
+                    delete_insns_since (last);
+            }
+        }
+    }
+    
+    /* If there is no negate operation, try doing a subtract from zero.
      The US Software GOFAST library needs this.  */
-  if (unoptab->code == NEG)
-    {    
-      rtx temp;
-      temp = expand_binop (mode,
-                           unoptab == negv_optab ? subv_optab : sub_optab,
-                           CONST0_RTX (mode), op0,
-                           target, unsignedp, OPTAB_LIB_WIDEN);
-      if (temp)
-	return temp;
+    if (unoptab->code == NEG)
+    {
+        rtx temp;
+        temp = expand_binop (mode,
+                             unoptab == negv_optab ? subv_optab : sub_optab,
+                             CONST0_RTX (mode), op0,
+                             target, unsignedp, OPTAB_LIB_WIDEN);
+        if (temp)
+            return temp;
     }
-      
-  return 0;
+    
+    return 0;
 }
 
 /* Emit code to compute the absolute value of OP0, with result to
-   TARGET if convenient.  (TARGET may be 0.)  The return value says
-   where the result actually is to be found.
-
-   MODE is the mode of the operand; the mode of the result is
-   different but can be deduced from MODE.
-
+ TARGET if convenient.  (TARGET may be 0.)  The return value says
+ where the result actually is to be found.
+ 
+ MODE is the mode of the operand; the mode of the result is
+ different but can be deduced from MODE.
+ 
  */
 
 rtx
 expand_abs (mode, op0, target, result_unsignedp, safe)
-     enum machine_mode mode;
-     rtx op0;
-     rtx target;
-     int result_unsignedp;
-     int safe;
+enum machine_mode mode;
+rtx op0;
+rtx target;
+int result_unsignedp;
+int safe;
 {
-  rtx temp, op1;
-
-  if (! flag_trapv)
-    result_unsignedp = 1;
-
-  /* First try to do it with a special abs instruction.  */
-  temp = expand_unop (mode, result_unsignedp ? abs_optab : absv_optab,
-                      op0, target, 0);
-  if (temp != 0)
-    return temp;
-
-  /* If we have a MAX insn, we can do this as MAX (x, -x).  */
-  if (smax_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
+    rtx temp, op1;
+    
+    if (! flag_trapv)
+        result_unsignedp = 1;
+    
+    /* First try to do it with a special abs instruction.  */
+    temp = expand_unop (mode, result_unsignedp ? abs_optab : absv_optab,
+                        op0, target, 0);
+    if (temp != 0)
+        return temp;
+    
+    /* If we have a MAX insn, we can do this as MAX (x, -x).  */
+    if (smax_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
     {
-      rtx last = get_last_insn ();
-
-      temp = expand_unop (mode, neg_optab, op0, NULL_RTX, 0);
-      if (temp != 0)
-	temp = expand_binop (mode, smax_optab, op0, temp, target, 0,
-			     OPTAB_WIDEN);
-
-      if (temp != 0)
-	return temp;
-
-      delete_insns_since (last);
+        rtx last = get_last_insn ();
+        
+        temp = expand_unop (mode, neg_optab, op0, NULL_RTX, 0);
+        if (temp != 0)
+            temp = expand_binop (mode, smax_optab, op0, temp, target, 0,
+                                 OPTAB_WIDEN);
+        
+        if (temp != 0)
+            return temp;
+        
+        delete_insns_since (last);
     }
-
-  /* If this machine has expensive jumps, we can do integer absolute
+    
+    /* If this machine has expensive jumps, we can do integer absolute
      value of X as (((signed) x >> (W-1)) ^ x) - ((signed) x >> (W-1)),
      where W is the width of MODE.  */
-
-  if (GET_MODE_CLASS (mode) == MODE_INT && BRANCH_COST >= 2)
+    
+    if (GET_MODE_CLASS (mode) == MODE_INT && BRANCH_COST >= 2)
     {
-      rtx extended = expand_shift (RSHIFT_EXPR, mode, op0,
-				   size_int (GET_MODE_BITSIZE (mode) - 1),
-				   NULL_RTX, 0);
-
-      temp = expand_binop (mode, xor_optab, extended, op0, target, 0,
-			   OPTAB_LIB_WIDEN);
-      if (temp != 0)
-	temp = expand_binop (mode, result_unsignedp ? sub_optab : subv_optab,
-                             temp, extended, target, 0, OPTAB_LIB_WIDEN);
-
-      if (temp != 0)
-	return temp;
+        rtx extended = expand_shift (RSHIFT_EXPR, mode, op0,
+                                     size_int (GET_MODE_BITSIZE (mode) - 1),
+                                     NULL_RTX, 0);
+        
+        temp = expand_binop (mode, xor_optab, extended, op0, target, 0,
+                             OPTAB_LIB_WIDEN);
+        if (temp != 0)
+            temp = expand_binop (mode, result_unsignedp ? sub_optab : subv_optab,
+                                 temp, extended, target, 0, OPTAB_LIB_WIDEN);
+        
+        if (temp != 0)
+            return temp;
     }
-
-  /* If that does not win, use conditional jump and negate.  */
-
-  /* It is safe to use the target if it is the same
+    
+    /* If that does not win, use conditional jump and negate.  */
+    
+    /* It is safe to use the target if it is the same
      as the source if this is also a pseudo register */
-  if (op0 == target && GET_CODE (op0) == REG
-      && REGNO (op0) >= FIRST_PSEUDO_REGISTER)
-    safe = 1;
-
-  op1 = gen_label_rtx ();
-  if (target == 0 || ! safe
-      || GET_MODE (target) != mode
-      || (GET_CODE (target) == MEM && MEM_VOLATILE_P (target))
-      || (GET_CODE (target) == REG
-	  && REGNO (target) < FIRST_PSEUDO_REGISTER))
-    target = gen_reg_rtx (mode);
-
-  emit_move_insn (target, op0);
-  NO_DEFER_POP;
-
-  /* If this mode is an integer too wide to compare properly,
-     compare word by word.  Rely on CSE to optimize constant cases.  */
-  if (GET_MODE_CLASS (mode) == MODE_INT
-      && ! can_compare_p (GE, mode, ccp_jump))
-    do_jump_by_parts_greater_rtx (mode, 0, target, const0_rtx, 
-				  NULL_RTX, op1);
-  else
-    do_compare_rtx_and_jump (target, CONST0_RTX (mode), GE, 0, mode,
-			     NULL_RTX, NULL_RTX, op1);
-
-  op0 = expand_unop (mode, result_unsignedp ? neg_optab : negv_optab,
-                     target, target, 0);
-  if (op0 != target)
+    if (op0 == target && GET_CODE (op0) == REG
+        && REGNO (op0) >= FIRST_PSEUDO_REGISTER)
+        safe = 1;
+    
+    op1 = gen_label_rtx ();
+    if (target == 0 || ! safe
+        || GET_MODE (target) != mode
+        || (GET_CODE (target) == MEM && MEM_VOLATILE_P (target))
+        || (GET_CODE (target) == REG
+            && REGNO (target) < FIRST_PSEUDO_REGISTER))
+        target = gen_reg_rtx (mode);
+    
     emit_move_insn (target, op0);
-  emit_label (op1);
-  OK_DEFER_POP;
-  return target;
+    NO_DEFER_POP;
+    
+    /* If this mode is an integer too wide to compare properly,
+     compare word by word.  Rely on CSE to optimize constant cases.  */
+    if (GET_MODE_CLASS (mode) == MODE_INT
+        && ! can_compare_p (GE, mode, ccp_jump))
+        do_jump_by_parts_greater_rtx (mode, 0, target, const0_rtx,
+                                      NULL_RTX, op1);
+    else
+        do_compare_rtx_and_jump (target, CONST0_RTX (mode), GE, 0, mode,
+                                 NULL_RTX, NULL_RTX, op1);
+    
+    op0 = expand_unop (mode, result_unsignedp ? neg_optab : negv_optab,
+                       target, target, 0);
+    if (op0 != target)
+        emit_move_insn (target, op0);
+    emit_label (op1);
+    OK_DEFER_POP;
+    return target;
 }
 
 /* Emit code to compute the absolute value of OP0, with result to
-   TARGET if convenient.  (TARGET may be 0.)  The return value says
-   where the result actually is to be found.
-
-   MODE is the mode of the operand; the mode of the result is
-   different but can be deduced from MODE.
-
-   UNSIGNEDP is relevant for complex integer modes.  */
+ TARGET if convenient.  (TARGET may be 0.)  The return value says
+ where the result actually is to be found.
+ 
+ MODE is the mode of the operand; the mode of the result is
+ different but can be deduced from MODE.
+ 
+ UNSIGNEDP is relevant for complex integer modes.  */
 
 rtx
 expand_complex_abs (mode, op0, target, unsignedp)
-     enum machine_mode mode;
-     rtx op0;
-     rtx target;
-     int unsignedp;
+enum machine_mode mode;
+rtx op0;
+rtx target;
+int unsignedp;
 {
-  enum mode_class class = GET_MODE_CLASS (mode);
-  enum machine_mode wider_mode;
-  rtx temp;
-  rtx entry_last = get_last_insn ();
-  rtx last;
-  rtx pat;
-  optab this_abs_optab;
-
-  /* Find the correct mode for the real and imaginary parts.  */
-  enum machine_mode submode
+    enum mode_class class = GET_MODE_CLASS (mode);
+    enum machine_mode wider_mode;
+    rtx temp;
+    rtx entry_last = get_last_insn ();
+    rtx last;
+    rtx pat;
+    optab this_abs_optab;
+    
+    /* Find the correct mode for the real and imaginary parts.  */
+    enum machine_mode submode
     = mode_for_size (GET_MODE_UNIT_SIZE (mode) * BITS_PER_UNIT,
-		     class == MODE_COMPLEX_INT ? MODE_INT : MODE_FLOAT,
-		     0);
-
-  if (submode == BLKmode)
-    abort ();
-
-  op0 = protect_from_queue (op0, 0);
-
-  if (flag_force_mem)
+                     class == MODE_COMPLEX_INT ? MODE_INT : MODE_FLOAT,
+                     0);
+    
+    if (submode == BLKmode)
+        abort ();
+    
+    op0 = protect_from_queue (op0, 0);
+    
+    if (flag_force_mem)
     {
-      op0 = force_not_mem (op0);
+        op0 = force_not_mem (op0);
     }
-
-  last = get_last_insn ();
-
-  if (target)
-    target = protect_from_queue (target, 1);
-
-  this_abs_optab = ! unsignedp && flag_trapv
-                   && (GET_MODE_CLASS(mode) == MODE_INT)
-                   ? absv_optab : abs_optab;
-
-  if (this_abs_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
+    
+    last = get_last_insn ();
+    
+    if (target)
+        target = protect_from_queue (target, 1);
+    
+    this_abs_optab = ! unsignedp && flag_trapv
+    && (GET_MODE_CLASS(mode) == MODE_INT)
+    ? absv_optab : abs_optab;
+    
+    if (this_abs_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
     {
-      int icode = (int) this_abs_optab->handlers[(int) mode].insn_code;
-      enum machine_mode mode0 = insn_data[icode].operand[1].mode;
-      rtx xop0 = op0;
-
-      if (target)
-	temp = target;
-      else
-	temp = gen_reg_rtx (submode);
-
-      if (GET_MODE (xop0) != VOIDmode
-	  && GET_MODE (xop0) != mode0)
-	xop0 = convert_to_mode (mode0, xop0, unsignedp);
-
-      /* Now, if insn doesn't accept our operand, put it into a pseudo.  */
-
-      if (! (*insn_data[icode].operand[1].predicate) (xop0, mode0))
-	xop0 = copy_to_mode_reg (mode0, xop0);
-
-      if (! (*insn_data[icode].operand[0].predicate) (temp, submode))
-	temp = gen_reg_rtx (submode);
-
-      pat = GEN_FCN (icode) (temp, xop0);
-      if (pat)
-	{
-	  if (GET_CODE (pat) == SEQUENCE
-	      && ! add_equal_note (pat, temp, this_abs_optab->code, xop0, 
-				   NULL_RTX))
-	    {
-	      delete_insns_since (last);
-	      return expand_unop (mode, this_abs_optab, op0, NULL_RTX, 
-				  unsignedp);
-	    }
-
-	  emit_insn (pat);
-	  
-	  return temp;
-	}
-      else
-	delete_insns_since (last);
+        int icode = (int) this_abs_optab->handlers[(int) mode].insn_code;
+        enum machine_mode mode0 = insn_data[icode].operand[1].mode;
+        rtx xop0 = op0;
+        
+        if (target)
+            temp = target;
+        else
+            temp = gen_reg_rtx (submode);
+        
+        if (GET_MODE (xop0) != VOIDmode
+            && GET_MODE (xop0) != mode0)
+            xop0 = convert_to_mode (mode0, xop0, unsignedp);
+        
+        /* Now, if insn doesn't accept our operand, put it into a pseudo.  */
+        
+        if (! (*insn_data[icode].operand[1].predicate) (xop0, mode0))
+            xop0 = copy_to_mode_reg (mode0, xop0);
+        
+        if (! (*insn_data[icode].operand[0].predicate) (temp, submode))
+            temp = gen_reg_rtx (submode);
+        
+        pat = GEN_FCN2 (icode) (temp, xop0);
+        if (pat)
+        {
+            if (GET_CODE (pat) == SEQUENCE
+                && ! add_equal_note (pat, temp, this_abs_optab->code, xop0,
+                                     NULL_RTX))
+            {
+                delete_insns_since (last);
+                return expand_unop (mode, this_abs_optab, op0, NULL_RTX,
+                                    unsignedp);
+            }
+            
+            emit_insn (pat);
+            
+            return temp;
+        }
+        else
+            delete_insns_since (last);
     }
-
-  /* It can't be done in this mode.  Can we open-code it in a wider mode?  */
-
-  for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
-       wider_mode = GET_MODE_WIDER_MODE (wider_mode))
+    
+    /* It can't be done in this mode.  Can we open-code it in a wider mode?  */
+    
+    for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
+         wider_mode = GET_MODE_WIDER_MODE (wider_mode))
     {
-      if (this_abs_optab->handlers[(int) wider_mode].insn_code 
-	  != CODE_FOR_nothing)
-	{
-	  rtx xop0 = op0;
-
-	  xop0 = convert_modes (wider_mode, mode, xop0, unsignedp);
-	  temp = expand_complex_abs (wider_mode, xop0, NULL_RTX, unsignedp);
-
-	  if (temp)
-	    {
-	      if (class != MODE_COMPLEX_INT)
-		{
-		  if (target == 0)
-		    target = gen_reg_rtx (submode);
-		  convert_move (target, temp, 0);
-		  return target;
-		}
-	      else
-		return gen_lowpart (submode, temp);
-	    }
-	  else
-	    delete_insns_since (last);
-	}
+        if (this_abs_optab->handlers[(int) wider_mode].insn_code
+            != CODE_FOR_nothing)
+        {
+            rtx xop0 = op0;
+            
+            xop0 = convert_modes (wider_mode, mode, xop0, unsignedp);
+            temp = expand_complex_abs (wider_mode, xop0, NULL_RTX, unsignedp);
+            
+            if (temp)
+            {
+                if (class != MODE_COMPLEX_INT)
+                {
+                    if (target == 0)
+                        target = gen_reg_rtx (submode);
+                    convert_move (target, temp, 0);
+                    return target;
+                }
+                else
+                    return gen_lowpart (submode, temp);
+            }
+            else
+                delete_insns_since (last);
+        }
     }
-
-  /* Open-code the complex absolute-value operation
+    
+    /* Open-code the complex absolute-value operation
      if we can open-code sqrt.  Otherwise it's not worth while.  */
-  if (sqrt_optab->handlers[(int) submode].insn_code != CODE_FOR_nothing
-      && ! flag_trapv)
+    if (sqrt_optab->handlers[(int) submode].insn_code != CODE_FOR_nothing
+        && ! flag_trapv)
     {
-      rtx real, imag, total;
-
-      real = gen_realpart (submode, op0);
-      imag = gen_imagpart (submode, op0);
-
-      /* Square both parts.  */
-      real = expand_mult (submode, real, real, NULL_RTX, 0);
-      imag = expand_mult (submode, imag, imag, NULL_RTX, 0);
-
-      /* Sum the parts.  */
-      total = expand_binop (submode, add_optab, real, imag, NULL_RTX,
-			    0, OPTAB_LIB_WIDEN);
-
-      /* Get sqrt in TARGET.  Set TARGET to where the result is.  */
-      target = expand_unop (submode, sqrt_optab, total, target, 0);
-      if (target == 0)
-	delete_insns_since (last);
-      else
-	return target;
+        rtx real, imag, total;
+        
+        real = gen_realpart (submode, op0);
+        imag = gen_imagpart (submode, op0);
+        
+        /* Square both parts.  */
+        real = expand_mult (submode, real, real, NULL_RTX, 0);
+        imag = expand_mult (submode, imag, imag, NULL_RTX, 0);
+        
+        /* Sum the parts.  */
+        total = expand_binop (submode, add_optab, real, imag, NULL_RTX,
+                              0, OPTAB_LIB_WIDEN);
+        
+        /* Get sqrt in TARGET.  Set TARGET to where the result is.  */
+        target = expand_unop (submode, sqrt_optab, total, target, 0);
+        if (target == 0)
+            delete_insns_since (last);
+        else
+            return target;
     }
-
-  /* Now try a library call in this mode.  */
-  if (this_abs_optab->handlers[(int) mode].libfunc)
+    
+    /* Now try a library call in this mode.  */
+    if (this_abs_optab->handlers[(int) mode].libfunc)
     {
-      rtx insns;
-      rtx value;
-
-      start_sequence ();
-
-      /* Pass 1 for NO_QUEUE so we don't lose any increments
-	 if the libcall is cse'd or moved.  */
-      value = emit_library_call_value (abs_optab->handlers[(int) mode].libfunc,
-				       NULL_RTX, LCT_CONST, submode, 1, op0, mode);
-      insns = get_insns ();
-      end_sequence ();
-
-      target = gen_reg_rtx (submode);
-      emit_libcall_block (insns, target, value,
-			  gen_rtx_fmt_e (this_abs_optab->code, mode, op0));
-
-      return target;
+        rtx insns;
+        rtx value;
+        
+        start_sequence ();
+        
+        /* Pass 1 for NO_QUEUE so we don't lose any increments
+         if the libcall is cse'd or moved.  */
+        value = emit_library_call_value (abs_optab->handlers[(int) mode].libfunc,
+                                         NULL_RTX, LCT_CONST, submode, 1, op0, mode);
+        insns = get_insns ();
+        end_sequence ();
+        
+        target = gen_reg_rtx (submode);
+        emit_libcall_block (insns, target, value,
+                            gen_rtx_fmt_e (this_abs_optab->code, mode, op0));
+        
+        return target;
     }
-
-  /* It can't be done in this mode.  Can we do it in a wider mode?  */
-
-  for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
-       wider_mode = GET_MODE_WIDER_MODE (wider_mode))
+    
+    /* It can't be done in this mode.  Can we do it in a wider mode?  */
+    
+    for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
+         wider_mode = GET_MODE_WIDER_MODE (wider_mode))
     {
-      if ((this_abs_optab->handlers[(int) wider_mode].insn_code
-	   != CODE_FOR_nothing)
-	  || this_abs_optab->handlers[(int) wider_mode].libfunc)
-	{
-	  rtx xop0 = op0;
-
-	  xop0 = convert_modes (wider_mode, mode, xop0, unsignedp);
-
-	  temp = expand_complex_abs (wider_mode, xop0, NULL_RTX, unsignedp);
-
-	  if (temp)
-	    {
-	      if (class != MODE_COMPLEX_INT)
-		{
-		  if (target == 0)
-		    target = gen_reg_rtx (submode);
-		  convert_move (target, temp, 0);
-		  return target;
-		}
-	      else
-		return gen_lowpart (submode, temp);
-	    }
-	  else
-	    delete_insns_since (last);
-	}
+        if ((this_abs_optab->handlers[(int) wider_mode].insn_code
+             != CODE_FOR_nothing)
+            || this_abs_optab->handlers[(int) wider_mode].libfunc)
+        {
+            rtx xop0 = op0;
+            
+            xop0 = convert_modes (wider_mode, mode, xop0, unsignedp);
+            
+            temp = expand_complex_abs (wider_mode, xop0, NULL_RTX, unsignedp);
+            
+            if (temp)
+            {
+                if (class != MODE_COMPLEX_INT)
+                {
+                    if (target == 0)
+                        target = gen_reg_rtx (submode);
+                    convert_move (target, temp, 0);
+                    return target;
+                }
+                else
+                    return gen_lowpart (submode, temp);
+            }
+            else
+                delete_insns_since (last);
+        }
     }
-
-  delete_insns_since (entry_last);
-  return 0;
+    
+    delete_insns_since (entry_last);
+    return 0;
 }
 
 /* Generate an instruction whose insn-code is INSN_CODE,
-   with two operands: an output TARGET and an input OP0.
-   TARGET *must* be nonzero, and the output is always stored there.
-   CODE is an rtx code such that (CODE OP0) is an rtx that describes
-   the value that is stored into TARGET.  */
+ with two operands: an output TARGET and an input OP0.
+ TARGET *must* be nonzero, and the output is always stored there.
+ CODE is an rtx code such that (CODE OP0) is an rtx that describes
+ the value that is stored into TARGET.  */
 
 void
 emit_unop_insn (icode, target, op0, code)
-     int icode;
-     rtx target;
-     rtx op0;
-     enum rtx_code code;
+int icode;
+rtx target;
+rtx op0;
+enum rtx_code code;
 {
-  rtx temp;
-  enum machine_mode mode0 = insn_data[icode].operand[1].mode;
-  rtx pat;
-
-  temp = target = protect_from_queue (target, 1);
-
-  op0 = protect_from_queue (op0, 0);
-
-  /* Sign and zero extension from memory is often done specially on
+    rtx temp;
+    enum machine_mode mode0 = insn_data[icode].operand[1].mode;
+    rtx pat;
+    
+    temp = target = protect_from_queue (target, 1);
+    
+    op0 = protect_from_queue (op0, 0);
+    
+    /* Sign and zero extension from memory is often done specially on
      RISC machines, so forcing into a register here can pessimize
      code.  */
-  if (flag_force_mem && code != SIGN_EXTEND && code != ZERO_EXTEND)
-    op0 = force_not_mem (op0);
-
-  /* Now, if insn does not accept our operands, put them into pseudos.  */
-
-  if (! (*insn_data[icode].operand[1].predicate) (op0, mode0))
-    op0 = copy_to_mode_reg (mode0, op0);
-
-  if (! (*insn_data[icode].operand[0].predicate) (temp, GET_MODE (temp))
-      || (flag_force_mem && GET_CODE (temp) == MEM))
-    temp = gen_reg_rtx (GET_MODE (temp));
-
-  pat = GEN_FCN (icode) (temp, op0);
-
-  if (GET_CODE (pat) == SEQUENCE && code != UNKNOWN)
-    add_equal_note (pat, temp, code, op0, NULL_RTX);
-  
-  emit_insn (pat);
-
-  if (temp != target)
-    emit_move_insn (target, temp);
+    if (flag_force_mem && code != SIGN_EXTEND && code != ZERO_EXTEND)
+        op0 = force_not_mem (op0);
+    
+    /* Now, if insn does not accept our operands, put them into pseudos.  */
+    
+    if (! (*insn_data[icode].operand[1].predicate) (op0, mode0))
+        op0 = copy_to_mode_reg (mode0, op0);
+    
+    if (! (*insn_data[icode].operand[0].predicate) (temp, GET_MODE (temp))
+        || (flag_force_mem && GET_CODE (temp) == MEM))
+        temp = gen_reg_rtx (GET_MODE (temp));
+    
+    pat = GEN_FCN2 (icode) (temp, op0);
+    
+    if (GET_CODE (pat) == SEQUENCE && code != UNKNOWN)
+        add_equal_note (pat, temp, code, op0, NULL_RTX);
+    
+    emit_insn (pat);
+    
+    if (temp != target)
+        emit_move_insn (target, temp);
 }
 
 /* Emit code to perform a series of operations on a multi-word quantity, one
-   word at a time.
-
-   Such a block is preceded by a CLOBBER of the output, consists of multiple
-   insns, each setting one word of the output, and followed by a SET copying
-   the output to itself.
-
-   Each of the insns setting words of the output receives a REG_NO_CONFLICT
-   note indicating that it doesn't conflict with the (also multi-word)
-   inputs.  The entire block is surrounded by REG_LIBCALL and REG_RETVAL
-   notes.
-
-   INSNS is a block of code generated to perform the operation, not including
-   the CLOBBER and final copy.  All insns that compute intermediate values
-   are first emitted, followed by the block as described above.  
-
-   TARGET, OP0, and OP1 are the output and inputs of the operations,
-   respectively.  OP1 may be zero for a unary operation.
-
-   EQUIV, if non-zero, is an expression to be placed into a REG_EQUAL note
-   on the last insn.
-
-   If TARGET is not a register, INSNS is simply emitted with no special
-   processing.  Likewise if anything in INSNS is not an INSN or if
-   there is a libcall block inside INSNS.
-
-   The final insn emitted is returned.  */
+ word at a time.
+ 
+ Such a block is preceded by a CLOBBER of the output, consists of multiple
+ insns, each setting one word of the output, and followed by a SET copying
+ the output to itself.
+ 
+ Each of the insns setting words of the output receives a REG_NO_CONFLICT
+ note indicating that it doesn't conflict with the (also multi-word)
+ inputs.  The entire block is surrounded by REG_LIBCALL and REG_RETVAL
+ notes.
+ 
+ INSNS is a block of code generated to perform the operation, not including
+ the CLOBBER and final copy.  All insns that compute intermediate values
+ are first emitted, followed by the block as described above.
+ 
+ TARGET, OP0, and OP1 are the output and inputs of the operations,
+ respectively.  OP1 may be zero for a unary operation.
+ 
+ EQUIV, if non-zero, is an expression to be placed into a REG_EQUAL note
+ on the last insn.
+ 
+ If TARGET is not a register, INSNS is simply emitted with no special
+ processing.  Likewise if anything in INSNS is not an INSN or if
+ there is a libcall block inside INSNS.
+ 
+ The final insn emitted is returned.  */
 
 rtx
 emit_no_conflict_block (insns, target, op0, op1, equiv)
-     rtx insns;
-     rtx target;
-     rtx op0, op1;
-     rtx equiv;
+rtx insns;
+rtx target;
+rtx op0, op1;
+rtx equiv;
 {
-  rtx prev, next, first, last, insn;
-
-  if (GET_CODE (target) != REG || reload_in_progress)
-    return emit_insns (insns);
-  else
-    for (insn = insns; insn; insn = NEXT_INSN (insn))
-      if (GET_CODE (insn) != INSN
-	  || find_reg_note (insn, REG_LIBCALL, NULL_RTX))
-	return emit_insns (insns);
-
-  /* First emit all insns that do not store into words of the output and remove
+    rtx prev, next, first, last, insn;
+    
+    if (GET_CODE (target) != REG || reload_in_progress)
+        return emit_insns (insns);
+    else
+        for (insn = insns; insn; insn = NEXT_INSN (insn))
+    if (GET_CODE (insn) != INSN
+        || find_reg_note (insn, REG_LIBCALL, NULL_RTX))
+        return emit_insns (insns);
+    
+    /* First emit all insns that do not store into words of the output and remove
      these from the list.  */
-  for (insn = insns; insn; insn = next)
+    for (insn = insns; insn; insn = next)
     {
-      rtx set = 0, note;
-      int i;
-
-      next = NEXT_INSN (insn);
-
-      /* Some ports (cris) create an libcall regions at their own.  We must
-	 avoid any potential nesting of LIBCALLs.  */
-      if ((note = find_reg_note (insn, REG_LIBCALL, NULL)) != NULL)
-	remove_note (insn, note);
-      if ((note = find_reg_note (insn, REG_RETVAL, NULL)) != NULL)
-	remove_note (insn, note);
-
-      if (GET_CODE (PATTERN (insn)) == SET || GET_CODE (PATTERN (insn)) == USE
-	  || GET_CODE (PATTERN (insn)) == CLOBBER)
-	set = PATTERN (insn);
-      else if (GET_CODE (PATTERN (insn)) == PARALLEL)
-	{
-	  for (i = 0; i < XVECLEN (PATTERN (insn), 0); i++)
-	    if (GET_CODE (XVECEXP (PATTERN (insn), 0, i)) == SET)
-	      {
-		set = XVECEXP (PATTERN (insn), 0, i);
-		break;
-	      }
-	}
-
-      if (set == 0)
-	abort ();
-
-      if (! reg_overlap_mentioned_p (target, SET_DEST (set)))
-	{
-	  if (PREV_INSN (insn))
-	    NEXT_INSN (PREV_INSN (insn)) = next;
-	  else
-	    insns = next;
-
-	  if (next)
-	    PREV_INSN (next) = PREV_INSN (insn);
-
-	  add_insn (insn);
-	}
+        rtx set = 0, note;
+        int i;
+        
+        next = NEXT_INSN (insn);
+        
+        /* Some ports (cris) create an libcall regions at their own.  We must
+         avoid any potential nesting of LIBCALLs.  */
+        if ((note = find_reg_note (insn, REG_LIBCALL, NULL)) != NULL)
+            remove_note (insn, note);
+        if ((note = find_reg_note (insn, REG_RETVAL, NULL)) != NULL)
+            remove_note (insn, note);
+        
+        if (GET_CODE (PATTERN (insn)) == SET || GET_CODE (PATTERN (insn)) == USE
+            || GET_CODE (PATTERN (insn)) == CLOBBER)
+            set = PATTERN (insn);
+        else if (GET_CODE (PATTERN (insn)) == PARALLEL)
+        {
+            for (i = 0; i < XVECLEN (PATTERN (insn), 0); i++)
+            if (GET_CODE (XVECEXP (PATTERN (insn), 0, i)) == SET)
+            {
+                set = XVECEXP (PATTERN (insn), 0, i);
+                break;
+            }
+        }
+        
+        if (set == 0)
+            abort ();
+        
+        if (! reg_overlap_mentioned_p (target, SET_DEST (set)))
+        {
+            if (PREV_INSN (insn))
+                NEXT_INSN (PREV_INSN (insn)) = next;
+            else
+                insns = next;
+            
+            if (next)
+                PREV_INSN (next) = PREV_INSN (insn);
+            
+            add_insn (insn);
+        }
     }
-
-  prev = get_last_insn ();
-
-  /* Now write the CLOBBER of the output, followed by the setting of each
+    
+    prev = get_last_insn ();
+    
+    /* Now write the CLOBBER of the output, followed by the setting of each
      of the words, followed by the final copy.  */
-  if (target != op0 && target != op1)
-    emit_insn (gen_rtx_CLOBBER (VOIDmode, target));
-
-  for (insn = insns; insn; insn = next)
+    if (target != op0 && target != op1)
+        emit_insn (gen_rtx_CLOBBER (VOIDmode, target));
+    
+    for (insn = insns; insn; insn = next)
     {
-      next = NEXT_INSN (insn);
-      add_insn (insn);
-
-      if (op1 && GET_CODE (op1) == REG)
-	REG_NOTES (insn) = gen_rtx_EXPR_LIST (REG_NO_CONFLICT, op1,
-					      REG_NOTES (insn));
-
-      if (op0 && GET_CODE (op0) == REG)
-	REG_NOTES (insn) = gen_rtx_EXPR_LIST (REG_NO_CONFLICT, op0,
-					      REG_NOTES (insn));
+        next = NEXT_INSN (insn);
+        add_insn (insn);
+        
+        if (op1 && GET_CODE (op1) == REG)
+            REG_NOTES (insn) = gen_rtx_EXPR_LIST (REG_NO_CONFLICT, op1,
+                                                  REG_NOTES (insn));
+        
+        if (op0 && GET_CODE (op0) == REG)
+            REG_NOTES (insn) = gen_rtx_EXPR_LIST (REG_NO_CONFLICT, op0,
+                                                  REG_NOTES (insn));
     }
-
-  if (mov_optab->handlers[(int) GET_MODE (target)].insn_code
-      != CODE_FOR_nothing)
+    
+    if (mov_optab->handlers[(int) GET_MODE (target)].insn_code
+        != CODE_FOR_nothing)
     {
-      last = emit_move_insn (target, target);
-      if (equiv)
-	set_unique_reg_note (last, REG_EQUAL, equiv);
+        last = emit_move_insn (target, target);
+        if (equiv)
+            set_unique_reg_note (last, REG_EQUAL, equiv);
     }
-  else
+    else
     {
-      last = get_last_insn ();
-
-      /* Remove any existing REG_EQUAL note from "last", or else it will
-	 be mistaken for a note referring to the full contents of the
-	 alleged libcall value when found together with the REG_RETVAL
-	 note added below.  An existing note can come from an insn
-	 expansion at "last".  */
-      remove_note (last, find_reg_note (last, REG_EQUAL, NULL_RTX));
+        last = get_last_insn ();
+        
+        /* Remove any existing REG_EQUAL note from "last", or else it will
+         be mistaken for a note referring to the full contents of the
+         alleged libcall value when found together with the REG_RETVAL
+         note added below.  An existing note can come from an insn
+         expansion at "last".  */
+        remove_note (last, find_reg_note (last, REG_EQUAL, NULL_RTX));
     }
-
-  if (prev == 0)
-    first = get_insns ();
-  else
-    first = NEXT_INSN (prev);
-
-  /* Encapsulate the block so it gets manipulated as a unit.  */
-  REG_NOTES (first) = gen_rtx_INSN_LIST (REG_LIBCALL, last,
-					 REG_NOTES (first));
-  REG_NOTES (last) = gen_rtx_INSN_LIST (REG_RETVAL, first, REG_NOTES (last));
-
-  return last;
+    
+    if (prev == 0)
+        first = get_insns ();
+    else
+        first = NEXT_INSN (prev);
+    
+    /* Encapsulate the block so it gets manipulated as a unit.  */
+    REG_NOTES (first) = gen_rtx_INSN_LIST (REG_LIBCALL, last,
+                                           REG_NOTES (first));
+    REG_NOTES (last) = gen_rtx_INSN_LIST (REG_RETVAL, first, REG_NOTES (last));
+    
+    return last;
 }
 
 /* Emit code to make a call to a constant function or a library call.
-
-   INSNS is a list containing all insns emitted in the call.
-   These insns leave the result in RESULT.  Our block is to copy RESULT
-   to TARGET, which is logically equivalent to EQUIV.
-
-   We first emit any insns that set a pseudo on the assumption that these are
-   loading constants into registers; doing so allows them to be safely cse'ed
-   between blocks.  Then we emit all the other insns in the block, followed by
-   an insn to move RESULT to TARGET.  This last insn will have a REQ_EQUAL
-   note with an operand of EQUIV.
-
-   Moving assignments to pseudos outside of the block is done to improve
-   the generated code, but is not required to generate correct code,
-   hence being unable to move an assignment is not grounds for not making
-   a libcall block.  There are two reasons why it is safe to leave these
-   insns inside the block: First, we know that these pseudos cannot be
-   used in generated RTL outside the block since they are created for
-   temporary purposes within the block.  Second, CSE will not record the
-   values of anything set inside a libcall block, so we know they must
-   be dead at the end of the block.
-
-   Except for the first group of insns (the ones setting pseudos), the
-   block is delimited by REG_RETVAL and REG_LIBCALL notes.  */
+ 
+ INSNS is a list containing all insns emitted in the call.
+ These insns leave the result in RESULT.  Our block is to copy RESULT
+ to TARGET, which is logically equivalent to EQUIV.
+ 
+ We first emit any insns that set a pseudo on the assumption that these are
+ loading constants into registers; doing so allows them to be safely cse'ed
+ between blocks.  Then we emit all the other insns in the block, followed by
+ an insn to move RESULT to TARGET.  This last insn will have a REQ_EQUAL
+ note with an operand of EQUIV.
+ 
+ Moving assignments to pseudos outside of the block is done to improve
+ the generated code, but is not required to generate correct code,
+ hence being unable to move an assignment is not grounds for not making
+ a libcall block.  There are two reasons why it is safe to leave these
+ insns inside the block: First, we know that these pseudos cannot be
+ used in generated RTL outside the block since they are created for
+ temporary purposes within the block.  Second, CSE will not record the
+ values of anything set inside a libcall block, so we know they must
+ be dead at the end of the block.
+ 
+ Except for the first group of insns (the ones setting pseudos), the
+ block is delimited by REG_RETVAL and REG_LIBCALL notes.  */
 
 void
 emit_libcall_block (insns, target, result, equiv)
-     rtx insns;
-     rtx target;
-     rtx result;
-     rtx equiv;
+rtx insns;
+rtx target;
+rtx result;
+rtx equiv;
 {
-  rtx final_dest = target;
-  rtx prev, next, first, last, insn;
-
-  /* If this is a reg with REG_USERVAR_P set, then it could possibly turn
+    rtx final_dest = target;
+    rtx prev, next, first, last, insn;
+    
+    /* If this is a reg with REG_USERVAR_P set, then it could possibly turn
      into a MEM later.  Protect the libcall block from this change.  */
-  if (! REG_P (target) || REG_USERVAR_P (target))
-    target = gen_reg_rtx (GET_MODE (target));
-  
-  /* If we're using non-call exceptions, a libcall corresponding to an
+    if (! REG_P (target) || REG_USERVAR_P (target))
+        target = gen_reg_rtx (GET_MODE (target));
+    
+    /* If we're using non-call exceptions, a libcall corresponding to an
      operation that may trap may also trap.  */
-  if (flag_non_call_exceptions && may_trap_p (equiv))
+    if (flag_non_call_exceptions && may_trap_p (equiv))
     {
-      for (insn = insns; insn; insn = NEXT_INSN (insn))
-	if (GET_CODE (insn) == CALL_INSN)
-	  {
-	    rtx note = find_reg_note (insn, REG_EH_REGION, NULL_RTX);
-	    
-	    if (note != 0 && INTVAL (XEXP (note, 0)) <= 0)
-	      remove_note (insn, note);
-	  }
+        for (insn = insns; insn; insn = NEXT_INSN (insn))
+        if (GET_CODE (insn) == CALL_INSN)
+        {
+            rtx note = find_reg_note (insn, REG_EH_REGION, NULL_RTX);
+            
+            if (note != 0 && INTVAL (XEXP (note, 0)) <= 0)
+                remove_note (insn, note);
+        }
     }
-  else
-  /* look for any CALL_INSNs in this sequence, and attach a REG_EH_REGION
+    else
+    /* look for any CALL_INSNs in this sequence, and attach a REG_EH_REGION
      reg note to indicate that this call cannot throw or execute a nonlocal
      goto (unless there is already a REG_EH_REGION note, in which case
      we update it).  */
-    for (insn = insns; insn; insn = NEXT_INSN (insn))
-      if (GET_CODE (insn) == CALL_INSN)
-	{
-	  rtx note = find_reg_note (insn, REG_EH_REGION, NULL_RTX);
-	
-	  if (note != 0)
-	    XEXP (note, 0) = GEN_INT (-1);
-	  else
-	    REG_NOTES (insn) = gen_rtx_EXPR_LIST (REG_EH_REGION, GEN_INT (-1),
-						  REG_NOTES (insn));
-	}
-
-  /* First emit all insns that set pseudos.  Remove them from the list as
+        for (insn = insns; insn; insn = NEXT_INSN (insn))
+    if (GET_CODE (insn) == CALL_INSN)
+    {
+        rtx note = find_reg_note (insn, REG_EH_REGION, NULL_RTX);
+        
+        if (note != 0)
+            XEXP (note, 0) = GEN_INT (-1);
+        else
+            REG_NOTES (insn) = gen_rtx_EXPR_LIST (REG_EH_REGION, GEN_INT (-1),
+                                                  REG_NOTES (insn));
+    }
+    
+    /* First emit all insns that set pseudos.  Remove them from the list as
      we go.  Avoid insns that set pseudos which were referenced in previous
      insns.  These can be generated by move_by_pieces, for example,
      to update an address.  Similarly, avoid insns that reference things
      set in previous insns.  */
-
-  for (insn = insns; insn; insn = next)
+    
+    for (insn = insns; insn; insn = next)
     {
-      rtx set = single_set (insn);
-      rtx note;
-
-      /* Some ports (cris) create an libcall regions at their own.  We must
-	 avoid any potential nesting of LIBCALLs.  */
-      if ((note = find_reg_note (insn, REG_LIBCALL, NULL)) != NULL)
-	remove_note (insn, note);
-      if ((note = find_reg_note (insn, REG_RETVAL, NULL)) != NULL)
-	remove_note (insn, note);
-
-      next = NEXT_INSN (insn);
-
-      if (set != 0 && GET_CODE (SET_DEST (set)) == REG
-	  && REGNO (SET_DEST (set)) >= FIRST_PSEUDO_REGISTER
-	  && (insn == insns
-	      || ((! INSN_P(insns)
-		   || ! reg_mentioned_p (SET_DEST (set), PATTERN (insns)))
-		  && ! reg_used_between_p (SET_DEST (set), insns, insn)
-		  && ! modified_in_p (SET_SRC (set), insns)
-		  && ! modified_between_p (SET_SRC (set), insns, insn))))
-	{
-	  if (PREV_INSN (insn))
-	    NEXT_INSN (PREV_INSN (insn)) = next;
-	  else
-	    insns = next;
-
-	  if (next)
-	    PREV_INSN (next) = PREV_INSN (insn);
-
-	  add_insn (insn);
-	}
+        rtx set = single_set (insn);
+        rtx note;
+        
+        /* Some ports (cris) create an libcall regions at their own.  We must
+         avoid any potential nesting of LIBCALLs.  */
+        if ((note = find_reg_note (insn, REG_LIBCALL, NULL)) != NULL)
+            remove_note (insn, note);
+        if ((note = find_reg_note (insn, REG_RETVAL, NULL)) != NULL)
+            remove_note (insn, note);
+        
+        next = NEXT_INSN (insn);
+        
+        if (set != 0 && GET_CODE (SET_DEST (set)) == REG
+            && REGNO (SET_DEST (set)) >= FIRST_PSEUDO_REGISTER
+            && (insn == insns
+                || ((! INSN_P(insns)
+                     || ! reg_mentioned_p (SET_DEST (set), PATTERN (insns)))
+                    && ! reg_used_between_p (SET_DEST (set), insns, insn)
+                    && ! modified_in_p (SET_SRC (set), insns)
+                    && ! modified_between_p (SET_SRC (set), insns, insn))))
+        {
+            if (PREV_INSN (insn))
+                NEXT_INSN (PREV_INSN (insn)) = next;
+            else
+                insns = next;
+            
+            if (next)
+                PREV_INSN (next) = PREV_INSN (insn);
+            
+            add_insn (insn);
+        }
     }
-
-  prev = get_last_insn ();
-
-  /* Write the remaining insns followed by the final copy.  */
-
-  for (insn = insns; insn; insn = next)
+    
+    prev = get_last_insn ();
+    
+    /* Write the remaining insns followed by the final copy.  */
+    
+    for (insn = insns; insn; insn = next)
     {
-      next = NEXT_INSN (insn);
-
-      add_insn (insn);
+        next = NEXT_INSN (insn);
+        
+        add_insn (insn);
     }
-
-  last = emit_move_insn (target, result);
-  if (mov_optab->handlers[(int) GET_MODE (target)].insn_code
-      != CODE_FOR_nothing)
-    set_unique_reg_note (last, REG_EQUAL, copy_rtx (equiv));
-  else
+    
+    last = emit_move_insn (target, result);
+    if (mov_optab->handlers[(int) GET_MODE (target)].insn_code
+        != CODE_FOR_nothing)
+        set_unique_reg_note (last, REG_EQUAL, copy_rtx (equiv));
+    else
     {
-      /* Remove any existing REG_EQUAL note from "last", or else it will
-	 be mistaken for a note referring to the full contents of the
-	 libcall value when found together with the REG_RETVAL note added
-	 below.  An existing note can come from an insn expansion at
-	 "last".  */
-      remove_note (last, find_reg_note (last, REG_EQUAL, NULL_RTX));
+        /* Remove any existing REG_EQUAL note from "last", or else it will
+         be mistaken for a note referring to the full contents of the
+         libcall value when found together with the REG_RETVAL note added
+         below.  An existing note can come from an insn expansion at
+         "last".  */
+        remove_note (last, find_reg_note (last, REG_EQUAL, NULL_RTX));
     }
-
-  if (final_dest != target)
-    emit_move_insn (final_dest, target);
-
-  if (prev == 0)
-    first = get_insns ();
-  else
-    first = NEXT_INSN (prev);
-
-  /* Encapsulate the block so it gets manipulated as a unit.  */
-  if (!flag_non_call_exceptions || !may_trap_p (equiv))
+    
+    if (final_dest != target)
+        emit_move_insn (final_dest, target);
+    
+    if (prev == 0)
+        first = get_insns ();
+    else
+        first = NEXT_INSN (prev);
+    
+    /* Encapsulate the block so it gets manipulated as a unit.  */
+    if (!flag_non_call_exceptions || !may_trap_p (equiv))
     {
-      REG_NOTES (first) = gen_rtx_INSN_LIST (REG_LIBCALL, last,
-		      			     REG_NOTES (first));
-      REG_NOTES (last) = gen_rtx_INSN_LIST (REG_RETVAL, first,
-		      			    REG_NOTES (last));
+        REG_NOTES (first) = gen_rtx_INSN_LIST (REG_LIBCALL, last,
+                                               REG_NOTES (first));
+        REG_NOTES (last) = gen_rtx_INSN_LIST (REG_RETVAL, first,
+                                              REG_NOTES (last));
     }
 }
 
@@ -2992,2154 +2992,2154 @@ emit_libcall_block (insns, target, result, equiv)
 
 void
 emit_clr_insn (x)
-     rtx x;
+rtx x;
 {
-  emit_move_insn (x, const0_rtx);
+    emit_move_insn (x, const0_rtx);
 }
 
 /* Generate code to store 1 in X
-   assuming it contains zero beforehand.  */
+ assuming it contains zero beforehand.  */
 
 void
 emit_0_to_1_insn (x)
-     rtx x;
+rtx x;
 {
-  emit_move_insn (x, const1_rtx);
+    emit_move_insn (x, const1_rtx);
 }
 
 /* Nonzero if we can perform a comparison of mode MODE straightforwardly.
-   PURPOSE describes how this comparison will be used.  CODE is the rtx
-   comparison code we will be using.
+ PURPOSE describes how this comparison will be used.  CODE is the rtx
+ comparison code we will be using.
+ 
+ ??? Actually, CODE is slightly weaker than that.  A target is still
+ required to implement all of the normal bcc operations, but not
+ required to implement all (or any) of the unordered bcc operations.  */
 
-   ??? Actually, CODE is slightly weaker than that.  A target is still
-   required to implement all of the normal bcc operations, but not 
-   required to implement all (or any) of the unordered bcc operations.  */
-  
 int
 can_compare_p (code, mode, purpose)
-     enum rtx_code code;
-     enum machine_mode mode;
-     enum can_compare_purpose purpose;
+enum rtx_code code;
+enum machine_mode mode;
+enum can_compare_purpose purpose;
 {
-  do
+    do
     {
-      if (cmp_optab->handlers[(int)mode].insn_code != CODE_FOR_nothing)
-	{
-	  if (purpose == ccp_jump)
-	    return bcc_gen_fctn[(int)code] != NULL;
-	  else if (purpose == ccp_store_flag)
-	    return setcc_gen_code[(int)code] != CODE_FOR_nothing;
-	  else
-	    /* There's only one cmov entry point, and it's allowed to fail.  */
-	    return 1;
-	}
-      if (purpose == ccp_jump
-	  && cbranch_optab->handlers[(int)mode].insn_code != CODE_FOR_nothing)
-	return 1;
-      if (purpose == ccp_cmov
-	  && cmov_optab->handlers[(int)mode].insn_code != CODE_FOR_nothing)
-	return 1;
-      if (purpose == ccp_store_flag
-	  && cstore_optab->handlers[(int)mode].insn_code != CODE_FOR_nothing)
-	return 1;
-
-      mode = GET_MODE_WIDER_MODE (mode);
+        if (cmp_optab->handlers[(int)mode].insn_code != CODE_FOR_nothing)
+        {
+            if (purpose == ccp_jump)
+                return bcc_gen_fctn[(int)code] != NULL;
+            else if (purpose == ccp_store_flag)
+                return setcc_gen_code[(int)code] != CODE_FOR_nothing;
+            else
+            /* There's only one cmov entry point, and it's allowed to fail.  */
+                return 1;
+        }
+        if (purpose == ccp_jump
+            && cbranch_optab->handlers[(int)mode].insn_code != CODE_FOR_nothing)
+            return 1;
+        if (purpose == ccp_cmov
+            && cmov_optab->handlers[(int)mode].insn_code != CODE_FOR_nothing)
+            return 1;
+        if (purpose == ccp_store_flag
+            && cstore_optab->handlers[(int)mode].insn_code != CODE_FOR_nothing)
+            return 1;
+        
+        mode = GET_MODE_WIDER_MODE (mode);
     }
-  while (mode != VOIDmode);
-
-  return 0;
+    while (mode != VOIDmode);
+    
+    return 0;
 }
 
 /* This function is called when we are going to emit a compare instruction that
-   compares the values found in *PX and *PY, using the rtl operator COMPARISON.
-
-   *PMODE is the mode of the inputs (in case they are const_int).
-   *PUNSIGNEDP nonzero says that the operands are unsigned;
-   this matters if they need to be widened.
-
-   If they have mode BLKmode, then SIZE specifies the size of both operands.
-
-   This function performs all the setup necessary so that the caller only has
-   to emit a single comparison insn.  This setup can involve doing a BLKmode
-   comparison or emitting a library call to perform the comparison if no insn
-   is available to handle it.
-   The values which are passed in through pointers can be modified; the caller
-   should perform the comparison on the modified values.  */
+ compares the values found in *PX and *PY, using the rtl operator COMPARISON.
+ 
+ *PMODE is the mode of the inputs (in case they are const_int).
+ *PUNSIGNEDP nonzero says that the operands are unsigned;
+ this matters if they need to be widened.
+ 
+ If they have mode BLKmode, then SIZE specifies the size of both operands.
+ 
+ This function performs all the setup necessary so that the caller only has
+ to emit a single comparison insn.  This setup can involve doing a BLKmode
+ comparison or emitting a library call to perform the comparison if no insn
+ is available to handle it.
+ The values which are passed in through pointers can be modified; the caller
+ should perform the comparison on the modified values.  */
 
 static void
 prepare_cmp_insn (px, py, pcomparison, size, pmode, punsignedp, purpose)
-     rtx *px, *py;
-     enum rtx_code *pcomparison;
-     rtx size;
-     enum machine_mode *pmode;
-     int *punsignedp;
-     enum can_compare_purpose purpose;
+rtx *px, *py;
+enum rtx_code *pcomparison;
+rtx size;
+enum machine_mode *pmode;
+int *punsignedp;
+enum can_compare_purpose purpose;
 {
-  enum machine_mode mode = *pmode;
-  rtx x = *px, y = *py;
-  int unsignedp = *punsignedp;
-  enum mode_class class;
-
-  class = GET_MODE_CLASS (mode);
-
-  /* They could both be VOIDmode if both args are immediate constants,
+    enum machine_mode mode = *pmode;
+    rtx x = *px, y = *py;
+    int unsignedp = *punsignedp;
+    enum mode_class class;
+    
+    class = GET_MODE_CLASS (mode);
+    
+    /* They could both be VOIDmode if both args are immediate constants,
      but we should fold that at an earlier stage.
      With no special code here, this will call abort,
      reminding the programmer to implement such folding.  */
-
-  if (mode != BLKmode && flag_force_mem)
+    
+    if (mode != BLKmode && flag_force_mem)
     {
-      x = force_not_mem (x);
-      y = force_not_mem (y);
+        x = force_not_mem (x);
+        y = force_not_mem (y);
     }
-
-  /* If we are inside an appropriately-short loop and one operand is an
+    
+    /* If we are inside an appropriately-short loop and one operand is an
      expensive constant, force it into a register.  */
-  if (CONSTANT_P (x) && preserve_subexpressions_p ()
-      && rtx_cost (x, COMPARE) > COSTS_N_INSNS (1))
-    x = force_reg (mode, x);
-
-  if (CONSTANT_P (y) && preserve_subexpressions_p ()
-      && rtx_cost (y, COMPARE) > COSTS_N_INSNS (1))
-    y = force_reg (mode, y);
-
+    if (CONSTANT_P (x) && preserve_subexpressions_p ()
+        && rtx_cost (x, COMPARE) > COSTS_N_INSNS (1))
+        x = force_reg (mode, x);
+    
+    if (CONSTANT_P (y) && preserve_subexpressions_p ()
+        && rtx_cost (y, COMPARE) > COSTS_N_INSNS (1))
+        y = force_reg (mode, y);
+    
 #ifdef HAVE_cc0
-  /* Abort if we have a non-canonical comparison.  The RTL documentation
+    /* Abort if we have a non-canonical comparison.  The RTL documentation
      states that canonical comparisons are required only for targets which
      have cc0.  */
-  if (CONSTANT_P (x) && ! CONSTANT_P (y))
-    abort();
+    if (CONSTANT_P (x) && ! CONSTANT_P (y))
+        abort();
 #endif
-
-  /* Don't let both operands fail to indicate the mode.  */
-  if (GET_MODE (x) == VOIDmode && GET_MODE (y) == VOIDmode)
-    x = force_reg (mode, x);
-
-  /* Handle all BLKmode compares.  */
-
-  if (mode == BLKmode)
+    
+    /* Don't let both operands fail to indicate the mode.  */
+    if (GET_MODE (x) == VOIDmode && GET_MODE (y) == VOIDmode)
+        x = force_reg (mode, x);
+    
+    /* Handle all BLKmode compares.  */
+    
+    if (mode == BLKmode)
     {
-      rtx result;
-      enum machine_mode result_mode;
-      rtx opalign ATTRIBUTE_UNUSED
-	= GEN_INT (MIN (MEM_ALIGN (x), MEM_ALIGN (y)) / BITS_PER_UNIT);
-
-      emit_queue ();
-      x = protect_from_queue (x, 0);
-      y = protect_from_queue (y, 0);
-
-      if (size == 0)
-	abort ();
+        rtx result;
+        enum machine_mode result_mode;
+        rtx opalign ATTRIBUTE_UNUSED
+        = GEN_INT (MIN (MEM_ALIGN (x), MEM_ALIGN (y)) / BITS_PER_UNIT);
+        
+        emit_queue ();
+        x = protect_from_queue (x, 0);
+        y = protect_from_queue (y, 0);
+        
+        if (size == 0)
+            abort ();
 #ifdef HAVE_cmpstrqi
-      if (HAVE_cmpstrqi
-	  && GET_CODE (size) == CONST_INT
-	  && INTVAL (size) < (1 << GET_MODE_BITSIZE (QImode)))
-	{
-	  result_mode = insn_data[(int) CODE_FOR_cmpstrqi].operand[0].mode;
-	  result = gen_reg_rtx (result_mode);
-	  emit_insn (gen_cmpstrqi (result, x, y, size, opalign));
-	}
-      else
+        if (HAVE_cmpstrqi
+            && GET_CODE (size) == CONST_INT
+            && INTVAL (size) < (1 << GET_MODE_BITSIZE (QImode)))
+        {
+            result_mode = insn_data[(int) CODE_FOR_cmpstrqi].operand[0].mode;
+            result = gen_reg_rtx (result_mode);
+            emit_insn (gen_cmpstrqi (result, x, y, size, opalign));
+        }
+        else
 #endif
 #ifdef HAVE_cmpstrhi
-      if (HAVE_cmpstrhi
-	  && GET_CODE (size) == CONST_INT
-	  && INTVAL (size) < (1 << GET_MODE_BITSIZE (HImode)))
-	{
-	  result_mode = insn_data[(int) CODE_FOR_cmpstrhi].operand[0].mode;
-	  result = gen_reg_rtx (result_mode);
-	  emit_insn (gen_cmpstrhi (result, x, y, size, opalign));
-	}
-      else
+            if (HAVE_cmpstrhi
+                && GET_CODE (size) == CONST_INT
+                && INTVAL (size) < (1 << GET_MODE_BITSIZE (HImode)))
+            {
+                result_mode = insn_data[(int) CODE_FOR_cmpstrhi].operand[0].mode;
+                result = gen_reg_rtx (result_mode);
+                emit_insn (gen_cmpstrhi (result, x, y, size, opalign));
+            }
+            else
 #endif
 #ifdef HAVE_cmpstrsi
-      if (HAVE_cmpstrsi)
-	{
-	  result_mode = insn_data[(int) CODE_FOR_cmpstrsi].operand[0].mode;
-	  result = gen_reg_rtx (result_mode);
-	  size = protect_from_queue (size, 0);
-	  emit_insn (gen_cmpstrsi (result, x, y,
-				   convert_to_mode (SImode, size, 1),
-				   opalign));
-	}
-      else
+                if (HAVE_cmpstrsi)
+                {
+                    result_mode = insn_data[(int) CODE_FOR_cmpstrsi].operand[0].mode;
+                    result = gen_reg_rtx (result_mode);
+                    size = protect_from_queue (size, 0);
+                    emit_insn (gen_cmpstrsi (result, x, y,
+                                             convert_to_mode (SImode, size, 1),
+                                             opalign));
+                }
+                else
 #endif
-	{
+                {
 #ifdef TARGET_MEM_FUNCTIONS
-	  emit_library_call (memcmp_libfunc, LCT_PURE_MAKE_BLOCK,
-			     TYPE_MODE (integer_type_node), 3,
-			     XEXP (x, 0), Pmode, XEXP (y, 0), Pmode,
-			     convert_to_mode (TYPE_MODE (sizetype), size,
-					      TREE_UNSIGNED (sizetype)),
-			     TYPE_MODE (sizetype));
+                    emit_library_call (memcmp_libfunc, LCT_PURE_MAKE_BLOCK,
+                                       TYPE_MODE (integer_type_node), 3,
+                                       XEXP (x, 0), Pmode, XEXP (y, 0), Pmode,
+                                       convert_to_mode (TYPE_MODE (sizetype), size,
+                                                          TREE_UNSIGNED (sizetype)),
+                                       TYPE_MODE (sizetype));
 #else
-	  emit_library_call (bcmp_libfunc, LCT_PURE_MAKE_BLOCK,
-			     TYPE_MODE (integer_type_node), 3,
-			     XEXP (x, 0), Pmode, XEXP (y, 0), Pmode,
-			     convert_to_mode (TYPE_MODE (integer_type_node),
-					      size,
-					      TREE_UNSIGNED (integer_type_node)),
-			     TYPE_MODE (integer_type_node));
+                    emit_library_call (bcmp_libfunc, LCT_PURE_MAKE_BLOCK,
+                                       TYPE_MODE (integer_type_node), 3,
+                                       XEXP (x, 0), Pmode, XEXP (y, 0), Pmode,
+                                       convert_to_mode (TYPE_MODE (integer_type_node),
+                                                          size,
+                                                          TREE_UNSIGNED (integer_type_node)),
+                                       TYPE_MODE (integer_type_node));
 #endif
-
-	  /* Immediately move the result of the libcall into a pseudo
-	     register so reload doesn't clobber the value if it needs
-	     the return register for a spill reg.  */
-	  result = gen_reg_rtx (TYPE_MODE (integer_type_node));
-	  result_mode = TYPE_MODE (integer_type_node);
-	  emit_move_insn (result,
-			  hard_libcall_value (result_mode));
-	}
-      *px = result;
-      *py = const0_rtx;
-      *pmode = result_mode;
-      return;
+                    
+                    /* Immediately move the result of the libcall into a pseudo
+                     register so reload doesn't clobber the value if it needs
+                     the return register for a spill reg.  */
+                    result = gen_reg_rtx (TYPE_MODE (integer_type_node));
+                    result_mode = TYPE_MODE (integer_type_node);
+                    emit_move_insn (result,
+                                    hard_libcall_value (result_mode));
+                }
+        *px = result;
+        *py = const0_rtx;
+        *pmode = result_mode;
+        return;
     }
-
-  *px = x;
-  *py = y;
-  if (can_compare_p (*pcomparison, mode, purpose))
-    return;
-
-  /* Handle a lib call just for the mode we are using.  */
-
-  if (cmp_optab->handlers[(int) mode].libfunc && class != MODE_FLOAT)
+    
+    *px = x;
+    *py = y;
+    if (can_compare_p (*pcomparison, mode, purpose))
+        return;
+    
+    /* Handle a lib call just for the mode we are using.  */
+    
+    if (cmp_optab->handlers[(int) mode].libfunc && class != MODE_FLOAT)
     {
-      rtx libfunc = cmp_optab->handlers[(int) mode].libfunc;
-      rtx result;
-
-      /* If we want unsigned, and this mode has a distinct unsigned
-	 comparison routine, use that.  */
-      if (unsignedp && ucmp_optab->handlers[(int) mode].libfunc)
-	libfunc = ucmp_optab->handlers[(int) mode].libfunc;
-
-      emit_library_call (libfunc, LCT_CONST_MAKE_BLOCK, word_mode, 2, x, mode,
-			 y, mode);
-
-      /* Immediately move the result of the libcall into a pseudo
-	 register so reload doesn't clobber the value if it needs
-	 the return register for a spill reg.  */
-      result = gen_reg_rtx (word_mode);
-      emit_move_insn (result, hard_libcall_value (word_mode));
-
-      /* Integer comparison returns a result that must be compared against 1,
-	 so that even if we do an unsigned compare afterward,
-	 there is still a value that can represent the result "less than".  */
-      *px = result;
-      *py = const1_rtx;
-      *pmode = word_mode;
-      return;
+        rtx libfunc = cmp_optab->handlers[(int) mode].libfunc;
+        rtx result;
+        
+        /* If we want unsigned, and this mode has a distinct unsigned
+         comparison routine, use that.  */
+        if (unsignedp && ucmp_optab->handlers[(int) mode].libfunc)
+            libfunc = ucmp_optab->handlers[(int) mode].libfunc;
+        
+        emit_library_call (libfunc, LCT_CONST_MAKE_BLOCK, word_mode, 2, x, mode,
+                           y, mode);
+        
+        /* Immediately move the result of the libcall into a pseudo
+         register so reload doesn't clobber the value if it needs
+         the return register for a spill reg.  */
+        result = gen_reg_rtx (word_mode);
+        emit_move_insn (result, hard_libcall_value (word_mode));
+        
+        /* Integer comparison returns a result that must be compared against 1,
+         so that even if we do an unsigned compare afterward,
+         there is still a value that can represent the result "less than".  */
+        *px = result;
+        *py = const1_rtx;
+        *pmode = word_mode;
+        return;
     }
-
-  if (class == MODE_FLOAT)
-    prepare_float_lib_cmp (px, py, pcomparison, pmode, punsignedp);
-
-  else
-    abort ();
+    
+    if (class == MODE_FLOAT)
+        prepare_float_lib_cmp (px, py, pcomparison, pmode, punsignedp);
+    
+    else
+        abort ();
 }
 
 /* Before emitting an insn with code ICODE, make sure that X, which is going
-   to be used for operand OPNUM of the insn, is converted from mode MODE to
-   WIDER_MODE (UNSIGNEDP determines whether it is an unsigned conversion), and
-   that it is accepted by the operand predicate.  Return the new value.  */
+ to be used for operand OPNUM of the insn, is converted from mode MODE to
+ WIDER_MODE (UNSIGNEDP determines whether it is an unsigned conversion), and
+ that it is accepted by the operand predicate.  Return the new value.  */
 
 rtx
 prepare_operand (icode, x, opnum, mode, wider_mode, unsignedp)
-     int icode;
-     rtx x;
-     int opnum;
-     enum machine_mode mode, wider_mode;
-     int unsignedp;
-{
-  x = protect_from_queue (x, 0);
-
-  if (mode != wider_mode)
-    x = convert_modes (wider_mode, mode, x, unsignedp);
-
-  if (! (*insn_data[icode].operand[opnum].predicate)
-      (x, insn_data[icode].operand[opnum].mode))
-    x = copy_to_mode_reg (insn_data[icode].operand[opnum].mode, x);
-  return x;
-}
-
-/* Subroutine of emit_cmp_and_jump_insns; this function is called when we know
-   we can do the comparison.
-   The arguments are the same as for emit_cmp_and_jump_insns; but LABEL may
-   be NULL_RTX which indicates that only a comparison is to be generated.  */
-
-static void
-emit_cmp_and_jump_insn_1 (x, y, mode, comparison, unsignedp, label)
-     rtx x, y;
-     enum machine_mode mode;
-     enum rtx_code comparison;
-     int unsignedp;
-     rtx label;
-{
-  rtx test = gen_rtx_fmt_ee (comparison, mode, x, y);
-  enum mode_class class = GET_MODE_CLASS (mode);
-  enum machine_mode wider_mode = mode;
-
-  /* Try combined insns first.  */
-  do
-    {
-      enum insn_code icode;
-      PUT_MODE (test, wider_mode);
-
-      if (label)
-	{	  
-	  icode = cbranch_optab->handlers[(int)wider_mode].insn_code;
-	  
-	  if (icode != CODE_FOR_nothing
-	      && (*insn_data[icode].operand[0].predicate) (test, wider_mode))
-	    {
-	      x = prepare_operand (icode, x, 1, mode, wider_mode, unsignedp);
-	      y = prepare_operand (icode, y, 2, mode, wider_mode, unsignedp);
-	      emit_jump_insn (GEN_FCN (icode) (test, x, y, label));
-	      return;
-	    }
-	}
-
-      /* Handle some compares against zero.  */
-      icode = (int) tst_optab->handlers[(int) wider_mode].insn_code;
-      if (y == CONST0_RTX (mode) && icode != CODE_FOR_nothing)
-	{
-	  x = prepare_operand (icode, x, 0, mode, wider_mode, unsignedp);
-	  emit_insn (GEN_FCN (icode) (x));
-	  if (label)
-	    emit_jump_insn ((*bcc_gen_fctn[(int) comparison]) (label));
-	  return;
-	}
-
-      /* Handle compares for which there is a directly suitable insn.  */
-
-      icode = (int) cmp_optab->handlers[(int) wider_mode].insn_code;
-      if (icode != CODE_FOR_nothing)
-	{
-	  x = prepare_operand (icode, x, 0, mode, wider_mode, unsignedp);
-	  y = prepare_operand (icode, y, 1, mode, wider_mode, unsignedp);
-	  emit_insn (GEN_FCN (icode) (x, y));
-	  if (label)
-	    emit_jump_insn ((*bcc_gen_fctn[(int) comparison]) (label));
-	  return;
-	}
-
-      if (class != MODE_INT && class != MODE_FLOAT
-	  && class != MODE_COMPLEX_FLOAT)
-	break;
-
-      wider_mode = GET_MODE_WIDER_MODE (wider_mode);
-    } while (wider_mode != VOIDmode);
-
-  abort ();
-}
-
-/* Generate code to compare X with Y so that the condition codes are
-   set and to jump to LABEL if the condition is true.  If X is a
-   constant and Y is not a constant, then the comparison is swapped to
-   ensure that the comparison RTL has the canonical form.
-
-   UNSIGNEDP nonzero says that X and Y are unsigned; this matters if they
-   need to be widened by emit_cmp_insn.  UNSIGNEDP is also used to select
-   the proper branch condition code.
-
-   If X and Y have mode BLKmode, then SIZE specifies the size of both X and Y.
-
-   MODE is the mode of the inputs (in case they are const_int).
-
-   COMPARISON is the rtl operator to compare with (EQ, NE, GT, etc.).  It will
-   be passed unchanged to emit_cmp_insn, then potentially converted into an
-   unsigned variant based on UNSIGNEDP to select a proper jump instruction.  */
-
-void
-emit_cmp_and_jump_insns (x, y, comparison, size, mode, unsignedp, label)
-     rtx x, y;
-     enum rtx_code comparison;
-     rtx size;
-     enum machine_mode mode;
-     int unsignedp;
-     rtx label;
-{
-  rtx op0 = x, op1 = y;
-
-  /* Swap operands and condition to ensure canonical RTL.  */
-  if (swap_commutative_operands_p (x, y))
-    {
-      /* If we're not emitting a branch, this means some caller
-         is out of sync.  */
-      if (! label)
-	abort ();
-
-      op0 = y, op1 = x;
-      comparison = swap_condition (comparison);
-    }
-
-#ifdef HAVE_cc0
-  /* If OP0 is still a constant, then both X and Y must be constants.  Force
-     X into a register to avoid aborting in emit_cmp_insn due to non-canonical
-     RTL.  */
-  if (CONSTANT_P (op0))
-    op0 = force_reg (mode, op0);
-#endif
-
-  emit_queue ();
-  if (unsignedp)
-    comparison = unsigned_condition (comparison);
-
-  prepare_cmp_insn (&op0, &op1, &comparison, size, &mode, &unsignedp,
-		    ccp_jump);
-  emit_cmp_and_jump_insn_1 (op0, op1, mode, comparison, unsignedp, label);
-}
-
-/* Like emit_cmp_and_jump_insns, but generate only the comparison.  */
-
-void
-emit_cmp_insn (x, y, comparison, size, mode, unsignedp)
-     rtx x, y;
-     enum rtx_code comparison;
-     rtx size;
-     enum machine_mode mode;
-     int unsignedp;
+int icode;
+rtx x;
+int opnum;
+enum machine_mode mode, wider_mode;
+int unsignedp;
 {
-  emit_cmp_and_jump_insns (x, y, comparison, size, mode, unsignedp, 0);
+    x = protect_from_queue (x, 0);
+    
+    if (mode != wider_mode)
+        x = convert_modes (wider_mode, mode, x, unsignedp);
+    
+    if (! (*insn_data[icode].operand[opnum].predicate)
+        (x, insn_data[icode].operand[opnum].mode))
+        x = copy_to_mode_reg (insn_data[icode].operand[opnum].mode, x);
+    return x;
 }
-
-/* Emit a library call comparison between floating point X and Y.
-   COMPARISON is the rtl operator to compare with (EQ, NE, GT, etc.).  */
-
-static void
-prepare_float_lib_cmp (px, py, pcomparison, pmode, punsignedp)
-     rtx *px, *py;
-     enum rtx_code *pcomparison;
-     enum machine_mode *pmode;
-     int *punsignedp;
-{
-  enum rtx_code comparison = *pcomparison;
-  rtx x = *px = protect_from_queue (*px, 0);
-  rtx y = *py = protect_from_queue (*py, 0);
-  enum machine_mode mode = GET_MODE (x);
-  rtx libfunc = 0;
-  rtx result;
-
-  if (mode == HFmode)
-    switch (comparison)
-      {
-      case EQ:
-	libfunc = eqhf2_libfunc;
-	break;
-
-      case NE:
-	libfunc = nehf2_libfunc;
-	break;
-
-      case GT:
-	libfunc = gthf2_libfunc;
-	break;
-
-      case GE:
-	libfunc = gehf2_libfunc;
-	break;
-
-      case LT:
-	libfunc = lthf2_libfunc;
-	break;
-
-      case LE:
-	libfunc = lehf2_libfunc;
-	break;
-
-      case UNORDERED:
-	libfunc = unordhf2_libfunc;
-	break;
-
-      default:
-	break;
-      }
-  else if (mode == SFmode)
-    switch (comparison)
-      {
-      case EQ:
-	libfunc = eqsf2_libfunc;
-	break;
-
-      case NE:
-	libfunc = nesf2_libfunc;
-	break;
-
-      case GT:
-	libfunc = gtsf2_libfunc;
-	break;
-
-      case GE:
-	libfunc = gesf2_libfunc;
-	break;
-
-      case LT:
-	libfunc = ltsf2_libfunc;
-	break;
-
-      case LE:
-	libfunc = lesf2_libfunc;
-	break;
-
-      case UNORDERED:
-	libfunc = unordsf2_libfunc;
-	break;
-
-      default:
-	break;
-      }
-  else if (mode == DFmode)
-    switch (comparison)
-      {
-      case EQ:
-	libfunc = eqdf2_libfunc;
-	break;
-
-      case NE:
-	libfunc = nedf2_libfunc;
-	break;
-
-      case GT:
-	libfunc = gtdf2_libfunc;
-	break;
-
-      case GE:
-	libfunc = gedf2_libfunc;
-	break;
-
-      case LT:
-	libfunc = ltdf2_libfunc;
-	break;
-
-      case LE:
-	libfunc = ledf2_libfunc;
-	break;
-
-      case UNORDERED:
-	libfunc = unorddf2_libfunc;
-	break;
-
-      default:
-	break;
-      }
-  else if (mode == XFmode)
-    switch (comparison)
-      {
-      case EQ:
-	libfunc = eqxf2_libfunc;
-	break;
-
-      case NE:
-	libfunc = nexf2_libfunc;
-	break;
-
-      case GT:
-	libfunc = gtxf2_libfunc;
-	break;
-
-      case GE:
-	libfunc = gexf2_libfunc;
-	break;
-
-      case LT:
-	libfunc = ltxf2_libfunc;
-	break;
-
-      case LE:
-	libfunc = lexf2_libfunc;
-	break;
-
-      case UNORDERED:
-	libfunc = unordxf2_libfunc;
-	break;
-
-      default:
-	break;
-      }
-  else if (mode == TFmode)
-    switch (comparison)
-      {
-      case EQ:
-	libfunc = eqtf2_libfunc;
-	break;
-
-      case NE:
-	libfunc = netf2_libfunc;
-	break;
-
-      case GT:
-	libfunc = gttf2_libfunc;
-	break;
-
-      case GE:
-	libfunc = getf2_libfunc;
-	break;
 
-      case LT:
-	libfunc = lttf2_libfunc;
-	break;
+/* Subroutine of emit_cmp_and_jump_insns; this function is called when we know
+ we can do the comparison.
+ The arguments are the same as for emit_cmp_and_jump_insns; but LABEL may
+ be NULL_RTX which indicates that only a comparison is to be generated.  */
 
-      case LE:
-	libfunc = letf2_libfunc;
-	break;
+static void
+emit_cmp_and_jump_insn_1 (x, y, mode, comparison, unsignedp, label)
+rtx x, y;
+enum machine_mode mode;
+enum rtx_code comparison;
+int unsignedp;
+rtx label;
+{
+    rtx test = gen_rtx_fmt_ee (comparison, mode, x, y);
+    enum mode_class class = GET_MODE_CLASS (mode);
+    enum machine_mode wider_mode = mode;
+    
+    /* Try combined insns first.  */
+    do
+    {
+        enum insn_code icode;
+        PUT_MODE (test, wider_mode);
+        
+        if (label)
+        {
+            icode = cbranch_optab->handlers[(int)wider_mode].insn_code;
+            
+            if (icode != CODE_FOR_nothing
+                && (*insn_data[icode].operand[0].predicate) (test, wider_mode))
+            {
+                x = prepare_operand (icode, x, 1, mode, wider_mode, unsignedp);
+                y = prepare_operand (icode, y, 2, mode, wider_mode, unsignedp);
+                emit_jump_insn (GEN_FCN4 (icode) (test, x, y, label));
+                return;
+            }
+        }
+        
+        /* Handle some compares against zero.  */
+        icode = (int) tst_optab->handlers[(int) wider_mode].insn_code;
+        if (y == CONST0_RTX (mode) && icode != CODE_FOR_nothing)
+        {
+            x = prepare_operand (icode, x, 0, mode, wider_mode, unsignedp);
+            emit_insn (GEN_FCN1 (icode) (x));
+            if (label)
+                emit_jump_insn ((*bcc_gen_fctn[(int) comparison]) (label));
+            return;
+        }
+        
+        /* Handle compares for which there is a directly suitable insn.  */
+        
+        icode = (int) cmp_optab->handlers[(int) wider_mode].insn_code;
+        if (icode != CODE_FOR_nothing)
+        {
+            x = prepare_operand (icode, x, 0, mode, wider_mode, unsignedp);
+            y = prepare_operand (icode, y, 1, mode, wider_mode, unsignedp);
+            emit_insn (GEN_FCN2 (icode) (x, y));
+            if (label)
+                emit_jump_insn ((*bcc_gen_fctn[(int) comparison]) (label));
+            return;
+        }
+        
+        if (class != MODE_INT && class != MODE_FLOAT
+            && class != MODE_COMPLEX_FLOAT)
+            break;
+        
+        wider_mode = GET_MODE_WIDER_MODE (wider_mode);
+    } while (wider_mode != VOIDmode);
+    
+    abort ();
+}
 
-      case UNORDERED:
-	libfunc = unordtf2_libfunc;
-	break;
+/* Generate code to compare X with Y so that the condition codes are
+ set and to jump to LABEL if the condition is true.  If X is a
+ constant and Y is not a constant, then the comparison is swapped to
+ ensure that the comparison RTL has the canonical form.
+ 
+ UNSIGNEDP nonzero says that X and Y are unsigned; this matters if they
+ need to be widened by emit_cmp_insn.  UNSIGNEDP is also used to select
+ the proper branch condition code.
+ 
+ If X and Y have mode BLKmode, then SIZE specifies the size of both X and Y.
+ 
+ MODE is the mode of the inputs (in case they are const_int).
+ 
+ COMPARISON is the rtl operator to compare with (EQ, NE, GT, etc.).  It will
+ be passed unchanged to emit_cmp_insn, then potentially converted into an
+ unsigned variant based on UNSIGNEDP to select a proper jump instruction.  */
 
-      default:
-	break;
-      }
-  else
+void
+emit_cmp_and_jump_insns (x, y, comparison, size, mode, unsignedp, label)
+rtx x, y;
+enum rtx_code comparison;
+rtx size;
+enum machine_mode mode;
+int unsignedp;
+rtx label;
+{
+    rtx op0 = x, op1 = y;
+    
+    /* Swap operands and condition to ensure canonical RTL.  */
+    if (swap_commutative_operands_p (x, y))
     {
-      enum machine_mode wider_mode;
-
-      for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
-	   wider_mode = GET_MODE_WIDER_MODE (wider_mode))
-	{
-	  if ((cmp_optab->handlers[(int) wider_mode].insn_code
-	       != CODE_FOR_nothing)
-	      || (cmp_optab->handlers[(int) wider_mode].libfunc != 0))
-	    {
-	      x = protect_from_queue (x, 0);
-	      y = protect_from_queue (y, 0);
-	      *px = convert_to_mode (wider_mode, x, 0);
-	      *py = convert_to_mode (wider_mode, y, 0);
-	      prepare_float_lib_cmp (px, py, pcomparison, pmode, punsignedp);
-	      return;
-	    }
-	}
-      abort ();
+        /* If we're not emitting a branch, this means some caller
+         is out of sync.  */
+        if (! label)
+            abort ();
+        
+        op0 = y, op1 = x;
+        comparison = swap_condition (comparison);
     }
+    
+#ifdef HAVE_cc0
+    /* If OP0 is still a constant, then both X and Y must be constants.  Force
+     X into a register to avoid aborting in emit_cmp_insn due to non-canonical
+     RTL.  */
+    if (CONSTANT_P (op0))
+        op0 = force_reg (mode, op0);
+#endif
+    
+    emit_queue ();
+    if (unsignedp)
+        comparison = unsigned_condition (comparison);
+    
+    prepare_cmp_insn (&op0, &op1, &comparison, size, &mode, &unsignedp,
+                      ccp_jump);
+    emit_cmp_and_jump_insn_1 (op0, op1, mode, comparison, unsignedp, label);
+}
 
-  if (libfunc == 0)
-    abort ();
+/* Like emit_cmp_and_jump_insns, but generate only the comparison.  */
 
-  emit_library_call (libfunc, LCT_CONST_MAKE_BLOCK, word_mode, 2, x, mode, y,
-		     mode);
+void
+emit_cmp_insn (x, y, comparison, size, mode, unsignedp)
+rtx x, y;
+enum rtx_code comparison;
+rtx size;
+enum machine_mode mode;
+int unsignedp;
+{
+    emit_cmp_and_jump_insns (x, y, comparison, size, mode, unsignedp, 0);
+}
+
+/* Emit a library call comparison between floating point X and Y.
+ COMPARISON is the rtl operator to compare with (EQ, NE, GT, etc.).  */
 
-  /* Immediately move the result of the libcall into a pseudo
+static void
+prepare_float_lib_cmp (px, py, pcomparison, pmode, punsignedp)
+rtx *px, *py;
+enum rtx_code *pcomparison;
+enum machine_mode *pmode;
+int *punsignedp;
+{
+    enum rtx_code comparison = *pcomparison;
+    rtx x = *px = protect_from_queue (*px, 0);
+    rtx y = *py = protect_from_queue (*py, 0);
+    enum machine_mode mode = GET_MODE (x);
+    rtx libfunc = 0;
+    rtx result;
+    
+    if (mode == HFmode)
+        switch (comparison)
+        {
+            case EQ:
+                libfunc = eqhf2_libfunc;
+                break;
+                
+            case NE:
+                libfunc = nehf2_libfunc;
+                break;
+                
+            case GT:
+                libfunc = gthf2_libfunc;
+                break;
+                
+            case GE:
+                libfunc = gehf2_libfunc;
+                break;
+                
+            case LT:
+                libfunc = lthf2_libfunc;
+                break;
+                
+            case LE:
+                libfunc = lehf2_libfunc;
+                break;
+                
+            case UNORDERED:
+                libfunc = unordhf2_libfunc;
+                break;
+                
+            default:
+                break;
+        }
+    else if (mode == SFmode)
+        switch (comparison)
+        {
+            case EQ:
+                libfunc = eqsf2_libfunc;
+                break;
+                
+            case NE:
+                libfunc = nesf2_libfunc;
+                break;
+                
+            case GT:
+                libfunc = gtsf2_libfunc;
+                break;
+                
+            case GE:
+                libfunc = gesf2_libfunc;
+                break;
+                
+            case LT:
+                libfunc = ltsf2_libfunc;
+                break;
+                
+            case LE:
+                libfunc = lesf2_libfunc;
+                break;
+                
+            case UNORDERED:
+                libfunc = unordsf2_libfunc;
+                break;
+                
+            default:
+                break;
+        }
+    else if (mode == DFmode)
+        switch (comparison)
+        {
+            case EQ:
+                libfunc = eqdf2_libfunc;
+                break;
+                
+            case NE:
+                libfunc = nedf2_libfunc;
+                break;
+                
+            case GT:
+                libfunc = gtdf2_libfunc;
+                break;
+                
+            case GE:
+                libfunc = gedf2_libfunc;
+                break;
+                
+            case LT:
+                libfunc = ltdf2_libfunc;
+                break;
+                
+            case LE:
+                libfunc = ledf2_libfunc;
+                break;
+                
+            case UNORDERED:
+                libfunc = unorddf2_libfunc;
+                break;
+                
+            default:
+                break;
+        }
+    else if (mode == XFmode)
+        switch (comparison)
+        {
+            case EQ:
+                libfunc = eqxf2_libfunc;
+                break;
+                
+            case NE:
+                libfunc = nexf2_libfunc;
+                break;
+                
+            case GT:
+                libfunc = gtxf2_libfunc;
+                break;
+                
+            case GE:
+                libfunc = gexf2_libfunc;
+                break;
+                
+            case LT:
+                libfunc = ltxf2_libfunc;
+                break;
+                
+            case LE:
+                libfunc = lexf2_libfunc;
+                break;
+                
+            case UNORDERED:
+                libfunc = unordxf2_libfunc;
+                break;
+                
+            default:
+                break;
+        }
+    else if (mode == TFmode)
+        switch (comparison)
+        {
+            case EQ:
+                libfunc = eqtf2_libfunc;
+                break;
+                
+            case NE:
+                libfunc = netf2_libfunc;
+                break;
+                
+            case GT:
+                libfunc = gttf2_libfunc;
+                break;
+                
+            case GE:
+                libfunc = getf2_libfunc;
+                break;
+                
+            case LT:
+                libfunc = lttf2_libfunc;
+                break;
+                
+            case LE:
+                libfunc = letf2_libfunc;
+                break;
+                
+            case UNORDERED:
+                libfunc = unordtf2_libfunc;
+                break;
+                
+            default:
+                break;
+        }
+    else
+    {
+        enum machine_mode wider_mode;
+        
+        for (wider_mode = GET_MODE_WIDER_MODE (mode); wider_mode != VOIDmode;
+             wider_mode = GET_MODE_WIDER_MODE (wider_mode))
+        {
+            if ((cmp_optab->handlers[(int) wider_mode].insn_code
+                 != CODE_FOR_nothing)
+                || (cmp_optab->handlers[(int) wider_mode].libfunc != 0))
+            {
+                x = protect_from_queue (x, 0);
+                y = protect_from_queue (y, 0);
+                *px = convert_to_mode (wider_mode, x, 0);
+                *py = convert_to_mode (wider_mode, y, 0);
+                prepare_float_lib_cmp (px, py, pcomparison, pmode, punsignedp);
+                return;
+            }
+        }
+        abort ();
+    }
+    
+    if (libfunc == 0)
+        abort ();
+    
+    emit_library_call (libfunc, LCT_CONST_MAKE_BLOCK, word_mode, 2, x, mode, y,
+                       mode);
+    
+    /* Immediately move the result of the libcall into a pseudo
      register so reload doesn't clobber the value if it needs
      the return register for a spill reg.  */
-  result = gen_reg_rtx (word_mode);
-  emit_move_insn (result, hard_libcall_value (word_mode));
-  *px = result;
-  *py = const0_rtx;
-  *pmode = word_mode;
-  if (comparison == UNORDERED)
-    *pcomparison = NE;
+    result = gen_reg_rtx (word_mode);
+    emit_move_insn (result, hard_libcall_value (word_mode));
+    *px = result;
+    *py = const0_rtx;
+    *pmode = word_mode;
+    if (comparison == UNORDERED)
+        *pcomparison = NE;
 #ifdef FLOAT_LIB_COMPARE_RETURNS_BOOL
-  else if (FLOAT_LIB_COMPARE_RETURNS_BOOL (mode, comparison))
-    *pcomparison = NE;
+    else if (FLOAT_LIB_COMPARE_RETURNS_BOOL (mode, comparison))
+        *pcomparison = NE;
 #endif
-  *punsignedp = 0;
+    *punsignedp = 0;
 }
 
 /* Generate code to indirectly jump to a location given in the rtx LOC.  */
 
 void
 emit_indirect_jump (loc)
-     rtx loc;
+rtx loc;
 {
-  if (! ((*insn_data[(int)CODE_FOR_indirect_jump].operand[0].predicate)
-	 (loc, Pmode)))
-    loc = copy_to_mode_reg (Pmode, loc);
-
-  emit_jump_insn (gen_indirect_jump (loc));
-  emit_barrier ();
+    if (! ((*insn_data[(int)CODE_FOR_indirect_jump].operand[0].predicate)
+           (loc, Pmode)))
+        loc = copy_to_mode_reg (Pmode, loc);
+    
+    emit_jump_insn (gen_indirect_jump (loc));
+    emit_barrier ();
 }
 
 #ifdef HAVE_conditional_move
 
 /* Emit a conditional move instruction if the machine supports one for that
-   condition and machine mode.
-
-   OP0 and OP1 are the operands that should be compared using CODE.  CMODE is
-   the mode to use should they be constants.  If it is VOIDmode, they cannot
-   both be constants.
-
-   OP2 should be stored in TARGET if the comparison is true, otherwise OP3
-   should be stored there.  MODE is the mode to use should they be constants.
-   If it is VOIDmode, they cannot both be constants.
-
-   The result is either TARGET (perhaps modified) or NULL_RTX if the operation
-   is not supported.  */
+ condition and machine mode.
+ 
+ OP0 and OP1 are the operands that should be compared using CODE.  CMODE is
+ the mode to use should they be constants.  If it is VOIDmode, they cannot
+ both be constants.
+ 
+ OP2 should be stored in TARGET if the comparison is true, otherwise OP3
+ should be stored there.  MODE is the mode to use should they be constants.
+ If it is VOIDmode, they cannot both be constants.
+ 
+ The result is either TARGET (perhaps modified) or NULL_RTX if the operation
+ is not supported.  */
 
 rtx
 emit_conditional_move (target, code, op0, op1, cmode, op2, op3, mode,
-		       unsignedp)
-     rtx target;
-     enum rtx_code code;
-     rtx op0, op1;
-     enum machine_mode cmode;
-     rtx op2, op3;
-     enum machine_mode mode;
-     int unsignedp;
+                       unsignedp)
+rtx target;
+enum rtx_code code;
+rtx op0, op1;
+enum machine_mode cmode;
+rtx op2, op3;
+enum machine_mode mode;
+int unsignedp;
 {
-  rtx tem, subtarget, comparison, insn;
-  enum insn_code icode;
-  enum rtx_code reversed;
-
-  /* If one operand is constant, make it the second one.  Only do this
+    rtx tem, subtarget, comparison, insn;
+    enum insn_code icode;
+    enum rtx_code reversed;
+    
+    /* If one operand is constant, make it the second one.  Only do this
      if the other operand is not constant as well.  */
-
-  if (swap_commutative_operands_p (op0, op1))
+    
+    if (swap_commutative_operands_p (op0, op1))
     {
-      tem = op0;
-      op0 = op1;
-      op1 = tem;
-      code = swap_condition (code);
+        tem = op0;
+        op0 = op1;
+        op1 = tem;
+        code = swap_condition (code);
     }
-
-  /* get_condition will prefer to generate LT and GT even if the old
+    
+    /* get_condition will prefer to generate LT and GT even if the old
      comparison was against zero, so undo that canonicalization here since
      comparisons against zero are cheaper.  */
-  if (code == LT && GET_CODE (op1) == CONST_INT && INTVAL (op1) == 1)
-    code = LE, op1 = const0_rtx;
-  else if (code == GT && GET_CODE (op1) == CONST_INT && INTVAL (op1) == -1)
-    code = GE, op1 = const0_rtx;
-
-  if (cmode == VOIDmode)
-    cmode = GET_MODE (op0);
-
-  if (swap_commutative_operands_p (op2, op3)
-      && ((reversed = reversed_comparison_code_parts (code, op0, op1, NULL))
-          != UNKNOWN))
+    if (code == LT && GET_CODE (op1) == CONST_INT && INTVAL (op1) == 1)
+        code = LE, op1 = const0_rtx;
+    else if (code == GT && GET_CODE (op1) == CONST_INT && INTVAL (op1) == -1)
+        code = GE, op1 = const0_rtx;
+    
+    if (cmode == VOIDmode)
+        cmode = GET_MODE (op0);
+    
+    if (swap_commutative_operands_p (op2, op3)
+        && ((reversed = reversed_comparison_code_parts (code, op0, op1, NULL))
+            != UNKNOWN))
     {
-      tem = op2;
-      op2 = op3;
-      op3 = tem;
-      code = reversed;
+        tem = op2;
+        op2 = op3;
+        op3 = tem;
+        code = reversed;
     }
-
-  if (mode == VOIDmode)
-    mode = GET_MODE (op2);
-
-  icode = movcc_gen_code[mode];
-
-  if (icode == CODE_FOR_nothing)
-    return 0;
-
-  if (flag_force_mem)
+    
+    if (mode == VOIDmode)
+        mode = GET_MODE (op2);
+    
+    icode = movcc_gen_code[mode];
+    
+    if (icode == CODE_FOR_nothing)
+        return 0;
+    
+    if (flag_force_mem)
     {
-      op2 = force_not_mem (op2);
-      op3 = force_not_mem (op3);
+        op2 = force_not_mem (op2);
+        op3 = force_not_mem (op3);
     }
-
-  if (target)
-    target = protect_from_queue (target, 1);
-  else
-    target = gen_reg_rtx (mode);
-
-  subtarget = target;
-
-  emit_queue ();
-
-  op2 = protect_from_queue (op2, 0);
-  op3 = protect_from_queue (op3, 0);
-
-  /* If the insn doesn't accept these operands, put them in pseudos.  */
-
-  if (! (*insn_data[icode].operand[0].predicate)
-      (subtarget, insn_data[icode].operand[0].mode))
-    subtarget = gen_reg_rtx (insn_data[icode].operand[0].mode);
-
-  if (! (*insn_data[icode].operand[2].predicate)
-      (op2, insn_data[icode].operand[2].mode))
-    op2 = copy_to_mode_reg (insn_data[icode].operand[2].mode, op2);
-
-  if (! (*insn_data[icode].operand[3].predicate)
-      (op3, insn_data[icode].operand[3].mode))
-    op3 = copy_to_mode_reg (insn_data[icode].operand[3].mode, op3);
-
-  /* Everything should now be in the suitable form, so emit the compare insn
+    
+    if (target)
+        target = protect_from_queue (target, 1);
+    else
+        target = gen_reg_rtx (mode);
+    
+    subtarget = target;
+    
+    emit_queue ();
+    
+    op2 = protect_from_queue (op2, 0);
+    op3 = protect_from_queue (op3, 0);
+    
+    /* If the insn doesn't accept these operands, put them in pseudos.  */
+    
+    if (! (*insn_data[icode].operand[0].predicate)
+        (subtarget, insn_data[icode].operand[0].mode))
+        subtarget = gen_reg_rtx (insn_data[icode].operand[0].mode);
+    
+    if (! (*insn_data[icode].operand[2].predicate)
+        (op2, insn_data[icode].operand[2].mode))
+        op2 = copy_to_mode_reg (insn_data[icode].operand[2].mode, op2);
+    
+    if (! (*insn_data[icode].operand[3].predicate)
+        (op3, insn_data[icode].operand[3].mode))
+        op3 = copy_to_mode_reg (insn_data[icode].operand[3].mode, op3);
+    
+    /* Everything should now be in the suitable form, so emit the compare insn
      and then the conditional move.  */
-
-  comparison 
+    
+    comparison
     = compare_from_rtx (op0, op1, code, unsignedp, cmode, NULL_RTX);
-
-  /* ??? Watch for const0_rtx (nop) and const_true_rtx (unconditional)?  */
-  /* We can get const0_rtx or const_true_rtx in some circumstances.  Just
+    
+    /* ??? Watch for const0_rtx (nop) and const_true_rtx (unconditional)?  */
+    /* We can get const0_rtx or const_true_rtx in some circumstances.  Just
      return NULL and let the caller figure out how best to deal with this
      situation.  */
-  if (GET_CODE (comparison) != code)
-    return NULL_RTX;
-  
-  insn = GEN_FCN (icode) (subtarget, comparison, op2, op3);
-
-  /* If that failed, then give up.  */
-  if (insn == 0)
-    return 0;
-
-  emit_insn (insn);
-
-  if (subtarget != target)
-    convert_move (target, subtarget, 0);
-
-  return target;
+    if (GET_CODE (comparison) != code)
+        return NULL_RTX;
+    
+    insn = GEN_FCN4 (icode) (subtarget, comparison, op2, op3);
+    
+    /* If that failed, then give up.  */
+    if (insn == 0)
+        return 0;
+    
+    emit_insn (insn);
+    
+    if (subtarget != target)
+        convert_move (target, subtarget, 0);
+    
+    return target;
 }
 
 /* Return non-zero if a conditional move of mode MODE is supported.
-
-   This function is for combine so it can tell whether an insn that looks
-   like a conditional move is actually supported by the hardware.  If we
-   guess wrong we lose a bit on optimization, but that's it.  */
+ 
+ This function is for combine so it can tell whether an insn that looks
+ like a conditional move is actually supported by the hardware.  If we
+ guess wrong we lose a bit on optimization, but that's it.  */
 /* ??? sparc64 supports conditionally moving integers values based on fp
-   comparisons, and vice versa.  How do we handle them?  */
+ comparisons, and vice versa.  How do we handle them?  */
 
 int
 can_conditionally_move_p (mode)
-     enum machine_mode mode;
+enum machine_mode mode;
 {
-  if (movcc_gen_code[mode] != CODE_FOR_nothing)
-    return 1;
-
-  return 0;
+    if (movcc_gen_code[mode] != CODE_FOR_nothing)
+        return 1;
+    
+    return 0;
 }
 
 #endif /* HAVE_conditional_move */
 
 /* These functions generate an insn body and return it
-   rather than emitting the insn.
-
-   They do not protect from queued increments,
-   because they may be used 1) in protect_from_queue itself
-   and 2) in other passes where there is no queue.  */
+ rather than emitting the insn.
+ 
+ They do not protect from queued increments,
+ because they may be used 1) in protect_from_queue itself
+ and 2) in other passes where there is no queue.  */
 
 /* Generate and return an insn body to add Y to X.  */
 
 rtx
 gen_add2_insn (x, y)
-     rtx x, y;
+rtx x, y;
 {
-  int icode = (int) add_optab->handlers[(int) GET_MODE (x)].insn_code; 
-
-  if (! ((*insn_data[icode].operand[0].predicate)
-	 (x, insn_data[icode].operand[0].mode))
-      || ! ((*insn_data[icode].operand[1].predicate)
-	    (x, insn_data[icode].operand[1].mode))
-      || ! ((*insn_data[icode].operand[2].predicate)
-	    (y, insn_data[icode].operand[2].mode)))
-    abort ();
-
-  return (GEN_FCN (icode) (x, x, y));
+    int icode = (int) add_optab->handlers[(int) GET_MODE (x)].insn_code;
+    
+    if (! ((*insn_data[icode].operand[0].predicate)
+           (x, insn_data[icode].operand[0].mode))
+        || ! ((*insn_data[icode].operand[1].predicate)
+              (x, insn_data[icode].operand[1].mode))
+        || ! ((*insn_data[icode].operand[2].predicate)
+              (y, insn_data[icode].operand[2].mode)))
+        abort ();
+    
+    return (GEN_FCN3 (icode) (x, x, y));
 }
 
 /* Generate and return an insn body to add r1 and c,
-   storing the result in r0.  */
+ storing the result in r0.  */
 rtx
 gen_add3_insn (r0, r1, c)
-     rtx r0, r1, c;
+rtx r0, r1, c;
 {
-  int icode = (int) add_optab->handlers[(int) GET_MODE (r0)].insn_code;
-
+    int icode = (int) add_optab->handlers[(int) GET_MODE (r0)].insn_code;
+    
     if (icode == CODE_FOR_nothing
-      || ! ((*insn_data[icode].operand[0].predicate)
-	    (r0, insn_data[icode].operand[0].mode))
-      || ! ((*insn_data[icode].operand[1].predicate)
-	    (r1, insn_data[icode].operand[1].mode))
-      || ! ((*insn_data[icode].operand[2].predicate)
-	    (c, insn_data[icode].operand[2].mode)))
-    return NULL_RTX;
-
-  return (GEN_FCN (icode) (r0, r1, c));
+        || ! ((*insn_data[icode].operand[0].predicate)
+              (r0, insn_data[icode].operand[0].mode))
+        || ! ((*insn_data[icode].operand[1].predicate)
+              (r1, insn_data[icode].operand[1].mode))
+        || ! ((*insn_data[icode].operand[2].predicate)
+              (c, insn_data[icode].operand[2].mode)))
+        return NULL_RTX;
+    
+    return (GEN_FCN3 (icode) (r0, r1, c));
 }
 
 int
 have_add2_insn (x, y)
-     rtx x, y;
+rtx x, y;
 {
-  int icode;
-
-  if (GET_MODE (x) == VOIDmode)
-    abort ();
-
-  icode = (int) add_optab->handlers[(int) GET_MODE (x)].insn_code; 
-
-  if (icode == CODE_FOR_nothing)
-    return 0;
-
-  if (! ((*insn_data[icode].operand[0].predicate)
-	 (x, insn_data[icode].operand[0].mode))
-      || ! ((*insn_data[icode].operand[1].predicate)
-	    (x, insn_data[icode].operand[1].mode))
-      || ! ((*insn_data[icode].operand[2].predicate)
-	    (y, insn_data[icode].operand[2].mode)))
-    return 0;
-
-  return 1;
+    int icode;
+    
+    if (GET_MODE (x) == VOIDmode)
+        abort ();
+    
+    icode = (int) add_optab->handlers[(int) GET_MODE (x)].insn_code;
+    
+    if (icode == CODE_FOR_nothing)
+        return 0;
+    
+    if (! ((*insn_data[icode].operand[0].predicate)
+           (x, insn_data[icode].operand[0].mode))
+        || ! ((*insn_data[icode].operand[1].predicate)
+              (x, insn_data[icode].operand[1].mode))
+        || ! ((*insn_data[icode].operand[2].predicate)
+              (y, insn_data[icode].operand[2].mode)))
+        return 0;
+    
+    return 1;
 }
 
 /* Generate and return an insn body to subtract Y from X.  */
 
 rtx
 gen_sub2_insn (x, y)
-     rtx x, y;
+rtx x, y;
 {
-  int icode = (int) sub_optab->handlers[(int) GET_MODE (x)].insn_code; 
-
-  if (! ((*insn_data[icode].operand[0].predicate)
-	 (x, insn_data[icode].operand[0].mode))
-      || ! ((*insn_data[icode].operand[1].predicate)
-	    (x, insn_data[icode].operand[1].mode))
-      || ! ((*insn_data[icode].operand[2].predicate)
-	    (y, insn_data[icode].operand[2].mode)))
-    abort ();
-
-  return (GEN_FCN (icode) (x, x, y));
+    int icode = (int) sub_optab->handlers[(int) GET_MODE (x)].insn_code;
+    
+    if (! ((*insn_data[icode].operand[0].predicate)
+           (x, insn_data[icode].operand[0].mode))
+        || ! ((*insn_data[icode].operand[1].predicate)
+              (x, insn_data[icode].operand[1].mode))
+        || ! ((*insn_data[icode].operand[2].predicate)
+              (y, insn_data[icode].operand[2].mode)))
+        abort ();
+    
+    return (GEN_FCN3 (icode) (x, x, y));
 }
 
 /* Generate and return an insn body to subtract r1 and c,
-   storing the result in r0.  */
+ storing the result in r0.  */
 rtx
 gen_sub3_insn (r0, r1, c)
-     rtx r0, r1, c;
+rtx r0, r1, c;
 {
-  int icode = (int) sub_optab->handlers[(int) GET_MODE (r0)].insn_code;
-
+    int icode = (int) sub_optab->handlers[(int) GET_MODE (r0)].insn_code;
+    
     if (icode == CODE_FOR_nothing
-      || ! ((*insn_data[icode].operand[0].predicate)
-	    (r0, insn_data[icode].operand[0].mode))
-      || ! ((*insn_data[icode].operand[1].predicate)
-	    (r1, insn_data[icode].operand[1].mode))
-      || ! ((*insn_data[icode].operand[2].predicate)
-	    (c, insn_data[icode].operand[2].mode)))
-    return NULL_RTX;
-
-  return (GEN_FCN (icode) (r0, r1, c));
+        || ! ((*insn_data[icode].operand[0].predicate)
+              (r0, insn_data[icode].operand[0].mode))
+        || ! ((*insn_data[icode].operand[1].predicate)
+              (r1, insn_data[icode].operand[1].mode))
+        || ! ((*insn_data[icode].operand[2].predicate)
+              (c, insn_data[icode].operand[2].mode)))
+        return NULL_RTX;
+    
+    return (GEN_FCN3 (icode) (r0, r1, c));
 }
 
 int
 have_sub2_insn (x, y)
-     rtx x, y;
+rtx x, y;
 {
-  int icode;
-
-  if (GET_MODE (x) == VOIDmode)
-    abort ();
-
-  icode = (int) sub_optab->handlers[(int) GET_MODE (x)].insn_code; 
-
-  if (icode == CODE_FOR_nothing)
-    return 0;
-
-  if (! ((*insn_data[icode].operand[0].predicate)
-	 (x, insn_data[icode].operand[0].mode))
-      || ! ((*insn_data[icode].operand[1].predicate)
-	    (x, insn_data[icode].operand[1].mode))
-      || ! ((*insn_data[icode].operand[2].predicate)
-	    (y, insn_data[icode].operand[2].mode)))
-    return 0;
-
-  return 1;
+    int icode;
+    
+    if (GET_MODE (x) == VOIDmode)
+        abort ();
+    
+    icode = (int) sub_optab->handlers[(int) GET_MODE (x)].insn_code;
+    
+    if (icode == CODE_FOR_nothing)
+        return 0;
+    
+    if (! ((*insn_data[icode].operand[0].predicate)
+           (x, insn_data[icode].operand[0].mode))
+        || ! ((*insn_data[icode].operand[1].predicate)
+              (x, insn_data[icode].operand[1].mode))
+        || ! ((*insn_data[icode].operand[2].predicate)
+              (y, insn_data[icode].operand[2].mode)))
+        return 0;
+    
+    return 1;
 }
 
 /* Generate the body of an instruction to copy Y into X.
-   It may be a SEQUENCE, if one insn isn't enough.  */
+ It may be a SEQUENCE, if one insn isn't enough.  */
 
 rtx
 gen_move_insn (x, y)
-     rtx x, y;
+rtx x, y;
 {
-  enum machine_mode mode = GET_MODE (x);
-  enum insn_code insn_code;
-  rtx seq;
-
-  if (mode == VOIDmode)
-    mode = GET_MODE (y); 
-
-  insn_code = mov_optab->handlers[(int) mode].insn_code;
-
-  /* Handle MODE_CC modes:  If we don't have a special move insn for this mode,
+    enum machine_mode mode = GET_MODE (x);
+    enum insn_code insn_code;
+    rtx seq;
+    
+    if (mode == VOIDmode)
+        mode = GET_MODE (y);
+    
+    insn_code = mov_optab->handlers[(int) mode].insn_code;
+    
+    /* Handle MODE_CC modes:  If we don't have a special move insn for this mode,
      find a mode to do it in.  If we have a movcc, use it.  Otherwise,
      find the MODE_INT mode of the same width.  */
-
-  if (GET_MODE_CLASS (mode) == MODE_CC && insn_code == CODE_FOR_nothing)
+    
+    if (GET_MODE_CLASS (mode) == MODE_CC && insn_code == CODE_FOR_nothing)
     {
-      enum machine_mode tmode = VOIDmode;
-      rtx x1 = x, y1 = y;
-
-      if (mode != CCmode
-	  && mov_optab->handlers[(int) CCmode].insn_code != CODE_FOR_nothing)
-	tmode = CCmode;
-      else
-	for (tmode = QImode; tmode != VOIDmode;
-	     tmode = GET_MODE_WIDER_MODE (tmode))
-	  if (GET_MODE_SIZE (tmode) == GET_MODE_SIZE (mode))
-	    break;
-
-      if (tmode == VOIDmode)
-	abort ();
-
-      /* Get X and Y in TMODE.  We can't use gen_lowpart here because it
-	 may call change_address which is not appropriate if we were
-	 called when a reload was in progress.  We don't have to worry
-	 about changing the address since the size in bytes is supposed to
-	 be the same.  Copy the MEM to change the mode and move any
-	 substitutions from the old MEM to the new one.  */
-
-      if (reload_in_progress)
-	{
-	  x = gen_lowpart_common (tmode, x1);
-	  if (x == 0 && GET_CODE (x1) == MEM)
-	    {
-	      x = adjust_address_nv (x1, tmode, 0);
-	      copy_replacements (x1, x);
-	    }
-
-	  y = gen_lowpart_common (tmode, y1);
-	  if (y == 0 && GET_CODE (y1) == MEM)
-	    {
-	      y = adjust_address_nv (y1, tmode, 0);
-	      copy_replacements (y1, y);
-	    }
-	}
-      else
-	{
-	  x = gen_lowpart (tmode, x);
-	  y = gen_lowpart (tmode, y);
-	}
-	  
-      insn_code = mov_optab->handlers[(int) tmode].insn_code;
-      return (GEN_FCN (insn_code) (x, y));
+        enum machine_mode tmode = VOIDmode;
+        rtx x1 = x, y1 = y;
+        
+        if (mode != CCmode
+            && mov_optab->handlers[(int) CCmode].insn_code != CODE_FOR_nothing)
+            tmode = CCmode;
+        else
+            for (tmode = QImode; tmode != VOIDmode;
+                 tmode = GET_MODE_WIDER_MODE (tmode))
+        if (GET_MODE_SIZE (tmode) == GET_MODE_SIZE (mode))
+            break;
+        
+        if (tmode == VOIDmode)
+            abort ();
+        
+        /* Get X and Y in TMODE.  We can't use gen_lowpart here because it
+         may call change_address which is not appropriate if we were
+         called when a reload was in progress.  We don't have to worry
+         about changing the address since the size in bytes is supposed to
+         be the same.  Copy the MEM to change the mode and move any
+         substitutions from the old MEM to the new one.  */
+        
+        if (reload_in_progress)
+        {
+            x = gen_lowpart_common (tmode, x1);
+            if (x == 0 && GET_CODE (x1) == MEM)
+            {
+                x = adjust_address_nv (x1, tmode, 0);
+                copy_replacements (x1, x);
+            }
+            
+            y = gen_lowpart_common (tmode, y1);
+            if (y == 0 && GET_CODE (y1) == MEM)
+            {
+                y = adjust_address_nv (y1, tmode, 0);
+                copy_replacements (y1, y);
+            }
+        }
+        else
+        {
+            x = gen_lowpart (tmode, x);
+            y = gen_lowpart (tmode, y);
+        }
+        
+        insn_code = mov_optab->handlers[(int) tmode].insn_code;
+        return (GEN_FCN2 (insn_code) (x, y));
     }
-
-  start_sequence ();
-  emit_move_insn_1 (x, y);
-  seq = gen_sequence ();
-  end_sequence ();
-  return seq;
+    
+    start_sequence ();
+    emit_move_insn_1 (x, y);
+    seq = gen_sequence ();
+    end_sequence ();
+    return seq;
 }
 
 /* Return the insn code used to extend FROM_MODE to TO_MODE.
-   UNSIGNEDP specifies zero-extension instead of sign-extension.  If
-   no such operation exists, CODE_FOR_nothing will be returned.  */
+ UNSIGNEDP specifies zero-extension instead of sign-extension.  If
+ no such operation exists, CODE_FOR_nothing will be returned.  */
 
 enum insn_code
 can_extend_p (to_mode, from_mode, unsignedp)
-     enum machine_mode to_mode, from_mode;
-     int unsignedp;
+enum machine_mode to_mode, from_mode;
+int unsignedp;
 {
 #ifdef HAVE_ptr_extend
-  if (unsignedp < 0)
-    return CODE_FOR_ptr_extend;
-  else
+    if (unsignedp < 0)
+        return CODE_FOR_ptr_extend;
+    else
 #endif
-    return extendtab[(int) to_mode][(int) from_mode][unsignedp != 0];
+        return extendtab[(int) to_mode][(int) from_mode][unsignedp != 0];
 }
 
 /* Generate the body of an insn to extend Y (with mode MFROM)
-   into X (with mode MTO).  Do zero-extension if UNSIGNEDP is nonzero.  */
+ into X (with mode MTO).  Do zero-extension if UNSIGNEDP is nonzero.  */
 
 rtx
 gen_extend_insn (x, y, mto, mfrom, unsignedp)
-     rtx x, y;
-     enum machine_mode mto, mfrom;
-     int unsignedp;
+rtx x, y;
+enum machine_mode mto, mfrom;
+int unsignedp;
 {
-  return (GEN_FCN (extendtab[(int) mto][(int) mfrom][unsignedp != 0]) (x, y));
+    return (GEN_FCN2 (extendtab[(int) mto][(int) mfrom][unsignedp != 0]) (x, y));
 }
 
 /* can_fix_p and can_float_p say whether the target machine
-   can directly convert a given fixed point type to
-   a given floating point type, or vice versa.
-   The returned value is the CODE_FOR_... value to use,
-   or CODE_FOR_nothing if these modes cannot be directly converted.
-
-   *TRUNCP_PTR is set to 1 if it is necessary to output
-   an explicit FTRUNC insn before the fix insn; otherwise 0.  */
+ can directly convert a given fixed point type to
+ a given floating point type, or vice versa.
+ The returned value is the CODE_FOR_... value to use,
+ or CODE_FOR_nothing if these modes cannot be directly converted.
+ 
+ *TRUNCP_PTR is set to 1 if it is necessary to output
+ an explicit FTRUNC insn before the fix insn; otherwise 0.  */
 
 static enum insn_code
 can_fix_p (fixmode, fltmode, unsignedp, truncp_ptr)
-     enum machine_mode fltmode, fixmode;
-     int unsignedp;
-     int *truncp_ptr;
+enum machine_mode fltmode, fixmode;
+int unsignedp;
+int *truncp_ptr;
 {
-  *truncp_ptr = 0;
-  if (fixtrunctab[(int) fltmode][(int) fixmode][unsignedp != 0]
-      != CODE_FOR_nothing)
-    return fixtrunctab[(int) fltmode][(int) fixmode][unsignedp != 0];
-
-  if (ftrunc_optab->handlers[(int) fltmode].insn_code != CODE_FOR_nothing)
+    *truncp_ptr = 0;
+    if (fixtrunctab[(int) fltmode][(int) fixmode][unsignedp != 0]
+        != CODE_FOR_nothing)
+        return fixtrunctab[(int) fltmode][(int) fixmode][unsignedp != 0];
+    
+    if (ftrunc_optab->handlers[(int) fltmode].insn_code != CODE_FOR_nothing)
     {
-      *truncp_ptr = 1;
-      return fixtab[(int) fltmode][(int) fixmode][unsignedp != 0];
+        *truncp_ptr = 1;
+        return fixtab[(int) fltmode][(int) fixmode][unsignedp != 0];
     }
-  return CODE_FOR_nothing;
+    return CODE_FOR_nothing;
 }
 
 static enum insn_code
 can_float_p (fltmode, fixmode, unsignedp)
-     enum machine_mode fixmode, fltmode;
-     int unsignedp;
+enum machine_mode fixmode, fltmode;
+int unsignedp;
 {
-  return floattab[(int) fltmode][(int) fixmode][unsignedp != 0];
+    return floattab[(int) fltmode][(int) fixmode][unsignedp != 0];
 }
 
 /* Generate code to convert FROM to floating point
-   and store in TO.  FROM must be fixed point and not VOIDmode.
-   UNSIGNEDP nonzero means regard FROM as unsigned.
-   Normally this is done by correcting the final value
-   if it is negative.  */
+ and store in TO.  FROM must be fixed point and not VOIDmode.
+ UNSIGNEDP nonzero means regard FROM as unsigned.
+ Normally this is done by correcting the final value
+ if it is negative.  */
 
 void
 expand_float (to, from, unsignedp)
-     rtx to, from;
-     int unsignedp;
+rtx to, from;
+int unsignedp;
 {
-  enum insn_code icode;
-  rtx target = to;
-  enum machine_mode fmode, imode;
-
-  /* Crash now, because we won't be able to decide which mode to use.  */
-  if (GET_MODE (from) == VOIDmode)
-    abort ();
-
-  /* Look for an insn to do the conversion.  Do it in the specified
+    enum insn_code icode;
+    rtx target = to;
+    enum machine_mode fmode, imode;
+    
+    /* Crash now, because we won't be able to decide which mode to use.  */
+    if (GET_MODE (from) == VOIDmode)
+        abort ();
+    
+    /* Look for an insn to do the conversion.  Do it in the specified
      modes if possible; otherwise convert either input, output or both to
      wider mode.  If the integer mode is wider than the mode of FROM,
      we can do the conversion signed even if the input is unsigned.  */
-
-  for (imode = GET_MODE (from); imode != VOIDmode;
-       imode = GET_MODE_WIDER_MODE (imode))
+    
+    for (imode = GET_MODE (from); imode != VOIDmode;
+         imode = GET_MODE_WIDER_MODE (imode))
     for (fmode = GET_MODE (to); fmode != VOIDmode;
-	 fmode = GET_MODE_WIDER_MODE (fmode))
-      {
-	int doing_unsigned = unsignedp;
-
-	if (fmode != GET_MODE (to)
-	    && significand_size (fmode) < GET_MODE_BITSIZE (GET_MODE (from)))
-	  continue;
-
-	icode = can_float_p (fmode, imode, unsignedp);
-	if (icode == CODE_FOR_nothing && imode != GET_MODE (from) && unsignedp)
-	  icode = can_float_p (fmode, imode, 0), doing_unsigned = 0;
-
-	if (icode != CODE_FOR_nothing)
-	  {
-	    to = protect_from_queue (to, 1);
-	    from = protect_from_queue (from, 0);
-
-	    if (imode != GET_MODE (from))
-	      from = convert_to_mode (imode, from, unsignedp);
-
-	    if (fmode != GET_MODE (to))
-	      target = gen_reg_rtx (fmode);
-
-	    emit_unop_insn (icode, target, from,
-			    doing_unsigned ? UNSIGNED_FLOAT : FLOAT);
-
-	    if (target != to)
-	      convert_move (to, target, 0);
-	    return;
-	  }
+         fmode = GET_MODE_WIDER_MODE (fmode))
+    {
+        int doing_unsigned = unsignedp;
+        
+        if (fmode != GET_MODE (to)
+            && significand_size (fmode) < GET_MODE_BITSIZE (GET_MODE (from)))
+            continue;
+        
+        icode = can_float_p (fmode, imode, unsignedp);
+        if (icode == CODE_FOR_nothing && imode != GET_MODE (from) && unsignedp)
+            icode = can_float_p (fmode, imode, 0), doing_unsigned = 0;
+        
+        if (icode != CODE_FOR_nothing)
+        {
+            to = protect_from_queue (to, 1);
+            from = protect_from_queue (from, 0);
+            
+            if (imode != GET_MODE (from))
+                from = convert_to_mode (imode, from, unsignedp);
+            
+            if (fmode != GET_MODE (to))
+                target = gen_reg_rtx (fmode);
+            
+            emit_unop_insn (icode, target, from,
+                            doing_unsigned ? UNSIGNED_FLOAT : FLOAT);
+            
+            if (target != to)
+                convert_move (to, target, 0);
+            return;
+        }
     }
-
+    
 #if !defined (REAL_IS_NOT_DOUBLE) || defined (REAL_ARITHMETIC)
-
-  /* Unsigned integer, and no way to convert directly.
+    
+    /* Unsigned integer, and no way to convert directly.
      Convert as signed, then conditionally adjust the result.  */
-  if (unsignedp)
+    if (unsignedp)
     {
-      rtx label = gen_label_rtx ();
-      rtx temp;
-      REAL_VALUE_TYPE offset;
-
-      emit_queue ();
-
-      to = protect_from_queue (to, 1);
-      from = protect_from_queue (from, 0);
-
-      if (flag_force_mem)
-	from = force_not_mem (from);
-
-      /* Look for a usable floating mode FMODE wider than the source and at
-	 least as wide as the target.  Using FMODE will avoid rounding woes
-	 with unsigned values greater than the signed maximum value.  */
-
-      for (fmode = GET_MODE (to);  fmode != VOIDmode;
-	   fmode = GET_MODE_WIDER_MODE (fmode))
-	if (GET_MODE_BITSIZE (GET_MODE (from)) < GET_MODE_BITSIZE (fmode)
-	    && can_float_p (fmode, GET_MODE (from), 0) != CODE_FOR_nothing)
-	  break;
-
-      if (fmode == VOIDmode)
-	{
-	  /* There is no such mode.  Pretend the target is wide enough.  */
-	  fmode = GET_MODE (to);
-
-	  /* Avoid double-rounding when TO is narrower than FROM.  */
-	  if ((significand_size (fmode) + 1)
-	      < GET_MODE_BITSIZE (GET_MODE (from)))
-	    {
-	      rtx temp1;
-	      rtx neglabel = gen_label_rtx ();
-
-	      /* Don't use TARGET if it isn't a register, is a hard register, 
-		 or is the wrong mode.  */
-	      if (GET_CODE (target) != REG
-		  || REGNO (target) < FIRST_PSEUDO_REGISTER
-		  || GET_MODE (target) != fmode)
-		target = gen_reg_rtx (fmode);
-
-	      imode = GET_MODE (from);
-	      do_pending_stack_adjust ();
-
-	      /* Test whether the sign bit is set.  */
-	      emit_cmp_and_jump_insns (from, const0_rtx, LT, NULL_RTX, imode,
-				       0, neglabel);
-
-	      /* The sign bit is not set.  Convert as signed.  */
-	      expand_float (target, from, 0);
-	      emit_jump_insn (gen_jump (label));
-	      emit_barrier ();
-
-	      /* The sign bit is set.
-		 Convert to a usable (positive signed) value by shifting right
-		 one bit, while remembering if a nonzero bit was shifted
-		 out; i.e., compute  (from & 1) | (from >> 1).  */
-
-	      emit_label (neglabel);
-	      temp = expand_binop (imode, and_optab, from, const1_rtx,
-				   NULL_RTX, 1, OPTAB_LIB_WIDEN);
-	      temp1 = expand_shift (RSHIFT_EXPR, imode, from, integer_one_node,
-				    NULL_RTX, 1);
-	      temp = expand_binop (imode, ior_optab, temp, temp1, temp, 1, 
-				   OPTAB_LIB_WIDEN);
-	      expand_float (target, temp, 0);
-
-	      /* Multiply by 2 to undo the shift above.  */
-	      temp = expand_binop (fmode, add_optab, target, target,
-				     target, 0, OPTAB_LIB_WIDEN);
-	      if (temp != target)
-		emit_move_insn (target, temp);
-
-	      do_pending_stack_adjust ();
-	      emit_label (label);
-	      goto done;
-	    }
-	}
-
-      /* If we are about to do some arithmetic to correct for an
-	 unsigned operand, do it in a pseudo-register.  */
-
-      if (GET_MODE (to) != fmode
-	  || GET_CODE (to) != REG || REGNO (to) < FIRST_PSEUDO_REGISTER)
-	target = gen_reg_rtx (fmode);
-
-      /* Convert as signed integer to floating.  */
-      expand_float (target, from, 0);
-
-      /* If FROM is negative (and therefore TO is negative),
-	 correct its value by 2**bitwidth.  */
-
-      do_pending_stack_adjust ();
-      emit_cmp_and_jump_insns (from, const0_rtx, GE, NULL_RTX, GET_MODE (from),
-			       0, label);
-
-      /* On SCO 3.2.1, ldexp rejects values outside [0.5, 1).
-	 Rather than setting up a dconst_dot_5, let's hope SCO
-	 fixes the bug.  */
-      offset = REAL_VALUE_LDEXP (dconst1, GET_MODE_BITSIZE (GET_MODE (from)));
-      temp = expand_binop (fmode, add_optab, target,
-			   CONST_DOUBLE_FROM_REAL_VALUE (offset, fmode),
-			   target, 0, OPTAB_LIB_WIDEN);
-      if (temp != target)
-	emit_move_insn (target, temp);
-
-      do_pending_stack_adjust ();
-      emit_label (label);
-      goto done;
+        rtx label = gen_label_rtx ();
+        rtx temp;
+        REAL_VALUE_TYPE offset;
+        
+        emit_queue ();
+        
+        to = protect_from_queue (to, 1);
+        from = protect_from_queue (from, 0);
+        
+        if (flag_force_mem)
+            from = force_not_mem (from);
+        
+        /* Look for a usable floating mode FMODE wider than the source and at
+         least as wide as the target.  Using FMODE will avoid rounding woes
+         with unsigned values greater than the signed maximum value.  */
+        
+        for (fmode = GET_MODE (to);  fmode != VOIDmode;
+             fmode = GET_MODE_WIDER_MODE (fmode))
+        if (GET_MODE_BITSIZE (GET_MODE (from)) < GET_MODE_BITSIZE (fmode)
+            && can_float_p (fmode, GET_MODE (from), 0) != CODE_FOR_nothing)
+            break;
+        
+        if (fmode == VOIDmode)
+        {
+            /* There is no such mode.  Pretend the target is wide enough.  */
+            fmode = GET_MODE (to);
+            
+            /* Avoid double-rounding when TO is narrower than FROM.  */
+            if ((significand_size (fmode) + 1)
+                < GET_MODE_BITSIZE (GET_MODE (from)))
+            {
+                rtx temp1;
+                rtx neglabel = gen_label_rtx ();
+                
+                /* Don't use TARGET if it isn't a register, is a hard register,
+                 or is the wrong mode.  */
+                if (GET_CODE (target) != REG
+                    || REGNO (target) < FIRST_PSEUDO_REGISTER
+                    || GET_MODE (target) != fmode)
+                    target = gen_reg_rtx (fmode);
+                
+                imode = GET_MODE (from);
+                do_pending_stack_adjust ();
+                
+                /* Test whether the sign bit is set.  */
+                emit_cmp_and_jump_insns (from, const0_rtx, LT, NULL_RTX, imode,
+                                         0, neglabel);
+                
+                /* The sign bit is not set.  Convert as signed.  */
+                expand_float (target, from, 0);
+                emit_jump_insn (gen_jump (label));
+                emit_barrier ();
+                
+                /* The sign bit is set.
+                 Convert to a usable (positive signed) value by shifting right
+                 one bit, while remembering if a nonzero bit was shifted
+                 out; i.e., compute  (from & 1) | (from >> 1).  */
+                
+                emit_label (neglabel);
+                temp = expand_binop (imode, and_optab, from, const1_rtx,
+                                     NULL_RTX, 1, OPTAB_LIB_WIDEN);
+                temp1 = expand_shift (RSHIFT_EXPR, imode, from, integer_one_node,
+                                      NULL_RTX, 1);
+                temp = expand_binop (imode, ior_optab, temp, temp1, temp, 1,
+                                     OPTAB_LIB_WIDEN);
+                expand_float (target, temp, 0);
+                
+                /* Multiply by 2 to undo the shift above.  */
+                temp = expand_binop (fmode, add_optab, target, target,
+                                     target, 0, OPTAB_LIB_WIDEN);
+                if (temp != target)
+                    emit_move_insn (target, temp);
+                
+                do_pending_stack_adjust ();
+                emit_label (label);
+                goto done;
+            }
+        }
+        
+        /* If we are about to do some arithmetic to correct for an
+         unsigned operand, do it in a pseudo-register.  */
+        
+        if (GET_MODE (to) != fmode
+            || GET_CODE (to) != REG || REGNO (to) < FIRST_PSEUDO_REGISTER)
+            target = gen_reg_rtx (fmode);
+        
+        /* Convert as signed integer to floating.  */
+        expand_float (target, from, 0);
+        
+        /* If FROM is negative (and therefore TO is negative),
+         correct its value by 2**bitwidth.  */
+        
+        do_pending_stack_adjust ();
+        emit_cmp_and_jump_insns (from, const0_rtx, GE, NULL_RTX, GET_MODE (from),
+                                 0, label);
+        
+        /* On SCO 3.2.1, ldexp rejects values outside [0.5, 1).
+         Rather than setting up a dconst_dot_5, let's hope SCO
+         fixes the bug.  */
+        offset = REAL_VALUE_LDEXP (dconst1, GET_MODE_BITSIZE (GET_MODE (from)));
+        temp = expand_binop (fmode, add_optab, target,
+                             CONST_DOUBLE_FROM_REAL_VALUE (offset, fmode),
+                             target, 0, OPTAB_LIB_WIDEN);
+        if (temp != target)
+            emit_move_insn (target, temp);
+        
+        do_pending_stack_adjust ();
+        emit_label (label);
+        goto done;
     }
 #endif
-
-  /* No hardware instruction available; call a library routine to convert from
+    
+    /* No hardware instruction available; call a library routine to convert from
      SImode, DImode, or TImode into SFmode, DFmode, XFmode, or TFmode.  */
     {
-      rtx libfcn;
-      rtx insns;
-      rtx value;
-
-      to = protect_from_queue (to, 1);
-      from = protect_from_queue (from, 0);
-
-      if (GET_MODE_SIZE (GET_MODE (from)) < GET_MODE_SIZE (SImode))
-	from = convert_to_mode (SImode, from, unsignedp);
-
-      if (flag_force_mem)
-	from = force_not_mem (from);
-
-      if (GET_MODE (to) == SFmode)
-	{
-	  if (GET_MODE (from) == SImode)
-	    libfcn = floatsisf_libfunc;
-	  else if (GET_MODE (from) == DImode)
-	    libfcn = floatdisf_libfunc;
-	  else if (GET_MODE (from) == TImode)
-	    libfcn = floattisf_libfunc;
-	  else
-	    abort ();
-	}
-      else if (GET_MODE (to) == DFmode)
-	{
-	  if (GET_MODE (from) == SImode)
-	    libfcn = floatsidf_libfunc;
-	  else if (GET_MODE (from) == DImode)
-	    libfcn = floatdidf_libfunc;
-	  else if (GET_MODE (from) == TImode)
-	    libfcn = floattidf_libfunc;
-	  else
-	    abort ();
-	}
-      else if (GET_MODE (to) == XFmode)
-	{
-	  if (GET_MODE (from) == SImode)
-	    libfcn = floatsixf_libfunc;
-	  else if (GET_MODE (from) == DImode)
-	    libfcn = floatdixf_libfunc;
-	  else if (GET_MODE (from) == TImode)
-	    libfcn = floattixf_libfunc;
-	  else
-	    abort ();
-	}
-      else if (GET_MODE (to) == TFmode)
-	{
-	  if (GET_MODE (from) == SImode)
-	    libfcn = floatsitf_libfunc;
-	  else if (GET_MODE (from) == DImode)
-	    libfcn = floatditf_libfunc;
-	  else if (GET_MODE (from) == TImode)
-	    libfcn = floattitf_libfunc;
-	  else
-	    abort ();
-	}
-      else
-	abort ();
-
-      start_sequence ();
-
-      value = emit_library_call_value (libfcn, NULL_RTX, LCT_CONST,
-				       GET_MODE (to), 1, from,
-				       GET_MODE (from));
-      insns = get_insns ();
-      end_sequence ();
-
-      emit_libcall_block (insns, target, value,
-			  gen_rtx_FLOAT (GET_MODE (to), from));
+        rtx libfcn;
+        rtx insns;
+        rtx value;
+        
+        to = protect_from_queue (to, 1);
+        from = protect_from_queue (from, 0);
+        
+        if (GET_MODE_SIZE (GET_MODE (from)) < GET_MODE_SIZE (SImode))
+            from = convert_to_mode (SImode, from, unsignedp);
+        
+        if (flag_force_mem)
+            from = force_not_mem (from);
+        
+        if (GET_MODE (to) == SFmode)
+        {
+            if (GET_MODE (from) == SImode)
+                libfcn = floatsisf_libfunc;
+            else if (GET_MODE (from) == DImode)
+                libfcn = floatdisf_libfunc;
+            else if (GET_MODE (from) == TImode)
+                libfcn = floattisf_libfunc;
+            else
+                abort ();
+        }
+        else if (GET_MODE (to) == DFmode)
+        {
+            if (GET_MODE (from) == SImode)
+                libfcn = floatsidf_libfunc;
+            else if (GET_MODE (from) == DImode)
+                libfcn = floatdidf_libfunc;
+            else if (GET_MODE (from) == TImode)
+                libfcn = floattidf_libfunc;
+            else
+                abort ();
+        }
+        else if (GET_MODE (to) == XFmode)
+        {
+            if (GET_MODE (from) == SImode)
+                libfcn = floatsixf_libfunc;
+            else if (GET_MODE (from) == DImode)
+                libfcn = floatdixf_libfunc;
+            else if (GET_MODE (from) == TImode)
+                libfcn = floattixf_libfunc;
+            else
+                abort ();
+        }
+        else if (GET_MODE (to) == TFmode)
+        {
+            if (GET_MODE (from) == SImode)
+                libfcn = floatsitf_libfunc;
+            else if (GET_MODE (from) == DImode)
+                libfcn = floatditf_libfunc;
+            else if (GET_MODE (from) == TImode)
+                libfcn = floattitf_libfunc;
+            else
+                abort ();
+        }
+        else
+            abort ();
+        
+        start_sequence ();
+        
+        value = emit_library_call_value (libfcn, NULL_RTX, LCT_CONST,
+                                         GET_MODE (to), 1, from,
+                                         GET_MODE (from));
+        insns = get_insns ();
+        end_sequence ();
+        
+        emit_libcall_block (insns, target, value,
+                            gen_rtx_FLOAT (GET_MODE (to), from));
     }
-
- done:
-
-  /* Copy result to requested destination
+    
+done:
+    
+    /* Copy result to requested destination
      if we have been computing in a temp location.  */
-
-  if (target != to)
+    
+    if (target != to)
     {
-      if (GET_MODE (target) == GET_MODE (to))
-	emit_move_insn (to, target);
-      else
-	convert_move (to, target, 0);
+        if (GET_MODE (target) == GET_MODE (to))
+            emit_move_insn (to, target);
+        else
+            convert_move (to, target, 0);
     }
 }
 
 /* expand_fix: generate code to convert FROM to fixed point
-   and store in TO.  FROM must be floating point.  */
+ and store in TO.  FROM must be floating point.  */
 
 static rtx
 ftruncify (x)
-     rtx x;
+rtx x;
 {
-  rtx temp = gen_reg_rtx (GET_MODE (x));
-  return expand_unop (GET_MODE (x), ftrunc_optab, x, temp, 0);
+    rtx temp = gen_reg_rtx (GET_MODE (x));
+    return expand_unop (GET_MODE (x), ftrunc_optab, x, temp, 0);
 }
 
 void
 expand_fix (to, from, unsignedp)
-     rtx to, from;
-     int unsignedp;
+rtx to, from;
+int unsignedp;
 {
-  enum insn_code icode;
-  rtx target = to;
-  enum machine_mode fmode, imode;
-  int must_trunc = 0;
-  rtx libfcn = 0;
-
-  /* We first try to find a pair of modes, one real and one integer, at
+    enum insn_code icode;
+    rtx target = to;
+    enum machine_mode fmode, imode;
+    int must_trunc = 0;
+    rtx libfcn = 0;
+    
+    /* We first try to find a pair of modes, one real and one integer, at
      least as wide as FROM and TO, respectively, in which we can open-code
      this conversion.  If the integer mode is wider than the mode of TO,
      we can do the conversion either signed or unsigned.  */
-
-  for (fmode = GET_MODE (from); fmode != VOIDmode;
-       fmode = GET_MODE_WIDER_MODE (fmode))
+    
+    for (fmode = GET_MODE (from); fmode != VOIDmode;
+         fmode = GET_MODE_WIDER_MODE (fmode))
     for (imode = GET_MODE (to); imode != VOIDmode;
-	 imode = GET_MODE_WIDER_MODE (imode))
-      {
-	int doing_unsigned = unsignedp;
-
-	icode = can_fix_p (imode, fmode, unsignedp, &must_trunc);
-	if (icode == CODE_FOR_nothing && imode != GET_MODE (to) && unsignedp)
-	  icode = can_fix_p (imode, fmode, 0, &must_trunc), doing_unsigned = 0;
-
-	if (icode != CODE_FOR_nothing)
-	  {
-	    to = protect_from_queue (to, 1);
-	    from = protect_from_queue (from, 0);
-
-	    if (fmode != GET_MODE (from))
-	      from = convert_to_mode (fmode, from, 0);
-
-	    if (must_trunc)
-	      from = ftruncify (from);
-
-	    if (imode != GET_MODE (to))
-	      target = gen_reg_rtx (imode);
-
-	    emit_unop_insn (icode, target, from,
-			    doing_unsigned ? UNSIGNED_FIX : FIX);
-	    if (target != to)
-	      convert_move (to, target, unsignedp);
-	    return;
-	  }
-      }
-
+         imode = GET_MODE_WIDER_MODE (imode))
+    {
+        int doing_unsigned = unsignedp;
+        
+        icode = can_fix_p (imode, fmode, unsignedp, &must_trunc);
+        if (icode == CODE_FOR_nothing && imode != GET_MODE (to) && unsignedp)
+            icode = can_fix_p (imode, fmode, 0, &must_trunc), doing_unsigned = 0;
+        
+        if (icode != CODE_FOR_nothing)
+        {
+            to = protect_from_queue (to, 1);
+            from = protect_from_queue (from, 0);
+            
+            if (fmode != GET_MODE (from))
+                from = convert_to_mode (fmode, from, 0);
+            
+            if (must_trunc)
+                from = ftruncify (from);
+            
+            if (imode != GET_MODE (to))
+                target = gen_reg_rtx (imode);
+            
+            emit_unop_insn (icode, target, from,
+                            doing_unsigned ? UNSIGNED_FIX : FIX);
+            if (target != to)
+                convert_move (to, target, unsignedp);
+            return;
+        }
+    }
+    
 #if !defined (REAL_IS_NOT_DOUBLE) || defined (REAL_ARITHMETIC)
-  /* For an unsigned conversion, there is one more way to do it.
+    /* For an unsigned conversion, there is one more way to do it.
      If we have a signed conversion, we generate code that compares
      the real value to the largest representable positive number.  If if
      is smaller, the conversion is done normally.  Otherwise, subtract
      one plus the highest signed number, convert, and add it back.
-
+     
      We only need to check all real modes, since we know we didn't find
      anything with a wider integer mode.  */
-
-  if (unsignedp && GET_MODE_BITSIZE (GET_MODE (to)) <= HOST_BITS_PER_WIDE_INT)
-    for (fmode = GET_MODE (from); fmode != VOIDmode;
-	 fmode = GET_MODE_WIDER_MODE (fmode))
-      /* Make sure we won't lose significant bits doing this.  */
-      if (GET_MODE_BITSIZE (fmode) > GET_MODE_BITSIZE (GET_MODE (to))
-	  && CODE_FOR_nothing != can_fix_p (GET_MODE (to), fmode, 0,
-					    &must_trunc))
-	{
-	  int bitsize;
-	  REAL_VALUE_TYPE offset;
-	  rtx limit, lab1, lab2, insn;
-
-	  bitsize = GET_MODE_BITSIZE (GET_MODE (to));
-	  offset = REAL_VALUE_LDEXP (dconst1, bitsize - 1);
-	  limit = CONST_DOUBLE_FROM_REAL_VALUE (offset, fmode);
-	  lab1 = gen_label_rtx ();
-	  lab2 = gen_label_rtx ();
-
-	  emit_queue ();
-	  to = protect_from_queue (to, 1);
-	  from = protect_from_queue (from, 0);
-
-	  if (flag_force_mem)
-	    from = force_not_mem (from);
-
-	  if (fmode != GET_MODE (from))
-	    from = convert_to_mode (fmode, from, 0);
-
-	  /* See if we need to do the subtraction.  */
-	  do_pending_stack_adjust ();
-	  emit_cmp_and_jump_insns (from, limit, GE, NULL_RTX, GET_MODE (from),
-				   0, lab1);
-
-	  /* If not, do the signed "fix" and branch around fixup code.  */
-	  expand_fix (to, from, 0);
-	  emit_jump_insn (gen_jump (lab2));
-	  emit_barrier ();
-
-	  /* Otherwise, subtract 2**(N-1), convert to signed number,
-	     then add 2**(N-1).  Do the addition using XOR since this
-	     will often generate better code.  */
-	  emit_label (lab1);
-	  target = expand_binop (GET_MODE (from), sub_optab, from, limit,
-				 NULL_RTX, 0, OPTAB_LIB_WIDEN);
-	  expand_fix (to, target, 0);
-	  target = expand_binop (GET_MODE (to), xor_optab, to,
-				 GEN_INT (trunc_int_for_mode
-					  ((HOST_WIDE_INT) 1 << (bitsize - 1),
-					   GET_MODE (to))),
-				 to, 1, OPTAB_LIB_WIDEN);
-
-	  if (target != to)
-	    emit_move_insn (to, target);
-
-	  emit_label (lab2);
-
-	  if (mov_optab->handlers[(int) GET_MODE (to)].insn_code
-	      != CODE_FOR_nothing)
-	    {
-	      /* Make a place for a REG_NOTE and add it.  */
-	      insn = emit_move_insn (to, to);
-	      set_unique_reg_note (insn,
-	                           REG_EQUAL,
-				   gen_rtx_fmt_e (UNSIGNED_FIX,
-						  GET_MODE (to),
-						  copy_rtx (from)));
-	    }
-
-	  return;
-	}
+    
+    if (unsignedp && GET_MODE_BITSIZE (GET_MODE (to)) <= HOST_BITS_PER_WIDE_INT)
+        for (fmode = GET_MODE (from); fmode != VOIDmode;
+             fmode = GET_MODE_WIDER_MODE (fmode))
+    /* Make sure we won't lose significant bits doing this.  */
+    if (GET_MODE_BITSIZE (fmode) > GET_MODE_BITSIZE (GET_MODE (to))
+        && CODE_FOR_nothing != can_fix_p (GET_MODE (to), fmode, 0,
+                                          &must_trunc))
+    {
+        int bitsize;
+        REAL_VALUE_TYPE offset;
+        rtx limit, lab1, lab2, insn;
+        
+        bitsize = GET_MODE_BITSIZE (GET_MODE (to));
+        offset = REAL_VALUE_LDEXP (dconst1, bitsize - 1);
+        limit = CONST_DOUBLE_FROM_REAL_VALUE (offset, fmode);
+        lab1 = gen_label_rtx ();
+        lab2 = gen_label_rtx ();
+        
+        emit_queue ();
+        to = protect_from_queue (to, 1);
+        from = protect_from_queue (from, 0);
+        
+        if (flag_force_mem)
+            from = force_not_mem (from);
+        
+        if (fmode != GET_MODE (from))
+            from = convert_to_mode (fmode, from, 0);
+        
+        /* See if we need to do the subtraction.  */
+        do_pending_stack_adjust ();
+        emit_cmp_and_jump_insns (from, limit, GE, NULL_RTX, GET_MODE (from),
+                                 0, lab1);
+        
+        /* If not, do the signed "fix" and branch around fixup code.  */
+        expand_fix (to, from, 0);
+        emit_jump_insn (gen_jump (lab2));
+        emit_barrier ();
+        
+        /* Otherwise, subtract 2**(N-1), convert to signed number,
+         then add 2**(N-1).  Do the addition using XOR since this
+         will often generate better code.  */
+        emit_label (lab1);
+        target = expand_binop (GET_MODE (from), sub_optab, from, limit,
+                               NULL_RTX, 0, OPTAB_LIB_WIDEN);
+        expand_fix (to, target, 0);
+        target = expand_binop (GET_MODE (to), xor_optab, to,
+                               GEN_INT (trunc_int_for_mode
+                                        ((HOST_WIDE_INT) 1 << (bitsize - 1),
+                                         GET_MODE (to))),
+                               to, 1, OPTAB_LIB_WIDEN);
+        
+        if (target != to)
+            emit_move_insn (to, target);
+        
+        emit_label (lab2);
+        
+        if (mov_optab->handlers[(int) GET_MODE (to)].insn_code
+            != CODE_FOR_nothing)
+        {
+            /* Make a place for a REG_NOTE and add it.  */
+            insn = emit_move_insn (to, to);
+            set_unique_reg_note (insn,
+                                 REG_EQUAL,
+                                 gen_rtx_fmt_e (UNSIGNED_FIX,
+                                                GET_MODE (to),
+                                                copy_rtx (from)));
+        }
+        
+        return;
+    }
 #endif
-
-  /* We can't do it with an insn, so use a library call.  But first ensure
+    
+    /* We can't do it with an insn, so use a library call.  But first ensure
      that the mode of TO is at least as wide as SImode, since those are the
      only library calls we know about.  */
-
-  if (GET_MODE_SIZE (GET_MODE (to)) < GET_MODE_SIZE (SImode))
+    
+    if (GET_MODE_SIZE (GET_MODE (to)) < GET_MODE_SIZE (SImode))
     {
-      target = gen_reg_rtx (SImode);
-
-      expand_fix (target, from, unsignedp);
+        target = gen_reg_rtx (SImode);
+        
+        expand_fix (target, from, unsignedp);
     }
-  else if (GET_MODE (from) == SFmode)
+    else if (GET_MODE (from) == SFmode)
     {
-      if (GET_MODE (to) == SImode)
-	libfcn = unsignedp ? fixunssfsi_libfunc : fixsfsi_libfunc;
-      else if (GET_MODE (to) == DImode)
-	libfcn = unsignedp ? fixunssfdi_libfunc : fixsfdi_libfunc;
-      else if (GET_MODE (to) == TImode)
-	libfcn = unsignedp ? fixunssfti_libfunc : fixsfti_libfunc;
-      else
-	abort ();
+        if (GET_MODE (to) == SImode)
+            libfcn = unsignedp ? fixunssfsi_libfunc : fixsfsi_libfunc;
+        else if (GET_MODE (to) == DImode)
+            libfcn = unsignedp ? fixunssfdi_libfunc : fixsfdi_libfunc;
+        else if (GET_MODE (to) == TImode)
+            libfcn = unsignedp ? fixunssfti_libfunc : fixsfti_libfunc;
+        else
+            abort ();
     }
-  else if (GET_MODE (from) == DFmode)
+    else if (GET_MODE (from) == DFmode)
     {
-      if (GET_MODE (to) == SImode)
-	libfcn = unsignedp ? fixunsdfsi_libfunc : fixdfsi_libfunc;
-      else if (GET_MODE (to) == DImode)
-	libfcn = unsignedp ? fixunsdfdi_libfunc : fixdfdi_libfunc;
-      else if (GET_MODE (to) == TImode)
-	libfcn = unsignedp ? fixunsdfti_libfunc : fixdfti_libfunc;
-      else
-	abort ();
+        if (GET_MODE (to) == SImode)
+            libfcn = unsignedp ? fixunsdfsi_libfunc : fixdfsi_libfunc;
+        else if (GET_MODE (to) == DImode)
+            libfcn = unsignedp ? fixunsdfdi_libfunc : fixdfdi_libfunc;
+        else if (GET_MODE (to) == TImode)
+            libfcn = unsignedp ? fixunsdfti_libfunc : fixdfti_libfunc;
+        else
+            abort ();
     }
-  else if (GET_MODE (from) == XFmode)
+    else if (GET_MODE (from) == XFmode)
     {
-      if (GET_MODE (to) == SImode)
-	libfcn = unsignedp ? fixunsxfsi_libfunc : fixxfsi_libfunc;
-      else if (GET_MODE (to) == DImode)
-	libfcn = unsignedp ? fixunsxfdi_libfunc : fixxfdi_libfunc;
-      else if (GET_MODE (to) == TImode)
-	libfcn = unsignedp ? fixunsxfti_libfunc : fixxfti_libfunc;
-      else
-	abort ();
+        if (GET_MODE (to) == SImode)
+            libfcn = unsignedp ? fixunsxfsi_libfunc : fixxfsi_libfunc;
+        else if (GET_MODE (to) == DImode)
+            libfcn = unsignedp ? fixunsxfdi_libfunc : fixxfdi_libfunc;
+        else if (GET_MODE (to) == TImode)
+            libfcn = unsignedp ? fixunsxfti_libfunc : fixxfti_libfunc;
+        else
+            abort ();
     }
-  else if (GET_MODE (from) == TFmode)
+    else if (GET_MODE (from) == TFmode)
     {
-      if (GET_MODE (to) == SImode)
-	libfcn = unsignedp ? fixunstfsi_libfunc : fixtfsi_libfunc;
-      else if (GET_MODE (to) == DImode)
-	libfcn = unsignedp ? fixunstfdi_libfunc : fixtfdi_libfunc;
-      else if (GET_MODE (to) == TImode)
-	libfcn = unsignedp ? fixunstfti_libfunc : fixtfti_libfunc;
-      else
-	abort ();
+        if (GET_MODE (to) == SImode)
+            libfcn = unsignedp ? fixunstfsi_libfunc : fixtfsi_libfunc;
+        else if (GET_MODE (to) == DImode)
+            libfcn = unsignedp ? fixunstfdi_libfunc : fixtfdi_libfunc;
+        else if (GET_MODE (to) == TImode)
+            libfcn = unsignedp ? fixunstfti_libfunc : fixtfti_libfunc;
+        else
+            abort ();
     }
-  else
-    abort ();
-
-  if (libfcn)
+    else
+        abort ();
+    
+    if (libfcn)
     {
-      rtx insns;
-      rtx value;
-
-      to = protect_from_queue (to, 1);
-      from = protect_from_queue (from, 0);
-
-      if (flag_force_mem)
-	from = force_not_mem (from);
-
-      start_sequence ();
-
-      value = emit_library_call_value (libfcn, NULL_RTX, LCT_CONST,
-				       GET_MODE (to), 1, from,
-				       GET_MODE (from));
-      insns = get_insns ();
-      end_sequence ();
-
-      emit_libcall_block (insns, target, value,
-			  gen_rtx_fmt_e (unsignedp ? UNSIGNED_FIX : FIX,
-					 GET_MODE (to), from));
+        rtx insns;
+        rtx value;
+        
+        to = protect_from_queue (to, 1);
+        from = protect_from_queue (from, 0);
+        
+        if (flag_force_mem)
+            from = force_not_mem (from);
+        
+        start_sequence ();
+        
+        value = emit_library_call_value (libfcn, NULL_RTX, LCT_CONST,
+                                         GET_MODE (to), 1, from,
+                                         GET_MODE (from));
+        insns = get_insns ();
+        end_sequence ();
+        
+        emit_libcall_block (insns, target, value,
+                            gen_rtx_fmt_e (unsignedp ? UNSIGNED_FIX : FIX,
+                                           GET_MODE (to), from));
     }
-      
-  if (target != to)
+    
+    if (target != to)
     {
-      if (GET_MODE (to) == GET_MODE (target))
-        emit_move_insn (to, target);
-      else
-        convert_move (to, target, 0);
+        if (GET_MODE (to) == GET_MODE (target))
+            emit_move_insn (to, target);
+        else
+            convert_move (to, target, 0);
     }
 }
 
 /* Report whether we have an instruction to perform the operation
-   specified by CODE on operands of mode MODE.  */
+ specified by CODE on operands of mode MODE.  */
 int
 have_insn_for (code, mode)
-     enum rtx_code code;
-     enum machine_mode mode;
+enum rtx_code code;
+enum machine_mode mode;
 {
-  return (code_to_optab[(int) code] != 0
-	  && (code_to_optab[(int) code]->handlers[(int) mode].insn_code
-	      != CODE_FOR_nothing));
+    return (code_to_optab[(int) code] != 0
+            && (code_to_optab[(int) code]->handlers[(int) mode].insn_code
+                != CODE_FOR_nothing));
 }
 
 /* Create a blank optab.  */
 static optab
 new_optab ()
 {
-  int i;
-  optab op = (optab) xmalloc (sizeof (struct optab));
-  for (i = 0; i < NUM_MACHINE_MODES; i++)
+    int i;
+    optab op = (optab) xmalloc (sizeof (struct optab));
+    for (i = 0; i < NUM_MACHINE_MODES; i++)
     {
-      op->handlers[i].insn_code = CODE_FOR_nothing;
-      op->handlers[i].libfunc = 0;
+        op->handlers[i].insn_code = CODE_FOR_nothing;
+        op->handlers[i].libfunc = 0;
     }
-
-  return op;
+    
+    return op;
 }
 
 /* Same, but fill in its code as CODE, and write it into the
-   code_to_optab table.  */
+ code_to_optab table.  */
 static inline optab
 init_optab (code)
-     enum rtx_code code;
+enum rtx_code code;
 {
-  optab op = new_optab ();
-  op->code = code;
-  code_to_optab[(int) code] = op;
-  return op;
+    optab op = new_optab ();
+    op->code = code;
+    code_to_optab[(int) code] = op;
+    return op;
 }
 
 /* Same, but fill in its code as CODE, and do _not_ write it into
-   the code_to_optab table.  */
+ the code_to_optab table.  */
 static inline optab
 init_optabv (code)
-     enum rtx_code code;
+enum rtx_code code;
 {
-  optab op = new_optab ();
-  op->code = code;
-  return op;
+    optab op = new_optab ();
+    op->code = code;
+    return op;
 }
 
 /* Initialize the libfunc fields of an entire group of entries in some
-   optab.  Each entry is set equal to a string consisting of a leading
-   pair of underscores followed by a generic operation name followed by
-   a mode name (downshifted to lower case) followed by a single character
-   representing the number of operands for the given operation (which is
-   usually one of the characters '2', '3', or '4').
-
-   OPTABLE is the table in which libfunc fields are to be initialized.
-   FIRST_MODE is the first machine mode index in the given optab to
-     initialize.
-   LAST_MODE is the last machine mode index in the given optab to
-     initialize.
-   OPNAME is the generic (string) name of the operation.
-   SUFFIX is the character which specifies the number of operands for
-     the given generic operation.
-*/
+ optab.  Each entry is set equal to a string consisting of a leading
+ pair of underscores followed by a generic operation name followed by
+ a mode name (downshifted to lower case) followed by a single character
+ representing the number of operands for the given operation (which is
+ usually one of the characters '2', '3', or '4').
+ 
+ OPTABLE is the table in which libfunc fields are to be initialized.
+ FIRST_MODE is the first machine mode index in the given optab to
+ initialize.
+ LAST_MODE is the last machine mode index in the given optab to
+ initialize.
+ OPNAME is the generic (string) name of the operation.
+ SUFFIX is the character which specifies the number of operands for
+ the given generic operation.
+ */
 
 static void
 init_libfuncs (optable, first_mode, last_mode, opname, suffix)
-    optab optable;
-    int first_mode;
-    int last_mode;
-    const char *opname;
-    int suffix;
+optab optable;
+int first_mode;
+int last_mode;
+const char *opname;
+int suffix;
 {
-  int mode;
-  unsigned opname_len = strlen (opname);
-
-  for (mode = first_mode; (int) mode <= (int) last_mode;
-       mode = (enum machine_mode) ((int) mode + 1))
+    int mode;
+    unsigned opname_len = strlen (opname);
+    
+    for (mode = first_mode; (int) mode <= (int) last_mode;
+         mode = (enum machine_mode) ((int) mode + 1))
     {
-      const char *mname = GET_MODE_NAME(mode);
-      unsigned mname_len = strlen (mname);
-      char *libfunc_name = alloca (2 + opname_len + mname_len + 1 + 1);
-      char *p;
-      const char *q;
-
-      p = libfunc_name;
-      *p++ = '_';
-      *p++ = '_';
-      for (q = opname; *q; )
-	*p++ = *q++;
-      for (q = mname; *q; q++)
-	*p++ = TOLOWER (*q);
-      *p++ = suffix;
-      *p = '\0';
-
-      optable->handlers[(int) mode].libfunc
-	= gen_rtx_SYMBOL_REF (Pmode, ggc_alloc_string (libfunc_name,
-						       p - libfunc_name));
+        const char *mname = GET_MODE_NAME(mode);
+        unsigned mname_len = strlen (mname);
+        char *libfunc_name = alloca (2 + opname_len + mname_len + 1 + 1);
+        char *p;
+        const char *q;
+        
+        p = libfunc_name;
+        *p++ = '_';
+        *p++ = '_';
+        for (q = opname; *q; )
+        *p++ = *q++;
+        for (q = mname; *q; q++)
+        *p++ = TOLOWER (*q);
+        *p++ = suffix;
+        *p = '\0';
+        
+        optable->handlers[(int) mode].libfunc
+        = gen_rtx_SYMBOL_REF (Pmode, ggc_alloc_string (libfunc_name,
+                                                       p - libfunc_name));
     }
 }
 
 /* Initialize the libfunc fields of an entire group of entries in some
-   optab which correspond to all integer mode operations.  The parameters
-   have the same meaning as similarly named ones for the `init_libfuncs'
-   routine.  (See above).  */
+ optab which correspond to all integer mode operations.  The parameters
+ have the same meaning as similarly named ones for the `init_libfuncs'
+ routine.  (See above).  */
 
 static void
 init_integral_libfuncs (optable, opname, suffix)
-    optab optable;
-    const char *opname;
-    int suffix;
+optab optable;
+const char *opname;
+int suffix;
 {
-  init_libfuncs (optable, SImode, TImode, opname, suffix);
+    init_libfuncs (optable, SImode, TImode, opname, suffix);
 }
 
 /* Initialize the libfunc fields of an entire group of entries in some
-   optab which correspond to all real mode operations.  The parameters
-   have the same meaning as similarly named ones for the `init_libfuncs'
-   routine.  (See above).  */
+ optab which correspond to all real mode operations.  The parameters
+ have the same meaning as similarly named ones for the `init_libfuncs'
+ routine.  (See above).  */
 
 static void
 init_floating_libfuncs (optable, opname, suffix)
-    optab optable;
-    const char *opname;
-    int suffix;
+optab optable;
+const char *opname;
+int suffix;
 {
-  init_libfuncs (optable, SFmode, TFmode, opname, suffix);
+    init_libfuncs (optable, SFmode, TFmode, opname, suffix);
 }
 
 rtx
 init_one_libfunc (name)
-     const char *name;
+const char *name;
 {
-  /* Create a FUNCTION_DECL that can be passed to ENCODE_SECTION_INFO.  */
-  /* ??? We don't have any type information except for this is
+    /* Create a FUNCTION_DECL that can be passed to ENCODE_SECTION_INFO.  */
+    /* ??? We don't have any type information except for this is
      a function.  Pretend this is "int foo()".  */
-  tree decl = build_decl (FUNCTION_DECL, get_identifier (name),
-			  build_function_type (integer_type_node, NULL_TREE));
-  DECL_ARTIFICIAL (decl) = 1;
-  DECL_EXTERNAL (decl) = 1;
-  TREE_PUBLIC (decl) = 1;
-
-  /* Return the symbol_ref from the mem rtx.  */
-  return XEXP (DECL_RTL (decl), 0);
+    tree decl = build_decl (FUNCTION_DECL, get_identifier (name),
+                            build_function_type (integer_type_node, NULL_TREE));
+    DECL_ARTIFICIAL (decl) = 1;
+    DECL_EXTERNAL (decl) = 1;
+    TREE_PUBLIC (decl) = 1;
+    
+    /* Return the symbol_ref from the mem rtx.  */
+    return XEXP (DECL_RTL (decl), 0);
 }
 
 /* Mark ARG (which is really an OPTAB *) for GC.  */
 
 void
 mark_optab (arg)
-     void *arg;
+void *arg;
 {
-  optab o = *(optab *) arg;
-  int i;
-
-  for (i = 0; i < NUM_MACHINE_MODES; ++i)
+    optab o = *(optab *) arg;
+    int i;
+    
+    for (i = 0; i < NUM_MACHINE_MODES; ++i)
     ggc_mark_rtx (o->handlers[i].libfunc);
 }
 
 /* Call this once to initialize the contents of the optabs
-   appropriately for the current target machine.  */
+ appropriately for the current target machine.  */
 
 void
 init_optabs ()
 {
-  unsigned int i, j, k;
-
-  /* Start by initializing all tables to contain CODE_FOR_nothing.  */
-
-  for (i = 0; i < ARRAY_SIZE (fixtab); i++)
+    unsigned int i, j, k;
+    
+    /* Start by initializing all tables to contain CODE_FOR_nothing.  */
+    
+    for (i = 0; i < ARRAY_SIZE (fixtab); i++)
     for (j = 0; j < ARRAY_SIZE (fixtab[0]); j++)
-      for (k = 0; k < ARRAY_SIZE (fixtab[0][0]); k++)
-	fixtab[i][j][k] = CODE_FOR_nothing;
-
-  for (i = 0; i < ARRAY_SIZE (fixtrunctab); i++)
+    for (k = 0; k < ARRAY_SIZE (fixtab[0][0]); k++)
+    fixtab[i][j][k] = CODE_FOR_nothing;
+    
+    for (i = 0; i < ARRAY_SIZE (fixtrunctab); i++)
     for (j = 0; j < ARRAY_SIZE (fixtrunctab[0]); j++)
-      for (k = 0; k < ARRAY_SIZE (fixtrunctab[0][0]); k++)
-	fixtrunctab[i][j][k] = CODE_FOR_nothing;
-
-  for (i = 0; i < ARRAY_SIZE (floattab); i++)
+    for (k = 0; k < ARRAY_SIZE (fixtrunctab[0][0]); k++)
+    fixtrunctab[i][j][k] = CODE_FOR_nothing;
+    
+    for (i = 0; i < ARRAY_SIZE (floattab); i++)
     for (j = 0; j < ARRAY_SIZE (floattab[0]); j++)
-      for (k = 0; k < ARRAY_SIZE (floattab[0][0]); k++)
-	floattab[i][j][k] = CODE_FOR_nothing;
-
-  for (i = 0; i < ARRAY_SIZE (extendtab); i++)
+    for (k = 0; k < ARRAY_SIZE (floattab[0][0]); k++)
+    floattab[i][j][k] = CODE_FOR_nothing;
+    
+    for (i = 0; i < ARRAY_SIZE (extendtab); i++)
     for (j = 0; j < ARRAY_SIZE (extendtab[0]); j++)
-      for (k = 0; k < ARRAY_SIZE (extendtab[0][0]); k++)
-	extendtab[i][j][k] = CODE_FOR_nothing;
-
-  for (i = 0; i < NUM_RTX_CODE; i++)
+    for (k = 0; k < ARRAY_SIZE (extendtab[0][0]); k++)
+    extendtab[i][j][k] = CODE_FOR_nothing;
+    
+    for (i = 0; i < NUM_RTX_CODE; i++)
     setcc_gen_code[i] = CODE_FOR_nothing;
-
+    
 #ifdef HAVE_conditional_move
-  for (i = 0; i < NUM_MACHINE_MODES; i++)
+    for (i = 0; i < NUM_MACHINE_MODES; i++)
     movcc_gen_code[i] = CODE_FOR_nothing;
 #endif
-
-  add_optab = init_optab (PLUS);
-  addv_optab = init_optabv (PLUS);
-  sub_optab = init_optab (MINUS);
-  subv_optab = init_optabv (MINUS);
-  smul_optab = init_optab (MULT);
-  smulv_optab = init_optabv (MULT);
-  smul_highpart_optab = init_optab (UNKNOWN);
-  umul_highpart_optab = init_optab (UNKNOWN);
-  smul_widen_optab = init_optab (UNKNOWN);
-  umul_widen_optab = init_optab (UNKNOWN);
-  sdiv_optab = init_optab (DIV);
-  sdivv_optab = init_optabv (DIV);
-  sdivmod_optab = init_optab (UNKNOWN);
-  udiv_optab = init_optab (UDIV);
-  udivmod_optab = init_optab (UNKNOWN);
-  smod_optab = init_optab (MOD);
-  umod_optab = init_optab (UMOD);
-  ftrunc_optab = init_optab (UNKNOWN);
-  and_optab = init_optab (AND);
-  ior_optab = init_optab (IOR);
-  xor_optab = init_optab (XOR);
-  ashl_optab = init_optab (ASHIFT);
-  ashr_optab = init_optab (ASHIFTRT);
-  lshr_optab = init_optab (LSHIFTRT);
-  rotl_optab = init_optab (ROTATE);
-  rotr_optab = init_optab (ROTATERT);
-  smin_optab = init_optab (SMIN);
-  smax_optab = init_optab (SMAX);
-  umin_optab = init_optab (UMIN);
-  umax_optab = init_optab (UMAX);
-
-  /* These three have codes assigned exclusively for the sake of
+    
+    add_optab = init_optab (PLUS);
+    addv_optab = init_optabv (PLUS);
+    sub_optab = init_optab (MINUS);
+    subv_optab = init_optabv (MINUS);
+    smul_optab = init_optab (MULT);
+    smulv_optab = init_optabv (MULT);
+    smul_highpart_optab = init_optab (UNKNOWN);
+    umul_highpart_optab = init_optab (UNKNOWN);
+    smul_widen_optab = init_optab (UNKNOWN);
+    umul_widen_optab = init_optab (UNKNOWN);
+    sdiv_optab = init_optab (DIV);
+    sdivv_optab = init_optabv (DIV);
+    sdivmod_optab = init_optab (UNKNOWN);
+    udiv_optab = init_optab (UDIV);
+    udivmod_optab = init_optab (UNKNOWN);
+    smod_optab = init_optab (MOD);
+    umod_optab = init_optab (UMOD);
+    ftrunc_optab = init_optab (UNKNOWN);
+    and_optab = init_optab (AND);
+    ior_optab = init_optab (IOR);
+    xor_optab = init_optab (XOR);
+    ashl_optab = init_optab (ASHIFT);
+    ashr_optab = init_optab (ASHIFTRT);
+    lshr_optab = init_optab (LSHIFTRT);
+    rotl_optab = init_optab (ROTATE);
+    rotr_optab = init_optab (ROTATERT);
+    smin_optab = init_optab (SMIN);
+    smax_optab = init_optab (SMAX);
+    umin_optab = init_optab (UMIN);
+    umax_optab = init_optab (UMAX);
+    
+    /* These three have codes assigned exclusively for the sake of
      have_insn_for.  */
-  mov_optab = init_optab (SET);
-  movstrict_optab = init_optab (STRICT_LOW_PART);
-  cmp_optab = init_optab (COMPARE);
-
-  ucmp_optab = init_optab (UNKNOWN);
-  tst_optab = init_optab (UNKNOWN);
-  neg_optab = init_optab (NEG);
-  negv_optab = init_optabv (NEG);
-  abs_optab = init_optab (ABS);
-  absv_optab = init_optabv (ABS);
-  one_cmpl_optab = init_optab (NOT);
-  ffs_optab = init_optab (FFS);
-  sqrt_optab = init_optab (SQRT);
-  sin_optab = init_optab (UNKNOWN);
-  cos_optab = init_optab (UNKNOWN);
-  strlen_optab = init_optab (UNKNOWN);
-  cbranch_optab = init_optab (UNKNOWN);
-  cmov_optab = init_optab (UNKNOWN);
-  cstore_optab = init_optab (UNKNOWN);
-  push_optab = init_optab (UNKNOWN);
-
-  for (i = 0; i < NUM_MACHINE_MODES; i++)
+    mov_optab = init_optab (SET);
+    movstrict_optab = init_optab (STRICT_LOW_PART);
+    cmp_optab = init_optab (COMPARE);
+    
+    ucmp_optab = init_optab (UNKNOWN);
+    tst_optab = init_optab (UNKNOWN);
+    neg_optab = init_optab (NEG);
+    negv_optab = init_optabv (NEG);
+    abs_optab = init_optab (ABS);
+    absv_optab = init_optabv (ABS);
+    one_cmpl_optab = init_optab (NOT);
+    ffs_optab = init_optab (FFS);
+    sqrt_optab = init_optab (SQRT);
+    sin_optab = init_optab (UNKNOWN);
+    cos_optab = init_optab (UNKNOWN);
+    strlen_optab = init_optab (UNKNOWN);
+    cbranch_optab = init_optab (UNKNOWN);
+    cmov_optab = init_optab (UNKNOWN);
+    cstore_optab = init_optab (UNKNOWN);
+    push_optab = init_optab (UNKNOWN);
+    
+    for (i = 0; i < NUM_MACHINE_MODES; i++)
     {
-      movstr_optab[i] = CODE_FOR_nothing;
-      clrstr_optab[i] = CODE_FOR_nothing;
-
+        movstr_optab[i] = CODE_FOR_nothing;
+        clrstr_optab[i] = CODE_FOR_nothing;
+        
 #ifdef HAVE_SECONDARY_RELOADS
-      reload_in_optab[i] = reload_out_optab[i] = CODE_FOR_nothing;
+        reload_in_optab[i] = reload_out_optab[i] = CODE_FOR_nothing;
 #endif
     }
-
-  /* Fill in the optabs with the insns we support.  */
-  init_all_optabs ();
-
+    
+    /* Fill in the optabs with the insns we support.  */
+    init_all_optabs ();
+    
 #ifdef FIXUNS_TRUNC_LIKE_FIX_TRUNC
-  /* This flag says the same insns that convert to a signed fixnum
+    /* This flag says the same insns that convert to a signed fixnum
      also convert validly to an unsigned one.  */
-  for (i = 0; i < NUM_MACHINE_MODES; i++)
+    for (i = 0; i < NUM_MACHINE_MODES; i++)
     for (j = 0; j < NUM_MACHINE_MODES; j++)
-      fixtrunctab[i][j][1] = fixtrunctab[i][j][0];
+    fixtrunctab[i][j][1] = fixtrunctab[i][j][0];
 #endif
-
-  /* Initialize the optabs with the names of the library functions.  */
-  init_integral_libfuncs (add_optab, "add", '3');
-  init_floating_libfuncs (add_optab, "add", '3');
-  init_integral_libfuncs (addv_optab, "addv", '3');
-  init_floating_libfuncs (addv_optab, "add", '3');
-  init_integral_libfuncs (sub_optab, "sub", '3');
-  init_floating_libfuncs (sub_optab, "sub", '3');
-  init_integral_libfuncs (subv_optab, "subv", '3');
-  init_floating_libfuncs (subv_optab, "sub", '3');
-  init_integral_libfuncs (smul_optab, "mul", '3');
-  init_floating_libfuncs (smul_optab, "mul", '3');
-  init_integral_libfuncs (smulv_optab, "mulv", '3');
-  init_floating_libfuncs (smulv_optab, "mul", '3');
-  init_integral_libfuncs (sdiv_optab, "div", '3');
-  init_floating_libfuncs (sdiv_optab, "div", '3');
-  init_integral_libfuncs (sdivv_optab, "divv", '3');
-  init_integral_libfuncs (udiv_optab, "udiv", '3');
-  init_integral_libfuncs (sdivmod_optab, "divmod", '4');
-  init_integral_libfuncs (udivmod_optab, "udivmod", '4');
-  init_integral_libfuncs (smod_optab, "mod", '3');
-  init_integral_libfuncs (umod_optab, "umod", '3');
-  init_floating_libfuncs (ftrunc_optab, "ftrunc", '2');
-  init_integral_libfuncs (and_optab, "and", '3');
-  init_integral_libfuncs (ior_optab, "ior", '3');
-  init_integral_libfuncs (xor_optab, "xor", '3');
-  init_integral_libfuncs (ashl_optab, "ashl", '3');
-  init_integral_libfuncs (ashr_optab, "ashr", '3');
-  init_integral_libfuncs (lshr_optab, "lshr", '3');
-  init_integral_libfuncs (smin_optab, "min", '3');
-  init_floating_libfuncs (smin_optab, "min", '3');
-  init_integral_libfuncs (smax_optab, "max", '3');
-  init_floating_libfuncs (smax_optab, "max", '3');
-  init_integral_libfuncs (umin_optab, "umin", '3');
-  init_integral_libfuncs (umax_optab, "umax", '3');
-  init_integral_libfuncs (neg_optab, "neg", '2');
-  init_floating_libfuncs (neg_optab, "neg", '2');
-  init_integral_libfuncs (negv_optab, "negv", '2');
-  init_floating_libfuncs (negv_optab, "neg", '2');
-  init_integral_libfuncs (one_cmpl_optab, "one_cmpl", '2');
-  init_integral_libfuncs (ffs_optab, "ffs", '2');
-
-  /* Comparison libcalls for integers MUST come in pairs, signed/unsigned.  */
-  init_integral_libfuncs (cmp_optab, "cmp", '2');
-  init_integral_libfuncs (ucmp_optab, "ucmp", '2');
-  init_floating_libfuncs (cmp_optab, "cmp", '2');
-
+    
+    /* Initialize the optabs with the names of the library functions.  */
+    init_integral_libfuncs (add_optab, "add", '3');
+    init_floating_libfuncs (add_optab, "add", '3');
+    init_integral_libfuncs (addv_optab, "addv", '3');
+    init_floating_libfuncs (addv_optab, "add", '3');
+    init_integral_libfuncs (sub_optab, "sub", '3');
+    init_floating_libfuncs (sub_optab, "sub", '3');
+    init_integral_libfuncs (subv_optab, "subv", '3');
+    init_floating_libfuncs (subv_optab, "sub", '3');
+    init_integral_libfuncs (smul_optab, "mul", '3');
+    init_floating_libfuncs (smul_optab, "mul", '3');
+    init_integral_libfuncs (smulv_optab, "mulv", '3');
+    init_floating_libfuncs (smulv_optab, "mul", '3');
+    init_integral_libfuncs (sdiv_optab, "div", '3');
+    init_floating_libfuncs (sdiv_optab, "div", '3');
+    init_integral_libfuncs (sdivv_optab, "divv", '3');
+    init_integral_libfuncs (udiv_optab, "udiv", '3');
+    init_integral_libfuncs (sdivmod_optab, "divmod", '4');
+    init_integral_libfuncs (udivmod_optab, "udivmod", '4');
+    init_integral_libfuncs (smod_optab, "mod", '3');
+    init_integral_libfuncs (umod_optab, "umod", '3');
+    init_floating_libfuncs (ftrunc_optab, "ftrunc", '2');
+    init_integral_libfuncs (and_optab, "and", '3');
+    init_integral_libfuncs (ior_optab, "ior", '3');
+    init_integral_libfuncs (xor_optab, "xor", '3');
+    init_integral_libfuncs (ashl_optab, "ashl", '3');
+    init_integral_libfuncs (ashr_optab, "ashr", '3');
+    init_integral_libfuncs (lshr_optab, "lshr", '3');
+    init_integral_libfuncs (smin_optab, "min", '3');
+    init_floating_libfuncs (smin_optab, "min", '3');
+    init_integral_libfuncs (smax_optab, "max", '3');
+    init_floating_libfuncs (smax_optab, "max", '3');
+    init_integral_libfuncs (umin_optab, "umin", '3');
+    init_integral_libfuncs (umax_optab, "umax", '3');
+    init_integral_libfuncs (neg_optab, "neg", '2');
+    init_floating_libfuncs (neg_optab, "neg", '2');
+    init_integral_libfuncs (negv_optab, "negv", '2');
+    init_floating_libfuncs (negv_optab, "neg", '2');
+    init_integral_libfuncs (one_cmpl_optab, "one_cmpl", '2');
+    init_integral_libfuncs (ffs_optab, "ffs", '2');
+    
+    /* Comparison libcalls for integers MUST come in pairs, signed/unsigned.  */
+    init_integral_libfuncs (cmp_optab, "cmp", '2');
+    init_integral_libfuncs (ucmp_optab, "ucmp", '2');
+    init_floating_libfuncs (cmp_optab, "cmp", '2');
+    
 #ifdef MULSI3_LIBCALL
-  smul_optab->handlers[(int) SImode].libfunc
+    smul_optab->handlers[(int) SImode].libfunc
     = init_one_libfunc (MULSI3_LIBCALL);
 #endif
 #ifdef MULDI3_LIBCALL
-  smul_optab->handlers[(int) DImode].libfunc
+    smul_optab->handlers[(int) DImode].libfunc
     = init_one_libfunc (MULDI3_LIBCALL);
 #endif
-
+    
 #ifdef DIVSI3_LIBCALL
-  sdiv_optab->handlers[(int) SImode].libfunc
+    sdiv_optab->handlers[(int) SImode].libfunc
     = init_one_libfunc (DIVSI3_LIBCALL);
 #endif
 #ifdef DIVDI3_LIBCALL
-  sdiv_optab->handlers[(int) DImode].libfunc
+    sdiv_optab->handlers[(int) DImode].libfunc
     = init_one_libfunc (DIVDI3_LIBCALL);
 #endif
-
+    
 #ifdef UDIVSI3_LIBCALL
-  udiv_optab->handlers[(int) SImode].libfunc
+    udiv_optab->handlers[(int) SImode].libfunc
     = init_one_libfunc (UDIVSI3_LIBCALL);
 #endif
 #ifdef UDIVDI3_LIBCALL
-  udiv_optab->handlers[(int) DImode].libfunc
+    udiv_optab->handlers[(int) DImode].libfunc
     = init_one_libfunc (UDIVDI3_LIBCALL);
 #endif
-
+    
 #ifdef MODSI3_LIBCALL
-  smod_optab->handlers[(int) SImode].libfunc
+    smod_optab->handlers[(int) SImode].libfunc
     = init_one_libfunc (MODSI3_LIBCALL);
 #endif
 #ifdef MODDI3_LIBCALL
-  smod_optab->handlers[(int) DImode].libfunc
+    smod_optab->handlers[(int) DImode].libfunc
     = init_one_libfunc (MODDI3_LIBCALL);
 #endif
-
+    
 #ifdef UMODSI3_LIBCALL
-  umod_optab->handlers[(int) SImode].libfunc
+    umod_optab->handlers[(int) SImode].libfunc
     = init_one_libfunc (UMODSI3_LIBCALL);
 #endif
 #ifdef UMODDI3_LIBCALL
-  umod_optab->handlers[(int) DImode].libfunc
+    umod_optab->handlers[(int) DImode].libfunc
     = init_one_libfunc (UMODDI3_LIBCALL);
 #endif
-
-  /* Use cabs for DC complex abs, since systems generally have cabs.
+    
+    /* Use cabs for DC complex abs, since systems generally have cabs.
      Don't define any libcall for SCmode, so that cabs will be used.  */
-  abs_optab->handlers[(int) DCmode].libfunc
+    abs_optab->handlers[(int) DCmode].libfunc
     = init_one_libfunc ("cabs");
-
-  /* The ffs function operates on `int'.  */
-  ffs_optab->handlers[(int) mode_for_size (INT_TYPE_SIZE, MODE_INT, 0)].libfunc
+    
+    /* The ffs function operates on `int'.  */
+    ffs_optab->handlers[(int) mode_for_size (INT_TYPE_SIZE, MODE_INT, 0)].libfunc
     = init_one_libfunc ("ffs");
-
-  extendsfdf2_libfunc = init_one_libfunc ("__extendsfdf2");
-  extendsfxf2_libfunc = init_one_libfunc ("__extendsfxf2");
-  extendsftf2_libfunc = init_one_libfunc ("__extendsftf2");
-  extenddfxf2_libfunc = init_one_libfunc ("__extenddfxf2");
-  extenddftf2_libfunc = init_one_libfunc ("__extenddftf2");
-
-  truncdfsf2_libfunc = init_one_libfunc ("__truncdfsf2");
-  truncxfsf2_libfunc = init_one_libfunc ("__truncxfsf2");
-  trunctfsf2_libfunc = init_one_libfunc ("__trunctfsf2");
-  truncxfdf2_libfunc = init_one_libfunc ("__truncxfdf2");
-  trunctfdf2_libfunc = init_one_libfunc ("__trunctfdf2");
-
-  abort_libfunc = init_one_libfunc ("abort");
-  memcpy_libfunc = init_one_libfunc ("memcpy");
-  memmove_libfunc = init_one_libfunc ("memmove");
-  bcopy_libfunc = init_one_libfunc ("bcopy");
-  memcmp_libfunc = init_one_libfunc ("memcmp");
-  bcmp_libfunc = init_one_libfunc ("__gcc_bcmp");
-  memset_libfunc = init_one_libfunc ("memset");
-  bzero_libfunc = init_one_libfunc ("bzero");
-
-  unwind_resume_libfunc = init_one_libfunc (USING_SJLJ_EXCEPTIONS
-					    ? "_Unwind_SjLj_Resume"
-					    : "_Unwind_Resume");
+    
+    extendsfdf2_libfunc = init_one_libfunc ("__extendsfdf2");
+    extendsfxf2_libfunc = init_one_libfunc ("__extendsfxf2");
+    extendsftf2_libfunc = init_one_libfunc ("__extendsftf2");
+    extenddfxf2_libfunc = init_one_libfunc ("__extenddfxf2");
+    extenddftf2_libfunc = init_one_libfunc ("__extenddftf2");
+    
+    truncdfsf2_libfunc = init_one_libfunc ("__truncdfsf2");
+    truncxfsf2_libfunc = init_one_libfunc ("__truncxfsf2");
+    trunctfsf2_libfunc = init_one_libfunc ("__trunctfsf2");
+    truncxfdf2_libfunc = init_one_libfunc ("__truncxfdf2");
+    trunctfdf2_libfunc = init_one_libfunc ("__trunctfdf2");
+    
+    abort_libfunc = init_one_libfunc ("abort");
+    memcpy_libfunc = init_one_libfunc ("memcpy");
+    memmove_libfunc = init_one_libfunc ("memmove");
+    bcopy_libfunc = init_one_libfunc ("bcopy");
+    memcmp_libfunc = init_one_libfunc ("memcmp");
+    bcmp_libfunc = init_one_libfunc ("__gcc_bcmp");
+    memset_libfunc = init_one_libfunc ("memset");
+    bzero_libfunc = init_one_libfunc ("bzero");
+    
+    unwind_resume_libfunc = init_one_libfunc (USING_SJLJ_EXCEPTIONS
+                                              ? "_Unwind_SjLj_Resume"
+                                              : "_Unwind_Resume");
 #ifndef DONT_USE_BUILTIN_SETJMP
-  setjmp_libfunc = init_one_libfunc ("__builtin_setjmp");
-  longjmp_libfunc = init_one_libfunc ("__builtin_longjmp");
+    setjmp_libfunc = init_one_libfunc ("__builtin_setjmp");
+    longjmp_libfunc = init_one_libfunc ("__builtin_longjmp");
 #else
-  setjmp_libfunc = init_one_libfunc ("setjmp");
-  longjmp_libfunc = init_one_libfunc ("longjmp");
+    setjmp_libfunc = init_one_libfunc ("setjmp");
+    longjmp_libfunc = init_one_libfunc ("longjmp");
 #endif
-  unwind_sjlj_register_libfunc = init_one_libfunc ("_Unwind_SjLj_Register");
-  unwind_sjlj_unregister_libfunc
+    unwind_sjlj_register_libfunc = init_one_libfunc ("_Unwind_SjLj_Register");
+    unwind_sjlj_unregister_libfunc
     = init_one_libfunc ("_Unwind_SjLj_Unregister");
-
-  eqhf2_libfunc = init_one_libfunc ("__eqhf2");
-  nehf2_libfunc = init_one_libfunc ("__nehf2");
-  gthf2_libfunc = init_one_libfunc ("__gthf2");
-  gehf2_libfunc = init_one_libfunc ("__gehf2");
-  lthf2_libfunc = init_one_libfunc ("__lthf2");
-  lehf2_libfunc = init_one_libfunc ("__lehf2");
-  unordhf2_libfunc = init_one_libfunc ("__unordhf2");
-
-  eqsf2_libfunc = init_one_libfunc ("__eqsf2");
-  nesf2_libfunc = init_one_libfunc ("__nesf2");
-  gtsf2_libfunc = init_one_libfunc ("__gtsf2");
-  gesf2_libfunc = init_one_libfunc ("__gesf2");
-  ltsf2_libfunc = init_one_libfunc ("__ltsf2");
-  lesf2_libfunc = init_one_libfunc ("__lesf2");
-  unordsf2_libfunc = init_one_libfunc ("__unordsf2");
-
-  eqdf2_libfunc = init_one_libfunc ("__eqdf2");
-  nedf2_libfunc = init_one_libfunc ("__nedf2");
-  gtdf2_libfunc = init_one_libfunc ("__gtdf2");
-  gedf2_libfunc = init_one_libfunc ("__gedf2");
-  ltdf2_libfunc = init_one_libfunc ("__ltdf2");
-  ledf2_libfunc = init_one_libfunc ("__ledf2");
-  unorddf2_libfunc = init_one_libfunc ("__unorddf2");
-
-  eqxf2_libfunc = init_one_libfunc ("__eqxf2");
-  nexf2_libfunc = init_one_libfunc ("__nexf2");
-  gtxf2_libfunc = init_one_libfunc ("__gtxf2");
-  gexf2_libfunc = init_one_libfunc ("__gexf2");
-  ltxf2_libfunc = init_one_libfunc ("__ltxf2");
-  lexf2_libfunc = init_one_libfunc ("__lexf2");
-  unordxf2_libfunc = init_one_libfunc ("__unordxf2");
-
-  eqtf2_libfunc = init_one_libfunc ("__eqtf2");
-  netf2_libfunc = init_one_libfunc ("__netf2");
-  gttf2_libfunc = init_one_libfunc ("__gttf2");
-  getf2_libfunc = init_one_libfunc ("__getf2");
-  lttf2_libfunc = init_one_libfunc ("__lttf2");
-  letf2_libfunc = init_one_libfunc ("__letf2");
-  unordtf2_libfunc = init_one_libfunc ("__unordtf2");
-
-  floatsisf_libfunc = init_one_libfunc ("__floatsisf");
-  floatdisf_libfunc = init_one_libfunc ("__floatdisf");
-  floattisf_libfunc = init_one_libfunc ("__floattisf");
-
-  floatsidf_libfunc = init_one_libfunc ("__floatsidf");
-  floatdidf_libfunc = init_one_libfunc ("__floatdidf");
-  floattidf_libfunc = init_one_libfunc ("__floattidf");
-
-  floatsixf_libfunc = init_one_libfunc ("__floatsixf");
-  floatdixf_libfunc = init_one_libfunc ("__floatdixf");
-  floattixf_libfunc = init_one_libfunc ("__floattixf");
-
-  floatsitf_libfunc = init_one_libfunc ("__floatsitf");
-  floatditf_libfunc = init_one_libfunc ("__floatditf");
-  floattitf_libfunc = init_one_libfunc ("__floattitf");
-
-  fixsfsi_libfunc = init_one_libfunc ("__fixsfsi");
-  fixsfdi_libfunc = init_one_libfunc ("__fixsfdi");
-  fixsfti_libfunc = init_one_libfunc ("__fixsfti");
-
-  fixdfsi_libfunc = init_one_libfunc ("__fixdfsi");
-  fixdfdi_libfunc = init_one_libfunc ("__fixdfdi");
-  fixdfti_libfunc = init_one_libfunc ("__fixdfti");
-
-  fixxfsi_libfunc = init_one_libfunc ("__fixxfsi");
-  fixxfdi_libfunc = init_one_libfunc ("__fixxfdi");
-  fixxfti_libfunc = init_one_libfunc ("__fixxfti");
-
-  fixtfsi_libfunc = init_one_libfunc ("__fixtfsi");
-  fixtfdi_libfunc = init_one_libfunc ("__fixtfdi");
-  fixtfti_libfunc = init_one_libfunc ("__fixtfti");
-
-  fixunssfsi_libfunc = init_one_libfunc ("__fixunssfsi");
-  fixunssfdi_libfunc = init_one_libfunc ("__fixunssfdi");
-  fixunssfti_libfunc = init_one_libfunc ("__fixunssfti");
-
-  fixunsdfsi_libfunc = init_one_libfunc ("__fixunsdfsi");
-  fixunsdfdi_libfunc = init_one_libfunc ("__fixunsdfdi");
-  fixunsdfti_libfunc = init_one_libfunc ("__fixunsdfti");
-
-  fixunsxfsi_libfunc = init_one_libfunc ("__fixunsxfsi");
-  fixunsxfdi_libfunc = init_one_libfunc ("__fixunsxfdi");
-  fixunsxfti_libfunc = init_one_libfunc ("__fixunsxfti");
-
-  fixunstfsi_libfunc = init_one_libfunc ("__fixunstfsi");
-  fixunstfdi_libfunc = init_one_libfunc ("__fixunstfdi");
-  fixunstfti_libfunc = init_one_libfunc ("__fixunstfti");
-
-  /* For function entry/exit instrumentation.  */
-  profile_function_entry_libfunc
+    
+    eqhf2_libfunc = init_one_libfunc ("__eqhf2");
+    nehf2_libfunc = init_one_libfunc ("__nehf2");
+    gthf2_libfunc = init_one_libfunc ("__gthf2");
+    gehf2_libfunc = init_one_libfunc ("__gehf2");
+    lthf2_libfunc = init_one_libfunc ("__lthf2");
+    lehf2_libfunc = init_one_libfunc ("__lehf2");
+    unordhf2_libfunc = init_one_libfunc ("__unordhf2");
+    
+    eqsf2_libfunc = init_one_libfunc ("__eqsf2");
+    nesf2_libfunc = init_one_libfunc ("__nesf2");
+    gtsf2_libfunc = init_one_libfunc ("__gtsf2");
+    gesf2_libfunc = init_one_libfunc ("__gesf2");
+    ltsf2_libfunc = init_one_libfunc ("__ltsf2");
+    lesf2_libfunc = init_one_libfunc ("__lesf2");
+    unordsf2_libfunc = init_one_libfunc ("__unordsf2");
+    
+    eqdf2_libfunc = init_one_libfunc ("__eqdf2");
+    nedf2_libfunc = init_one_libfunc ("__nedf2");
+    gtdf2_libfunc = init_one_libfunc ("__gtdf2");
+    gedf2_libfunc = init_one_libfunc ("__gedf2");
+    ltdf2_libfunc = init_one_libfunc ("__ltdf2");
+    ledf2_libfunc = init_one_libfunc ("__ledf2");
+    unorddf2_libfunc = init_one_libfunc ("__unorddf2");
+    
+    eqxf2_libfunc = init_one_libfunc ("__eqxf2");
+    nexf2_libfunc = init_one_libfunc ("__nexf2");
+    gtxf2_libfunc = init_one_libfunc ("__gtxf2");
+    gexf2_libfunc = init_one_libfunc ("__gexf2");
+    ltxf2_libfunc = init_one_libfunc ("__ltxf2");
+    lexf2_libfunc = init_one_libfunc ("__lexf2");
+    unordxf2_libfunc = init_one_libfunc ("__unordxf2");
+    
+    eqtf2_libfunc = init_one_libfunc ("__eqtf2");
+    netf2_libfunc = init_one_libfunc ("__netf2");
+    gttf2_libfunc = init_one_libfunc ("__gttf2");
+    getf2_libfunc = init_one_libfunc ("__getf2");
+    lttf2_libfunc = init_one_libfunc ("__lttf2");
+    letf2_libfunc = init_one_libfunc ("__letf2");
+    unordtf2_libfunc = init_one_libfunc ("__unordtf2");
+    
+    floatsisf_libfunc = init_one_libfunc ("__floatsisf");
+    floatdisf_libfunc = init_one_libfunc ("__floatdisf");
+    floattisf_libfunc = init_one_libfunc ("__floattisf");
+    
+    floatsidf_libfunc = init_one_libfunc ("__floatsidf");
+    floatdidf_libfunc = init_one_libfunc ("__floatdidf");
+    floattidf_libfunc = init_one_libfunc ("__floattidf");
+    
+    floatsixf_libfunc = init_one_libfunc ("__floatsixf");
+    floatdixf_libfunc = init_one_libfunc ("__floatdixf");
+    floattixf_libfunc = init_one_libfunc ("__floattixf");
+    
+    floatsitf_libfunc = init_one_libfunc ("__floatsitf");
+    floatditf_libfunc = init_one_libfunc ("__floatditf");
+    floattitf_libfunc = init_one_libfunc ("__floattitf");
+    
+    fixsfsi_libfunc = init_one_libfunc ("__fixsfsi");
+    fixsfdi_libfunc = init_one_libfunc ("__fixsfdi");
+    fixsfti_libfunc = init_one_libfunc ("__fixsfti");
+    
+    fixdfsi_libfunc = init_one_libfunc ("__fixdfsi");
+    fixdfdi_libfunc = init_one_libfunc ("__fixdfdi");
+    fixdfti_libfunc = init_one_libfunc ("__fixdfti");
+    
+    fixxfsi_libfunc = init_one_libfunc ("__fixxfsi");
+    fixxfdi_libfunc = init_one_libfunc ("__fixxfdi");
+    fixxfti_libfunc = init_one_libfunc ("__fixxfti");
+    
+    fixtfsi_libfunc = init_one_libfunc ("__fixtfsi");
+    fixtfdi_libfunc = init_one_libfunc ("__fixtfdi");
+    fixtfti_libfunc = init_one_libfunc ("__fixtfti");
+    
+    fixunssfsi_libfunc = init_one_libfunc ("__fixunssfsi");
+    fixunssfdi_libfunc = init_one_libfunc ("__fixunssfdi");
+    fixunssfti_libfunc = init_one_libfunc ("__fixunssfti");
+    
+    fixunsdfsi_libfunc = init_one_libfunc ("__fixunsdfsi");
+    fixunsdfdi_libfunc = init_one_libfunc ("__fixunsdfdi");
+    fixunsdfti_libfunc = init_one_libfunc ("__fixunsdfti");
+    
+    fixunsxfsi_libfunc = init_one_libfunc ("__fixunsxfsi");
+    fixunsxfdi_libfunc = init_one_libfunc ("__fixunsxfdi");
+    fixunsxfti_libfunc = init_one_libfunc ("__fixunsxfti");
+    
+    fixunstfsi_libfunc = init_one_libfunc ("__fixunstfsi");
+    fixunstfdi_libfunc = init_one_libfunc ("__fixunstfdi");
+    fixunstfti_libfunc = init_one_libfunc ("__fixunstfti");
+    
+    /* For function entry/exit instrumentation.  */
+    profile_function_entry_libfunc
     = init_one_libfunc ("__cyg_profile_func_enter");
-  profile_function_exit_libfunc
+    profile_function_exit_libfunc
     = init_one_libfunc ("__cyg_profile_func_exit");
-
+    
 #ifdef HAVE_conditional_trap
-  init_traps ();
+    init_traps ();
 #endif
-
+    
 #ifdef INIT_TARGET_OPTABS
-  /* Allow the target to add more libcalls or rename some, etc.  */
-  INIT_TARGET_OPTABS;
+    /* Allow the target to add more libcalls or rename some, etc.  */
+    INIT_TARGET_OPTABS;
 #endif
-
-  /* Add these GC roots.  */
-  ggc_add_root (optab_table, OTI_MAX, sizeof(optab), mark_optab);
-  ggc_add_rtx_root (libfunc_table, LTI_MAX);
+    
+    /* Add these GC roots.  */
+    ggc_add_root (optab_table, OTI_MAX, sizeof(optab), mark_optab);
+    ggc_add_rtx_root (libfunc_table, LTI_MAX);
 }
 
 #ifdef HAVE_conditional_trap
 /* The insn generating function can not take an rtx_code argument.
-   TRAP_RTX is used as an rtx argument.  Its code is replaced with
-   the code to be used in the trap insn and all other fields are
-   ignored.  */
+ TRAP_RTX is used as an rtx argument.  Its code is replaced with
+ the code to be used in the trap insn and all other fields are
+ ignored.  */
 static rtx trap_rtx;
 
 static void
 init_traps ()
 {
-  if (HAVE_conditional_trap)
+    if (HAVE_conditional_trap)
     {
-      trap_rtx = gen_rtx_fmt_ee (EQ, VOIDmode, NULL_RTX, NULL_RTX);
-      ggc_add_rtx_root (&trap_rtx, 1);
+        trap_rtx = gen_rtx_fmt_ee (EQ, VOIDmode, NULL_RTX, NULL_RTX);
+        ggc_add_rtx_root (&trap_rtx, 1);
     }
 }
 #endif
 
 /* Generate insns to trap with code TCODE if OP1 and OP2 satisfy condition
-   CODE.  Return 0 on failure.  */
+ CODE.  Return 0 on failure.  */
 
 rtx
 gen_cond_trap (code, op1, op2, tcode)
-  enum rtx_code code ATTRIBUTE_UNUSED;
-  rtx op1, op2 ATTRIBUTE_UNUSED, tcode ATTRIBUTE_UNUSED;
+enum rtx_code code ATTRIBUTE_UNUSED;
+rtx op1, op2 ATTRIBUTE_UNUSED, tcode ATTRIBUTE_UNUSED;
 {
-  enum machine_mode mode = GET_MODE (op1);
-
-  if (mode == VOIDmode)
-    return 0;
-
+    enum machine_mode mode = GET_MODE (op1);
+    
+    if (mode == VOIDmode)
+        return 0;
+    
 #ifdef HAVE_conditional_trap
-  if (HAVE_conditional_trap
-      && cmp_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
+    if (HAVE_conditional_trap
+        && cmp_optab->handlers[(int) mode].insn_code != CODE_FOR_nothing)
     {
-      rtx insn;
-      start_sequence();
-      emit_insn (GEN_FCN (cmp_optab->handlers[(int) mode].insn_code) (op1, op2));
-      PUT_CODE (trap_rtx, code);
-      insn = gen_conditional_trap (trap_rtx, tcode);
-      if (insn)
-	{
-	  emit_insn (insn);
-	  insn = gen_sequence ();
-	}
-      end_sequence();
-      return insn;
+        rtx insn;
+        start_sequence();
+        emit_insn (GEN_FCN2 (cmp_optab->handlers[(int) mode].insn_code) (op1, op2));
+        PUT_CODE (trap_rtx, code);
+        insn = gen_conditional_trap (trap_rtx, tcode);
+        if (insn)
+        {
+            emit_insn (insn);
+            insn = gen_sequence ();
+        }
+        end_sequence();
+        return insn;
     }
 #endif
-
-  return 0;
+    
+    return 0;
 }
diff --git a/optabs.h b/optabs.h
index 0c488b8..f1bd521 100644
--- a/optabs.h
+++ b/optabs.h
@@ -49,7 +49,20 @@ typedef struct optab
 
 /* Given an enum insn_code, access the function to construct
    the body of that kind of insn.  */
-#define GEN_FCN(CODE) (*insn_data[(int) (CODE)].genfun)
+// #define GEN_FCN(CODE) (*insn_data[(int) (CODE)].genfun)
+#define GEN_FCN0(CODE)	(insn_data[CODE].genfun.argc0)
+#define GEN_FCN1(CODE)	(insn_data[CODE].genfun.argc1)
+#define GEN_FCN2(CODE)	(insn_data[CODE].genfun.argc2)
+#define GEN_FCN3(CODE)	(insn_data[CODE].genfun.argc3)
+#define GEN_FCN4(CODE)	(insn_data[CODE].genfun.argc4)
+#define GEN_FCN5(CODE)	(insn_data[CODE].genfun.argc5)
+#define GEN_FCN6(CODE)	(insn_data[CODE].genfun.argc6)
+#define GEN_FCN7(CODE)	(insn_data[CODE].genfun.argc7)
+#define GEN_FCN8(CODE)	(insn_data[CODE].genfun.argc8)
+#define GEN_FCN9(CODE)	(insn_data[CODE].genfun.argc9)
+#define GEN_FCN10(CODE)	(insn_data[CODE].genfun.argc10)
+#define GEN_FCN11(CODE)	(insn_data[CODE].genfun.argc11)
+
 
 /* Enumeration of valid indexes into optab_table.  */
 enum optab_index
diff --git a/recog.c b/recog.c
index d9848dd..d7aa9ae 100644
--- a/recog.c
+++ b/recog.c
@@ -1,23 +1,23 @@
 /* Subroutines used by or related to instruction recognition.
-   Copyright (C) 1987, 1988, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998
-   1999, 2000, 2001, 2002 Free Software Foundation, Inc.
-
-This file is part of GCC.
-
-GCC is free software; you can redistribute it and/or modify it under
-the terms of the GNU General Public License as published by the Free
-Software Foundation; either version 2, or (at your option) any later
-version.
-
-GCC is distributed in the hope that it will be useful, but WITHOUT ANY
-WARRANTY; without even the implied warranty of MERCHANTABILITY or
-FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
-for more details.
-
-You should have received a copy of the GNU General Public License
-along with GCC; see the file COPYING.  If not, write to the Free
-Software Foundation, 59 Temple Place - Suite 330, Boston, MA
-02111-1307, USA.  */
+ Copyright (C) 1987, 1988, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998
+ 1999, 2000, 2001, 2002 Free Software Foundation, Inc.
+ 
+ This file is part of GCC.
+ 
+ GCC is free software; you can redistribute it and/or modify it under
+ the terms of the GNU General Public License as published by the Free
+ Software Foundation; either version 2, or (at your option) any later
+ version.
+ 
+ GCC is distributed in the hope that it will be useful, but WITHOUT ANY
+ WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ for more details.
+ 
+ You should have received a copy of the GNU General Public License
+ along with GCC; see the file COPYING.  If not, write to the Free
+ Software Foundation, 59 Temple Place - Suite 330, Boston, MA
+ 02111-1307, USA.  */
 
 
 #include "config.h"
@@ -60,121 +60,121 @@ static void validate_replace_src_1 	PARAMS ((rtx *, void *));
 static rtx split_insn			PARAMS ((rtx));
 
 /* Nonzero means allow operands to be volatile.
-   This should be 0 if you are generating rtl, such as if you are calling
-   the functions in optabs.c and expmed.c (most of the time).
-   This should be 1 if all valid insns need to be recognized,
-   such as in regclass.c and final.c and reload.c.
-
-   init_recog and init_recog_no_volatile are responsible for setting this.  */
+ This should be 0 if you are generating rtl, such as if you are calling
+ the functions in optabs.c and expmed.c (most of the time).
+ This should be 1 if all valid insns need to be recognized,
+ such as in regclass.c and final.c and reload.c.
+ 
+ init_recog and init_recog_no_volatile are responsible for setting this.  */
 
 int volatile_ok;
 
 struct recog_data recog_data;
 
 /* Contains a vector of operand_alternative structures for every operand.
-   Set up by preprocess_constraints.  */
+ Set up by preprocess_constraints.  */
 struct operand_alternative recog_op_alt[MAX_RECOG_OPERANDS][MAX_RECOG_ALTERNATIVES];
 
 /* On return from `constrain_operands', indicate which alternative
-   was satisfied.  */
+ was satisfied.  */
 
 int which_alternative;
 
 /* Nonzero after end of reload pass.
-   Set to 1 or 0 by toplev.c.
-   Controls the significance of (SUBREG (MEM)).  */
+ Set to 1 or 0 by toplev.c.
+ Controls the significance of (SUBREG (MEM)).  */
 
 int reload_completed;
 
 /* Initialize data used by the function `recog'.
-   This must be called once in the compilation of a function
-   before any insn recognition may be done in the function.  */
+ This must be called once in the compilation of a function
+ before any insn recognition may be done in the function.  */
 
 void
 init_recog_no_volatile ()
 {
-  volatile_ok = 0;
+    volatile_ok = 0;
 }
 
 void
 init_recog ()
 {
-  volatile_ok = 1;
+    volatile_ok = 1;
 }
 
 /* Try recognizing the instruction INSN,
-   and return the code number that results.
-   Remember the code so that repeated calls do not
-   need to spend the time for actual rerecognition.
-
-   This function is the normal interface to instruction recognition.
-   The automatically-generated function `recog' is normally called
-   through this one.  (The only exception is in combine.c.)  */
+ and return the code number that results.
+ Remember the code so that repeated calls do not
+ need to spend the time for actual rerecognition.
+ 
+ This function is the normal interface to instruction recognition.
+ The automatically-generated function `recog' is normally called
+ through this one.  (The only exception is in combine.c.)  */
 
 int
 recog_memoized_1 (insn)
-     rtx insn;
+rtx insn;
 {
-  if (INSN_CODE (insn) < 0)
-    INSN_CODE (insn) = recog (PATTERN (insn), insn, 0);
-  return INSN_CODE (insn);
+    if (INSN_CODE (insn) < 0)
+        INSN_CODE (insn) = recog (PATTERN (insn), insn, 0);
+    return INSN_CODE (insn);
 }
 
 /* Check that X is an insn-body for an `asm' with operands
-   and that the operands mentioned in it are legitimate.  */
+ and that the operands mentioned in it are legitimate.  */
 
 int
 check_asm_operands (x)
-     rtx x;
+rtx x;
 {
-  int noperands;
-  rtx *operands;
-  const char **constraints;
-  int i;
-
-  /* Post-reload, be more strict with things.  */
-  if (reload_completed)
+    int noperands;
+    rtx *operands;
+    const char **constraints;
+    int i;
+    
+    /* Post-reload, be more strict with things.  */
+    if (reload_completed)
     {
-      /* ??? Doh!  We've not got the wrapping insn.  Cook one up.  */
-      extract_insn (make_insn_raw (x));
-      constrain_operands (1);
-      return which_alternative >= 0;
+        /* ??? Doh!  We've not got the wrapping insn.  Cook one up.  */
+        extract_insn (make_insn_raw (x));
+        constrain_operands (1);
+        return which_alternative >= 0;
     }
-
-  noperands = asm_noperands (x);
-  if (noperands < 0)
-    return 0;
-  if (noperands == 0)
-    return 1;
-
-  operands = (rtx *) alloca (noperands * sizeof (rtx));
-  constraints = (const char **) alloca (noperands * sizeof (char *));
-
-  decode_asm_operands (x, operands, NULL, constraints, NULL);
-
-  for (i = 0; i < noperands; i++)
-    {
-      const char *c = constraints[i];
-      if (c[0] == '%')
-	c++;
-      if (ISDIGIT ((unsigned char) c[0]) && c[1] == '\0')
-	c = constraints[c[0] - '0'];
-
-      if (! asm_operand_ok (operands[i], c))
+    
+    noperands = asm_noperands (x);
+    if (noperands < 0)
         return 0;
+    if (noperands == 0)
+        return 1;
+    
+    operands = (rtx *) alloca (noperands * sizeof (rtx));
+    constraints = (const char **) alloca (noperands * sizeof (char *));
+    
+    decode_asm_operands (x, operands, NULL, constraints, NULL);
+    
+    for (i = 0; i < noperands; i++)
+    {
+        const char *c = constraints[i];
+        if (c[0] == '%')
+            c++;
+        if (ISDIGIT ((unsigned char) c[0]) && c[1] == '\0')
+            c = constraints[c[0] - '0'];
+        
+        if (! asm_operand_ok (operands[i], c))
+            return 0;
     }
-
-  return 1;
+    
+    return 1;
 }
 
 /* Static data for the next two routines.  */
 
 typedef struct change_t
 {
-  rtx object;
-  int old_code;
-  rtx *loc;
-  rtx old;
+    rtx object;
+    int old_code;
+    rtx *loc;
+    rtx old;
 } change_t;
 
 static change_t *changes;
@@ -183,222 +183,222 @@ static int changes_allocated;
 static int num_changes = 0;
 
 /* Validate a proposed change to OBJECT.  LOC is the location in the rtl
-   at which NEW will be placed.  If OBJECT is zero, no validation is done,
-   the change is simply made.
-
-   Two types of objects are supported:  If OBJECT is a MEM, memory_address_p
-   will be called with the address and mode as parameters.  If OBJECT is
-   an INSN, CALL_INSN, or JUMP_INSN, the insn will be re-recognized with
-   the change in place.
-
-   IN_GROUP is non-zero if this is part of a group of changes that must be
-   performed as a group.  In that case, the changes will be stored.  The
-   function `apply_change_group' will validate and apply the changes.
-
-   If IN_GROUP is zero, this is a single change.  Try to recognize the insn
-   or validate the memory reference with the change applied.  If the result
-   is not valid for the machine, suppress the change and return zero.
-   Otherwise, perform the change and return 1.  */
+ at which NEW will be placed.  If OBJECT is zero, no validation is done,
+ the change is simply made.
+ 
+ Two types of objects are supported:  If OBJECT is a MEM, memory_address_p
+ will be called with the address and mode as parameters.  If OBJECT is
+ an INSN, CALL_INSN, or JUMP_INSN, the insn will be re-recognized with
+ the change in place.
+ 
+ IN_GROUP is non-zero if this is part of a group of changes that must be
+ performed as a group.  In that case, the changes will be stored.  The
+ function `apply_change_group' will validate and apply the changes.
+ 
+ If IN_GROUP is zero, this is a single change.  Try to recognize the insn
+ or validate the memory reference with the change applied.  If the result
+ is not valid for the machine, suppress the change and return zero.
+ Otherwise, perform the change and return 1.  */
 
 int
 validate_change (object, loc, new, in_group)
-    rtx object;
-    rtx *loc;
-    rtx new;
-    int in_group;
+rtx object;
+rtx *loc;
+rtx new;
+int in_group;
 {
-  rtx old = *loc;
-
-  if (old == new || rtx_equal_p (old, new))
-    return 1;
-
-  if (in_group == 0 && num_changes != 0)
-    abort ();
-
-  *loc = new;
-
-  /* Save the information describing this change.  */
-  if (num_changes >= changes_allocated)
+    rtx old = *loc;
+    
+    if (old == new || rtx_equal_p (old, new))
+        return 1;
+    
+    if (in_group == 0 && num_changes != 0)
+        abort ();
+    
+    *loc = new;
+    
+    /* Save the information describing this change.  */
+    if (num_changes >= changes_allocated)
     {
-      if (changes_allocated == 0)
-	/* This value allows for repeated substitutions inside complex
-	   indexed addresses, or changes in up to 5 insns.  */
-	changes_allocated = MAX_RECOG_OPERANDS * 5;
-      else
-	changes_allocated *= 2;
-
-      changes = 
-	(change_t*) xrealloc (changes, 
-			      sizeof (change_t) * changes_allocated); 
+        if (changes_allocated == 0)
+        /* This value allows for repeated substitutions inside complex
+         indexed addresses, or changes in up to 5 insns.  */
+            changes_allocated = MAX_RECOG_OPERANDS * 5;
+        else
+            changes_allocated *= 2;
+        
+        changes =
+        (change_t*) xrealloc (changes,
+                              sizeof (change_t) * changes_allocated);
     }
-  
-  changes[num_changes].object = object;
-  changes[num_changes].loc = loc;
-  changes[num_changes].old = old;
-
-  if (object && GET_CODE (object) != MEM)
+    
+    changes[num_changes].object = object;
+    changes[num_changes].loc = loc;
+    changes[num_changes].old = old;
+    
+    if (object && GET_CODE (object) != MEM)
     {
-      /* Set INSN_CODE to force rerecognition of insn.  Save old code in
-	 case invalid.  */
-      changes[num_changes].old_code = INSN_CODE (object);
-      INSN_CODE (object) = -1;
+        /* Set INSN_CODE to force rerecognition of insn.  Save old code in
+         case invalid.  */
+        changes[num_changes].old_code = INSN_CODE (object);
+        INSN_CODE (object) = -1;
     }
-
-  num_changes++;
-
-  /* If we are making a group of changes, return 1.  Otherwise, validate the
+    
+    num_changes++;
+    
+    /* If we are making a group of changes, return 1.  Otherwise, validate the
      change group we made.  */
-
-  if (in_group)
-    return 1;
-  else
-    return apply_change_group ();
+    
+    if (in_group)
+        return 1;
+    else
+        return apply_change_group ();
 }
 
 /* This subroutine of apply_change_group verifies whether the changes to INSN
-   were valid; i.e. whether INSN can still be recognized.  */
+ were valid; i.e. whether INSN can still be recognized.  */
 
 int
 insn_invalid_p (insn)
-     rtx insn;
+rtx insn;
 {
-  rtx pat = PATTERN (insn);
-  int num_clobbers = 0;
-  /* If we are before reload and the pattern is a SET, see if we can add
+    rtx pat = PATTERN (insn);
+    int num_clobbers = 0;
+    /* If we are before reload and the pattern is a SET, see if we can add
      clobbers.  */
-  int icode = recog (pat, insn,
-		     (GET_CODE (pat) == SET
-		      && ! reload_completed && ! reload_in_progress)
-		     ? &num_clobbers : 0);
-  int is_asm = icode < 0 && asm_noperands (PATTERN (insn)) >= 0;
-
-  
-  /* If this is an asm and the operand aren't legal, then fail.  Likewise if
+    int icode = recog (pat, insn,
+                       (GET_CODE (pat) == SET
+                        && ! reload_completed && ! reload_in_progress)
+                       ? &num_clobbers : 0);
+    int is_asm = icode < 0 && asm_noperands (PATTERN (insn)) >= 0;
+    
+    
+    /* If this is an asm and the operand aren't legal, then fail.  Likewise if
      this is not an asm and the insn wasn't recognized.  */
-  if ((is_asm && ! check_asm_operands (PATTERN (insn)))
-      || (!is_asm && icode < 0))
-    return 1;
-
-  /* If we have to add CLOBBERs, fail if we have to add ones that reference
+    if ((is_asm && ! check_asm_operands (PATTERN (insn)))
+        || (!is_asm && icode < 0))
+        return 1;
+    
+    /* If we have to add CLOBBERs, fail if we have to add ones that reference
      hard registers since our callers can't know if they are live or not.
      Otherwise, add them.  */
-  if (num_clobbers > 0)
+    if (num_clobbers > 0)
     {
-      rtx newpat;
-
-      if (added_clobbers_hard_reg_p (icode))
-	return 1;
-
-      newpat = gen_rtx_PARALLEL (VOIDmode, rtvec_alloc (num_clobbers + 1));
-      XVECEXP (newpat, 0, 0) = pat;
-      add_clobbers (newpat, icode);
-      PATTERN (insn) = pat = newpat;
+        rtx newpat;
+        
+        if (added_clobbers_hard_reg_p (icode))
+            return 1;
+        
+        newpat = gen_rtx_PARALLEL (VOIDmode, rtvec_alloc (num_clobbers + 1));
+        XVECEXP (newpat, 0, 0) = pat;
+        add_clobbers (newpat, icode);
+        PATTERN (insn) = pat = newpat;
     }
-
-  /* After reload, verify that all constraints are satisfied.  */
-  if (reload_completed)
+    
+    /* After reload, verify that all constraints are satisfied.  */
+    if (reload_completed)
     {
-      extract_insn (insn);
-
-      if (! constrain_operands (1))
-	return 1;
+        extract_insn (insn);
+        
+        if (! constrain_operands (1))
+            return 1;
     }
-
-  INSN_CODE (insn) = icode;
-  return 0;
+    
+    INSN_CODE (insn) = icode;
+    return 0;
 }
 
 /* Apply a group of changes previously issued with `validate_change'.
-   Return 1 if all changes are valid, zero otherwise.  */
+ Return 1 if all changes are valid, zero otherwise.  */
 
 int
 apply_change_group ()
 {
-  int i;
-  rtx last_validated = NULL_RTX;
-
-  /* The changes have been applied and all INSN_CODEs have been reset to force
+    int i;
+    rtx last_validated = NULL_RTX;
+    
+    /* The changes have been applied and all INSN_CODEs have been reset to force
      rerecognition.
-
+     
      The changes are valid if we aren't given an object, or if we are
      given a MEM and it still is a valid address, or if this is in insn
      and it is recognized.  In the latter case, if reload has completed,
      we also require that the operands meet the constraints for
      the insn.  */
-
-  for (i = 0; i < num_changes; i++)
+    
+    for (i = 0; i < num_changes; i++)
     {
-      rtx object = changes[i].object;
-
-      /* if there is no object to test or if it is the same as the one we
+        rtx object = changes[i].object;
+        
+        /* if there is no object to test or if it is the same as the one we
          already tested, ignore it.  */
-      if (object == 0 || object == last_validated)
-	continue;
-
-      if (GET_CODE (object) == MEM)
-	{
-	  if (! memory_address_p (GET_MODE (object), XEXP (object, 0)))
-	    break;
-	}
-      else if (insn_invalid_p (object))
-	{
-	  rtx pat = PATTERN (object);
-
-	  /* Perhaps we couldn't recognize the insn because there were
-	     extra CLOBBERs at the end.  If so, try to re-recognize
-	     without the last CLOBBER (later iterations will cause each of
-	     them to be eliminated, in turn).  But don't do this if we
-	     have an ASM_OPERAND.  */
-	  if (GET_CODE (pat) == PARALLEL
-	      && GET_CODE (XVECEXP (pat, 0, XVECLEN (pat, 0) - 1)) == CLOBBER
-	      && asm_noperands (PATTERN (object)) < 0)
-	    {
-	      rtx newpat;
-
-	      if (XVECLEN (pat, 0) == 2)
-		newpat = XVECEXP (pat, 0, 0);
-	      else
-		{
-		  int j;
-
-		  newpat
-		    = gen_rtx_PARALLEL (VOIDmode, 
-					rtvec_alloc (XVECLEN (pat, 0) - 1));
-		  for (j = 0; j < XVECLEN (newpat, 0); j++)
-		    XVECEXP (newpat, 0, j) = XVECEXP (pat, 0, j);
-		}
-
-	      /* Add a new change to this group to replace the pattern
-		 with this new pattern.  Then consider this change
-		 as having succeeded.  The change we added will
-		 cause the entire call to fail if things remain invalid.
-
-		 Note that this can lose if a later change than the one
-		 we are processing specified &XVECEXP (PATTERN (object), 0, X)
-		 but this shouldn't occur.  */
-
-	      validate_change (object, &PATTERN (object), newpat, 1);
-	      continue;
-	    }
-	  else if (GET_CODE (pat) == USE || GET_CODE (pat) == CLOBBER)
-	    /* If this insn is a CLOBBER or USE, it is always valid, but is
-	       never recognized.  */
-	    continue;
-	  else
-	    break;
-	}
-      last_validated = object;
+        if (object == 0 || object == last_validated)
+            continue;
+        
+        if (GET_CODE (object) == MEM)
+        {
+            if (! memory_address_p (GET_MODE (object), XEXP (object, 0)))
+                break;
+        }
+        else if (insn_invalid_p (object))
+        {
+            rtx pat = PATTERN (object);
+            
+            /* Perhaps we couldn't recognize the insn because there were
+             extra CLOBBERs at the end.  If so, try to re-recognize
+             without the last CLOBBER (later iterations will cause each of
+             them to be eliminated, in turn).  But don't do this if we
+             have an ASM_OPERAND.  */
+            if (GET_CODE (pat) == PARALLEL
+                && GET_CODE (XVECEXP (pat, 0, XVECLEN (pat, 0) - 1)) == CLOBBER
+                && asm_noperands (PATTERN (object)) < 0)
+            {
+                rtx newpat;
+                
+                if (XVECLEN (pat, 0) == 2)
+                    newpat = XVECEXP (pat, 0, 0);
+                else
+                {
+                    int j;
+                    
+                    newpat
+                    = gen_rtx_PARALLEL (VOIDmode,
+                                        rtvec_alloc (XVECLEN (pat, 0) - 1));
+                    for (j = 0; j < XVECLEN (newpat, 0); j++)
+                    XVECEXP (newpat, 0, j) = XVECEXP (pat, 0, j);
+                }
+                
+                /* Add a new change to this group to replace the pattern
+                 with this new pattern.  Then consider this change
+                 as having succeeded.  The change we added will
+                 cause the entire call to fail if things remain invalid.
+                 
+                 Note that this can lose if a later change than the one
+                 we are processing specified &XVECEXP (PATTERN (object), 0, X)
+                 but this shouldn't occur.  */
+                
+                validate_change (object, &PATTERN (object), newpat, 1);
+                continue;
+            }
+            else if (GET_CODE (pat) == USE || GET_CODE (pat) == CLOBBER)
+            /* If this insn is a CLOBBER or USE, it is always valid, but is
+             never recognized.  */
+                continue;
+            else
+                break;
+        }
+        last_validated = object;
     }
-
-  if (i == num_changes)
+    
+    if (i == num_changes)
     {
-      num_changes = 0;
-      return 1;
+        num_changes = 0;
+        return 1;
     }
-  else
+    else
     {
-      cancel_changes (0);
-      return 0;
+        cancel_changes (0);
+        return 0;
     }
 }
 
@@ -407,2906 +407,2906 @@ apply_change_group ()
 int
 num_validated_changes ()
 {
-  return num_changes;
+    return num_changes;
 }
 
 /* Retract the changes numbered NUM and up.  */
 
 void
 cancel_changes (num)
-     int num;
+int num;
 {
-  int i;
-
-  /* Back out all the changes.  Do this in the opposite order in which
+    int i;
+    
+    /* Back out all the changes.  Do this in the opposite order in which
      they were made.  */
-  for (i = num_changes - 1; i >= num; i--)
+    for (i = num_changes - 1; i >= num; i--)
     {
-      *changes[i].loc = changes[i].old;
-      if (changes[i].object && GET_CODE (changes[i].object) != MEM)
-	INSN_CODE (changes[i].object) = changes[i].old_code;
+        *changes[i].loc = changes[i].old;
+        if (changes[i].object && GET_CODE (changes[i].object) != MEM)
+            INSN_CODE (changes[i].object) = changes[i].old_code;
     }
-  num_changes = num;
+    num_changes = num;
 }
 
 /* Replace every occurrence of FROM in X with TO.  Mark each change with
-   validate_change passing OBJECT.  */
+ validate_change passing OBJECT.  */
 
 static void
 validate_replace_rtx_1 (loc, from, to, object)
-     rtx *loc;
-     rtx from, to, object;
+rtx *loc;
+rtx from, to, object;
 {
-  int i, j;
-  const char *fmt;
-  rtx x = *loc;
-  enum rtx_code code;
-  enum machine_mode op0_mode = VOIDmode;
-  int prev_changes = num_changes;
-  rtx new;
-
-  if (!x)
-    return;
-
-  code = GET_CODE (x);
-  fmt = GET_RTX_FORMAT (code);
-  if (fmt[0] == 'e')
-    op0_mode = GET_MODE (XEXP (x, 0));
-
-  /* X matches FROM if it is the same rtx or they are both referring to the
+    int i, j;
+    const char *fmt;
+    rtx x = *loc;
+    enum rtx_code code;
+    enum machine_mode op0_mode = VOIDmode;
+    int prev_changes = num_changes;
+    rtx new;
+    
+    if (!x)
+        return;
+    
+    code = GET_CODE (x);
+    fmt = GET_RTX_FORMAT (code);
+    if (fmt[0] == 'e')
+        op0_mode = GET_MODE (XEXP (x, 0));
+    
+    /* X matches FROM if it is the same rtx or they are both referring to the
      same register in the same mode.  Avoid calling rtx_equal_p unless the
      operands look similar.  */
-
-  if (x == from
-      || (GET_CODE (x) == REG && GET_CODE (from) == REG
-	  && GET_MODE (x) == GET_MODE (from)
-	  && REGNO (x) == REGNO (from))
-      || (GET_CODE (x) == GET_CODE (from) && GET_MODE (x) == GET_MODE (from)
-	  && rtx_equal_p (x, from)))
+    
+    if (x == from
+        || (GET_CODE (x) == REG && GET_CODE (from) == REG
+            && GET_MODE (x) == GET_MODE (from)
+            && REGNO (x) == REGNO (from))
+        || (GET_CODE (x) == GET_CODE (from) && GET_MODE (x) == GET_MODE (from)
+            && rtx_equal_p (x, from)))
     {
-      validate_change (object, loc, to, 1);
-      return;
+        validate_change (object, loc, to, 1);
+        return;
     }
-
-  /* Call ourself recursively to perform the replacements.  */
-
-  for (i = GET_RTX_LENGTH (code) - 1; i >= 0; i--)
+    
+    /* Call ourself recursively to perform the replacements.  */
+    
+    for (i = GET_RTX_LENGTH (code) - 1; i >= 0; i--)
     {
-      if (fmt[i] == 'e')
-	validate_replace_rtx_1 (&XEXP (x, i), from, to, object);
-      else if (fmt[i] == 'E')
-	for (j = XVECLEN (x, i) - 1; j >= 0; j--)
-	  validate_replace_rtx_1 (&XVECEXP (x, i, j), from, to, object);
+        if (fmt[i] == 'e')
+            validate_replace_rtx_1 (&XEXP (x, i), from, to, object);
+        else if (fmt[i] == 'E')
+            for (j = XVECLEN (x, i) - 1; j >= 0; j--)
+        validate_replace_rtx_1 (&XVECEXP (x, i, j), from, to, object);
     }
-
-  /* If we didn't substitute, there is nothing more to do.  */
-  if (num_changes == prev_changes)
-    return;
-
-  /* Allow substituted expression to have different mode.  This is used by
+    
+    /* If we didn't substitute, there is nothing more to do.  */
+    if (num_changes == prev_changes)
+        return;
+    
+    /* Allow substituted expression to have different mode.  This is used by
      regmove to change mode of pseudo register.  */
-  if (fmt[0] == 'e' && GET_MODE (XEXP (x, 0)) != VOIDmode)
-    op0_mode = GET_MODE (XEXP (x, 0));
-
-  /* Do changes needed to keep rtx consistent.  Don't do any other
+    if (fmt[0] == 'e' && GET_MODE (XEXP (x, 0)) != VOIDmode)
+        op0_mode = GET_MODE (XEXP (x, 0));
+    
+    /* Do changes needed to keep rtx consistent.  Don't do any other
      simplifications, as it is not our job.  */
-
-  if ((GET_RTX_CLASS (code) == '<' || GET_RTX_CLASS (code) == 'c')
-      && swap_commutative_operands_p (XEXP (x, 0), XEXP (x, 1)))
+    
+    if ((GET_RTX_CLASS (code) == '<' || GET_RTX_CLASS (code) == 'c')
+        && swap_commutative_operands_p (XEXP (x, 0), XEXP (x, 1)))
     {
-      validate_change (object, loc,
-		       gen_rtx_fmt_ee (GET_RTX_CLASS (code) == 'c' ? code
-				       : swap_condition (code),
-				       GET_MODE (x), XEXP (x, 1),
-				       XEXP (x, 0)), 1);
-      x = *loc;
-      code = GET_CODE (x);
+        validate_change (object, loc,
+                         gen_rtx_fmt_ee (GET_RTX_CLASS (code) == 'c' ? code
+                                         : swap_condition (code),
+                                         GET_MODE (x), XEXP (x, 1),
+                                         XEXP (x, 0)), 1);
+        x = *loc;
+        code = GET_CODE (x);
     }
-
-  switch (code)
+    
+    switch (code)
     {
-    case PLUS:
-      /* If we have a PLUS whose second operand is now a CONST_INT, use
-         plus_constant to try to simplify it.
-         ??? We may want later to remove this, once simplification is
-         separated from this function.  */
-      if (GET_CODE (XEXP (x, 1)) == CONST_INT)
-	validate_change (object, loc,
-			 simplify_gen_binary
-			 (PLUS, GET_MODE (x), XEXP (x, 0), XEXP (x, 1)), 1);
-      break;
-    case MINUS:
-      if (GET_CODE (XEXP (x, 1)) == CONST_INT
-	  || GET_CODE (XEXP (x, 1)) == CONST_DOUBLE)
-	validate_change (object, loc,
-			 simplify_gen_binary
-			 (PLUS, GET_MODE (x), XEXP (x, 0),
-			  simplify_gen_unary (NEG,
-					      GET_MODE (x), XEXP (x, 1),
-					      GET_MODE (x))), 1);
-      break;
-    case ZERO_EXTEND:
-    case SIGN_EXTEND:
-      if (GET_MODE (XEXP (x, 0)) == VOIDmode)
-	{
-	  new = simplify_gen_unary (code, GET_MODE (x), XEXP (x, 0),
-				    op0_mode);
-	  /* If any of the above failed, substitute in something that
-	     we know won't be recognized.  */
-	  if (!new)
-	    new = gen_rtx_CLOBBER (GET_MODE (x), const0_rtx);
-	  validate_change (object, loc, new, 1);
-	}
-      break;
-    case SUBREG:
-      /* All subregs possible to simplify should be simplified.  */
-      new = simplify_subreg (GET_MODE (x), SUBREG_REG (x), op0_mode,
-			     SUBREG_BYTE (x));
-
-      /* Subregs of VOIDmode operands are incorrect.  */
-      if (!new && GET_MODE (SUBREG_REG (x)) == VOIDmode)
-	new = gen_rtx_CLOBBER (GET_MODE (x), const0_rtx);
-      if (new)
-	validate_change (object, loc, new, 1);
-      break;
-    case ZERO_EXTRACT:
-    case SIGN_EXTRACT:
-      /* If we are replacing a register with memory, try to change the memory
-         to be the mode required for memory in extract operations (this isn't
-         likely to be an insertion operation; if it was, nothing bad will
-         happen, we might just fail in some cases).  */
-
-      if (GET_CODE (XEXP (x, 0)) == MEM
-	  && GET_CODE (XEXP (x, 1)) == CONST_INT
-	  && GET_CODE (XEXP (x, 2)) == CONST_INT
-	  && !mode_dependent_address_p (XEXP (XEXP (x, 0), 0))
-	  && !MEM_VOLATILE_P (XEXP (x, 0)))
-	{
-	  enum machine_mode wanted_mode = VOIDmode;
-	  enum machine_mode is_mode = GET_MODE (XEXP (x, 0));
-	  int pos = INTVAL (XEXP (x, 2));
-
-	  if (GET_CODE (x) == ZERO_EXTRACT)
-	    {
-	      enum machine_mode new_mode
-		= mode_for_extraction (EP_extzv, 1);
-	      if (new_mode != MAX_MACHINE_MODE)
-		wanted_mode = new_mode;
-	    }
-	  else if (GET_CODE (x) == SIGN_EXTRACT)
-	    {
-	      enum machine_mode new_mode
-		= mode_for_extraction (EP_extv, 1);
-	      if (new_mode != MAX_MACHINE_MODE)
-		wanted_mode = new_mode;
-	    }
-
-	  /* If we have a narrower mode, we can do something.  */
-	  if (wanted_mode != VOIDmode
-	      && GET_MODE_SIZE (wanted_mode) < GET_MODE_SIZE (is_mode))
-	    {
-	      int offset = pos / BITS_PER_UNIT;
-	      rtx newmem;
-
-	      /* If the bytes and bits are counted differently, we
-	         must adjust the offset.  */
-	      if (BYTES_BIG_ENDIAN != BITS_BIG_ENDIAN)
-		offset =
-		  (GET_MODE_SIZE (is_mode) - GET_MODE_SIZE (wanted_mode) -
-		   offset);
-
-	      pos %= GET_MODE_BITSIZE (wanted_mode);
-
-	      newmem = adjust_address_nv (XEXP (x, 0), wanted_mode, offset);
-
-	      validate_change (object, &XEXP (x, 2), GEN_INT (pos), 1);
-	      validate_change (object, &XEXP (x, 0), newmem, 1);
-	    }
-	}
-
-      break;
-
-    default:
-      break;
+        case PLUS:
+            /* If we have a PLUS whose second operand is now a CONST_INT, use
+             plus_constant to try to simplify it.
+             ??? We may want later to remove this, once simplification is
+             separated from this function.  */
+            if (GET_CODE (XEXP (x, 1)) == CONST_INT)
+                validate_change (object, loc,
+                                 simplify_gen_binary
+                                 (PLUS, GET_MODE (x), XEXP (x, 0), XEXP (x, 1)), 1);
+            break;
+        case MINUS:
+            if (GET_CODE (XEXP (x, 1)) == CONST_INT
+                || GET_CODE (XEXP (x, 1)) == CONST_DOUBLE)
+                validate_change (object, loc,
+                                 simplify_gen_binary
+                                 (PLUS, GET_MODE (x), XEXP (x, 0),
+                                  simplify_gen_unary (NEG,
+                                                      GET_MODE (x), XEXP (x, 1),
+                                                      GET_MODE (x))), 1);
+            break;
+        case ZERO_EXTEND:
+        case SIGN_EXTEND:
+            if (GET_MODE (XEXP (x, 0)) == VOIDmode)
+            {
+                new = simplify_gen_unary (code, GET_MODE (x), XEXP (x, 0),
+                                          op0_mode);
+                /* If any of the above failed, substitute in something that
+                 we know won't be recognized.  */
+                if (!new)
+                    new = gen_rtx_CLOBBER (GET_MODE (x), const0_rtx);
+                validate_change (object, loc, new, 1);
+            }
+            break;
+        case SUBREG:
+            /* All subregs possible to simplify should be simplified.  */
+            new = simplify_subreg (GET_MODE (x), SUBREG_REG (x), op0_mode,
+                                   SUBREG_BYTE (x));
+            
+            /* Subregs of VOIDmode operands are incorrect.  */
+            if (!new && GET_MODE (SUBREG_REG (x)) == VOIDmode)
+                new = gen_rtx_CLOBBER (GET_MODE (x), const0_rtx);
+            if (new)
+                validate_change (object, loc, new, 1);
+            break;
+        case ZERO_EXTRACT:
+        case SIGN_EXTRACT:
+            /* If we are replacing a register with memory, try to change the memory
+             to be the mode required for memory in extract operations (this isn't
+             likely to be an insertion operation; if it was, nothing bad will
+             happen, we might just fail in some cases).  */
+            
+            if (GET_CODE (XEXP (x, 0)) == MEM
+                && GET_CODE (XEXP (x, 1)) == CONST_INT
+                && GET_CODE (XEXP (x, 2)) == CONST_INT
+                && !mode_dependent_address_p (XEXP (XEXP (x, 0), 0))
+                && !MEM_VOLATILE_P (XEXP (x, 0)))
+            {
+                enum machine_mode wanted_mode = VOIDmode;
+                enum machine_mode is_mode = GET_MODE (XEXP (x, 0));
+                int pos = INTVAL (XEXP (x, 2));
+                
+                if (GET_CODE (x) == ZERO_EXTRACT)
+                {
+                    enum machine_mode new_mode
+                    = mode_for_extraction (EP_extzv, 1);
+                    if (new_mode != MAX_MACHINE_MODE)
+                        wanted_mode = new_mode;
+                }
+                else if (GET_CODE (x) == SIGN_EXTRACT)
+                {
+                    enum machine_mode new_mode
+                    = mode_for_extraction (EP_extv, 1);
+                    if (new_mode != MAX_MACHINE_MODE)
+                        wanted_mode = new_mode;
+                }
+                
+                /* If we have a narrower mode, we can do something.  */
+                if (wanted_mode != VOIDmode
+                    && GET_MODE_SIZE (wanted_mode) < GET_MODE_SIZE (is_mode))
+                {
+                    int offset = pos / BITS_PER_UNIT;
+                    rtx newmem;
+                    
+                    /* If the bytes and bits are counted differently, we
+                     must adjust the offset.  */
+                    if (BYTES_BIG_ENDIAN != BITS_BIG_ENDIAN)
+                        offset =
+                        (GET_MODE_SIZE (is_mode) - GET_MODE_SIZE (wanted_mode) -
+                         offset);
+                    
+                    pos %= GET_MODE_BITSIZE (wanted_mode);
+                    
+                    newmem = adjust_address_nv (XEXP (x, 0), wanted_mode, offset);
+                    
+                    validate_change (object, &XEXP (x, 2), GEN_INT (pos), 1);
+                    validate_change (object, &XEXP (x, 0), newmem, 1);
+                }
+            }
+            
+            break;
+            
+        default:
+            break;
     }
 }
 
 /* Try replacing every occurrence of FROM in subexpression LOC of INSN
-   with TO.  After all changes have been made, validate by seeing
-   if INSN is still valid.  */
+ with TO.  After all changes have been made, validate by seeing
+ if INSN is still valid.  */
 
 int
 validate_replace_rtx_subexp (from, to, insn, loc)
-     rtx from, to, insn, *loc;
+rtx from, to, insn, *loc;
 {
-  validate_replace_rtx_1 (loc, from, to, insn);
-  return apply_change_group ();
+    validate_replace_rtx_1 (loc, from, to, insn);
+    return apply_change_group ();
 }
 
 /* Try replacing every occurrence of FROM in INSN with TO.  After all
-   changes have been made, validate by seeing if INSN is still valid.  */
+ changes have been made, validate by seeing if INSN is still valid.  */
 
 int
 validate_replace_rtx (from, to, insn)
-     rtx from, to, insn;
+rtx from, to, insn;
 {
-  validate_replace_rtx_1 (&PATTERN (insn), from, to, insn);
-  return apply_change_group ();
+    validate_replace_rtx_1 (&PATTERN (insn), from, to, insn);
+    return apply_change_group ();
 }
 
 /* Try replacing every occurrence of FROM in INSN with TO.  */
 
 void
 validate_replace_rtx_group (from, to, insn)
-     rtx from, to, insn;
+rtx from, to, insn;
 {
-  validate_replace_rtx_1 (&PATTERN (insn), from, to, insn);
+    validate_replace_rtx_1 (&PATTERN (insn), from, to, insn);
 }
 
 /* Function called by note_uses to replace used subexpressions.  */
 struct validate_replace_src_data
 {
-  rtx from;			/* Old RTX */
-  rtx to;			/* New RTX */
-  rtx insn;			/* Insn in which substitution is occurring.  */
+    rtx from;			/* Old RTX */
+    rtx to;			/* New RTX */
+    rtx insn;			/* Insn in which substitution is occurring.  */
 };
 
 static void
 validate_replace_src_1 (x, data)
-     rtx *x;
-     void *data;
+rtx *x;
+void *data;
 {
-  struct validate_replace_src_data *d
+    struct validate_replace_src_data *d
     = (struct validate_replace_src_data *) data;
-
-  validate_replace_rtx_1 (x, d->from, d->to, d->insn);
+    
+    validate_replace_rtx_1 (x, d->from, d->to, d->insn);
 }
 
 /* Try replacing every occurrence of FROM in INSN with TO, avoiding
-   SET_DESTs.  After all changes have been made, validate by seeing if
-   INSN is still valid.  */
+ SET_DESTs.  After all changes have been made, validate by seeing if
+ INSN is still valid.  */
 
 int
 validate_replace_src (from, to, insn)
-     rtx from, to, insn;
+rtx from, to, insn;
 {
-  struct validate_replace_src_data d;
-
-  d.from = from;
-  d.to = to;
-  d.insn = insn;
-  note_uses (&PATTERN (insn), validate_replace_src_1, &d);
-  return apply_change_group ();
+    struct validate_replace_src_data d;
+    
+    d.from = from;
+    d.to = to;
+    d.insn = insn;
+    note_uses (&PATTERN (insn), validate_replace_src_1, &d);
+    return apply_change_group ();
 }
 
 #ifdef HAVE_cc0
 /* Return 1 if the insn using CC0 set by INSN does not contain
-   any ordered tests applied to the condition codes.
-   EQ and NE tests do not count.  */
+ any ordered tests applied to the condition codes.
+ EQ and NE tests do not count.  */
 
 int
 next_insn_tests_no_inequality (insn)
-     rtx insn;
+rtx insn;
 {
-  rtx next = next_cc0_user (insn);
-
-  /* If there is no next insn, we have to take the conservative choice.  */
-  if (next == 0)
-    return 0;
-
-  return ((GET_CODE (next) == JUMP_INSN
-	   || GET_CODE (next) == INSN
-	   || GET_CODE (next) == CALL_INSN)
-	  && ! inequality_comparisons_p (PATTERN (next)));
+    rtx next = next_cc0_user (insn);
+    
+    /* If there is no next insn, we have to take the conservative choice.  */
+    if (next == 0)
+        return 0;
+    
+    return ((GET_CODE (next) == JUMP_INSN
+             || GET_CODE (next) == INSN
+             || GET_CODE (next) == CALL_INSN)
+            && ! inequality_comparisons_p (PATTERN (next)));
 }
 
 #if 0  /* This is useless since the insn that sets the cc's
-	  must be followed immediately by the use of them.  */
+must be followed immediately by the use of them.  */
 /* Return 1 if the CC value set up by INSN is not used.  */
 
 int
 next_insns_test_no_inequality (insn)
-     rtx insn;
+rtx insn;
 {
-  rtx next = NEXT_INSN (insn);
-
-  for (; next != 0; next = NEXT_INSN (next))
+    rtx next = NEXT_INSN (insn);
+    
+    for (; next != 0; next = NEXT_INSN (next))
     {
-      if (GET_CODE (next) == CODE_LABEL
-	  || GET_CODE (next) == BARRIER)
-	return 1;
-      if (GET_CODE (next) == NOTE)
-	continue;
-      if (inequality_comparisons_p (PATTERN (next)))
-	return 0;
-      if (sets_cc0_p (PATTERN (next)) == 1)
-	return 1;
-      if (! reg_mentioned_p (cc0_rtx, PATTERN (next)))
-	return 1;
+        if (GET_CODE (next) == CODE_LABEL
+            || GET_CODE (next) == BARRIER)
+            return 1;
+        if (GET_CODE (next) == NOTE)
+            continue;
+        if (inequality_comparisons_p (PATTERN (next)))
+            return 0;
+        if (sets_cc0_p (PATTERN (next)) == 1)
+            return 1;
+        if (! reg_mentioned_p (cc0_rtx, PATTERN (next)))
+            return 1;
     }
-  return 1;
+    return 1;
 }
 #endif
 #endif
 
 /* This is used by find_single_use to locate an rtx that contains exactly one
-   use of DEST, which is typically either a REG or CC0.  It returns a
-   pointer to the innermost rtx expression containing DEST.  Appearances of
-   DEST that are being used to totally replace it are not counted.  */
+ use of DEST, which is typically either a REG or CC0.  It returns a
+ pointer to the innermost rtx expression containing DEST.  Appearances of
+ DEST that are being used to totally replace it are not counted.  */
 
 static rtx *
 find_single_use_1 (dest, loc)
-     rtx dest;
-     rtx *loc;
+rtx dest;
+rtx *loc;
 {
-  rtx x = *loc;
-  enum rtx_code code = GET_CODE (x);
-  rtx *result = 0;
-  rtx *this_result;
-  int i;
-  const char *fmt;
-
-  switch (code)
+    rtx x = *loc;
+    enum rtx_code code = GET_CODE (x);
+    rtx *result = 0;
+    rtx *this_result;
+    int i;
+    const char *fmt;
+    
+    switch (code)
     {
-    case CONST_INT:
-    case CONST:
-    case LABEL_REF:
-    case SYMBOL_REF:
-    case CONST_DOUBLE:
-    case CONST_VECTOR:
-    case CLOBBER:
-      return 0;
-
-    case SET:
-      /* If the destination is anything other than CC0, PC, a REG or a SUBREG
-	 of a REG that occupies all of the REG, the insn uses DEST if
-	 it is mentioned in the destination or the source.  Otherwise, we
-	 need just check the source.  */
-      if (GET_CODE (SET_DEST (x)) != CC0
-	  && GET_CODE (SET_DEST (x)) != PC
-	  && GET_CODE (SET_DEST (x)) != REG
-	  && ! (GET_CODE (SET_DEST (x)) == SUBREG
-		&& GET_CODE (SUBREG_REG (SET_DEST (x))) == REG
-		&& (((GET_MODE_SIZE (GET_MODE (SUBREG_REG (SET_DEST (x))))
-		      + (UNITS_PER_WORD - 1)) / UNITS_PER_WORD)
-		    == ((GET_MODE_SIZE (GET_MODE (SET_DEST (x)))
-			 + (UNITS_PER_WORD - 1)) / UNITS_PER_WORD))))
-	break;
-
-      return find_single_use_1 (dest, &SET_SRC (x));
-
-    case MEM:
-    case SUBREG:
-      return find_single_use_1 (dest, &XEXP (x, 0));
-      
-    default:
-      break;
+        case CONST_INT:
+        case CONST:
+        case LABEL_REF:
+        case SYMBOL_REF:
+        case CONST_DOUBLE:
+        case CONST_VECTOR:
+        case CLOBBER:
+            return 0;
+            
+        case SET:
+            /* If the destination is anything other than CC0, PC, a REG or a SUBREG
+             of a REG that occupies all of the REG, the insn uses DEST if
+             it is mentioned in the destination or the source.  Otherwise, we
+             need just check the source.  */
+            if (GET_CODE (SET_DEST (x)) != CC0
+                && GET_CODE (SET_DEST (x)) != PC
+                && GET_CODE (SET_DEST (x)) != REG
+                && ! (GET_CODE (SET_DEST (x)) == SUBREG
+                      && GET_CODE (SUBREG_REG (SET_DEST (x))) == REG
+                      && (((GET_MODE_SIZE (GET_MODE (SUBREG_REG (SET_DEST (x))))
+                            + (UNITS_PER_WORD - 1)) / UNITS_PER_WORD)
+                          == ((GET_MODE_SIZE (GET_MODE (SET_DEST (x)))
+                               + (UNITS_PER_WORD - 1)) / UNITS_PER_WORD))))
+                break;
+            
+            return find_single_use_1 (dest, &SET_SRC (x));
+            
+        case MEM:
+        case SUBREG:
+            return find_single_use_1 (dest, &XEXP (x, 0));
+            
+        default:
+            break;
     }
-
-  /* If it wasn't one of the common cases above, check each expression and
+    
+    /* If it wasn't one of the common cases above, check each expression and
      vector of this code.  Look for a unique usage of DEST.  */
-
-  fmt = GET_RTX_FORMAT (code);
-  for (i = GET_RTX_LENGTH (code) - 1; i >= 0; i--)
+    
+    fmt = GET_RTX_FORMAT (code);
+    for (i = GET_RTX_LENGTH (code) - 1; i >= 0; i--)
     {
-      if (fmt[i] == 'e')
-	{
-	  if (dest == XEXP (x, i)
-	      || (GET_CODE (dest) == REG && GET_CODE (XEXP (x, i)) == REG
-		  && REGNO (dest) == REGNO (XEXP (x, i))))
-	    this_result = loc;
-	  else
-	    this_result = find_single_use_1 (dest, &XEXP (x, i));
-
-	  if (result == 0)
-	    result = this_result;
-	  else if (this_result)
-	    /* Duplicate usage.  */
-	    return 0;
-	}
-      else if (fmt[i] == 'E')
-	{
-	  int j;
-
-	  for (j = XVECLEN (x, i) - 1; j >= 0; j--)
-	    {
-	      if (XVECEXP (x, i, j) == dest
-		  || (GET_CODE (dest) == REG
-		      && GET_CODE (XVECEXP (x, i, j)) == REG
-		      && REGNO (XVECEXP (x, i, j)) == REGNO (dest)))
-		this_result = loc;
-	      else
-		this_result = find_single_use_1 (dest, &XVECEXP (x, i, j));
-
-	      if (result == 0)
-		result = this_result;
-	      else if (this_result)
-		return 0;
-	    }
-	}
+        if (fmt[i] == 'e')
+        {
+            if (dest == XEXP (x, i)
+                || (GET_CODE (dest) == REG && GET_CODE (XEXP (x, i)) == REG
+                    && REGNO (dest) == REGNO (XEXP (x, i))))
+                this_result = loc;
+            else
+                this_result = find_single_use_1 (dest, &XEXP (x, i));
+            
+            if (result == 0)
+                result = this_result;
+            else if (this_result)
+            /* Duplicate usage.  */
+                return 0;
+        }
+        else if (fmt[i] == 'E')
+        {
+            int j;
+            
+            for (j = XVECLEN (x, i) - 1; j >= 0; j--)
+            {
+                if (XVECEXP (x, i, j) == dest
+                    || (GET_CODE (dest) == REG
+                        && GET_CODE (XVECEXP (x, i, j)) == REG
+                        && REGNO (XVECEXP (x, i, j)) == REGNO (dest)))
+                    this_result = loc;
+                else
+                    this_result = find_single_use_1 (dest, &XVECEXP (x, i, j));
+                
+                if (result == 0)
+                    result = this_result;
+                else if (this_result)
+                    return 0;
+            }
+        }
     }
-
-  return result;
+    
+    return result;
 }
 
 /* See if DEST, produced in INSN, is used only a single time in the
-   sequel.  If so, return a pointer to the innermost rtx expression in which
-   it is used.
-
-   If PLOC is non-zero, *PLOC is set to the insn containing the single use.
-
-   This routine will return usually zero either before flow is called (because
-   there will be no LOG_LINKS notes) or after reload (because the REG_DEAD
-   note can't be trusted).
-
-   If DEST is cc0_rtx, we look only at the next insn.  In that case, we don't
-   care about REG_DEAD notes or LOG_LINKS.
-
-   Otherwise, we find the single use by finding an insn that has a
-   LOG_LINKS pointing at INSN and has a REG_DEAD note for DEST.  If DEST is
-   only referenced once in that insn, we know that it must be the first
-   and last insn referencing DEST.  */
+ sequel.  If so, return a pointer to the innermost rtx expression in which
+ it is used.
+ 
+ If PLOC is non-zero, *PLOC is set to the insn containing the single use.
+ 
+ This routine will return usually zero either before flow is called (because
+ there will be no LOG_LINKS notes) or after reload (because the REG_DEAD
+ note can't be trusted).
+ 
+ If DEST is cc0_rtx, we look only at the next insn.  In that case, we don't
+ care about REG_DEAD notes or LOG_LINKS.
+ 
+ Otherwise, we find the single use by finding an insn that has a
+ LOG_LINKS pointing at INSN and has a REG_DEAD note for DEST.  If DEST is
+ only referenced once in that insn, we know that it must be the first
+ and last insn referencing DEST.  */
 
 rtx *
 find_single_use (dest, insn, ploc)
-     rtx dest;
-     rtx insn;
-     rtx *ploc;
+rtx dest;
+rtx insn;
+rtx *ploc;
 {
-  rtx next;
-  rtx *result;
-  rtx link;
-
+    rtx next;
+    rtx *result;
+    rtx link;
+    
 #ifdef HAVE_cc0
-  if (dest == cc0_rtx)
+    if (dest == cc0_rtx)
     {
-      next = NEXT_INSN (insn);
-      if (next == 0
-	  || (GET_CODE (next) != INSN && GET_CODE (next) != JUMP_INSN))
-	return 0;
-
-      result = find_single_use_1 (dest, &PATTERN (next));
-      if (result && ploc)
-	*ploc = next;
-      return result;
+        next = NEXT_INSN (insn);
+        if (next == 0
+            || (GET_CODE (next) != INSN && GET_CODE (next) != JUMP_INSN))
+            return 0;
+        
+        result = find_single_use_1 (dest, &PATTERN (next));
+        if (result && ploc)
+            *ploc = next;
+        return result;
     }
 #endif
-
-  if (reload_completed || reload_in_progress || GET_CODE (dest) != REG)
-    return 0;
-
-  for (next = next_nonnote_insn (insn);
-       next != 0 && GET_CODE (next) != CODE_LABEL;
-       next = next_nonnote_insn (next))
+    
+    if (reload_completed || reload_in_progress || GET_CODE (dest) != REG)
+        return 0;
+    
+    for (next = next_nonnote_insn (insn);
+         next != 0 && GET_CODE (next) != CODE_LABEL;
+         next = next_nonnote_insn (next))
     if (INSN_P (next) && dead_or_set_p (next, dest))
-      {
-	for (link = LOG_LINKS (next); link; link = XEXP (link, 1))
-	  if (XEXP (link, 0) == insn)
-	    break;
-
-	if (link)
-	  {
-	    result = find_single_use_1 (dest, &PATTERN (next));
-	    if (ploc)
-	      *ploc = next;
-	    return result;
-	  }
-      }
-
-  return 0;
+    {
+        for (link = LOG_LINKS (next); link; link = XEXP (link, 1))
+        if (XEXP (link, 0) == insn)
+            break;
+        
+        if (link)
+        {
+            result = find_single_use_1 (dest, &PATTERN (next));
+            if (ploc)
+                *ploc = next;
+            return result;
+        }
+    }
+    
+    return 0;
 }
 
 /* Return 1 if OP is a valid general operand for machine mode MODE.
-   This is either a register reference, a memory reference,
-   or a constant.  In the case of a memory reference, the address
-   is checked for general validity for the target machine.
-
-   Register and memory references must have mode MODE in order to be valid,
-   but some constants have no machine mode and are valid for any mode.
-
-   If MODE is VOIDmode, OP is checked for validity for whatever mode
-   it has.
-
-   The main use of this function is as a predicate in match_operand
-   expressions in the machine description.
-
-   For an explanation of this function's behavior for registers of
-   class NO_REGS, see the comment for `register_operand'.  */
+ This is either a register reference, a memory reference,
+ or a constant.  In the case of a memory reference, the address
+ is checked for general validity for the target machine.
+ 
+ Register and memory references must have mode MODE in order to be valid,
+ but some constants have no machine mode and are valid for any mode.
+ 
+ If MODE is VOIDmode, OP is checked for validity for whatever mode
+ it has.
+ 
+ The main use of this function is as a predicate in match_operand
+ expressions in the machine description.
+ 
+ For an explanation of this function's behavior for registers of
+ class NO_REGS, see the comment for `register_operand'.  */
 
 int
 general_operand (op, mode)
-     rtx op;
-     enum machine_mode mode;
+rtx op;
+enum machine_mode mode;
 {
-  enum rtx_code code = GET_CODE (op);
-
-  if (mode == VOIDmode)
-    mode = GET_MODE (op);
-
-  /* Don't accept CONST_INT or anything similar
+    enum rtx_code code = GET_CODE (op);
+    
+    if (mode == VOIDmode)
+        mode = GET_MODE (op);
+    
+    /* Don't accept CONST_INT or anything similar
      if the caller wants something floating.  */
-  if (GET_MODE (op) == VOIDmode && mode != VOIDmode
-      && GET_MODE_CLASS (mode) != MODE_INT
-      && GET_MODE_CLASS (mode) != MODE_PARTIAL_INT)
-    return 0;
-
-  if (GET_CODE (op) == CONST_INT
-      && trunc_int_for_mode (INTVAL (op), mode) != INTVAL (op))
-    return 0;
-
-  if (CONSTANT_P (op))
-    return ((GET_MODE (op) == VOIDmode || GET_MODE (op) == mode
-	     || mode == VOIDmode)
+    if (GET_MODE (op) == VOIDmode && mode != VOIDmode
+        && GET_MODE_CLASS (mode) != MODE_INT
+        && GET_MODE_CLASS (mode) != MODE_PARTIAL_INT)
+        return 0;
+    
+    if (GET_CODE (op) == CONST_INT
+        && trunc_int_for_mode (INTVAL (op), mode) != INTVAL (op))
+        return 0;
+    
+    if (CONSTANT_P (op))
+        return ((GET_MODE (op) == VOIDmode || GET_MODE (op) == mode
+                 || mode == VOIDmode)
 #ifdef LEGITIMATE_PIC_OPERAND_P
-	    && (! flag_pic || LEGITIMATE_PIC_OPERAND_P (op))
+                && (! flag_pic || LEGITIMATE_PIC_OPERAND_P (op))
 #endif
-	    && LEGITIMATE_CONSTANT_P (op));
-
-  /* Except for certain constants with VOIDmode, already checked for,
+                && LEGITIMATE_CONSTANT_P (op));
+    
+    /* Except for certain constants with VOIDmode, already checked for,
      OP's mode must match MODE if MODE specifies a mode.  */
-
-  if (GET_MODE (op) != mode)
-    return 0;
-
-  if (code == SUBREG)
+    
+    if (GET_MODE (op) != mode)
+        return 0;
+    
+    if (code == SUBREG)
     {
-      rtx sub = SUBREG_REG (op);
-
+        rtx sub = SUBREG_REG (op);
+        
 #ifdef INSN_SCHEDULING
-      /* On machines that have insn scheduling, we want all memory
-	 reference to be explicit, so outlaw paradoxical SUBREGs.  */
-      if (GET_CODE (sub) == MEM
-	  && GET_MODE_SIZE (mode) > GET_MODE_SIZE (GET_MODE (sub)))
-	return 0;
+        /* On machines that have insn scheduling, we want all memory
+         reference to be explicit, so outlaw paradoxical SUBREGs.  */
+        if (GET_CODE (sub) == MEM
+            && GET_MODE_SIZE (mode) > GET_MODE_SIZE (GET_MODE (sub)))
+            return 0;
 #endif
-      /* Avoid memories with nonzero SUBREG_BYTE, as offsetting the memory
+        /* Avoid memories with nonzero SUBREG_BYTE, as offsetting the memory
          may result in incorrect reference.  We should simplify all valid
          subregs of MEM anyway.  But allow this after reload because we
-	 might be called from cleanup_subreg_operands. 
-
-	 ??? This is a kludge.  */
-      if (!reload_completed && SUBREG_BYTE (op) != 0
-	  && GET_CODE (sub) == MEM)
-        return 0;
-
-      /* FLOAT_MODE subregs can't be paradoxical.  Combine will occasionally
-	 create such rtl, and we must reject it.  */
-      if (GET_MODE_CLASS (GET_MODE (op)) == MODE_FLOAT
-	  && GET_MODE_SIZE (GET_MODE (op)) > GET_MODE_SIZE (GET_MODE (sub)))
-	return 0;
-
-      op = sub;
-      code = GET_CODE (op);
+         might be called from cleanup_subreg_operands.
+         
+         ??? This is a kludge.  */
+        if (!reload_completed && SUBREG_BYTE (op) != 0
+            && GET_CODE (sub) == MEM)
+            return 0;
+        
+        /* FLOAT_MODE subregs can't be paradoxical.  Combine will occasionally
+         create such rtl, and we must reject it.  */
+        if (GET_MODE_CLASS (GET_MODE (op)) == MODE_FLOAT
+            && GET_MODE_SIZE (GET_MODE (op)) > GET_MODE_SIZE (GET_MODE (sub)))
+            return 0;
+        
+        op = sub;
+        code = GET_CODE (op);
     }
-
-  if (code == REG)
+    
+    if (code == REG)
     /* A register whose class is NO_REGS is not a general operand.  */
-    return (REGNO (op) >= FIRST_PSEUDO_REGISTER
-	    || REGNO_REG_CLASS (REGNO (op)) != NO_REGS);
-
-  if (code == MEM)
+        return (REGNO (op) >= FIRST_PSEUDO_REGISTER
+                || REGNO_REG_CLASS (REGNO (op)) != NO_REGS);
+    
+    if (code == MEM)
     {
-      rtx y = XEXP (op, 0);
-
-      if (! volatile_ok && MEM_VOLATILE_P (op))
-	return 0;
-
-      if (GET_CODE (y) == ADDRESSOF)
-	return 1;
-
-      /* Use the mem's mode, since it will be reloaded thus.  */
-      mode = GET_MODE (op);
-      GO_IF_LEGITIMATE_ADDRESS (mode, y, win);
+        rtx y = XEXP (op, 0);
+        
+        if (! volatile_ok && MEM_VOLATILE_P (op))
+            return 0;
+        
+        if (GET_CODE (y) == ADDRESSOF)
+            return 1;
+        
+        /* Use the mem's mode, since it will be reloaded thus.  */
+        mode = GET_MODE (op);
+        GO_IF_LEGITIMATE_ADDRESS (mode, y, win);
     }
-
-  /* Pretend this is an operand for now; we'll run force_operand
+    
+    /* Pretend this is an operand for now; we'll run force_operand
      on its replacement in fixup_var_refs_1.  */
-  if (code == ADDRESSOF)
+    if (code == ADDRESSOF)
+        return 1;
+    
+    return 0;
+    
+win:
     return 1;
-
-  return 0;
-
- win:
-  return 1;
 }
 
 /* Return 1 if OP is a valid memory address for a memory reference
-   of mode MODE.
-
-   The main use of this function is as a predicate in match_operand
-   expressions in the machine description.  */
+ of mode MODE.
+ 
+ The main use of this function is as a predicate in match_operand
+ expressions in the machine description.  */
 
 int
 address_operand (op, mode)
-     rtx op;
-     enum machine_mode mode;
+rtx op;
+enum machine_mode mode;
 {
-  return memory_address_p (mode, op);
+    return memory_address_p (mode, op);
 }
 
 /* Return 1 if OP is a register reference of mode MODE.
-   If MODE is VOIDmode, accept a register in any mode.
-
-   The main use of this function is as a predicate in match_operand
-   expressions in the machine description.
-
-   As a special exception, registers whose class is NO_REGS are
-   not accepted by `register_operand'.  The reason for this change
-   is to allow the representation of special architecture artifacts
-   (such as a condition code register) without extending the rtl
-   definitions.  Since registers of class NO_REGS cannot be used
-   as registers in any case where register classes are examined,
-   it is most consistent to keep this function from accepting them.  */
+ If MODE is VOIDmode, accept a register in any mode.
+ 
+ The main use of this function is as a predicate in match_operand
+ expressions in the machine description.
+ 
+ As a special exception, registers whose class is NO_REGS are
+ not accepted by `register_operand'.  The reason for this change
+ is to allow the representation of special architecture artifacts
+ (such as a condition code register) without extending the rtl
+ definitions.  Since registers of class NO_REGS cannot be used
+ as registers in any case where register classes are examined,
+ it is most consistent to keep this function from accepting them.  */
 
 int
 register_operand (op, mode)
-     rtx op;
-     enum machine_mode mode;
+rtx op;
+enum machine_mode mode;
 {
-  if (GET_MODE (op) != mode && mode != VOIDmode)
-    return 0;
-
-  if (GET_CODE (op) == SUBREG)
+    if (GET_MODE (op) != mode && mode != VOIDmode)
+        return 0;
+    
+    if (GET_CODE (op) == SUBREG)
     {
-      rtx sub = SUBREG_REG (op);
-
-      /* Before reload, we can allow (SUBREG (MEM...)) as a register operand
-	 because it is guaranteed to be reloaded into one.
-	 Just make sure the MEM is valid in itself.
-	 (Ideally, (SUBREG (MEM)...) should not exist after reload,
-	 but currently it does result from (SUBREG (REG)...) where the
-	 reg went on the stack.)  */
-      if (! reload_completed && GET_CODE (sub) == MEM)
-	return general_operand (op, mode);
-
+        rtx sub = SUBREG_REG (op);
+        
+        /* Before reload, we can allow (SUBREG (MEM...)) as a register operand
+         because it is guaranteed to be reloaded into one.
+         Just make sure the MEM is valid in itself.
+         (Ideally, (SUBREG (MEM)...) should not exist after reload,
+         but currently it does result from (SUBREG (REG)...) where the
+         reg went on the stack.)  */
+        if (! reload_completed && GET_CODE (sub) == MEM)
+            return general_operand (op, mode);
+        
 #ifdef CLASS_CANNOT_CHANGE_MODE
-      if (GET_CODE (sub) == REG
-	  && REGNO (sub) < FIRST_PSEUDO_REGISTER
-	  && (TEST_HARD_REG_BIT
-	      (reg_class_contents[(int) CLASS_CANNOT_CHANGE_MODE],
-	       REGNO (sub)))
-	  && CLASS_CANNOT_CHANGE_MODE_P (mode, GET_MODE (sub))
-	  && GET_MODE_CLASS (GET_MODE (sub)) != MODE_COMPLEX_INT
-	  && GET_MODE_CLASS (GET_MODE (sub)) != MODE_COMPLEX_FLOAT)
-	return 0;
+        if (GET_CODE (sub) == REG
+            && REGNO (sub) < FIRST_PSEUDO_REGISTER
+            && (TEST_HARD_REG_BIT
+                (reg_class_contents[(int) CLASS_CANNOT_CHANGE_MODE],
+                 REGNO (sub)))
+            && CLASS_CANNOT_CHANGE_MODE_P (mode, GET_MODE (sub))
+            && GET_MODE_CLASS (GET_MODE (sub)) != MODE_COMPLEX_INT
+            && GET_MODE_CLASS (GET_MODE (sub)) != MODE_COMPLEX_FLOAT)
+            return 0;
 #endif
-
-      /* FLOAT_MODE subregs can't be paradoxical.  Combine will occasionally
-	 create such rtl, and we must reject it.  */
-      if (GET_MODE_CLASS (GET_MODE (op)) == MODE_FLOAT
-	  && GET_MODE_SIZE (GET_MODE (op)) > GET_MODE_SIZE (GET_MODE (sub)))
-	return 0;
-
-      op = sub;
+        
+        /* FLOAT_MODE subregs can't be paradoxical.  Combine will occasionally
+         create such rtl, and we must reject it.  */
+        if (GET_MODE_CLASS (GET_MODE (op)) == MODE_FLOAT
+            && GET_MODE_SIZE (GET_MODE (op)) > GET_MODE_SIZE (GET_MODE (sub)))
+            return 0;
+        
+        op = sub;
     }
-
-  /* If we have an ADDRESSOF, consider it valid since it will be
+    
+    /* If we have an ADDRESSOF, consider it valid since it will be
      converted into something that will not be a MEM.  */
-  if (GET_CODE (op) == ADDRESSOF)
-    return 1;
-
-  /* We don't consider registers whose class is NO_REGS
+    if (GET_CODE (op) == ADDRESSOF)
+        return 1;
+    
+    /* We don't consider registers whose class is NO_REGS
      to be a register operand.  */
-  return (GET_CODE (op) == REG
-	  && (REGNO (op) >= FIRST_PSEUDO_REGISTER
-	      || REGNO_REG_CLASS (REGNO (op)) != NO_REGS));
+    return (GET_CODE (op) == REG
+            && (REGNO (op) >= FIRST_PSEUDO_REGISTER
+                || REGNO_REG_CLASS (REGNO (op)) != NO_REGS));
 }
 
 /* Return 1 for a register in Pmode; ignore the tested mode.  */
 
 int
 pmode_register_operand (op, mode)
-     rtx op;
-     enum machine_mode mode ATTRIBUTE_UNUSED;
+rtx op;
+enum machine_mode mode ATTRIBUTE_UNUSED;
 {
-  return register_operand (op, Pmode);
+    return register_operand (op, Pmode);
 }
 
 /* Return 1 if OP should match a MATCH_SCRATCH, i.e., if it is a SCRATCH
-   or a hard register.  */
+ or a hard register.  */
 
 int
 scratch_operand (op, mode)
-     rtx op;
-     enum machine_mode mode;
+rtx op;
+enum machine_mode mode;
 {
-  if (GET_MODE (op) != mode && mode != VOIDmode)
-    return 0;
-
-  return (GET_CODE (op) == SCRATCH
-	  || (GET_CODE (op) == REG
-	      && REGNO (op) < FIRST_PSEUDO_REGISTER));
+    if (GET_MODE (op) != mode && mode != VOIDmode)
+        return 0;
+    
+    return (GET_CODE (op) == SCRATCH
+            || (GET_CODE (op) == REG
+                && REGNO (op) < FIRST_PSEUDO_REGISTER));
 }
 
 /* Return 1 if OP is a valid immediate operand for mode MODE.
-
-   The main use of this function is as a predicate in match_operand
-   expressions in the machine description.  */
+ 
+ The main use of this function is as a predicate in match_operand
+ expressions in the machine description.  */
 
 int
 immediate_operand (op, mode)
-     rtx op;
-     enum machine_mode mode;
+rtx op;
+enum machine_mode mode;
 {
-  /* Don't accept CONST_INT or anything similar
+    /* Don't accept CONST_INT or anything similar
      if the caller wants something floating.  */
-  if (GET_MODE (op) == VOIDmode && mode != VOIDmode
-      && GET_MODE_CLASS (mode) != MODE_INT
-      && GET_MODE_CLASS (mode) != MODE_PARTIAL_INT)
-    return 0;
-
-  if (GET_CODE (op) == CONST_INT
-      && trunc_int_for_mode (INTVAL (op), mode) != INTVAL (op))
-    return 0;
-
-  /* Accept CONSTANT_P_RTX, since it will be gone by CSE1 and
+    if (GET_MODE (op) == VOIDmode && mode != VOIDmode
+        && GET_MODE_CLASS (mode) != MODE_INT
+        && GET_MODE_CLASS (mode) != MODE_PARTIAL_INT)
+        return 0;
+    
+    if (GET_CODE (op) == CONST_INT
+        && trunc_int_for_mode (INTVAL (op), mode) != INTVAL (op))
+        return 0;
+    
+    /* Accept CONSTANT_P_RTX, since it will be gone by CSE1 and
      result in 0/1.  It seems a safe assumption that this is
      in range for everyone.  */
-  if (GET_CODE (op) == CONSTANT_P_RTX)
-    return 1;
-
-  return (CONSTANT_P (op)
-	  && (GET_MODE (op) == mode || mode == VOIDmode
-	      || GET_MODE (op) == VOIDmode)
+    if (GET_CODE (op) == CONSTANT_P_RTX)
+        return 1;
+    
+    return (CONSTANT_P (op)
+            && (GET_MODE (op) == mode || mode == VOIDmode
+                || GET_MODE (op) == VOIDmode)
 #ifdef LEGITIMATE_PIC_OPERAND_P
-	  && (! flag_pic || LEGITIMATE_PIC_OPERAND_P (op))
+            && (! flag_pic || LEGITIMATE_PIC_OPERAND_P (op))
 #endif
-	  && LEGITIMATE_CONSTANT_P (op));
+            && LEGITIMATE_CONSTANT_P (op));
 }
 
 /* Returns 1 if OP is an operand that is a CONST_INT.  */
 
 int
 const_int_operand (op, mode)
-     rtx op;
-     enum machine_mode mode;
+rtx op;
+enum machine_mode mode;
 {
-  if (GET_CODE (op) != CONST_INT)
-    return 0;
-
-  if (mode != VOIDmode
-      && trunc_int_for_mode (INTVAL (op), mode) != INTVAL (op))
-    return 0;
-
-  return 1;
+    if (GET_CODE (op) != CONST_INT)
+        return 0;
+    
+    if (mode != VOIDmode
+        && trunc_int_for_mode (INTVAL (op), mode) != INTVAL (op))
+        return 0;
+    
+    return 1;
 }
 
 /* Returns 1 if OP is an operand that is a constant integer or constant
-   floating-point number.  */
+ floating-point number.  */
 
 int
 const_double_operand (op, mode)
-     rtx op;
-     enum machine_mode mode;
+rtx op;
+enum machine_mode mode;
 {
-  /* Don't accept CONST_INT or anything similar
+    /* Don't accept CONST_INT or anything similar
      if the caller wants something floating.  */
-  if (GET_MODE (op) == VOIDmode && mode != VOIDmode
-      && GET_MODE_CLASS (mode) != MODE_INT
-      && GET_MODE_CLASS (mode) != MODE_PARTIAL_INT)
-    return 0;
-
-  return ((GET_CODE (op) == CONST_DOUBLE || GET_CODE (op) == CONST_INT)
-	  && (mode == VOIDmode || GET_MODE (op) == mode
-	      || GET_MODE (op) == VOIDmode));
+    if (GET_MODE (op) == VOIDmode && mode != VOIDmode
+        && GET_MODE_CLASS (mode) != MODE_INT
+        && GET_MODE_CLASS (mode) != MODE_PARTIAL_INT)
+        return 0;
+    
+    return ((GET_CODE (op) == CONST_DOUBLE || GET_CODE (op) == CONST_INT)
+            && (mode == VOIDmode || GET_MODE (op) == mode
+                || GET_MODE (op) == VOIDmode));
 }
 
 /* Return 1 if OP is a general operand that is not an immediate operand.  */
 
 int
 nonimmediate_operand (op, mode)
-     rtx op;
-     enum machine_mode mode;
+rtx op;
+enum machine_mode mode;
 {
-  return (general_operand (op, mode) && ! CONSTANT_P (op));
+    return (general_operand (op, mode) && ! CONSTANT_P (op));
 }
 
 /* Return 1 if OP is a register reference or immediate value of mode MODE.  */
 
 int
 nonmemory_operand (op, mode)
-     rtx op;
-     enum machine_mode mode;
+rtx op;
+enum machine_mode mode;
 {
-  if (CONSTANT_P (op))
+    if (CONSTANT_P (op))
     {
-      /* Don't accept CONST_INT or anything similar
-	 if the caller wants something floating.  */
-      if (GET_MODE (op) == VOIDmode && mode != VOIDmode
-	  && GET_MODE_CLASS (mode) != MODE_INT
-	  && GET_MODE_CLASS (mode) != MODE_PARTIAL_INT)
-	return 0;
-
-      if (GET_CODE (op) == CONST_INT
-	  && trunc_int_for_mode (INTVAL (op), mode) != INTVAL (op))
-	return 0;
-
-      return ((GET_MODE (op) == VOIDmode || GET_MODE (op) == mode
-	       || mode == VOIDmode)
+        /* Don't accept CONST_INT or anything similar
+         if the caller wants something floating.  */
+        if (GET_MODE (op) == VOIDmode && mode != VOIDmode
+            && GET_MODE_CLASS (mode) != MODE_INT
+            && GET_MODE_CLASS (mode) != MODE_PARTIAL_INT)
+            return 0;
+        
+        if (GET_CODE (op) == CONST_INT
+            && trunc_int_for_mode (INTVAL (op), mode) != INTVAL (op))
+            return 0;
+        
+        return ((GET_MODE (op) == VOIDmode || GET_MODE (op) == mode
+                 || mode == VOIDmode)
 #ifdef LEGITIMATE_PIC_OPERAND_P
-	      && (! flag_pic || LEGITIMATE_PIC_OPERAND_P (op))
+                && (! flag_pic || LEGITIMATE_PIC_OPERAND_P (op))
 #endif
-	      && LEGITIMATE_CONSTANT_P (op));
+                && LEGITIMATE_CONSTANT_P (op));
     }
-
-  if (GET_MODE (op) != mode && mode != VOIDmode)
-    return 0;
-
-  if (GET_CODE (op) == SUBREG)
+    
+    if (GET_MODE (op) != mode && mode != VOIDmode)
+        return 0;
+    
+    if (GET_CODE (op) == SUBREG)
     {
-      /* Before reload, we can allow (SUBREG (MEM...)) as a register operand
-	 because it is guaranteed to be reloaded into one.
-	 Just make sure the MEM is valid in itself.
-	 (Ideally, (SUBREG (MEM)...) should not exist after reload,
-	 but currently it does result from (SUBREG (REG)...) where the
-	 reg went on the stack.)  */
-      if (! reload_completed && GET_CODE (SUBREG_REG (op)) == MEM)
-	return general_operand (op, mode);
-      op = SUBREG_REG (op);
+        /* Before reload, we can allow (SUBREG (MEM...)) as a register operand
+         because it is guaranteed to be reloaded into one.
+         Just make sure the MEM is valid in itself.
+         (Ideally, (SUBREG (MEM)...) should not exist after reload,
+         but currently it does result from (SUBREG (REG)...) where the
+         reg went on the stack.)  */
+        if (! reload_completed && GET_CODE (SUBREG_REG (op)) == MEM)
+            return general_operand (op, mode);
+        op = SUBREG_REG (op);
     }
-
-  /* We don't consider registers whose class is NO_REGS
+    
+    /* We don't consider registers whose class is NO_REGS
      to be a register operand.  */
-  return (GET_CODE (op) == REG
-	  && (REGNO (op) >= FIRST_PSEUDO_REGISTER
-	      || REGNO_REG_CLASS (REGNO (op)) != NO_REGS));
+    return (GET_CODE (op) == REG
+            && (REGNO (op) >= FIRST_PSEUDO_REGISTER
+                || REGNO_REG_CLASS (REGNO (op)) != NO_REGS));
 }
 
 /* Return 1 if OP is a valid operand that stands for pushing a
-   value of mode MODE onto the stack.
-
-   The main use of this function is as a predicate in match_operand
-   expressions in the machine description.  */
+ value of mode MODE onto the stack.
+ 
+ The main use of this function is as a predicate in match_operand
+ expressions in the machine description.  */
 
 int
 push_operand (op, mode)
-     rtx op;
-     enum machine_mode mode;
+rtx op;
+enum machine_mode mode;
 {
-  unsigned int rounded_size = GET_MODE_SIZE (mode);
-
+    unsigned int rounded_size = GET_MODE_SIZE (mode);
+    
 #ifdef PUSH_ROUNDING
-  rounded_size = PUSH_ROUNDING (rounded_size);
+    rounded_size = PUSH_ROUNDING (rounded_size);
 #endif
-
-  if (GET_CODE (op) != MEM)
-    return 0;
-
-  if (mode != VOIDmode && GET_MODE (op) != mode)
-    return 0;
-
-  op = XEXP (op, 0);
-
-  if (rounded_size == GET_MODE_SIZE (mode))
+    
+    if (GET_CODE (op) != MEM)
+        return 0;
+    
+    if (mode != VOIDmode && GET_MODE (op) != mode)
+        return 0;
+    
+    op = XEXP (op, 0);
+    
+    if (rounded_size == GET_MODE_SIZE (mode))
     {
-      if (GET_CODE (op) != STACK_PUSH_CODE)
-	return 0;
+        if (GET_CODE (op) != STACK_PUSH_CODE)
+            return 0;
     }
-  else
+    else
     {
-      if (GET_CODE (op) != PRE_MODIFY
-	  || GET_CODE (XEXP (op, 1)) != PLUS
-	  || XEXP (XEXP (op, 1), 0) != XEXP (op, 0)
-	  || GET_CODE (XEXP (XEXP (op, 1), 1)) != CONST_INT
+        if (GET_CODE (op) != PRE_MODIFY
+            || GET_CODE (XEXP (op, 1)) != PLUS
+            || XEXP (XEXP (op, 1), 0) != XEXP (op, 0)
+            || GET_CODE (XEXP (XEXP (op, 1), 1)) != CONST_INT
 #ifdef STACK_GROWS_DOWNWARD
-	  || INTVAL (XEXP (XEXP (op, 1), 1)) != - (int) rounded_size
+            || INTVAL (XEXP (XEXP (op, 1), 1)) != - (int) rounded_size
 #else
-	  || INTVAL (XEXP (XEXP (op, 1), 1)) != rounded_size
+            || INTVAL (XEXP (XEXP (op, 1), 1)) != rounded_size
 #endif
-	  )
-	return 0;
+            )
+            return 0;
     }
-
-  return XEXP (op, 0) == stack_pointer_rtx;
+    
+    return XEXP (op, 0) == stack_pointer_rtx;
 }
 
 /* Return 1 if OP is a valid operand that stands for popping a
-   value of mode MODE off the stack.
-
-   The main use of this function is as a predicate in match_operand
-   expressions in the machine description.  */
+ value of mode MODE off the stack.
+ 
+ The main use of this function is as a predicate in match_operand
+ expressions in the machine description.  */
 
 int
 pop_operand (op, mode)
-     rtx op;
-     enum machine_mode mode;
+rtx op;
+enum machine_mode mode;
 {
-  if (GET_CODE (op) != MEM)
-    return 0;
-
-  if (mode != VOIDmode && GET_MODE (op) != mode)
-    return 0;
-
-  op = XEXP (op, 0);
-
-  if (GET_CODE (op) != STACK_POP_CODE)
-    return 0;
-
-  return XEXP (op, 0) == stack_pointer_rtx;
+    if (GET_CODE (op) != MEM)
+        return 0;
+    
+    if (mode != VOIDmode && GET_MODE (op) != mode)
+        return 0;
+    
+    op = XEXP (op, 0);
+    
+    if (GET_CODE (op) != STACK_POP_CODE)
+        return 0;
+    
+    return XEXP (op, 0) == stack_pointer_rtx;
 }
 
 /* Return 1 if ADDR is a valid memory address for mode MODE.  */
 
 int
 memory_address_p (mode, addr)
-     enum machine_mode mode ATTRIBUTE_UNUSED;
-     rtx addr;
+enum machine_mode mode ATTRIBUTE_UNUSED;
+rtx addr;
 {
-  if (GET_CODE (addr) == ADDRESSOF)
+    if (GET_CODE (addr) == ADDRESSOF)
+        return 1;
+    
+    GO_IF_LEGITIMATE_ADDRESS (mode, addr, win);
+    return 0;
+    
+win:
     return 1;
-  
-  GO_IF_LEGITIMATE_ADDRESS (mode, addr, win);
-  return 0;
-
- win:
-  return 1;
 }
 
 /* Return 1 if OP is a valid memory reference with mode MODE,
-   including a valid address.
-
-   The main use of this function is as a predicate in match_operand
-   expressions in the machine description.  */
+ including a valid address.
+ 
+ The main use of this function is as a predicate in match_operand
+ expressions in the machine description.  */
 
 int
 memory_operand (op, mode)
-     rtx op;
-     enum machine_mode mode;
+rtx op;
+enum machine_mode mode;
 {
-  rtx inner;
-
-  if (! reload_completed)
+    rtx inner;
+    
+    if (! reload_completed)
     /* Note that no SUBREG is a memory operand before end of reload pass,
-       because (SUBREG (MEM...)) forces reloading into a register.  */
-    return GET_CODE (op) == MEM && general_operand (op, mode);
-
-  if (mode != VOIDmode && GET_MODE (op) != mode)
-    return 0;
-
-  inner = op;
-  if (GET_CODE (inner) == SUBREG)
-    inner = SUBREG_REG (inner);
-
-  return (GET_CODE (inner) == MEM && general_operand (op, mode));
+     because (SUBREG (MEM...)) forces reloading into a register.  */
+        return GET_CODE (op) == MEM && general_operand (op, mode);
+    
+    if (mode != VOIDmode && GET_MODE (op) != mode)
+        return 0;
+    
+    inner = op;
+    if (GET_CODE (inner) == SUBREG)
+        inner = SUBREG_REG (inner);
+    
+    return (GET_CODE (inner) == MEM && general_operand (op, mode));
 }
 
 /* Return 1 if OP is a valid indirect memory reference with mode MODE;
-   that is, a memory reference whose address is a general_operand.  */
+ that is, a memory reference whose address is a general_operand.  */
 
 int
 indirect_operand (op, mode)
-     rtx op;
-     enum machine_mode mode;
+rtx op;
+enum machine_mode mode;
 {
-  /* Before reload, a SUBREG isn't in memory (see memory_operand, above).  */
-  if (! reload_completed
-      && GET_CODE (op) == SUBREG && GET_CODE (SUBREG_REG (op)) == MEM)
+    /* Before reload, a SUBREG isn't in memory (see memory_operand, above).  */
+    if (! reload_completed
+        && GET_CODE (op) == SUBREG && GET_CODE (SUBREG_REG (op)) == MEM)
     {
-      int offset = SUBREG_BYTE (op);
-      rtx inner = SUBREG_REG (op);
-
-      if (mode != VOIDmode && GET_MODE (op) != mode)
-	return 0;
-
-      /* The only way that we can have a general_operand as the resulting
-	 address is if OFFSET is zero and the address already is an operand
-	 or if the address is (plus Y (const_int -OFFSET)) and Y is an
-	 operand.  */
-
-      return ((offset == 0 && general_operand (XEXP (inner, 0), Pmode))
-	      || (GET_CODE (XEXP (inner, 0)) == PLUS
-		  && GET_CODE (XEXP (XEXP (inner, 0), 1)) == CONST_INT
-		  && INTVAL (XEXP (XEXP (inner, 0), 1)) == -offset
-		  && general_operand (XEXP (XEXP (inner, 0), 0), Pmode)));
+        int offset = SUBREG_BYTE (op);
+        rtx inner = SUBREG_REG (op);
+        
+        if (mode != VOIDmode && GET_MODE (op) != mode)
+            return 0;
+        
+        /* The only way that we can have a general_operand as the resulting
+         address is if OFFSET is zero and the address already is an operand
+         or if the address is (plus Y (const_int -OFFSET)) and Y is an
+         operand.  */
+        
+        return ((offset == 0 && general_operand (XEXP (inner, 0), Pmode))
+                || (GET_CODE (XEXP (inner, 0)) == PLUS
+                    && GET_CODE (XEXP (XEXP (inner, 0), 1)) == CONST_INT
+                    && INTVAL (XEXP (XEXP (inner, 0), 1)) == -offset
+                    && general_operand (XEXP (XEXP (inner, 0), 0), Pmode)));
     }
-
-  return (GET_CODE (op) == MEM
-	  && memory_operand (op, mode)
-	  && general_operand (XEXP (op, 0), Pmode));
+    
+    return (GET_CODE (op) == MEM
+            && memory_operand (op, mode)
+            && general_operand (XEXP (op, 0), Pmode));
 }
 
 /* Return 1 if this is a comparison operator.  This allows the use of
-   MATCH_OPERATOR to recognize all the branch insns.  */
+ MATCH_OPERATOR to recognize all the branch insns.  */
 
 int
 comparison_operator (op, mode)
-    rtx op;
-    enum machine_mode mode;
+rtx op;
+enum machine_mode mode;
 {
-  return ((mode == VOIDmode || GET_MODE (op) == mode)
-	  && GET_RTX_CLASS (GET_CODE (op)) == '<');
+    return ((mode == VOIDmode || GET_MODE (op) == mode)
+            && GET_RTX_CLASS (GET_CODE (op)) == '<');
 }
 
 /* If BODY is an insn body that uses ASM_OPERANDS,
-   return the number of operands (both input and output) in the insn.
-   Otherwise return -1.  */
+ return the number of operands (both input and output) in the insn.
+ Otherwise return -1.  */
 
 int
 asm_noperands (body)
-     rtx body;
+rtx body;
 {
-  switch (GET_CODE (body))
+    switch (GET_CODE (body))
     {
-    case ASM_OPERANDS:
-      /* No output operands: return number of input operands.  */
-      return ASM_OPERANDS_INPUT_LENGTH (body);
-    case SET:
-      if (GET_CODE (SET_SRC (body)) == ASM_OPERANDS)
-	/* Single output operand: BODY is (set OUTPUT (asm_operands ...)).  */
-	return ASM_OPERANDS_INPUT_LENGTH (SET_SRC (body)) + 1;
-      else
-	return -1;
-    case PARALLEL:
-      if (GET_CODE (XVECEXP (body, 0, 0)) == SET
-	  && GET_CODE (SET_SRC (XVECEXP (body, 0, 0))) == ASM_OPERANDS)
-	{
-	  /* Multiple output operands, or 1 output plus some clobbers:
-	     body is [(set OUTPUT (asm_operands ...))... (clobber (reg ...))...].  */
-	  int i;
-	  int n_sets;
-
-	  /* Count backwards through CLOBBERs to determine number of SETs.  */
-	  for (i = XVECLEN (body, 0); i > 0; i--)
-	    {
-	      if (GET_CODE (XVECEXP (body, 0, i - 1)) == SET)
-		break;
-	      if (GET_CODE (XVECEXP (body, 0, i - 1)) != CLOBBER)
-		return -1;
-	    }
-
-	  /* N_SETS is now number of output operands.  */
-	  n_sets = i;
-
-	  /* Verify that all the SETs we have
-	     came from a single original asm_operands insn
-	     (so that invalid combinations are blocked).  */
-	  for (i = 0; i < n_sets; i++)
-	    {
-	      rtx elt = XVECEXP (body, 0, i);
-	      if (GET_CODE (elt) != SET)
-		return -1;
-	      if (GET_CODE (SET_SRC (elt)) != ASM_OPERANDS)
-		return -1;
-	      /* If these ASM_OPERANDS rtx's came from different original insns
-	         then they aren't allowed together.  */
-	      if (ASM_OPERANDS_INPUT_VEC (SET_SRC (elt))
-		  != ASM_OPERANDS_INPUT_VEC (SET_SRC (XVECEXP (body, 0, 0))))
-		return -1;
-	    }
-	  return (ASM_OPERANDS_INPUT_LENGTH (SET_SRC (XVECEXP (body, 0, 0)))
-		  + n_sets);
-	}
-      else if (GET_CODE (XVECEXP (body, 0, 0)) == ASM_OPERANDS)
-	{
-	  /* 0 outputs, but some clobbers:
-	     body is [(asm_operands ...) (clobber (reg ...))...].  */
-	  int i;
-
-	  /* Make sure all the other parallel things really are clobbers.  */
-	  for (i = XVECLEN (body, 0) - 1; i > 0; i--)
-	    if (GET_CODE (XVECEXP (body, 0, i)) != CLOBBER)
-	      return -1;
-
-	  return ASM_OPERANDS_INPUT_LENGTH (XVECEXP (body, 0, 0));
-	}
-      else
-	return -1;
-    default:
-      return -1;
+        case ASM_OPERANDS:
+            /* No output operands: return number of input operands.  */
+            return ASM_OPERANDS_INPUT_LENGTH (body);
+        case SET:
+            if (GET_CODE (SET_SRC (body)) == ASM_OPERANDS)
+            /* Single output operand: BODY is (set OUTPUT (asm_operands ...)).  */
+                return ASM_OPERANDS_INPUT_LENGTH (SET_SRC (body)) + 1;
+            else
+                return -1;
+        case PARALLEL:
+            if (GET_CODE (XVECEXP (body, 0, 0)) == SET
+                && GET_CODE (SET_SRC (XVECEXP (body, 0, 0))) == ASM_OPERANDS)
+            {
+                /* Multiple output operands, or 1 output plus some clobbers:
+                 body is [(set OUTPUT (asm_operands ...))... (clobber (reg ...))...].  */
+                int i;
+                int n_sets;
+                
+                /* Count backwards through CLOBBERs to determine number of SETs.  */
+                for (i = XVECLEN (body, 0); i > 0; i--)
+                {
+                    if (GET_CODE (XVECEXP (body, 0, i - 1)) == SET)
+                        break;
+                    if (GET_CODE (XVECEXP (body, 0, i - 1)) != CLOBBER)
+                        return -1;
+                }
+                
+                /* N_SETS is now number of output operands.  */
+                n_sets = i;
+                
+                /* Verify that all the SETs we have
+                 came from a single original asm_operands insn
+                 (so that invalid combinations are blocked).  */
+                for (i = 0; i < n_sets; i++)
+                {
+                    rtx elt = XVECEXP (body, 0, i);
+                    if (GET_CODE (elt) != SET)
+                        return -1;
+                    if (GET_CODE (SET_SRC (elt)) != ASM_OPERANDS)
+                        return -1;
+                    /* If these ASM_OPERANDS rtx's came from different original insns
+                     then they aren't allowed together.  */
+                    if (ASM_OPERANDS_INPUT_VEC (SET_SRC (elt))
+                        != ASM_OPERANDS_INPUT_VEC (SET_SRC (XVECEXP (body, 0, 0))))
+                        return -1;
+                }
+                return (ASM_OPERANDS_INPUT_LENGTH (SET_SRC (XVECEXP (body, 0, 0)))
+                        + n_sets);
+            }
+            else if (GET_CODE (XVECEXP (body, 0, 0)) == ASM_OPERANDS)
+            {
+                /* 0 outputs, but some clobbers:
+                 body is [(asm_operands ...) (clobber (reg ...))...].  */
+                int i;
+                
+                /* Make sure all the other parallel things really are clobbers.  */
+                for (i = XVECLEN (body, 0) - 1; i > 0; i--)
+                if (GET_CODE (XVECEXP (body, 0, i)) != CLOBBER)
+                    return -1;
+                
+                return ASM_OPERANDS_INPUT_LENGTH (XVECEXP (body, 0, 0));
+            }
+            else
+                return -1;
+        default:
+            return -1;
     }
 }
 
 /* Assuming BODY is an insn body that uses ASM_OPERANDS,
-   copy its operands (both input and output) into the vector OPERANDS,
-   the locations of the operands within the insn into the vector OPERAND_LOCS,
-   and the constraints for the operands into CONSTRAINTS.
-   Write the modes of the operands into MODES.
-   Return the assembler-template.
-
-   If MODES, OPERAND_LOCS, CONSTRAINTS or OPERANDS is 0,
-   we don't store that info.  */
+ copy its operands (both input and output) into the vector OPERANDS,
+ the locations of the operands within the insn into the vector OPERAND_LOCS,
+ and the constraints for the operands into CONSTRAINTS.
+ Write the modes of the operands into MODES.
+ Return the assembler-template.
+ 
+ If MODES, OPERAND_LOCS, CONSTRAINTS or OPERANDS is 0,
+ we don't store that info.  */
 
 const char *
 decode_asm_operands (body, operands, operand_locs, constraints, modes)
-     rtx body;
-     rtx *operands;
-     rtx **operand_locs;
-     const char **constraints;
-     enum machine_mode *modes;
+rtx body;
+rtx *operands;
+rtx **operand_locs;
+const char **constraints;
+enum machine_mode *modes;
 {
-  int i;
-  int noperands;
-  const char *template = 0;
-
-  if (GET_CODE (body) == SET && GET_CODE (SET_SRC (body)) == ASM_OPERANDS)
+    int i;
+    int noperands;
+    const char *template = 0;
+    
+    if (GET_CODE (body) == SET && GET_CODE (SET_SRC (body)) == ASM_OPERANDS)
     {
-      rtx asmop = SET_SRC (body);
-      /* Single output operand: BODY is (set OUTPUT (asm_operands ....)).  */
-
-      noperands = ASM_OPERANDS_INPUT_LENGTH (asmop) + 1;
-
-      for (i = 1; i < noperands; i++)
-	{
-	  if (operand_locs)
-	    operand_locs[i] = &ASM_OPERANDS_INPUT (asmop, i - 1);
-	  if (operands)
-	    operands[i] = ASM_OPERANDS_INPUT (asmop, i - 1);
-	  if (constraints)
-	    constraints[i] = ASM_OPERANDS_INPUT_CONSTRAINT (asmop, i - 1);
-	  if (modes)
-	    modes[i] = ASM_OPERANDS_INPUT_MODE (asmop, i - 1);
-	}
-
-      /* The output is in the SET.
-	 Its constraint is in the ASM_OPERANDS itself.  */
-      if (operands)
-	operands[0] = SET_DEST (body);
-      if (operand_locs)
-	operand_locs[0] = &SET_DEST (body);
-      if (constraints)
-	constraints[0] = ASM_OPERANDS_OUTPUT_CONSTRAINT (asmop);
-      if (modes)
-	modes[0] = GET_MODE (SET_DEST (body));
-      template = ASM_OPERANDS_TEMPLATE (asmop);
+        rtx asmop = SET_SRC (body);
+        /* Single output operand: BODY is (set OUTPUT (asm_operands ....)).  */
+        
+        noperands = ASM_OPERANDS_INPUT_LENGTH (asmop) + 1;
+        
+        for (i = 1; i < noperands; i++)
+        {
+            if (operand_locs)
+                operand_locs[i] = &ASM_OPERANDS_INPUT (asmop, i - 1);
+            if (operands)
+                operands[i] = ASM_OPERANDS_INPUT (asmop, i - 1);
+            if (constraints)
+                constraints[i] = ASM_OPERANDS_INPUT_CONSTRAINT (asmop, i - 1);
+            if (modes)
+                modes[i] = ASM_OPERANDS_INPUT_MODE (asmop, i - 1);
+        }
+        
+        /* The output is in the SET.
+         Its constraint is in the ASM_OPERANDS itself.  */
+        if (operands)
+            operands[0] = SET_DEST (body);
+        if (operand_locs)
+            operand_locs[0] = &SET_DEST (body);
+        if (constraints)
+            constraints[0] = ASM_OPERANDS_OUTPUT_CONSTRAINT (asmop);
+        if (modes)
+            modes[0] = GET_MODE (SET_DEST (body));
+        template = ASM_OPERANDS_TEMPLATE (asmop);
     }
-  else if (GET_CODE (body) == ASM_OPERANDS)
+    else if (GET_CODE (body) == ASM_OPERANDS)
     {
-      rtx asmop = body;
-      /* No output operands: BODY is (asm_operands ....).  */
-
-      noperands = ASM_OPERANDS_INPUT_LENGTH (asmop);
-
-      /* The input operands are found in the 1st element vector.  */
-      /* Constraints for inputs are in the 2nd element vector.  */
-      for (i = 0; i < noperands; i++)
-	{
-	  if (operand_locs)
-	    operand_locs[i] = &ASM_OPERANDS_INPUT (asmop, i);
-	  if (operands)
-	    operands[i] = ASM_OPERANDS_INPUT (asmop, i);
-	  if (constraints)
-	    constraints[i] = ASM_OPERANDS_INPUT_CONSTRAINT (asmop, i);
-	  if (modes)
-	    modes[i] = ASM_OPERANDS_INPUT_MODE (asmop, i);
-	}
-      template = ASM_OPERANDS_TEMPLATE (asmop);
+        rtx asmop = body;
+        /* No output operands: BODY is (asm_operands ....).  */
+        
+        noperands = ASM_OPERANDS_INPUT_LENGTH (asmop);
+        
+        /* The input operands are found in the 1st element vector.  */
+        /* Constraints for inputs are in the 2nd element vector.  */
+        for (i = 0; i < noperands; i++)
+        {
+            if (operand_locs)
+                operand_locs[i] = &ASM_OPERANDS_INPUT (asmop, i);
+            if (operands)
+                operands[i] = ASM_OPERANDS_INPUT (asmop, i);
+            if (constraints)
+                constraints[i] = ASM_OPERANDS_INPUT_CONSTRAINT (asmop, i);
+            if (modes)
+                modes[i] = ASM_OPERANDS_INPUT_MODE (asmop, i);
+        }
+        template = ASM_OPERANDS_TEMPLATE (asmop);
     }
-  else if (GET_CODE (body) == PARALLEL
-	   && GET_CODE (XVECEXP (body, 0, 0)) == SET
-	   && GET_CODE (SET_SRC (XVECEXP (body, 0, 0))) == ASM_OPERANDS)
+    else if (GET_CODE (body) == PARALLEL
+             && GET_CODE (XVECEXP (body, 0, 0)) == SET
+             && GET_CODE (SET_SRC (XVECEXP (body, 0, 0))) == ASM_OPERANDS)
     {
-      rtx asmop = SET_SRC (XVECEXP (body, 0, 0));
-      int nparallel = XVECLEN (body, 0); /* Includes CLOBBERs.  */
-      int nin = ASM_OPERANDS_INPUT_LENGTH (asmop);
-      int nout = 0;		/* Does not include CLOBBERs.  */
-
-      /* At least one output, plus some CLOBBERs.  */
-
-      /* The outputs are in the SETs.
-	 Their constraints are in the ASM_OPERANDS itself.  */
-      for (i = 0; i < nparallel; i++)
-	{
-	  if (GET_CODE (XVECEXP (body, 0, i)) == CLOBBER)
-	    break;		/* Past last SET */
-	  
-	  if (operands)
-	    operands[i] = SET_DEST (XVECEXP (body, 0, i));
-	  if (operand_locs)
-	    operand_locs[i] = &SET_DEST (XVECEXP (body, 0, i));
-	  if (constraints)
-	    constraints[i] = XSTR (SET_SRC (XVECEXP (body, 0, i)), 1);
-	  if (modes)
-	    modes[i] = GET_MODE (SET_DEST (XVECEXP (body, 0, i)));
-	  nout++;
-	}
-
-      for (i = 0; i < nin; i++)
-	{
-	  if (operand_locs)
-	    operand_locs[i + nout] = &ASM_OPERANDS_INPUT (asmop, i);
-	  if (operands)
-	    operands[i + nout] = ASM_OPERANDS_INPUT (asmop, i);
-	  if (constraints)
-	    constraints[i + nout] = ASM_OPERANDS_INPUT_CONSTRAINT (asmop, i);
-	  if (modes)
-	    modes[i + nout] = ASM_OPERANDS_INPUT_MODE (asmop, i);
-	}
-
-      template = ASM_OPERANDS_TEMPLATE (asmop);
+        rtx asmop = SET_SRC (XVECEXP (body, 0, 0));
+        int nparallel = XVECLEN (body, 0); /* Includes CLOBBERs.  */
+        int nin = ASM_OPERANDS_INPUT_LENGTH (asmop);
+        int nout = 0;		/* Does not include CLOBBERs.  */
+        
+        /* At least one output, plus some CLOBBERs.  */
+        
+        /* The outputs are in the SETs.
+         Their constraints are in the ASM_OPERANDS itself.  */
+        for (i = 0; i < nparallel; i++)
+        {
+            if (GET_CODE (XVECEXP (body, 0, i)) == CLOBBER)
+                break;		/* Past last SET */
+            
+            if (operands)
+                operands[i] = SET_DEST (XVECEXP (body, 0, i));
+            if (operand_locs)
+                operand_locs[i] = &SET_DEST (XVECEXP (body, 0, i));
+            if (constraints)
+                constraints[i] = XSTR (SET_SRC (XVECEXP (body, 0, i)), 1);
+            if (modes)
+                modes[i] = GET_MODE (SET_DEST (XVECEXP (body, 0, i)));
+            nout++;
+        }
+        
+        for (i = 0; i < nin; i++)
+        {
+            if (operand_locs)
+                operand_locs[i + nout] = &ASM_OPERANDS_INPUT (asmop, i);
+            if (operands)
+                operands[i + nout] = ASM_OPERANDS_INPUT (asmop, i);
+            if (constraints)
+                constraints[i + nout] = ASM_OPERANDS_INPUT_CONSTRAINT (asmop, i);
+            if (modes)
+                modes[i + nout] = ASM_OPERANDS_INPUT_MODE (asmop, i);
+        }
+        
+        template = ASM_OPERANDS_TEMPLATE (asmop);
     }
-  else if (GET_CODE (body) == PARALLEL
-	   && GET_CODE (XVECEXP (body, 0, 0)) == ASM_OPERANDS)
+    else if (GET_CODE (body) == PARALLEL
+             && GET_CODE (XVECEXP (body, 0, 0)) == ASM_OPERANDS)
     {
-      /* No outputs, but some CLOBBERs.  */
-
-      rtx asmop = XVECEXP (body, 0, 0);
-      int nin = ASM_OPERANDS_INPUT_LENGTH (asmop);
-
-      for (i = 0; i < nin; i++)
-	{
-	  if (operand_locs)
-	    operand_locs[i] = &ASM_OPERANDS_INPUT (asmop, i);
-	  if (operands)
-	    operands[i] = ASM_OPERANDS_INPUT (asmop, i);
-	  if (constraints)
-	    constraints[i] = ASM_OPERANDS_INPUT_CONSTRAINT (asmop, i);
-	  if (modes)
-	    modes[i] = ASM_OPERANDS_INPUT_MODE (asmop, i);
-	}
-
-      template = ASM_OPERANDS_TEMPLATE (asmop);
+        /* No outputs, but some CLOBBERs.  */
+        
+        rtx asmop = XVECEXP (body, 0, 0);
+        int nin = ASM_OPERANDS_INPUT_LENGTH (asmop);
+        
+        for (i = 0; i < nin; i++)
+        {
+            if (operand_locs)
+                operand_locs[i] = &ASM_OPERANDS_INPUT (asmop, i);
+            if (operands)
+                operands[i] = ASM_OPERANDS_INPUT (asmop, i);
+            if (constraints)
+                constraints[i] = ASM_OPERANDS_INPUT_CONSTRAINT (asmop, i);
+            if (modes)
+                modes[i] = ASM_OPERANDS_INPUT_MODE (asmop, i);
+        }
+        
+        template = ASM_OPERANDS_TEMPLATE (asmop);
     }
-
-  return template;
+    
+    return template;
 }
 
 /* Check if an asm_operand matches it's constraints. 
-   Return > 0 if ok, = 0 if bad, < 0 if inconclusive.  */
+ Return > 0 if ok, = 0 if bad, < 0 if inconclusive.  */
 
 int
 asm_operand_ok (op, constraint)
-     rtx op;
-     const char *constraint;
+rtx op;
+const char *constraint;
 {
-  int result = 0;
-
-  /* Use constrain_operands after reload.  */
-  if (reload_completed)
-    abort ();
-
-  while (*constraint)
+    int result = 0;
+    
+    /* Use constrain_operands after reload.  */
+    if (reload_completed)
+        abort ();
+    
+    while (*constraint)
     {
-      char c = *constraint++;
-      switch (c)
-	{
-	case '=':
-	case '+':
-	case '*':
-	case '%':
-	case '?':
-	case '!':
-	case '#':
-	case '&':
-	case ',':
-	  break;
-
-	case '0': case '1': case '2': case '3': case '4':
-	case '5': case '6': case '7': case '8': case '9':
-	  /* For best results, our caller should have given us the
-	     proper matching constraint, but we can't actually fail
-	     the check if they didn't.  Indicate that results are
-	     inconclusive.  */
-	  while (ISDIGIT (*constraint))
-	    constraint++;
-	  result = -1;
-	  break;
-
-	case 'p':
-	  if (address_operand (op, VOIDmode))
-	    return 1;
-	  break;
-
-	case 'm':
-	case 'V': /* non-offsettable */
-	  if (memory_operand (op, VOIDmode))
-	    return 1;
-	  break;
-
-	case 'o': /* offsettable */
-	  if (offsettable_nonstrict_memref_p (op))
-	    return 1;
-	  break;
-
-	case '<':
-	  /* ??? Before flow, auto inc/dec insns are not supposed to exist,
-	     excepting those that expand_call created.  Further, on some
-	     machines which do not have generalized auto inc/dec, an inc/dec
-	     is not a memory_operand.
-
-	     Match any memory and hope things are resolved after reload.  */
-
-	  if (GET_CODE (op) == MEM
-	      && (1
-		  || GET_CODE (XEXP (op, 0)) == PRE_DEC
-                  || GET_CODE (XEXP (op, 0)) == POST_DEC))
-	    return 1;
-	  break;
-
-	case '>':
-	  if (GET_CODE (op) == MEM
-	      && (1
-		  || GET_CODE (XEXP (op, 0)) == PRE_INC
-                  || GET_CODE (XEXP (op, 0)) == POST_INC))
-	    return 1;
-	  break;
-
-	case 'E':
+        char c = *constraint++;
+        switch (c)
+        {
+            case '=':
+            case '+':
+            case '*':
+            case '%':
+            case '?':
+            case '!':
+            case '#':
+            case '&':
+            case ',':
+                break;
+                
+            case '0': case '1': case '2': case '3': case '4':
+            case '5': case '6': case '7': case '8': case '9':
+                /* For best results, our caller should have given us the
+                 proper matching constraint, but we can't actually fail
+                 the check if they didn't.  Indicate that results are
+                 inconclusive.  */
+                while (ISDIGIT (*constraint))
+                    constraint++;
+                result = -1;
+                break;
+                
+            case 'p':
+                if (address_operand (op, VOIDmode))
+                    return 1;
+                break;
+                
+            case 'm':
+            case 'V': /* non-offsettable */
+                if (memory_operand (op, VOIDmode))
+                    return 1;
+                break;
+                
+            case 'o': /* offsettable */
+                if (offsettable_nonstrict_memref_p (op))
+                    return 1;
+                break;
+                
+            case '<':
+                /* ??? Before flow, auto inc/dec insns are not supposed to exist,
+                 excepting those that expand_call created.  Further, on some
+                 machines which do not have generalized auto inc/dec, an inc/dec
+                 is not a memory_operand.
+                 
+                 Match any memory and hope things are resolved after reload.  */
+                
+                if (GET_CODE (op) == MEM
+                    && (1
+                        || GET_CODE (XEXP (op, 0)) == PRE_DEC
+                        || GET_CODE (XEXP (op, 0)) == POST_DEC))
+                    return 1;
+                break;
+                
+            case '>':
+                if (GET_CODE (op) == MEM
+                    && (1
+                        || GET_CODE (XEXP (op, 0)) == PRE_INC
+                        || GET_CODE (XEXP (op, 0)) == POST_INC))
+                    return 1;
+                break;
+                
+            case 'E':
 #ifndef REAL_ARITHMETIC
-	  /* Match any floating double constant, but only if
-	     we can examine the bits of it reliably.  */
-	  if ((HOST_FLOAT_FORMAT != TARGET_FLOAT_FORMAT
-	       || HOST_BITS_PER_WIDE_INT != BITS_PER_WORD)
-	      && GET_MODE (op) != VOIDmode && ! flag_pretend_float)
-	    break;
+                /* Match any floating double constant, but only if
+                 we can examine the bits of it reliably.  */
+                if ((HOST_FLOAT_FORMAT != TARGET_FLOAT_FORMAT
+                     || HOST_BITS_PER_WIDE_INT != BITS_PER_WORD)
+                    && GET_MODE (op) != VOIDmode && ! flag_pretend_float)
+                    break;
 #endif
-	  /* FALLTHRU */
-
-	case 'F':
-	  if (GET_CODE (op) == CONST_DOUBLE)
-	    return 1;
-	  break;
-
-	case 'G':
-	  if (GET_CODE (op) == CONST_DOUBLE
-	      && CONST_DOUBLE_OK_FOR_LETTER_P (op, 'G'))
-	    return 1;
-	  break;
-	case 'H':
-	  if (GET_CODE (op) == CONST_DOUBLE
-	      && CONST_DOUBLE_OK_FOR_LETTER_P (op, 'H'))
-	    return 1;
-	  break;
-
-	case 's':
-	  if (GET_CODE (op) == CONST_INT
-	      || (GET_CODE (op) == CONST_DOUBLE
-		  && GET_MODE (op) == VOIDmode))
-	    break;
-	  /* FALLTHRU */
-
-	case 'i':
-	  if (CONSTANT_P (op)
+                /* FALLTHRU */
+                
+            case 'F':
+                if (GET_CODE (op) == CONST_DOUBLE)
+                    return 1;
+                break;
+                
+            case 'G':
+                if (GET_CODE (op) == CONST_DOUBLE
+                    && CONST_DOUBLE_OK_FOR_LETTER_P (op, 'G'))
+                    return 1;
+                break;
+            case 'H':
+                if (GET_CODE (op) == CONST_DOUBLE
+                    && CONST_DOUBLE_OK_FOR_LETTER_P (op, 'H'))
+                    return 1;
+                break;
+                
+            case 's':
+                if (GET_CODE (op) == CONST_INT
+                    || (GET_CODE (op) == CONST_DOUBLE
+                        && GET_MODE (op) == VOIDmode))
+                    break;
+                /* FALLTHRU */
+                
+            case 'i':
+                if (CONSTANT_P (op)
 #ifdef LEGITIMATE_PIC_OPERAND_P
-	      && (! flag_pic || LEGITIMATE_PIC_OPERAND_P (op))
+                    && (! flag_pic || LEGITIMATE_PIC_OPERAND_P (op))
 #endif
-	      )
-	    return 1;
-	  break;
-
-	case 'n':
-	  if (GET_CODE (op) == CONST_INT
-	      || (GET_CODE (op) == CONST_DOUBLE
-		  && GET_MODE (op) == VOIDmode))
-	    return 1;
-	  break;
-
-	case 'I':
-	  if (GET_CODE (op) == CONST_INT
-	      && CONST_OK_FOR_LETTER_P (INTVAL (op), 'I'))
-	    return 1;
-	  break;
-	case 'J':
-	  if (GET_CODE (op) == CONST_INT
-	      && CONST_OK_FOR_LETTER_P (INTVAL (op), 'J'))
-	    return 1;
-	  break;
-	case 'K':
-	  if (GET_CODE (op) == CONST_INT
-	      && CONST_OK_FOR_LETTER_P (INTVAL (op), 'K'))
-	    return 1;
-	  break;
-	case 'L':
-	  if (GET_CODE (op) == CONST_INT
-	      && CONST_OK_FOR_LETTER_P (INTVAL (op), 'L'))
-	    return 1;
-	  break;
-	case 'M':
-	  if (GET_CODE (op) == CONST_INT
-	      && CONST_OK_FOR_LETTER_P (INTVAL (op), 'M'))
-	    return 1;
-	  break;
-	case 'N':
-	  if (GET_CODE (op) == CONST_INT
-	      && CONST_OK_FOR_LETTER_P (INTVAL (op), 'N'))
-	    return 1;
-	  break;
-	case 'O':
-	  if (GET_CODE (op) == CONST_INT
-	      && CONST_OK_FOR_LETTER_P (INTVAL (op), 'O'))
-	    return 1;
-	  break;
-	case 'P':
-	  if (GET_CODE (op) == CONST_INT
-	      && CONST_OK_FOR_LETTER_P (INTVAL (op), 'P'))
-	    return 1;
-	  break;
-
-	case 'X':
-	  return 1;
-
-	case 'g':
-	  if (general_operand (op, VOIDmode))
-	    return 1;
-	  break;
-
-	default:
-	  /* For all other letters, we first check for a register class,
-	     otherwise it is an EXTRA_CONSTRAINT.  */
-	  if (REG_CLASS_FROM_LETTER (c) != NO_REGS)
-	    {
-	    case 'r':
-	      if (GET_MODE (op) == BLKmode)
-		break;
-	      if (register_operand (op, VOIDmode))
-		return 1;
-	    }
+                    )
+                    return 1;
+                break;
+                
+            case 'n':
+                if (GET_CODE (op) == CONST_INT
+                    || (GET_CODE (op) == CONST_DOUBLE
+                        && GET_MODE (op) == VOIDmode))
+                    return 1;
+                break;
+                
+            case 'I':
+                if (GET_CODE (op) == CONST_INT
+                    && CONST_OK_FOR_LETTER_P (INTVAL (op), 'I'))
+                    return 1;
+                break;
+            case 'J':
+                if (GET_CODE (op) == CONST_INT
+                    && CONST_OK_FOR_LETTER_P (INTVAL (op), 'J'))
+                    return 1;
+                break;
+            case 'K':
+                if (GET_CODE (op) == CONST_INT
+                    && CONST_OK_FOR_LETTER_P (INTVAL (op), 'K'))
+                    return 1;
+                break;
+            case 'L':
+                if (GET_CODE (op) == CONST_INT
+                    && CONST_OK_FOR_LETTER_P (INTVAL (op), 'L'))
+                    return 1;
+                break;
+            case 'M':
+                if (GET_CODE (op) == CONST_INT
+                    && CONST_OK_FOR_LETTER_P (INTVAL (op), 'M'))
+                    return 1;
+                break;
+            case 'N':
+                if (GET_CODE (op) == CONST_INT
+                    && CONST_OK_FOR_LETTER_P (INTVAL (op), 'N'))
+                    return 1;
+                break;
+            case 'O':
+                if (GET_CODE (op) == CONST_INT
+                    && CONST_OK_FOR_LETTER_P (INTVAL (op), 'O'))
+                    return 1;
+                break;
+            case 'P':
+                if (GET_CODE (op) == CONST_INT
+                    && CONST_OK_FOR_LETTER_P (INTVAL (op), 'P'))
+                    return 1;
+                break;
+                
+            case 'X':
+                return 1;
+                
+            case 'g':
+                if (general_operand (op, VOIDmode))
+                    return 1;
+                break;
+                
+            default:
+                /* For all other letters, we first check for a register class,
+                 otherwise it is an EXTRA_CONSTRAINT.  */
+                if (REG_CLASS_FROM_LETTER (c) != NO_REGS)
+                {
+                case 'r':
+                    if (GET_MODE (op) == BLKmode)
+                        break;
+                    if (register_operand (op, VOIDmode))
+                        return 1;
+                }
 #ifdef EXTRA_CONSTRAINT
-	  if (EXTRA_CONSTRAINT (op, c))
-	    return 1;
+                if (EXTRA_CONSTRAINT (op, c))
+                    return 1;
 #endif
-	  break;
-	}
+                break;
+        }
     }
-
-  return result;
+    
+    return result;
 }
 
 /* Given an rtx *P, if it is a sum containing an integer constant term,
-   return the location (type rtx *) of the pointer to that constant term.
-   Otherwise, return a null pointer.  */
+ return the location (type rtx *) of the pointer to that constant term.
+ Otherwise, return a null pointer.  */
 
 rtx *
 find_constant_term_loc (p)
-     rtx *p;
+rtx *p;
 {
-  rtx *tem;
-  enum rtx_code code = GET_CODE (*p);
-
-  /* If *P IS such a constant term, P is its location.  */
-
-  if (code == CONST_INT || code == SYMBOL_REF || code == LABEL_REF
-      || code == CONST)
-    return p;
-
-  /* Otherwise, if not a sum, it has no constant term.  */
-
-  if (GET_CODE (*p) != PLUS)
-    return 0;
-
-  /* If one of the summands is constant, return its location.  */
-
-  if (XEXP (*p, 0) && CONSTANT_P (XEXP (*p, 0))
-      && XEXP (*p, 1) && CONSTANT_P (XEXP (*p, 1)))
-    return p;
-
-  /* Otherwise, check each summand for containing a constant term.  */
-
-  if (XEXP (*p, 0) != 0)
+    rtx *tem;
+    enum rtx_code code = GET_CODE (*p);
+    
+    /* If *P IS such a constant term, P is its location.  */
+    
+    if (code == CONST_INT || code == SYMBOL_REF || code == LABEL_REF
+        || code == CONST)
+        return p;
+    
+    /* Otherwise, if not a sum, it has no constant term.  */
+    
+    if (GET_CODE (*p) != PLUS)
+        return 0;
+    
+    /* If one of the summands is constant, return its location.  */
+    
+    if (XEXP (*p, 0) && CONSTANT_P (XEXP (*p, 0))
+        && XEXP (*p, 1) && CONSTANT_P (XEXP (*p, 1)))
+        return p;
+    
+    /* Otherwise, check each summand for containing a constant term.  */
+    
+    if (XEXP (*p, 0) != 0)
     {
-      tem = find_constant_term_loc (&XEXP (*p, 0));
-      if (tem != 0)
-	return tem;
+        tem = find_constant_term_loc (&XEXP (*p, 0));
+        if (tem != 0)
+            return tem;
     }
-
-  if (XEXP (*p, 1) != 0)
+    
+    if (XEXP (*p, 1) != 0)
     {
-      tem = find_constant_term_loc (&XEXP (*p, 1));
-      if (tem != 0)
-	return tem;
+        tem = find_constant_term_loc (&XEXP (*p, 1));
+        if (tem != 0)
+            return tem;
     }
-
-  return 0;
+    
+    return 0;
 }
 
 /* Return 1 if OP is a memory reference
-   whose address contains no side effects
-   and remains valid after the addition
-   of a positive integer less than the
-   size of the object being referenced.
-
-   We assume that the original address is valid and do not check it.
-
-   This uses strict_memory_address_p as a subroutine, so
-   don't use it before reload.  */
+ whose address contains no side effects
+ and remains valid after the addition
+ of a positive integer less than the
+ size of the object being referenced.
+ 
+ We assume that the original address is valid and do not check it.
+ 
+ This uses strict_memory_address_p as a subroutine, so
+ don't use it before reload.  */
 
 int
 offsettable_memref_p (op)
-     rtx op;
+rtx op;
 {
-  return ((GET_CODE (op) == MEM)
-	  && offsettable_address_p (1, GET_MODE (op), XEXP (op, 0)));
+    return ((GET_CODE (op) == MEM)
+            && offsettable_address_p (1, GET_MODE (op), XEXP (op, 0)));
 }
 
 /* Similar, but don't require a strictly valid mem ref:
-   consider pseudo-regs valid as index or base regs.  */
+ consider pseudo-regs valid as index or base regs.  */
 
 int
 offsettable_nonstrict_memref_p (op)
-     rtx op;
+rtx op;
 {
-  return ((GET_CODE (op) == MEM)
-	  && offsettable_address_p (0, GET_MODE (op), XEXP (op, 0)));
+    return ((GET_CODE (op) == MEM)
+            && offsettable_address_p (0, GET_MODE (op), XEXP (op, 0)));
 }
 
 /* Return 1 if Y is a memory address which contains no side effects
-   and would remain valid after the addition of a positive integer
-   less than the size of that mode.
-
-   We assume that the original address is valid and do not check it.
-   We do check that it is valid for narrower modes.
-
-   If STRICTP is nonzero, we require a strictly valid address,
-   for the sake of use in reload.c.  */
+ and would remain valid after the addition of a positive integer
+ less than the size of that mode.
+ 
+ We assume that the original address is valid and do not check it.
+ We do check that it is valid for narrower modes.
+ 
+ If STRICTP is nonzero, we require a strictly valid address,
+ for the sake of use in reload.c.  */
 
 int
 offsettable_address_p (strictp, mode, y)
-     int strictp;
-     enum machine_mode mode;
-     rtx y;
+int strictp;
+enum machine_mode mode;
+rtx y;
 {
-  enum rtx_code ycode = GET_CODE (y);
-  rtx z;
-  rtx y1 = y;
-  rtx *y2;
-  int (*addressp) PARAMS ((enum machine_mode, rtx)) =
+    enum rtx_code ycode = GET_CODE (y);
+    rtx z;
+    rtx y1 = y;
+    rtx *y2;
+    int (*addressp) PARAMS ((enum machine_mode, rtx)) =
     (strictp ? strict_memory_address_p : memory_address_p);
-  unsigned int mode_sz = GET_MODE_SIZE (mode);
-
-  if (CONSTANT_ADDRESS_P (y))
-    return 1;
-
-  /* Adjusting an offsettable address involves changing to a narrower mode.
+    unsigned int mode_sz = GET_MODE_SIZE (mode);
+    
+    if (CONSTANT_ADDRESS_P (y))
+        return 1;
+    
+    /* Adjusting an offsettable address involves changing to a narrower mode.
      Make sure that's OK.  */
-
-  if (mode_dependent_address_p (y))
-    return 0;
-
-  /* ??? How much offset does an offsettable BLKmode reference need?
+    
+    if (mode_dependent_address_p (y))
+        return 0;
+    
+    /* ??? How much offset does an offsettable BLKmode reference need?
      Clearly that depends on the situation in which it's being used.
      However, the current situation in which we test 0xffffffff is
      less than ideal.  Caveat user.  */
-  if (mode_sz == 0)
-    mode_sz = BIGGEST_ALIGNMENT / BITS_PER_UNIT;
-
-  /* If the expression contains a constant term,
+    if (mode_sz == 0)
+        mode_sz = BIGGEST_ALIGNMENT / BITS_PER_UNIT;
+    
+    /* If the expression contains a constant term,
      see if it remains valid when max possible offset is added.  */
-
-  if ((ycode == PLUS) && (y2 = find_constant_term_loc (&y1)))
+    
+    if ((ycode == PLUS) && (y2 = find_constant_term_loc (&y1)))
     {
-      int good;
-
-      y1 = *y2;
-      *y2 = plus_constant (*y2, mode_sz - 1);
-      /* Use QImode because an odd displacement may be automatically invalid
-	 for any wider mode.  But it should be valid for a single byte.  */
-      good = (*addressp) (QImode, y);
-
-      /* In any case, restore old contents of memory.  */
-      *y2 = y1;
-      return good;
+        int good;
+        
+        y1 = *y2;
+        *y2 = plus_constant (*y2, mode_sz - 1);
+        /* Use QImode because an odd displacement may be automatically invalid
+         for any wider mode.  But it should be valid for a single byte.  */
+        good = (*addressp) (QImode, y);
+        
+        /* In any case, restore old contents of memory.  */
+        *y2 = y1;
+        return good;
     }
-
-  if (GET_RTX_CLASS (ycode) == 'a')
-    return 0;
-
-  /* The offset added here is chosen as the maximum offset that
+    
+    if (GET_RTX_CLASS (ycode) == 'a')
+        return 0;
+    
+    /* The offset added here is chosen as the maximum offset that
      any instruction could need to add when operating on something
      of the specified mode.  We assume that if Y and Y+c are
      valid addresses then so is Y+d for all 0<d<c.  adjust_address will
      go inside a LO_SUM here, so we do so as well.  */
-  if (GET_CODE (y) == LO_SUM
-      && mode != BLKmode
-      && mode_sz <= GET_MODE_ALIGNMENT (mode) / BITS_PER_UNIT)
-    z = gen_rtx_LO_SUM (GET_MODE (y), XEXP (y, 0),
-			plus_constant (XEXP (y, 1), mode_sz - 1));
-  else
-    z = plus_constant (y, mode_sz - 1);
-
-  /* Use QImode because an odd displacement may be automatically invalid
+    if (GET_CODE (y) == LO_SUM
+        && mode != BLKmode
+        && mode_sz <= GET_MODE_ALIGNMENT (mode) / BITS_PER_UNIT)
+        z = gen_rtx_LO_SUM (GET_MODE (y), XEXP (y, 0),
+                            plus_constant (XEXP (y, 1), mode_sz - 1));
+    else
+        z = plus_constant (y, mode_sz - 1);
+    
+    /* Use QImode because an odd displacement may be automatically invalid
      for any wider mode.  But it should be valid for a single byte.  */
-  return (*addressp) (QImode, z);
+    return (*addressp) (QImode, z);
 }
 
 /* Return 1 if ADDR is an address-expression whose effect depends
-   on the mode of the memory reference it is used in.
-
-   Autoincrement addressing is a typical example of mode-dependence
-   because the amount of the increment depends on the mode.  */
+ on the mode of the memory reference it is used in.
+ 
+ Autoincrement addressing is a typical example of mode-dependence
+ because the amount of the increment depends on the mode.  */
 
 int
 mode_dependent_address_p (addr)
-  rtx addr ATTRIBUTE_UNUSED; /* Maybe used in GO_IF_MODE_DEPENDENT_ADDRESS.  */
+rtx addr ATTRIBUTE_UNUSED; /* Maybe used in GO_IF_MODE_DEPENDENT_ADDRESS.  */
 {
-  GO_IF_MODE_DEPENDENT_ADDRESS (addr, win);
-  return 0;
-  /* Label `win' might (not) be used via GO_IF_MODE_DEPENDENT_ADDRESS.  */
- win: ATTRIBUTE_UNUSED_LABEL
-  return 1;
+    GO_IF_MODE_DEPENDENT_ADDRESS (addr, win);
+    return 0;
+    /* Label `win' might (not) be used via GO_IF_MODE_DEPENDENT_ADDRESS.  */
+win: ATTRIBUTE_UNUSED_LABEL
+    return 1;
 }
 
 /* Return 1 if OP is a general operand
-   other than a memory ref with a mode dependent address.  */
+ other than a memory ref with a mode dependent address.  */
 
 int
 mode_independent_operand (op, mode)
-     enum machine_mode mode;
-     rtx op;
+enum machine_mode mode;
+rtx op;
 {
-  rtx addr;
-
-  if (! general_operand (op, mode))
-    return 0;
-
-  if (GET_CODE (op) != MEM)
+    rtx addr;
+    
+    if (! general_operand (op, mode))
+        return 0;
+    
+    if (GET_CODE (op) != MEM)
+        return 1;
+    
+    addr = XEXP (op, 0);
+    GO_IF_MODE_DEPENDENT_ADDRESS (addr, lose);
     return 1;
-
-  addr = XEXP (op, 0);
-  GO_IF_MODE_DEPENDENT_ADDRESS (addr, lose);
-  return 1;
-  /* Label `lose' might (not) be used via GO_IF_MODE_DEPENDENT_ADDRESS.  */
- lose: ATTRIBUTE_UNUSED_LABEL
-  return 0;
+    /* Label `lose' might (not) be used via GO_IF_MODE_DEPENDENT_ADDRESS.  */
+lose: ATTRIBUTE_UNUSED_LABEL
+    return 0;
 }
 
 /* Like extract_insn, but save insn extracted and don't extract again, when
-   called again for the same insn expecting that recog_data still contain the
-   valid information.  This is used primary by gen_attr infrastructure that
-   often does extract insn again and again.  */
+ called again for the same insn expecting that recog_data still contain the
+ valid information.  This is used primary by gen_attr infrastructure that
+ often does extract insn again and again.  */
 void
 extract_insn_cached (insn)
-     rtx insn;
+rtx insn;
 {
-  if (recog_data.insn == insn && INSN_CODE (insn) >= 0)
-    return;
-  extract_insn (insn);
-  recog_data.insn = insn;
+    if (recog_data.insn == insn && INSN_CODE (insn) >= 0)
+        return;
+    extract_insn (insn);
+    recog_data.insn = insn;
 }
 /* Do cached extract_insn, constrain_operand and complain about failures.
-   Used by insn_attrtab.  */
+ Used by insn_attrtab.  */
 void
 extract_constrain_insn_cached (insn)
-     rtx insn;
+rtx insn;
 {
-  extract_insn_cached (insn);
-  if (which_alternative == -1
-      && !constrain_operands (reload_completed))
-    fatal_insn_not_found (insn);
+    extract_insn_cached (insn);
+    if (which_alternative == -1
+        && !constrain_operands (reload_completed))
+        fatal_insn_not_found (insn);
 }
 /* Do cached constrain_operand and complain about failures.  */
 int
 constrain_operands_cached (strict)
-	int strict;
+int strict;
 {
-  if (which_alternative == -1)
-    return constrain_operands (strict);
-  else
-    return 1;
+    if (which_alternative == -1)
+        return constrain_operands (strict);
+    else
+        return 1;
 }
 
 /* Analyze INSN and fill in recog_data.  */
 
 void
 extract_insn (insn)
-     rtx insn;
+rtx insn;
 {
-  int i;
-  int icode;
-  int noperands;
-  rtx body = PATTERN (insn);
-
-  recog_data.insn = NULL;
-  recog_data.n_operands = 0;
-  recog_data.n_alternatives = 0;
-  recog_data.n_dups = 0;
-  which_alternative = -1;
-
-  switch (GET_CODE (body))
+    int i;
+    int icode;
+    int noperands;
+    rtx body = PATTERN (insn);
+    
+    recog_data.insn = NULL;
+    recog_data.n_operands = 0;
+    recog_data.n_alternatives = 0;
+    recog_data.n_dups = 0;
+    which_alternative = -1;
+    
+    switch (GET_CODE (body))
     {
-    case USE:
-    case CLOBBER:
-    case ASM_INPUT:
-    case ADDR_VEC:
-    case ADDR_DIFF_VEC:
-      return;
-
-    case SET:
-      if (GET_CODE (SET_SRC (body)) == ASM_OPERANDS)
-	goto asm_insn;
-      else
-	goto normal_insn;
-    case PARALLEL:
-      if ((GET_CODE (XVECEXP (body, 0, 0)) == SET
-	   && GET_CODE (SET_SRC (XVECEXP (body, 0, 0))) == ASM_OPERANDS)
-	  || GET_CODE (XVECEXP (body, 0, 0)) == ASM_OPERANDS)
-	goto asm_insn;
-      else
-	goto normal_insn;
-    case ASM_OPERANDS:
-    asm_insn:
-      recog_data.n_operands = noperands = asm_noperands (body);
-      if (noperands >= 0)
-	{
-	  /* This insn is an `asm' with operands.  */
-
-	  /* expand_asm_operands makes sure there aren't too many operands.  */
-	  if (noperands > MAX_RECOG_OPERANDS)
-	    abort ();
-
-	  /* Now get the operand values and constraints out of the insn.  */
-	  decode_asm_operands (body, recog_data.operand,
-			       recog_data.operand_loc,
-			       recog_data.constraints,
-			       recog_data.operand_mode);
-	  if (noperands > 0)
-	    {
-	      const char *p =  recog_data.constraints[0];
-	      recog_data.n_alternatives = 1;
-	      while (*p)
-		recog_data.n_alternatives += (*p++ == ',');
-	    }
-	  break;
-	}
-      fatal_insn_not_found (insn);
-
-    default:
-    normal_insn:
-      /* Ordinary insn: recognize it, get the operands via insn_extract
-	 and get the constraints.  */
-
-      icode = recog_memoized (insn);
-      if (icode < 0)
-	fatal_insn_not_found (insn);
-
-      recog_data.n_operands = noperands = insn_data[icode].n_operands;
-      recog_data.n_alternatives = insn_data[icode].n_alternatives;
-      recog_data.n_dups = insn_data[icode].n_dups;
-
-      insn_extract (insn);
-
-      for (i = 0; i < noperands; i++)
-	{
-	  recog_data.constraints[i] = insn_data[icode].operand[i].constraint;
-	  recog_data.operand_mode[i] = insn_data[icode].operand[i].mode;
-	  /* VOIDmode match_operands gets mode from their real operand.  */
-	  if (recog_data.operand_mode[i] == VOIDmode)
-	    recog_data.operand_mode[i] = GET_MODE (recog_data.operand[i]);
-	}
+        case USE:
+        case CLOBBER:
+        case ASM_INPUT:
+        case ADDR_VEC:
+        case ADDR_DIFF_VEC:
+            return;
+            
+        case SET:
+            if (GET_CODE (SET_SRC (body)) == ASM_OPERANDS)
+                goto asm_insn;
+            else
+                goto normal_insn;
+        case PARALLEL:
+            if ((GET_CODE (XVECEXP (body, 0, 0)) == SET
+                 && GET_CODE (SET_SRC (XVECEXP (body, 0, 0))) == ASM_OPERANDS)
+                || GET_CODE (XVECEXP (body, 0, 0)) == ASM_OPERANDS)
+                goto asm_insn;
+            else
+                goto normal_insn;
+        case ASM_OPERANDS:
+        asm_insn:
+            recog_data.n_operands = noperands = asm_noperands (body);
+            if (noperands >= 0)
+            {
+                /* This insn is an `asm' with operands.  */
+                
+                /* expand_asm_operands makes sure there aren't too many operands.  */
+                if (noperands > MAX_RECOG_OPERANDS)
+                    abort ();
+                
+                /* Now get the operand values and constraints out of the insn.  */
+                decode_asm_operands (body, recog_data.operand,
+                                     recog_data.operand_loc,
+                                     recog_data.constraints,
+                                     recog_data.operand_mode);
+                if (noperands > 0)
+                {
+                    const char *p =  recog_data.constraints[0];
+                    recog_data.n_alternatives = 1;
+                    while (*p)
+                        recog_data.n_alternatives += (*p++ == ',');
+                }
+                break;
+            }
+            fatal_insn_not_found (insn);
+            
+        default:
+        normal_insn:
+            /* Ordinary insn: recognize it, get the operands via insn_extract
+             and get the constraints.  */
+            
+            icode = recog_memoized (insn);
+            if (icode < 0)
+                fatal_insn_not_found (insn);
+            
+            recog_data.n_operands = noperands = insn_data[icode].n_operands;
+            recog_data.n_alternatives = insn_data[icode].n_alternatives;
+            recog_data.n_dups = insn_data[icode].n_dups;
+            
+            insn_extract (insn);
+            
+            for (i = 0; i < noperands; i++)
+        {
+            recog_data.constraints[i] = insn_data[icode].operand[i].constraint;
+            recog_data.operand_mode[i] = insn_data[icode].operand[i].mode;
+            /* VOIDmode match_operands gets mode from their real operand.  */
+            if (recog_data.operand_mode[i] == VOIDmode)
+                recog_data.operand_mode[i] = GET_MODE (recog_data.operand[i]);
+        }
     }
-  for (i = 0; i < noperands; i++)
+    for (i = 0; i < noperands; i++)
     recog_data.operand_type[i]
-      = (recog_data.constraints[i][0] == '=' ? OP_OUT
-	 : recog_data.constraints[i][0] == '+' ? OP_INOUT
-	 : OP_IN);
-
-  if (recog_data.n_alternatives > MAX_RECOG_ALTERNATIVES)
-    abort ();
+    = (recog_data.constraints[i][0] == '=' ? OP_OUT
+       : recog_data.constraints[i][0] == '+' ? OP_INOUT
+       : OP_IN);
+    
+    if (recog_data.n_alternatives > MAX_RECOG_ALTERNATIVES)
+        abort ();
 }
 
 /* After calling extract_insn, you can use this function to extract some
-   information from the constraint strings into a more usable form.
-   The collected data is stored in recog_op_alt.  */
+ information from the constraint strings into a more usable form.
+ The collected data is stored in recog_op_alt.  */
 void
 preprocess_constraints ()
 {
-  int i;
-
-  memset (recog_op_alt, 0, sizeof recog_op_alt);
-  for (i = 0; i < recog_data.n_operands; i++)
+    int i;
+    
+    memset (recog_op_alt, 0, sizeof recog_op_alt);
+    for (i = 0; i < recog_data.n_operands; i++)
     {
-      int j;
-      struct operand_alternative *op_alt;
-      const char *p = recog_data.constraints[i];
-
-      op_alt = recog_op_alt[i];
-
-      for (j = 0; j < recog_data.n_alternatives; j++)
-	{
-	  op_alt[j].class = NO_REGS;
-	  op_alt[j].constraint = p;
-	  op_alt[j].matches = -1;
-	  op_alt[j].matched = -1;
-
-	  if (*p == '\0' || *p == ',')
-	    {
-	      op_alt[j].anything_ok = 1;
-	      continue;
-	    }
-
-	  for (;;)
-	    {
-	      char c = *p++;
-	      if (c == '#')
-		do
-		  c = *p++;
-		while (c != ',' && c != '\0');
-	      if (c == ',' || c == '\0')
-		break;
-
-	      switch (c)
-		{
-		case '=': case '+': case '*': case '%':
-		case 'E': case 'F': case 'G': case 'H':
-		case 's': case 'i': case 'n':
-		case 'I': case 'J': case 'K': case 'L':
-		case 'M': case 'N': case 'O': case 'P':
-		  /* These don't say anything we care about.  */
-		  break;
-
-		case '?':
-		  op_alt[j].reject += 6;
-		  break;
-		case '!':
-		  op_alt[j].reject += 600;
-		  break;
-		case '&':
-		  op_alt[j].earlyclobber = 1;
-		  break;		  
-
-		case '0': case '1': case '2': case '3': case '4':
-		case '5': case '6': case '7': case '8': case '9':
-		  {
-		    char *end;
-		    op_alt[j].matches = strtoul (p - 1, &end, 10);
-		    recog_op_alt[op_alt[j].matches][j].matched = i;
-		    p = end;
-		  }
-		  break;
-
-		case 'm':
-		  op_alt[j].memory_ok = 1;
-		  break;
-		case '<':
-		  op_alt[j].decmem_ok = 1;
-		  break;
-		case '>':
-		  op_alt[j].incmem_ok = 1;
-		  break;
-		case 'V':
-		  op_alt[j].nonoffmem_ok = 1;
-		  break;
-		case 'o':
-		  op_alt[j].offmem_ok = 1;
-		  break;
-		case 'X':
-		  op_alt[j].anything_ok = 1;
-		  break;
-
-		case 'p':
-		  op_alt[j].is_address = 1;
-		  op_alt[j].class = reg_class_subunion[(int) op_alt[j].class]
-		    [(int) MODE_BASE_REG_CLASS (VOIDmode)];
-		  break;
-
-		case 'g': case 'r':
-		  op_alt[j].class = reg_class_subunion[(int) op_alt[j].class][(int) GENERAL_REGS];
-		  break;
-
-		default:
-		  op_alt[j].class = reg_class_subunion[(int) op_alt[j].class][(int) REG_CLASS_FROM_LETTER ((unsigned char) c)];
-		  break;
-		}
-	    }
-	}
+        int j;
+        struct operand_alternative *op_alt;
+        const char *p = recog_data.constraints[i];
+        
+        op_alt = recog_op_alt[i];
+        
+        for (j = 0; j < recog_data.n_alternatives; j++)
+        {
+            op_alt[j].class = NO_REGS;
+            op_alt[j].constraint = p;
+            op_alt[j].matches = -1;
+            op_alt[j].matched = -1;
+            
+            if (*p == '\0' || *p == ',')
+            {
+                op_alt[j].anything_ok = 1;
+                continue;
+            }
+            
+            for (;;)
+            {
+                char c = *p++;
+                if (c == '#')
+                    do
+                        c = *p++;
+                while (c != ',' && c != '\0');
+                if (c == ',' || c == '\0')
+                    break;
+                
+                switch (c)
+                {
+                    case '=': case '+': case '*': case '%':
+                    case 'E': case 'F': case 'G': case 'H':
+                    case 's': case 'i': case 'n':
+                    case 'I': case 'J': case 'K': case 'L':
+                    case 'M': case 'N': case 'O': case 'P':
+                        /* These don't say anything we care about.  */
+                        break;
+                        
+                    case '?':
+                        op_alt[j].reject += 6;
+                        break;
+                    case '!':
+                        op_alt[j].reject += 600;
+                        break;
+                    case '&':
+                        op_alt[j].earlyclobber = 1;
+                        break;
+                        
+                    case '0': case '1': case '2': case '3': case '4':
+                    case '5': case '6': case '7': case '8': case '9':
+                    {
+                        char *end;
+                        op_alt[j].matches = strtoul (p - 1, &end, 10);
+                        recog_op_alt[op_alt[j].matches][j].matched = i;
+                        p = end;
+                    }
+                        break;
+                        
+                    case 'm':
+                        op_alt[j].memory_ok = 1;
+                        break;
+                    case '<':
+                        op_alt[j].decmem_ok = 1;
+                        break;
+                    case '>':
+                        op_alt[j].incmem_ok = 1;
+                        break;
+                    case 'V':
+                        op_alt[j].nonoffmem_ok = 1;
+                        break;
+                    case 'o':
+                        op_alt[j].offmem_ok = 1;
+                        break;
+                    case 'X':
+                        op_alt[j].anything_ok = 1;
+                        break;
+                        
+                    case 'p':
+                        op_alt[j].is_address = 1;
+                        op_alt[j].class = reg_class_subunion[(int) op_alt[j].class]
+                        [(int) MODE_BASE_REG_CLASS (VOIDmode)];
+                        break;
+                        
+                    case 'g': case 'r':
+                        op_alt[j].class = reg_class_subunion[(int) op_alt[j].class][(int) GENERAL_REGS];
+                        break;
+                        
+                    default:
+                        op_alt[j].class = reg_class_subunion[(int) op_alt[j].class][(int) REG_CLASS_FROM_LETTER ((unsigned char) c)];
+                        break;
+                }
+            }
+        }
     }
 }
- 
+
 /* Check the operands of an insn against the insn's operand constraints
-   and return 1 if they are valid.
-   The information about the insn's operands, constraints, operand modes
-   etc. is obtained from the global variables set up by extract_insn.
-
-   WHICH_ALTERNATIVE is set to a number which indicates which
-   alternative of constraints was matched: 0 for the first alternative,
-   1 for the next, etc.
-
-   In addition, when two operands are match
-   and it happens that the output operand is (reg) while the
-   input operand is --(reg) or ++(reg) (a pre-inc or pre-dec),
-   make the output operand look like the input.
-   This is because the output operand is the one the template will print.
-
-   This is used in final, just before printing the assembler code and by
-   the routines that determine an insn's attribute.
-
-   If STRICT is a positive non-zero value, it means that we have been
-   called after reload has been completed.  In that case, we must
-   do all checks strictly.  If it is zero, it means that we have been called
-   before reload has completed.  In that case, we first try to see if we can
-   find an alternative that matches strictly.  If not, we try again, this
-   time assuming that reload will fix up the insn.  This provides a "best
-   guess" for the alternative and is used to compute attributes of insns prior
-   to reload.  A negative value of STRICT is used for this internal call.  */
+ and return 1 if they are valid.
+ The information about the insn's operands, constraints, operand modes
+ etc. is obtained from the global variables set up by extract_insn.
+ 
+ WHICH_ALTERNATIVE is set to a number which indicates which
+ alternative of constraints was matched: 0 for the first alternative,
+ 1 for the next, etc.
+ 
+ In addition, when two operands are match
+ and it happens that the output operand is (reg) while the
+ input operand is --(reg) or ++(reg) (a pre-inc or pre-dec),
+ make the output operand look like the input.
+ This is because the output operand is the one the template will print.
+ 
+ This is used in final, just before printing the assembler code and by
+ the routines that determine an insn's attribute.
+ 
+ If STRICT is a positive non-zero value, it means that we have been
+ called after reload has been completed.  In that case, we must
+ do all checks strictly.  If it is zero, it means that we have been called
+ before reload has completed.  In that case, we first try to see if we can
+ find an alternative that matches strictly.  If not, we try again, this
+ time assuming that reload will fix up the insn.  This provides a "best
+ guess" for the alternative and is used to compute attributes of insns prior
+ to reload.  A negative value of STRICT is used for this internal call.  */
 
 struct funny_match
 {
-  int this, other;
+    int this, other;
 };
 
 int
 constrain_operands (strict)
-     int strict;
+int strict;
 {
-  const char *constraints[MAX_RECOG_OPERANDS];
-  int matching_operands[MAX_RECOG_OPERANDS];
-  int earlyclobber[MAX_RECOG_OPERANDS];
-  int c;
-
-  struct funny_match funny_match[MAX_RECOG_OPERANDS];
-  int funny_match_index;
-
-  which_alternative = 0;
-  if (recog_data.n_operands == 0 || recog_data.n_alternatives == 0)
-    return 1;
-
-  for (c = 0; c < recog_data.n_operands; c++)
+    const char *constraints[MAX_RECOG_OPERANDS];
+    int matching_operands[MAX_RECOG_OPERANDS];
+    int earlyclobber[MAX_RECOG_OPERANDS];
+    int c;
+    
+    struct funny_match funny_match[MAX_RECOG_OPERANDS];
+    int funny_match_index;
+    
+    which_alternative = 0;
+    if (recog_data.n_operands == 0 || recog_data.n_alternatives == 0)
+        return 1;
+    
+    for (c = 0; c < recog_data.n_operands; c++)
     {
-      constraints[c] = recog_data.constraints[c];
-      matching_operands[c] = -1;
+        constraints[c] = recog_data.constraints[c];
+        matching_operands[c] = -1;
     }
-
-  do
+    
+    do
     {
-      int opno;
-      int lose = 0;
-      funny_match_index = 0;
-
-      for (opno = 0; opno < recog_data.n_operands; opno++)
-	{
-	  rtx op = recog_data.operand[opno];
-	  enum machine_mode mode = GET_MODE (op);
-	  const char *p = constraints[opno];
-	  int offset = 0;
-	  int win = 0;
-	  int val;
-
-	  earlyclobber[opno] = 0;
-
-	  /* A unary operator may be accepted by the predicate, but it
-	     is irrelevant for matching constraints.  */
-	  if (GET_RTX_CLASS (GET_CODE (op)) == '1')
-	    op = XEXP (op, 0);
-
-	  if (GET_CODE (op) == SUBREG)
-	    {
-	      if (GET_CODE (SUBREG_REG (op)) == REG
-		  && REGNO (SUBREG_REG (op)) < FIRST_PSEUDO_REGISTER)
-		offset = subreg_regno_offset (REGNO (SUBREG_REG (op)),
-					      GET_MODE (SUBREG_REG (op)),
-					      SUBREG_BYTE (op),
-					      GET_MODE (op));
-	      op = SUBREG_REG (op);
-	    }
-
-	  /* An empty constraint or empty alternative
-	     allows anything which matched the pattern.  */
-	  if (*p == 0 || *p == ',')
-	    win = 1;
-
-	  while (*p && (c = *p++) != ',')
-	    switch (c)
-	      {
-	      case '?':  case '!': case '*':  case '%':
-	      case '=':  case '+':
-		break;
-
-	      case '#':
-		/* Ignore rest of this alternative as far as
-		   constraint checking is concerned.  */
-		while (*p && *p != ',')
-		  p++;
-		break;
-
-	      case '&':
-		earlyclobber[opno] = 1;
-		break;
-
-	      case '0':  case '1':  case '2':  case '3':  case '4':
-	      case '5':  case '6':  case '7':  case '8':  case '9':
-		{
-		  /* This operand must be the same as a previous one.
-		     This kind of constraint is used for instructions such
-		     as add when they take only two operands.
-
-		     Note that the lower-numbered operand is passed first.
-
-		     If we are not testing strictly, assume that this
-		     constraint will be satisfied.  */
-
-		  char *end;
-		  int match;
-
-		  match = strtoul (p - 1, &end, 10);
-		  p = end;
-
-		  if (strict < 0)
-		    val = 1;
-		  else
-		    {
-		      rtx op1 = recog_data.operand[match];
-		      rtx op2 = recog_data.operand[opno];
-
-		      /* A unary operator may be accepted by the predicate,
-			 but it is irrelevant for matching constraints.  */
-		      if (GET_RTX_CLASS (GET_CODE (op1)) == '1')
-			op1 = XEXP (op1, 0);
-		      if (GET_RTX_CLASS (GET_CODE (op2)) == '1')
-			op2 = XEXP (op2, 0);
-
-		      val = operands_match_p (op1, op2);
-		    }
-
-		  matching_operands[opno] = match;
-		  matching_operands[match] = opno;
-
-		  if (val != 0)
-		    win = 1;
-
-		  /* If output is *x and input is *--x, arrange later
-		     to change the output to *--x as well, since the
-		     output op is the one that will be printed.  */
-		  if (val == 2 && strict > 0)
-		    {
-		      funny_match[funny_match_index].this = opno;
-		      funny_match[funny_match_index++].other = match;
-		    }
-		}
-		break;
-
-	      case 'p':
-		/* p is used for address_operands.  When we are called by
-		   gen_reload, no one will have checked that the address is
-		   strictly valid, i.e., that all pseudos requiring hard regs
-		   have gotten them.  */
-		if (strict <= 0
-		    || (strict_memory_address_p (recog_data.operand_mode[opno],
-						 op)))
-		  win = 1;
-		break;
-
-		/* No need to check general_operand again;
-		   it was done in insn-recog.c.  */
-	      case 'g':
-		/* Anything goes unless it is a REG and really has a hard reg
-		   but the hard reg is not in the class GENERAL_REGS.  */
-		if (strict < 0
-		    || GENERAL_REGS == ALL_REGS
-		    || GET_CODE (op) != REG
-		    || (reload_in_progress
-			&& REGNO (op) >= FIRST_PSEUDO_REGISTER)
-		    || reg_fits_class_p (op, GENERAL_REGS, offset, mode))
-		  win = 1;
-		break;
-
-	      case 'X':
-		/* This is used for a MATCH_SCRATCH in the cases when
-		   we don't actually need anything.  So anything goes
-		   any time.  */
-		win = 1;
-		break;
-
-	      case 'm':
-		if (GET_CODE (op) == MEM
-		    /* Before reload, accept what reload can turn into mem.  */
-		    || (strict < 0 && CONSTANT_P (op))
-		    /* During reload, accept a pseudo  */
-		    || (reload_in_progress && GET_CODE (op) == REG
-			&& REGNO (op) >= FIRST_PSEUDO_REGISTER))
-		  win = 1;
-		break;
-
-	      case '<':
-		if (GET_CODE (op) == MEM
-		    && (GET_CODE (XEXP (op, 0)) == PRE_DEC
-			|| GET_CODE (XEXP (op, 0)) == POST_DEC))
-		  win = 1;
-		break;
-
-	      case '>':
-		if (GET_CODE (op) == MEM
-		    && (GET_CODE (XEXP (op, 0)) == PRE_INC
-			|| GET_CODE (XEXP (op, 0)) == POST_INC))
-		  win = 1;
-		break;
-
-	      case 'E':
+        int opno;
+        int lose = 0;
+        funny_match_index = 0;
+        
+        for (opno = 0; opno < recog_data.n_operands; opno++)
+        {
+            rtx op = recog_data.operand[opno];
+            enum machine_mode mode = GET_MODE (op);
+            const char *p = constraints[opno];
+            int offset = 0;
+            int win = 0;
+            int val;
+            
+            earlyclobber[opno] = 0;
+            
+            /* A unary operator may be accepted by the predicate, but it
+             is irrelevant for matching constraints.  */
+            if (GET_RTX_CLASS (GET_CODE (op)) == '1')
+                op = XEXP (op, 0);
+            
+            if (GET_CODE (op) == SUBREG)
+            {
+                if (GET_CODE (SUBREG_REG (op)) == REG
+                    && REGNO (SUBREG_REG (op)) < FIRST_PSEUDO_REGISTER)
+                    offset = subreg_regno_offset (REGNO (SUBREG_REG (op)),
+                                                  GET_MODE (SUBREG_REG (op)),
+                                                  SUBREG_BYTE (op),
+                                                  GET_MODE (op));
+                op = SUBREG_REG (op);
+            }
+            
+            /* An empty constraint or empty alternative
+             allows anything which matched the pattern.  */
+            if (*p == 0 || *p == ',')
+                win = 1;
+            
+            while (*p && (c = *p++) != ',')
+                switch (c)
+                {
+                    case '?':  case '!': case '*':  case '%':
+                    case '=':  case '+':
+                        break;
+                        
+                    case '#':
+                        /* Ignore rest of this alternative as far as
+                         constraint checking is concerned.  */
+                        while (*p && *p != ',')
+                            p++;
+                        break;
+                        
+                    case '&':
+                        earlyclobber[opno] = 1;
+                        break;
+                        
+                    case '0':  case '1':  case '2':  case '3':  case '4':
+                    case '5':  case '6':  case '7':  case '8':  case '9':
+                    {
+                        /* This operand must be the same as a previous one.
+                         This kind of constraint is used for instructions such
+                         as add when they take only two operands.
+                         
+                         Note that the lower-numbered operand is passed first.
+                         
+                         If we are not testing strictly, assume that this
+                         constraint will be satisfied.  */
+                        
+                        char *end;
+                        int match;
+                        
+                        match = strtoul (p - 1, &end, 10);
+                        p = end;
+                        
+                        if (strict < 0)
+                            val = 1;
+                        else
+                        {
+                            rtx op1 = recog_data.operand[match];
+                            rtx op2 = recog_data.operand[opno];
+                            
+                            /* A unary operator may be accepted by the predicate,
+                             but it is irrelevant for matching constraints.  */
+                            if (GET_RTX_CLASS (GET_CODE (op1)) == '1')
+                                op1 = XEXP (op1, 0);
+                            if (GET_RTX_CLASS (GET_CODE (op2)) == '1')
+                                op2 = XEXP (op2, 0);
+                            
+                            val = operands_match_p (op1, op2);
+                        }
+                        
+                        matching_operands[opno] = match;
+                        matching_operands[match] = opno;
+                        
+                        if (val != 0)
+                            win = 1;
+                        
+                        /* If output is *x and input is *--x, arrange later
+                         to change the output to *--x as well, since the
+                         output op is the one that will be printed.  */
+                        if (val == 2 && strict > 0)
+                        {
+                            funny_match[funny_match_index].this = opno;
+                            funny_match[funny_match_index++].other = match;
+                        }
+                    }
+                        break;
+                        
+                    case 'p':
+                        /* p is used for address_operands.  When we are called by
+                         gen_reload, no one will have checked that the address is
+                         strictly valid, i.e., that all pseudos requiring hard regs
+                         have gotten them.  */
+                        if (strict <= 0
+                            || (strict_memory_address_p (recog_data.operand_mode[opno],
+                                                         op)))
+                            win = 1;
+                        break;
+                        
+                        /* No need to check general_operand again;
+                         it was done in insn-recog.c.  */
+                    case 'g':
+                        /* Anything goes unless it is a REG and really has a hard reg
+                         but the hard reg is not in the class GENERAL_REGS.  */
+                        if (strict < 0
+                            || GENERAL_REGS == ALL_REGS
+                            || GET_CODE (op) != REG
+                            || (reload_in_progress
+                                && REGNO (op) >= FIRST_PSEUDO_REGISTER)
+                            || reg_fits_class_p (op, GENERAL_REGS, offset, mode))
+                            win = 1;
+                        break;
+                        
+                    case 'X':
+                        /* This is used for a MATCH_SCRATCH in the cases when
+                         we don't actually need anything.  So anything goes
+                         any time.  */
+                        win = 1;
+                        break;
+                        
+                    case 'm':
+                        if (GET_CODE (op) == MEM
+                            /* Before reload, accept what reload can turn into mem.  */
+                            || (strict < 0 && CONSTANT_P (op))
+                            /* During reload, accept a pseudo  */
+                            || (reload_in_progress && GET_CODE (op) == REG
+                                && REGNO (op) >= FIRST_PSEUDO_REGISTER))
+                            win = 1;
+                        break;
+                        
+                    case '<':
+                        if (GET_CODE (op) == MEM
+                            && (GET_CODE (XEXP (op, 0)) == PRE_DEC
+                                || GET_CODE (XEXP (op, 0)) == POST_DEC))
+                            win = 1;
+                        break;
+                        
+                    case '>':
+                        if (GET_CODE (op) == MEM
+                            && (GET_CODE (XEXP (op, 0)) == PRE_INC
+                                || GET_CODE (XEXP (op, 0)) == POST_INC))
+                            win = 1;
+                        break;
+                        
+                    case 'E':
 #ifndef REAL_ARITHMETIC
-		/* Match any CONST_DOUBLE, but only if
-		   we can examine the bits of it reliably.  */
-		if ((HOST_FLOAT_FORMAT != TARGET_FLOAT_FORMAT
-		     || HOST_BITS_PER_WIDE_INT != BITS_PER_WORD)
-		    && GET_MODE (op) != VOIDmode && ! flag_pretend_float)
-		  break;
+                        /* Match any CONST_DOUBLE, but only if
+                         we can examine the bits of it reliably.  */
+                        if ((HOST_FLOAT_FORMAT != TARGET_FLOAT_FORMAT
+                             || HOST_BITS_PER_WIDE_INT != BITS_PER_WORD)
+                            && GET_MODE (op) != VOIDmode && ! flag_pretend_float)
+                            break;
 #endif
-		if (GET_CODE (op) == CONST_DOUBLE)
-		  win = 1;
-		break;
-
-	      case 'F':
-		if (GET_CODE (op) == CONST_DOUBLE)
-		  win = 1;
-		break;
-
-	      case 'G':
-	      case 'H':
-		if (GET_CODE (op) == CONST_DOUBLE
-		    && CONST_DOUBLE_OK_FOR_LETTER_P (op, c))
-		  win = 1;
-		break;
-
-	      case 's':
-		if (GET_CODE (op) == CONST_INT
-		    || (GET_CODE (op) == CONST_DOUBLE
-			&& GET_MODE (op) == VOIDmode))
-		  break;
-	      case 'i':
-		if (CONSTANT_P (op))
-		  win = 1;
-		break;
-
-	      case 'n':
-		if (GET_CODE (op) == CONST_INT
-		    || (GET_CODE (op) == CONST_DOUBLE
-			&& GET_MODE (op) == VOIDmode))
-		  win = 1;
-		break;
-
-	      case 'I':
-	      case 'J':
-	      case 'K':
-	      case 'L':
-	      case 'M':
-	      case 'N':
-	      case 'O':
-	      case 'P':
-		if (GET_CODE (op) == CONST_INT
-		    && CONST_OK_FOR_LETTER_P (INTVAL (op), c))
-		  win = 1;
-		break;
-
-	      case 'V':
-		if (GET_CODE (op) == MEM
-		    && ((strict > 0 && ! offsettable_memref_p (op))
-			|| (strict < 0
-			    && !(CONSTANT_P (op) || GET_CODE (op) == MEM))
-			|| (reload_in_progress
-			    && !(GET_CODE (op) == REG
-				 && REGNO (op) >= FIRST_PSEUDO_REGISTER))))
-		  win = 1;
-		break;
-
-	      case 'o':
-		if ((strict > 0 && offsettable_memref_p (op))
-		    || (strict == 0 && offsettable_nonstrict_memref_p (op))
-		    /* Before reload, accept what reload can handle.  */
-		    || (strict < 0
-			&& (CONSTANT_P (op) || GET_CODE (op) == MEM))
-		    /* During reload, accept a pseudo  */
-		    || (reload_in_progress && GET_CODE (op) == REG
-			&& REGNO (op) >= FIRST_PSEUDO_REGISTER))
-		  win = 1;
-		break;
-
-	      default:
-		{
-		  enum reg_class class;
-
-		  class = (c == 'r' ? GENERAL_REGS : REG_CLASS_FROM_LETTER (c));
-		  if (class != NO_REGS)
-		    {
-		      if (strict < 0
-			  || (strict == 0
-			      && GET_CODE (op) == REG
-			      && REGNO (op) >= FIRST_PSEUDO_REGISTER)
-			  || (strict == 0 && GET_CODE (op) == SCRATCH)
-			  || (GET_CODE (op) == REG
-			      && reg_fits_class_p (op, class, offset, mode)))
-		        win = 1;
-		    }
+                        if (GET_CODE (op) == CONST_DOUBLE)
+                            win = 1;
+                        break;
+                        
+                    case 'F':
+                        if (GET_CODE (op) == CONST_DOUBLE)
+                            win = 1;
+                        break;
+                        
+                    case 'G':
+                    case 'H':
+                        if (GET_CODE (op) == CONST_DOUBLE
+                            && CONST_DOUBLE_OK_FOR_LETTER_P (op, c))
+                            win = 1;
+                        break;
+                        
+                    case 's':
+                        if (GET_CODE (op) == CONST_INT
+                            || (GET_CODE (op) == CONST_DOUBLE
+                                && GET_MODE (op) == VOIDmode))
+                            break;
+                    case 'i':
+                        if (CONSTANT_P (op))
+                            win = 1;
+                        break;
+                        
+                    case 'n':
+                        if (GET_CODE (op) == CONST_INT
+                            || (GET_CODE (op) == CONST_DOUBLE
+                                && GET_MODE (op) == VOIDmode))
+                            win = 1;
+                        break;
+                        
+                    case 'I':
+                    case 'J':
+                    case 'K':
+                    case 'L':
+                    case 'M':
+                    case 'N':
+                    case 'O':
+                    case 'P':
+                        if (GET_CODE (op) == CONST_INT
+                            && CONST_OK_FOR_LETTER_P (INTVAL (op), c))
+                            win = 1;
+                        break;
+                        
+                    case 'V':
+                        if (GET_CODE (op) == MEM
+                            && ((strict > 0 && ! offsettable_memref_p (op))
+                                || (strict < 0
+                                    && !(CONSTANT_P (op) || GET_CODE (op) == MEM))
+                                || (reload_in_progress
+                                    && !(GET_CODE (op) == REG
+                                         && REGNO (op) >= FIRST_PSEUDO_REGISTER))))
+                            win = 1;
+                        break;
+                        
+                    case 'o':
+                        if ((strict > 0 && offsettable_memref_p (op))
+                            || (strict == 0 && offsettable_nonstrict_memref_p (op))
+                            /* Before reload, accept what reload can handle.  */
+                            || (strict < 0
+                                && (CONSTANT_P (op) || GET_CODE (op) == MEM))
+                            /* During reload, accept a pseudo  */
+                            || (reload_in_progress && GET_CODE (op) == REG
+                                && REGNO (op) >= FIRST_PSEUDO_REGISTER))
+                            win = 1;
+                        break;
+                        
+                    default:
+                    {
+                        enum reg_class class;
+                        
+                        class = (c == 'r' ? GENERAL_REGS : REG_CLASS_FROM_LETTER (c));
+                        if (class != NO_REGS)
+                        {
+                            if (strict < 0
+                                || (strict == 0
+                                    && GET_CODE (op) == REG
+                                    && REGNO (op) >= FIRST_PSEUDO_REGISTER)
+                                || (strict == 0 && GET_CODE (op) == SCRATCH)
+                                || (GET_CODE (op) == REG
+                                    && reg_fits_class_p (op, class, offset, mode)))
+                                win = 1;
+                        }
 #ifdef EXTRA_CONSTRAINT
-		  else if (EXTRA_CONSTRAINT (op, c))
-		    win = 1;
+                        else if (EXTRA_CONSTRAINT (op, c))
+                            win = 1;
 #endif
-		  break;
-		}
-	      }
-
-	  constraints[opno] = p;
-	  /* If this operand did not win somehow,
-	     this alternative loses.  */
-	  if (! win)
-	    lose = 1;
-	}
-      /* This alternative won; the operands are ok.
-	 Change whichever operands this alternative says to change.  */
-      if (! lose)
-	{
-	  int opno, eopno;
-
-	  /* See if any earlyclobber operand conflicts with some other
-	     operand.  */
-
-	  if (strict > 0)
-	    for (eopno = 0; eopno < recog_data.n_operands; eopno++)
-	      /* Ignore earlyclobber operands now in memory,
-		 because we would often report failure when we have
-		 two memory operands, one of which was formerly a REG.  */
-	      if (earlyclobber[eopno]
-		  && GET_CODE (recog_data.operand[eopno]) == REG)
-		for (opno = 0; opno < recog_data.n_operands; opno++)
-		  if ((GET_CODE (recog_data.operand[opno]) == MEM
-		       || recog_data.operand_type[opno] != OP_OUT)
-		      && opno != eopno
-		      /* Ignore things like match_operator operands.  */
-		      && *recog_data.constraints[opno] != 0
-		      && ! (matching_operands[opno] == eopno
-			    && operands_match_p (recog_data.operand[opno],
-						 recog_data.operand[eopno]))
-		      && ! safe_from_earlyclobber (recog_data.operand[opno],
-						   recog_data.operand[eopno]))
-		    lose = 1;
-
-	  if (! lose)
-	    {
-	      while (--funny_match_index >= 0)
-		{
-		  recog_data.operand[funny_match[funny_match_index].other]
-		    = recog_data.operand[funny_match[funny_match_index].this];
-		}
-
-	      return 1;
-	    }
-	}
-
-      which_alternative++;
+                        break;
+                    }
+                }
+            
+            constraints[opno] = p;
+            /* If this operand did not win somehow,
+             this alternative loses.  */
+            if (! win)
+                lose = 1;
+        }
+        /* This alternative won; the operands are ok.
+         Change whichever operands this alternative says to change.  */
+        if (! lose)
+        {
+            int opno, eopno;
+            
+            /* See if any earlyclobber operand conflicts with some other
+             operand.  */
+            
+            if (strict > 0)
+                for (eopno = 0; eopno < recog_data.n_operands; eopno++)
+            /* Ignore earlyclobber operands now in memory,
+             because we would often report failure when we have
+             two memory operands, one of which was formerly a REG.  */
+            if (earlyclobber[eopno]
+                && GET_CODE (recog_data.operand[eopno]) == REG)
+                for (opno = 0; opno < recog_data.n_operands; opno++)
+            if ((GET_CODE (recog_data.operand[opno]) == MEM
+                 || recog_data.operand_type[opno] != OP_OUT)
+                && opno != eopno
+                /* Ignore things like match_operator operands.  */
+                && *recog_data.constraints[opno] != 0
+                && ! (matching_operands[opno] == eopno
+                      && operands_match_p (recog_data.operand[opno],
+                                           recog_data.operand[eopno]))
+                && ! safe_from_earlyclobber (recog_data.operand[opno],
+                                             recog_data.operand[eopno]))
+                lose = 1;
+            
+            if (! lose)
+            {
+                while (--funny_match_index >= 0)
+                {
+                    recog_data.operand[funny_match[funny_match_index].other]
+                    = recog_data.operand[funny_match[funny_match_index].this];
+                }
+                
+                return 1;
+            }
+        }
+        
+        which_alternative++;
     }
-  while (which_alternative < recog_data.n_alternatives);
-
-  which_alternative = -1;
-  /* If we are about to reject this, but we are not to test strictly,
+    while (which_alternative < recog_data.n_alternatives);
+    
+    which_alternative = -1;
+    /* If we are about to reject this, but we are not to test strictly,
      try a very loose test.  Only return failure if it fails also.  */
-  if (strict == 0)
-    return constrain_operands (-1);
-  else
-    return 0;
+    if (strict == 0)
+        return constrain_operands (-1);
+    else
+        return 0;
 }
 
 /* Return 1 iff OPERAND (assumed to be a REG rtx)
-   is a hard reg in class CLASS when its regno is offset by OFFSET
-   and changed to mode MODE.
-   If REG occupies multiple hard regs, all of them must be in CLASS.  */
+ is a hard reg in class CLASS when its regno is offset by OFFSET
+ and changed to mode MODE.
+ If REG occupies multiple hard regs, all of them must be in CLASS.  */
 
 int
 reg_fits_class_p (operand, class, offset, mode)
-     rtx operand;
-     enum reg_class class;
-     int offset;
-     enum machine_mode mode;
+rtx operand;
+enum reg_class class;
+int offset;
+enum machine_mode mode;
 {
-  int regno = REGNO (operand);
-  if (regno < FIRST_PSEUDO_REGISTER
-      && TEST_HARD_REG_BIT (reg_class_contents[(int) class],
-			    regno + offset))
+    int regno = REGNO (operand);
+    if (regno < FIRST_PSEUDO_REGISTER
+        && TEST_HARD_REG_BIT (reg_class_contents[(int) class],
+                              regno + offset))
     {
-      int sr;
-      regno += offset;
-      for (sr = HARD_REGNO_NREGS (regno, mode) - 1;
-	   sr > 0; sr--)
-	if (! TEST_HARD_REG_BIT (reg_class_contents[(int) class],
-				 regno + sr))
-	  break;
-      return sr == 0;
+        int sr;
+        regno += offset;
+        for (sr = HARD_REGNO_NREGS (regno, mode) - 1;
+             sr > 0; sr--)
+        if (! TEST_HARD_REG_BIT (reg_class_contents[(int) class],
+                                 regno + sr))
+            break;
+        return sr == 0;
     }
-
-  return 0;
+    
+    return 0;
 }
 
 /* Split single instruction.  Helper function for split_all_insns.
-   Return last insn in the sequence if successful, or NULL if unsuccessful.  */
+ Return last insn in the sequence if successful, or NULL if unsuccessful.  */
 static rtx
 split_insn (insn)
-     rtx insn;
+rtx insn;
 {
-  rtx set;
-  if (!INSN_P (insn))
-    ;
-  /* Don't split no-op move insns.  These should silently
+    rtx set;
+    if (!INSN_P (insn))
+        ;
+    /* Don't split no-op move insns.  These should silently
      disappear later in final.  Splitting such insns would
      break the code that handles REG_NO_CONFLICT blocks.  */
-
-  else if ((set = single_set (insn)) != NULL && set_noop_p (set))
+    
+    else if ((set = single_set (insn)) != NULL && set_noop_p (set))
     {
-      /* Nops get in the way while scheduling, so delete them
+        /* Nops get in the way while scheduling, so delete them
          now if register allocation has already been done.  It
          is too risky to try to do this before register
          allocation, and there are unlikely to be very many
          nops then anyways.  */
-      if (reload_completed)
-	{
-	  PUT_CODE (insn, NOTE);
-	  NOTE_LINE_NUMBER (insn) = NOTE_INSN_DELETED;
-	  NOTE_SOURCE_FILE (insn) = 0;
-	}
+        if (reload_completed)
+        {
+            PUT_CODE (insn, NOTE);
+            NOTE_LINE_NUMBER (insn) = NOTE_INSN_DELETED;
+            NOTE_SOURCE_FILE (insn) = 0;
+        }
     }
-  else
+    else
     {
-      /* Split insns here to get max fine-grain parallelism.  */
-      rtx first = PREV_INSN (insn);
-      rtx last = try_split (PATTERN (insn), insn, 1);
-
-      if (last != insn)
-	{
-	  /* try_split returns the NOTE that INSN became.  */
-	  PUT_CODE (insn, NOTE);
-	  NOTE_SOURCE_FILE (insn) = 0;
-	  NOTE_LINE_NUMBER (insn) = NOTE_INSN_DELETED;
-
-	  /* ??? Coddle to md files that generate subregs in post-
-	     reload splitters instead of computing the proper 
-	     hard register.  */
-	  if (reload_completed && first != last)
-	    {
-	      first = NEXT_INSN (first);
-	      while (1)
-		{
-		  if (INSN_P (first))
-		    cleanup_subreg_operands (first);
-		  if (first == last)
-		    break;
-		  first = NEXT_INSN (first);
-		}
-	    }
-	  return last;
-	}
+        /* Split insns here to get max fine-grain parallelism.  */
+        rtx first = PREV_INSN (insn);
+        rtx last = try_split (PATTERN (insn), insn, 1);
+        
+        if (last != insn)
+        {
+            /* try_split returns the NOTE that INSN became.  */
+            PUT_CODE (insn, NOTE);
+            NOTE_SOURCE_FILE (insn) = 0;
+            NOTE_LINE_NUMBER (insn) = NOTE_INSN_DELETED;
+            
+            /* ??? Coddle to md files that generate subregs in post-
+             reload splitters instead of computing the proper
+             hard register.  */
+            if (reload_completed && first != last)
+            {
+                first = NEXT_INSN (first);
+                while (1)
+                {
+                    if (INSN_P (first))
+                        cleanup_subreg_operands (first);
+                    if (first == last)
+                        break;
+                    first = NEXT_INSN (first);
+                }
+            }
+            return last;
+        }
     }
-  return NULL_RTX;
+    return NULL_RTX;
 }
 /* Split all insns in the function.  If UPD_LIFE, update life info after.  */
 
 void
 split_all_insns (upd_life)
-     int upd_life;
+int upd_life;
 {
-  sbitmap blocks;
-  int changed;
-  int i;
-
-  blocks = sbitmap_alloc (n_basic_blocks);
-  sbitmap_zero (blocks);
-  changed = 0;
-
-  for (i = n_basic_blocks - 1; i >= 0; --i)
+    sbitmap blocks;
+    int changed;
+    int i;
+    
+    blocks = sbitmap_alloc (n_basic_blocks);
+    sbitmap_zero (blocks);
+    changed = 0;
+    
+    for (i = n_basic_blocks - 1; i >= 0; --i)
     {
-      basic_block bb = BASIC_BLOCK (i);
-      rtx insn, next;
-
-      for (insn = bb->head; insn ; insn = next)
-	{
-	  rtx last;
-
-	  /* Can't use `next_real_insn' because that might go across
-	     CODE_LABELS and short-out basic blocks.  */
-	  next = NEXT_INSN (insn);
-	  last = split_insn (insn);
-	  if (last)
-	    {
-	      /* The split sequence may include barrier, but the
-		 BB boundary we are interested in will be set to previous
-		 one.  */
-
-	      while (GET_CODE (last) == BARRIER)
-		last = PREV_INSN (last);
-	      SET_BIT (blocks, i);
-	      changed = 1;
-	      insn = last;
-	    }
-
-	  if (insn == bb->end)
-	    break;
-	}
-
-      if (insn == NULL)
-	abort ();
+        basic_block bb = BASIC_BLOCK (i);
+        rtx insn, next;
+        
+        for (insn = bb->head; insn ; insn = next)
+        {
+            rtx last;
+            
+            /* Can't use `next_real_insn' because that might go across
+             CODE_LABELS and short-out basic blocks.  */
+            next = NEXT_INSN (insn);
+            last = split_insn (insn);
+            if (last)
+            {
+                /* The split sequence may include barrier, but the
+                 BB boundary we are interested in will be set to previous
+                 one.  */
+                
+                while (GET_CODE (last) == BARRIER)
+                    last = PREV_INSN (last);
+                SET_BIT (blocks, i);
+                changed = 1;
+                insn = last;
+            }
+            
+            if (insn == bb->end)
+                break;
+        }
+        
+        if (insn == NULL)
+            abort ();
     }
-
-  if (changed)
+    
+    if (changed)
     {
-      find_many_sub_basic_blocks (blocks);
+        find_many_sub_basic_blocks (blocks);
     }
-
-  if (changed && upd_life)
+    
+    if (changed && upd_life)
     {
-      count_or_remove_death_notes (blocks, 1);
-      update_life_info (blocks, UPDATE_LIFE_LOCAL, PROP_DEATH_NOTES);
+        count_or_remove_death_notes (blocks, 1);
+        update_life_info (blocks, UPDATE_LIFE_LOCAL, PROP_DEATH_NOTES);
     }
 #ifdef ENABLE_CHECKING
-  verify_flow_info ();
+    verify_flow_info ();
 #endif
-
-  sbitmap_free (blocks);
+    
+    sbitmap_free (blocks);
 }
 
 /* Same as split_all_insns, but do not expect CFG to be available. 
-   Used by machine depedent reorg passes.  */
+ Used by machine depedent reorg passes.  */
 
 void
 split_all_insns_noflow ()
 {
-  rtx next, insn;
-
-  for (insn = get_insns (); insn; insn = next)
+    rtx next, insn;
+    
+    for (insn = get_insns (); insn; insn = next)
     {
-      next = NEXT_INSN (insn);
-      split_insn (insn);
+        next = NEXT_INSN (insn);
+        split_insn (insn);
     }
-  return;
+    return;
 }
 
 #ifdef HAVE_peephole2
 struct peep2_insn_data
 {
-  rtx insn;
-  regset live_before;
+    rtx insn;
+    regset live_before;
 };
 
 static struct peep2_insn_data peep2_insn_data[MAX_INSNS_PER_PEEP2 + 1];
 static int peep2_current;
 
 /* A non-insn marker indicating the last insn of the block.
-   The live_before regset for this element is correct, indicating
-   global_live_at_end for the block.  */
+ The live_before regset for this element is correct, indicating
+ global_live_at_end for the block.  */
 #define PEEP2_EOB	pc_rtx
 
 /* Return the Nth non-note insn after `current', or return NULL_RTX if it
-   does not exist.  Used by the recognizer to find the next insn to match
-   in a multi-insn pattern.  */
+ does not exist.  Used by the recognizer to find the next insn to match
+ in a multi-insn pattern.  */
 
 rtx
 peep2_next_insn (n)
-     int n;
+int n;
 {
-  if (n >= MAX_INSNS_PER_PEEP2 + 1)
-    abort ();
-
-  n += peep2_current;
-  if (n >= MAX_INSNS_PER_PEEP2 + 1)
-    n -= MAX_INSNS_PER_PEEP2 + 1;
-
-  if (peep2_insn_data[n].insn == PEEP2_EOB)
-    return NULL_RTX;
-  return peep2_insn_data[n].insn;
+    if (n >= MAX_INSNS_PER_PEEP2 + 1)
+        abort ();
+    
+    n += peep2_current;
+    if (n >= MAX_INSNS_PER_PEEP2 + 1)
+        n -= MAX_INSNS_PER_PEEP2 + 1;
+    
+    if (peep2_insn_data[n].insn == PEEP2_EOB)
+        return NULL_RTX;
+    return peep2_insn_data[n].insn;
 }
 
 /* Return true if REGNO is dead before the Nth non-note insn
-   after `current'.  */
+ after `current'.  */
 
 int
 peep2_regno_dead_p (ofs, regno)
-     int ofs;
-     int regno;
+int ofs;
+int regno;
 {
-  if (ofs >= MAX_INSNS_PER_PEEP2 + 1)
-    abort ();
-
-  ofs += peep2_current;
-  if (ofs >= MAX_INSNS_PER_PEEP2 + 1)
-    ofs -= MAX_INSNS_PER_PEEP2 + 1;
-
-  if (peep2_insn_data[ofs].insn == NULL_RTX)
-    abort ();
-
-  return ! REGNO_REG_SET_P (peep2_insn_data[ofs].live_before, regno);
+    if (ofs >= MAX_INSNS_PER_PEEP2 + 1)
+        abort ();
+    
+    ofs += peep2_current;
+    if (ofs >= MAX_INSNS_PER_PEEP2 + 1)
+        ofs -= MAX_INSNS_PER_PEEP2 + 1;
+    
+    if (peep2_insn_data[ofs].insn == NULL_RTX)
+        abort ();
+    
+    return ! REGNO_REG_SET_P (peep2_insn_data[ofs].live_before, regno);
 }
 
 /* Similarly for a REG.  */
 
 int
 peep2_reg_dead_p (ofs, reg)
-     int ofs;
-     rtx reg;
+int ofs;
+rtx reg;
 {
-  int regno, n;
-
-  if (ofs >= MAX_INSNS_PER_PEEP2 + 1)
-    abort ();
-
-  ofs += peep2_current;
-  if (ofs >= MAX_INSNS_PER_PEEP2 + 1)
-    ofs -= MAX_INSNS_PER_PEEP2 + 1;
-
-  if (peep2_insn_data[ofs].insn == NULL_RTX)
-    abort ();
-
-  regno = REGNO (reg);
-  n = HARD_REGNO_NREGS (regno, GET_MODE (reg));
-  while (--n >= 0)
-    if (REGNO_REG_SET_P (peep2_insn_data[ofs].live_before, regno + n))
-      return 0;
-  return 1;
+    int regno, n;
+    
+    if (ofs >= MAX_INSNS_PER_PEEP2 + 1)
+        abort ();
+    
+    ofs += peep2_current;
+    if (ofs >= MAX_INSNS_PER_PEEP2 + 1)
+        ofs -= MAX_INSNS_PER_PEEP2 + 1;
+    
+    if (peep2_insn_data[ofs].insn == NULL_RTX)
+        abort ();
+    
+    regno = REGNO (reg);
+    n = HARD_REGNO_NREGS (regno, GET_MODE (reg));
+    while (--n >= 0)
+        if (REGNO_REG_SET_P (peep2_insn_data[ofs].live_before, regno + n))
+            return 0;
+    return 1;
 }
 
 /* Try to find a hard register of mode MODE, matching the register class in
-   CLASS_STR, which is available at the beginning of insn CURRENT_INSN and
-   remains available until the end of LAST_INSN.  LAST_INSN may be NULL_RTX,
-   in which case the only condition is that the register must be available
-   before CURRENT_INSN.
-   Registers that already have bits set in REG_SET will not be considered.
-
-   If an appropriate register is available, it will be returned and the
-   corresponding bit(s) in REG_SET will be set; otherwise, NULL_RTX is
-   returned.  */
+ CLASS_STR, which is available at the beginning of insn CURRENT_INSN and
+ remains available until the end of LAST_INSN.  LAST_INSN may be NULL_RTX,
+ in which case the only condition is that the register must be available
+ before CURRENT_INSN.
+ Registers that already have bits set in REG_SET will not be considered.
+ 
+ If an appropriate register is available, it will be returned and the
+ corresponding bit(s) in REG_SET will be set; otherwise, NULL_RTX is
+ returned.  */
 
 rtx
 peep2_find_free_register (from, to, class_str, mode, reg_set)
-     int from, to;
-     const char *class_str;
-     enum machine_mode mode;
-     HARD_REG_SET *reg_set;
+int from, to;
+const char *class_str;
+enum machine_mode mode;
+HARD_REG_SET *reg_set;
 {
-  static int search_ofs;
-  enum reg_class class;
-  HARD_REG_SET live;
-  int i;
-
-  if (from >= MAX_INSNS_PER_PEEP2 + 1 || to >= MAX_INSNS_PER_PEEP2 + 1)
-    abort ();
-
-  from += peep2_current;
-  if (from >= MAX_INSNS_PER_PEEP2 + 1)
-    from -= MAX_INSNS_PER_PEEP2 + 1;
-  to += peep2_current;
-  if (to >= MAX_INSNS_PER_PEEP2 + 1)
-    to -= MAX_INSNS_PER_PEEP2 + 1;
-
-  if (peep2_insn_data[from].insn == NULL_RTX)
-    abort ();
-  REG_SET_TO_HARD_REG_SET (live, peep2_insn_data[from].live_before);
-
-  while (from != to)
+    static int search_ofs;
+    enum reg_class class;
+    HARD_REG_SET live;
+    int i;
+    
+    if (from >= MAX_INSNS_PER_PEEP2 + 1 || to >= MAX_INSNS_PER_PEEP2 + 1)
+        abort ();
+    
+    from += peep2_current;
+    if (from >= MAX_INSNS_PER_PEEP2 + 1)
+        from -= MAX_INSNS_PER_PEEP2 + 1;
+    to += peep2_current;
+    if (to >= MAX_INSNS_PER_PEEP2 + 1)
+        to -= MAX_INSNS_PER_PEEP2 + 1;
+    
+    if (peep2_insn_data[from].insn == NULL_RTX)
+        abort ();
+    REG_SET_TO_HARD_REG_SET (live, peep2_insn_data[from].live_before);
+    
+    while (from != to)
     {
-      HARD_REG_SET this_live;
-
-      if (++from >= MAX_INSNS_PER_PEEP2 + 1)
-	from = 0;
-      if (peep2_insn_data[from].insn == NULL_RTX)
-	abort ();
-      REG_SET_TO_HARD_REG_SET (this_live, peep2_insn_data[from].live_before);
-      IOR_HARD_REG_SET (live, this_live);
+        HARD_REG_SET this_live;
+        
+        if (++from >= MAX_INSNS_PER_PEEP2 + 1)
+            from = 0;
+        if (peep2_insn_data[from].insn == NULL_RTX)
+            abort ();
+        REG_SET_TO_HARD_REG_SET (this_live, peep2_insn_data[from].live_before);
+        IOR_HARD_REG_SET (live, this_live);
     }
-
-  class = (class_str[0] == 'r' ? GENERAL_REGS
-	   : REG_CLASS_FROM_LETTER (class_str[0]));
-
-  for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)
+    
+    class = (class_str[0] == 'r' ? GENERAL_REGS
+             : REG_CLASS_FROM_LETTER (class_str[0]));
+    
+    for (i = 0; i < FIRST_PSEUDO_REGISTER; i++)
     {
-      int raw_regno, regno, success, j;
-
-      /* Distribute the free registers as much as possible.  */
-      raw_regno = search_ofs + i;
-      if (raw_regno >= FIRST_PSEUDO_REGISTER)
-	raw_regno -= FIRST_PSEUDO_REGISTER;
+        int raw_regno, regno, success, j;
+        
+        /* Distribute the free registers as much as possible.  */
+        raw_regno = search_ofs + i;
+        if (raw_regno >= FIRST_PSEUDO_REGISTER)
+            raw_regno -= FIRST_PSEUDO_REGISTER;
 #ifdef REG_ALLOC_ORDER
-      regno = reg_alloc_order[raw_regno];
+        regno = reg_alloc_order[raw_regno];
 #else
-      regno = raw_regno;
+        regno = raw_regno;
 #endif
-
-      /* Don't allocate fixed registers.  */
-      if (fixed_regs[regno])
-	continue;
-      /* Make sure the register is of the right class.  */
-      if (! TEST_HARD_REG_BIT (reg_class_contents[class], regno))
-	continue;
-      /* And can support the mode we need.  */
-      if (! HARD_REGNO_MODE_OK (regno, mode))
-	continue;
-      /* And that we don't create an extra save/restore.  */
-      if (! call_used_regs[regno] && ! regs_ever_live[regno])
-	continue;
-      /* And we don't clobber traceback for noreturn functions.  */
-      if ((regno == FRAME_POINTER_REGNUM || regno == HARD_FRAME_POINTER_REGNUM)
-	  && (! reload_completed || frame_pointer_needed))
-	continue;
-
-      success = 1;
-      for (j = HARD_REGNO_NREGS (regno, mode) - 1; j >= 0; j--)
-	{
-	  if (TEST_HARD_REG_BIT (*reg_set, regno + j)
-	      || TEST_HARD_REG_BIT (live, regno + j))
-	    {
-	      success = 0;
-	      break;
-	    }
-	}
-      if (success)
-	{
-	  for (j = HARD_REGNO_NREGS (regno, mode) - 1; j >= 0; j--)
-	    SET_HARD_REG_BIT (*reg_set, regno + j);
-
-	  /* Start the next search with the next register.  */
-	  if (++raw_regno >= FIRST_PSEUDO_REGISTER)
-	    raw_regno = 0;
-	  search_ofs = raw_regno;
-
-	  return gen_rtx_REG (mode, regno);
-	}
+        
+        /* Don't allocate fixed registers.  */
+        if (fixed_regs[regno])
+            continue;
+        /* Make sure the register is of the right class.  */
+        if (! TEST_HARD_REG_BIT (reg_class_contents[class], regno))
+            continue;
+        /* And can support the mode we need.  */
+        if (! HARD_REGNO_MODE_OK (regno, mode))
+            continue;
+        /* And that we don't create an extra save/restore.  */
+        if (! call_used_regs[regno] && ! regs_ever_live[regno])
+            continue;
+        /* And we don't clobber traceback for noreturn functions.  */
+        if ((regno == FRAME_POINTER_REGNUM || regno == HARD_FRAME_POINTER_REGNUM)
+            && (! reload_completed || frame_pointer_needed))
+            continue;
+        
+        success = 1;
+        for (j = HARD_REGNO_NREGS (regno, mode) - 1; j >= 0; j--)
+        {
+            if (TEST_HARD_REG_BIT (*reg_set, regno + j)
+                || TEST_HARD_REG_BIT (live, regno + j))
+            {
+                success = 0;
+                break;
+            }
+        }
+        if (success)
+        {
+            for (j = HARD_REGNO_NREGS (regno, mode) - 1; j >= 0; j--)
+            SET_HARD_REG_BIT (*reg_set, regno + j);
+            
+            /* Start the next search with the next register.  */
+            if (++raw_regno >= FIRST_PSEUDO_REGISTER)
+                raw_regno = 0;
+            search_ofs = raw_regno;
+            
+            return gen_rtx_REG (mode, regno);
+        }
     }
-
-  search_ofs = 0;
-  return NULL_RTX;
+    
+    search_ofs = 0;
+    return NULL_RTX;
 }
 
 /* Perform the peephole2 optimization pass.  */
 
 void
 peephole2_optimize (dump_file)
-     FILE *dump_file ATTRIBUTE_UNUSED;
+FILE *dump_file ATTRIBUTE_UNUSED;
 {
-  regset_head rs_heads[MAX_INSNS_PER_PEEP2 + 2];
-  rtx insn, prev;
-  regset live;
-  int i, b;
+    regset_head rs_heads[MAX_INSNS_PER_PEEP2 + 2];
+    rtx insn, prev;
+    regset live;
+    int i, b;
 #ifdef HAVE_conditional_execution
-  sbitmap blocks;
-  bool changed;
+    sbitmap blocks;
+    bool changed;
 #endif
-  bool do_cleanup_cfg = false;
-  bool do_rebuild_jump_labels = false;
-
-  /* Initialize the regsets we're going to use.  */
-  for (i = 0; i < MAX_INSNS_PER_PEEP2 + 1; ++i)
+    bool do_cleanup_cfg = false;
+    bool do_rebuild_jump_labels = false;
+    
+    /* Initialize the regsets we're going to use.  */
+    for (i = 0; i < MAX_INSNS_PER_PEEP2 + 1; ++i)
     peep2_insn_data[i].live_before = INITIALIZE_REG_SET (rs_heads[i]);
-  live = INITIALIZE_REG_SET (rs_heads[i]);
-
+    live = INITIALIZE_REG_SET (rs_heads[i]);
+    
 #ifdef HAVE_conditional_execution
-  blocks = sbitmap_alloc (n_basic_blocks);
-  sbitmap_zero (blocks);
-  changed = false;
+    blocks = sbitmap_alloc (n_basic_blocks);
+    sbitmap_zero (blocks);
+    changed = false;
 #else
-  count_or_remove_death_notes (NULL, 1);
+    count_or_remove_death_notes (NULL, 1);
 #endif
-
-  for (b = n_basic_blocks - 1; b >= 0; --b)
+    
+    for (b = n_basic_blocks - 1; b >= 0; --b)
     {
-      basic_block bb = BASIC_BLOCK (b);
-      struct propagate_block_info *pbi;
-
-      /* Indicate that all slots except the last holds invalid data.  */
-      for (i = 0; i < MAX_INSNS_PER_PEEP2; ++i)
-	peep2_insn_data[i].insn = NULL_RTX;
-
-      /* Indicate that the last slot contains live_after data.  */
-      peep2_insn_data[MAX_INSNS_PER_PEEP2].insn = PEEP2_EOB;
-      peep2_current = MAX_INSNS_PER_PEEP2;
-
-      /* Start up propagation.  */
-      COPY_REG_SET (live, bb->global_live_at_end);
-      COPY_REG_SET (peep2_insn_data[MAX_INSNS_PER_PEEP2].live_before, live);
-
+        basic_block bb = BASIC_BLOCK (b);
+        struct propagate_block_info *pbi;
+        
+        /* Indicate that all slots except the last holds invalid data.  */
+        for (i = 0; i < MAX_INSNS_PER_PEEP2; ++i)
+        peep2_insn_data[i].insn = NULL_RTX;
+        
+        /* Indicate that the last slot contains live_after data.  */
+        peep2_insn_data[MAX_INSNS_PER_PEEP2].insn = PEEP2_EOB;
+        peep2_current = MAX_INSNS_PER_PEEP2;
+        
+        /* Start up propagation.  */
+        COPY_REG_SET (live, bb->global_live_at_end);
+        COPY_REG_SET (peep2_insn_data[MAX_INSNS_PER_PEEP2].live_before, live);
+        
 #ifdef HAVE_conditional_execution
-      pbi = init_propagate_block_info (bb, live, NULL, NULL, 0);
+        pbi = init_propagate_block_info (bb, live, NULL, NULL, 0);
 #else
-      pbi = init_propagate_block_info (bb, live, NULL, NULL, PROP_DEATH_NOTES);
+        pbi = init_propagate_block_info (bb, live, NULL, NULL, PROP_DEATH_NOTES);
 #endif
-
-      for (insn = bb->end; ; insn = prev)
-	{
-	  prev = PREV_INSN (insn);
-	  if (INSN_P (insn))
-	    {
-	      rtx try, before_try, x;
-	      int match_len;
-	      rtx note;
-
-	      /* Record this insn.  */
-	      if (--peep2_current < 0)
-		peep2_current = MAX_INSNS_PER_PEEP2;
-	      peep2_insn_data[peep2_current].insn = insn;
-	      propagate_one_insn (pbi, insn);
-	      COPY_REG_SET (peep2_insn_data[peep2_current].live_before, live);
-
-	      /* Match the peephole.  */
-	      try = peephole2_insns (PATTERN (insn), insn, &match_len);
-	      if (try != NULL)
-		{
-		  /* If we are splitting a CALL_INSN, look for the CALL_INSN
-		     in SEQ and copy our CALL_INSN_FUNCTION_USAGE and other
-		     cfg-related call notes.  */
-		  for (i = 0; i <= match_len; ++i)
-		    {
-		      int j, k;
-		      rtx old_insn, new_insn, note;
-
-		      j = i + peep2_current;
-		      if (j >= MAX_INSNS_PER_PEEP2 + 1)
-			j -= MAX_INSNS_PER_PEEP2 + 1;
-		      old_insn = peep2_insn_data[j].insn;
-		      if (GET_CODE (old_insn) != CALL_INSN)
-			continue;
-
-		      new_insn = NULL_RTX;
-		      if (GET_CODE (try) == SEQUENCE)
-			for (k = XVECLEN (try, 0) - 1; k >= 0; k--)
-			  {
-			    rtx x = XVECEXP (try, 0, k);
-			    if (GET_CODE (x) == CALL_INSN)
-			      {
-				new_insn = x;
-				break;
-			      }
-			  }
-		      else if (GET_CODE (try) == CALL_INSN)
-			new_insn = try;
-		      if (! new_insn)
-			abort ();
-
-		      CALL_INSN_FUNCTION_USAGE (new_insn)
-			= CALL_INSN_FUNCTION_USAGE (old_insn);
-
-		      for (note = REG_NOTES (old_insn);
-			   note;
-			   note = XEXP (note, 1))
-			switch (REG_NOTE_KIND (note))
-			  {
-			  case REG_NORETURN:
-			  case REG_SETJMP:
-			  case REG_ALWAYS_RETURN:
-			    REG_NOTES (new_insn)
-			      = gen_rtx_EXPR_LIST (REG_NOTE_KIND (note),
-						   XEXP (note, 0),
-						   REG_NOTES (new_insn));
-			  default:
-			    /* Discard all other reg notes.  */
-			    break;
-			  }
-
-		      /* Croak if there is another call in the sequence.  */
-		      while (++i <= match_len)
-			{
-			  j = i + peep2_current;
-			  if (j >= MAX_INSNS_PER_PEEP2 + 1)
-			    j -= MAX_INSNS_PER_PEEP2 + 1;
-			  old_insn = peep2_insn_data[j].insn;
-			  if (GET_CODE (old_insn) == CALL_INSN)
-			    abort ();
-			}
-		      break;
-		    }
-
-		  i = match_len + peep2_current;
-		  if (i >= MAX_INSNS_PER_PEEP2 + 1)
-		    i -= MAX_INSNS_PER_PEEP2 + 1;
-
-		  note = find_reg_note (peep2_insn_data[i].insn, 
-					REG_EH_REGION, NULL_RTX);
-
-		  /* Replace the old sequence with the new.  */
-		  try = emit_insn_after (try, peep2_insn_data[i].insn);
-		  before_try = PREV_INSN (insn);
-		  delete_insn_chain (insn, peep2_insn_data[i].insn);
-
-		  /* Re-insert the EH_REGION notes.  */
-		  if (note)
-		    {
-		      edge eh_edge;
-
-		      for (eh_edge = bb->succ; eh_edge
-			   ; eh_edge = eh_edge->succ_next)
-			if (eh_edge->flags & EDGE_EH)
-			  break;
-
-		      for (x = try ; x != before_try ; x = PREV_INSN (x))
-			if (GET_CODE (x) == CALL_INSN
-			    || (flag_non_call_exceptions
-				&& may_trap_p (PATTERN (x))
-				&& !find_reg_note (x, REG_EH_REGION, NULL)))
-			  {
-			    REG_NOTES (x)
-			      = gen_rtx_EXPR_LIST (REG_EH_REGION,
-						   XEXP (note, 0),
-						   REG_NOTES (x));
-
-			    if (x != bb->end && eh_edge)
-			      {
-				edge nfte, nehe;
-				int flags;
-
-				nfte = split_block (bb, x);
-				flags = EDGE_EH | EDGE_ABNORMAL;
-				if (GET_CODE (x) == CALL_INSN)
-				  flags |= EDGE_ABNORMAL_CALL;
-				nehe = make_edge (nfte->src, eh_edge->dest,
-						  flags);
-
-				nehe->probability = eh_edge->probability;
-				nfte->probability
-				  = REG_BR_PROB_BASE - nehe->probability;
-
-			        do_cleanup_cfg |= purge_dead_edges (nfte->dest);
+        
+        for (insn = bb->end; ; insn = prev)
+        {
+            prev = PREV_INSN (insn);
+            if (INSN_P (insn))
+            {
+                rtx try, before_try, x;
+                int match_len;
+                rtx note;
+                
+                /* Record this insn.  */
+                if (--peep2_current < 0)
+                    peep2_current = MAX_INSNS_PER_PEEP2;
+                peep2_insn_data[peep2_current].insn = insn;
+                propagate_one_insn (pbi, insn);
+                COPY_REG_SET (peep2_insn_data[peep2_current].live_before, live);
+                
+                /* Match the peephole.  */
+                try = peephole2_insns (PATTERN (insn), insn, &match_len);
+                if (try != NULL)
+                {
+                    /* If we are splitting a CALL_INSN, look for the CALL_INSN
+                     in SEQ and copy our CALL_INSN_FUNCTION_USAGE and other
+                     cfg-related call notes.  */
+                    for (i = 0; i <= match_len; ++i)
+                    {
+                        int j, k;
+                        rtx old_insn, new_insn, note;
+                        
+                        j = i + peep2_current;
+                        if (j >= MAX_INSNS_PER_PEEP2 + 1)
+                            j -= MAX_INSNS_PER_PEEP2 + 1;
+                        old_insn = peep2_insn_data[j].insn;
+                        if (GET_CODE (old_insn) != CALL_INSN)
+                            continue;
+                        
+                        new_insn = NULL_RTX;
+                        if (GET_CODE (try) == SEQUENCE)
+                            for (k = XVECLEN (try, 0) - 1; k >= 0; k--)
+                        {
+                            rtx x = XVECEXP (try, 0, k);
+                            if (GET_CODE (x) == CALL_INSN)
+                            {
+                                new_insn = x;
+                                break;
+                            }
+                        }
+                        else if (GET_CODE (try) == CALL_INSN)
+                            new_insn = try;
+                        if (! new_insn)
+                            abort ();
+                        
+                        CALL_INSN_FUNCTION_USAGE (new_insn)
+                        = CALL_INSN_FUNCTION_USAGE (old_insn);
+                        
+                        for (note = REG_NOTES (old_insn);
+                             note;
+                             note = XEXP (note, 1))
+                        switch (REG_NOTE_KIND (note))
+                        {
+                            case REG_NORETURN:
+                            case REG_SETJMP:
+                            case REG_ALWAYS_RETURN:
+                                REG_NOTES (new_insn)
+                                = gen_rtx_EXPR_LIST (REG_NOTE_KIND (note),
+                                                     XEXP (note, 0),
+                                                     REG_NOTES (new_insn));
+                            default:
+                                /* Discard all other reg notes.  */
+                                break;
+                        }
+                        
+                        /* Croak if there is another call in the sequence.  */
+                        while (++i <= match_len)
+                        {
+                            j = i + peep2_current;
+                            if (j >= MAX_INSNS_PER_PEEP2 + 1)
+                                j -= MAX_INSNS_PER_PEEP2 + 1;
+                            old_insn = peep2_insn_data[j].insn;
+                            if (GET_CODE (old_insn) == CALL_INSN)
+                                abort ();
+                        }
+                        break;
+                    }
+                    
+                    i = match_len + peep2_current;
+                    if (i >= MAX_INSNS_PER_PEEP2 + 1)
+                        i -= MAX_INSNS_PER_PEEP2 + 1;
+                    
+                    note = find_reg_note (peep2_insn_data[i].insn,
+                                          REG_EH_REGION, NULL_RTX);
+                    
+                    /* Replace the old sequence with the new.  */
+                    try = emit_insn_after (try, peep2_insn_data[i].insn);
+                    before_try = PREV_INSN (insn);
+                    delete_insn_chain (insn, peep2_insn_data[i].insn);
+                    
+                    /* Re-insert the EH_REGION notes.  */
+                    if (note)
+                    {
+                        edge eh_edge;
+                        
+                        for (eh_edge = bb->succ; eh_edge
+                             ; eh_edge = eh_edge->succ_next)
+                        if (eh_edge->flags & EDGE_EH)
+                            break;
+                        
+                        for (x = try ; x != before_try ; x = PREV_INSN (x))
+                        if (GET_CODE (x) == CALL_INSN
+                            || (flag_non_call_exceptions
+                                && may_trap_p (PATTERN (x))
+                                && !find_reg_note (x, REG_EH_REGION, NULL)))
+                        {
+                            REG_NOTES (x)
+                            = gen_rtx_EXPR_LIST (REG_EH_REGION,
+                                                 XEXP (note, 0),
+                                                 REG_NOTES (x));
+                            
+                            if (x != bb->end && eh_edge)
+                            {
+                                edge nfte, nehe;
+                                int flags;
+                                
+                                nfte = split_block (bb, x);
+                                flags = EDGE_EH | EDGE_ABNORMAL;
+                                if (GET_CODE (x) == CALL_INSN)
+                                    flags |= EDGE_ABNORMAL_CALL;
+                                nehe = make_edge (nfte->src, eh_edge->dest,
+                                                  flags);
+                                
+                                nehe->probability = eh_edge->probability;
+                                nfte->probability
+                                = REG_BR_PROB_BASE - nehe->probability;
+                                
+                                do_cleanup_cfg |= purge_dead_edges (nfte->dest);
 #ifdef HAVE_conditional_execution
-				SET_BIT (blocks, nfte->dest->index);
-				changed = true;
+                                SET_BIT (blocks, nfte->dest->index);
+                                changed = true;
 #endif
-				bb = nfte->src;
-				eh_edge = nehe;
-			      }
-			  }
-
-		      /* Converting possibly trapping insn to non-trapping is
-			 possible.  Zap dummy outgoing edges.  */
-		      do_cleanup_cfg |= purge_dead_edges (bb);
-		    }
-
+                                bb = nfte->src;
+                                eh_edge = nehe;
+                            }
+                        }
+                        
+                        /* Converting possibly trapping insn to non-trapping is
+                         possible.  Zap dummy outgoing edges.  */
+                        do_cleanup_cfg |= purge_dead_edges (bb);
+                    }
+                    
 #ifdef HAVE_conditional_execution
-		  /* With conditional execution, we cannot back up the
-		     live information so easily, since the conditional
-		     death data structures are not so self-contained.
-		     So record that we've made a modification to this
-		     block and update life information at the end.  */
-		  SET_BIT (blocks, b);
-		  changed = true;
-
-		  for (i = 0; i < MAX_INSNS_PER_PEEP2 + 1; ++i)
-		    peep2_insn_data[i].insn = NULL_RTX;
-		  peep2_insn_data[peep2_current].insn = PEEP2_EOB;
+                    /* With conditional execution, we cannot back up the
+                     live information so easily, since the conditional
+                     death data structures are not so self-contained.
+                     So record that we've made a modification to this
+                     block and update life information at the end.  */
+                    SET_BIT (blocks, b);
+                    changed = true;
+                    
+                    for (i = 0; i < MAX_INSNS_PER_PEEP2 + 1; ++i)
+                    peep2_insn_data[i].insn = NULL_RTX;
+                    peep2_insn_data[peep2_current].insn = PEEP2_EOB;
 #else
-		  /* Back up lifetime information past the end of the
-		     newly created sequence.  */
-		  if (++i >= MAX_INSNS_PER_PEEP2 + 1)
-		    i = 0;
-		  COPY_REG_SET (live, peep2_insn_data[i].live_before);
-
-		  /* Update life information for the new sequence.  */
-		  x = try;
-		  do
-		    {
-		      if (INSN_P (x))
-			{
-			  if (--i < 0)
-			    i = MAX_INSNS_PER_PEEP2;
-			  peep2_insn_data[i].insn = x;
-			  propagate_one_insn (pbi, x);
-			  COPY_REG_SET (peep2_insn_data[i].live_before, live);
-			}
-		      x = PREV_INSN (x);
-		    }
-		  while (x != prev);
-
-		  /* ??? Should verify that LIVE now matches what we
-		     had before the new sequence.  */
-
-		  peep2_current = i;
+                    /* Back up lifetime information past the end of the
+                     newly created sequence.  */
+                    if (++i >= MAX_INSNS_PER_PEEP2 + 1)
+                        i = 0;
+                    COPY_REG_SET (live, peep2_insn_data[i].live_before);
+                    
+                    /* Update life information for the new sequence.  */
+                    x = try;
+                    do
+                    {
+                        if (INSN_P (x))
+                        {
+                            if (--i < 0)
+                                i = MAX_INSNS_PER_PEEP2;
+                            peep2_insn_data[i].insn = x;
+                            propagate_one_insn (pbi, x);
+                            COPY_REG_SET (peep2_insn_data[i].live_before, live);
+                        }
+                        x = PREV_INSN (x);
+                    }
+                    while (x != prev);
+                    
+                    /* ??? Should verify that LIVE now matches what we
+                     had before the new sequence.  */
+                    
+                    peep2_current = i;
 #endif
-
-		  /* If we generated a jump instruction, it won't have
-		     JUMP_LABEL set.  Recompute after we're done.  */
-		  for (x = try; x != before_try; x = PREV_INSN (x))
-		    if (GET_CODE (x) == JUMP_INSN)
-		      {
-		        do_rebuild_jump_labels = true;
-			break;
-		      }
-		}
-	    }
-
-	  if (insn == bb->head)
-	    break;
-	}
-
-      free_propagate_block_info (pbi);
+                    
+                    /* If we generated a jump instruction, it won't have
+                     JUMP_LABEL set.  Recompute after we're done.  */
+                    for (x = try; x != before_try; x = PREV_INSN (x))
+                    if (GET_CODE (x) == JUMP_INSN)
+                    {
+                        do_rebuild_jump_labels = true;
+                        break;
+                    }
+                }
+            }
+            
+            if (insn == bb->head)
+                break;
+        }
+        
+        free_propagate_block_info (pbi);
     }
-
-  for (i = 0; i < MAX_INSNS_PER_PEEP2 + 1; ++i)
+    
+    for (i = 0; i < MAX_INSNS_PER_PEEP2 + 1; ++i)
     FREE_REG_SET (peep2_insn_data[i].live_before);
-  FREE_REG_SET (live);
-
-  if (do_rebuild_jump_labels)
-    rebuild_jump_labels (get_insns ());
-
-  /* If we eliminated EH edges, we may be able to merge blocks.  Further,
+    FREE_REG_SET (live);
+    
+    if (do_rebuild_jump_labels)
+        rebuild_jump_labels (get_insns ());
+    
+    /* If we eliminated EH edges, we may be able to merge blocks.  Further,
      we've changed global life since exception handlers are no longer
      reachable.  */
-  if (do_cleanup_cfg)
+    if (do_cleanup_cfg)
     {
-      cleanup_cfg (0);
-      update_life_info (0, UPDATE_LIFE_GLOBAL_RM_NOTES, PROP_DEATH_NOTES);
+        cleanup_cfg (0);
+        update_life_info (0, UPDATE_LIFE_GLOBAL_RM_NOTES, PROP_DEATH_NOTES);
     }
 #ifdef HAVE_conditional_execution
-  else
+    else
     {
-      count_or_remove_death_notes (blocks, 1);
-      update_life_info (blocks, UPDATE_LIFE_LOCAL, PROP_DEATH_NOTES);
+        count_or_remove_death_notes (blocks, 1);
+        update_life_info (blocks, UPDATE_LIFE_LOCAL, PROP_DEATH_NOTES);
     }
-  sbitmap_free (blocks);
+    sbitmap_free (blocks);
 #endif
 }
 #endif /* HAVE_peephole2 */
diff --git a/recog.h b/recog.h
index ff96e47..b5f881d 100644
--- a/recog.h
+++ b/recog.h
@@ -211,7 +211,7 @@ extern struct operand_alternative recog_op_alt[MAX_RECOG_OPERANDS][MAX_RECOG_ALT
 
 typedef int (*insn_operand_predicate_fn) PARAMS ((rtx, enum machine_mode));
 typedef const char * (*insn_output_fn) PARAMS ((rtx *, rtx));
-typedef rtx (*insn_gen_fn) PARAMS ((rtx, ...));
+// typedef rtx (*insn_gen_fn) PARAMS ((rtx, ...));
 
 struct insn_operand_data
 {
@@ -237,7 +237,20 @@ struct insn_data
 {
   const char *const name;
   const PTR output;
-  const insn_gen_fn genfun;
+  union {
+    rtx (*argc0)	(void);
+    rtx (*argc1)	(rtx);
+    rtx (*argc2)	(rtx, rtx);
+    rtx (*argc3)	(rtx, rtx, rtx);
+    rtx (*argc4)	(rtx, rtx, rtx, rtx);
+    rtx (*argc5)	(rtx, rtx, rtx, rtx, rtx);
+    rtx (*argc6)	(rtx, rtx, rtx, rtx, rtx, rtx);
+    rtx (*argc7)	(rtx, rtx, rtx, rtx, rtx, rtx, rtx);
+    rtx (*argc8)	(rtx, rtx, rtx, rtx, rtx, rtx, rtx, rtx);
+    rtx (*argc9)	(rtx, rtx, rtx, rtx, rtx, rtx, rtx, rtx, rtx);
+    rtx (*argc10)	(rtx, rtx, rtx, rtx, rtx, rtx, rtx, rtx, rtx, rtx);
+    rtx (*argc11)	(rtx, rtx, rtx, rtx, rtx, rtx, rtx, rtx, rtx, rtx, rtx);
+  } genfun;
   const struct insn_operand_data *const operand;
 
   const char n_operands;
diff --git a/reload1.c b/reload1.c
index f96c735..b04dccb 100644
--- a/reload1.c
+++ b/reload1.c
@@ -6551,7 +6551,7 @@ emit_input_reload_insns (chain, rl, old, j)
 	{
 	  if (icode != CODE_FOR_nothing)
 	    {
-	      emit_insn (GEN_FCN (icode) (reloadreg, real_oldequiv,
+	      emit_insn (GEN_FCN3 (icode) (reloadreg, real_oldequiv,
 					  second_reload_reg));
 	      special = 1;
 	    }
@@ -6567,7 +6567,7 @@ emit_input_reload_insns (chain, rl, old, j)
 		  rtx third_reload_reg
 		    = rld[rld[secondary_reload].secondary_in_reload].reg_rtx;
 
-		  emit_insn ((GEN_FCN (tertiary_icode)
+		  emit_insn ((GEN_FCN3 (tertiary_icode)
 			      (second_reload_reg, real_oldequiv,
 			       third_reload_reg)));
 		}
@@ -6683,7 +6683,7 @@ emit_output_reload_insns (chain, rl, j)
 	     or as an intermediate register.  */
 	  if (rl->secondary_out_icode != CODE_FOR_nothing)
 	    {
-	      emit_insn ((GEN_FCN (rl->secondary_out_icode)
+	      emit_insn ((GEN_FCN3 (rl->secondary_out_icode)
 			  (real_old, second_reloadreg, reloadreg)));
 	      special = 1;
 	    }
@@ -6722,7 +6722,7 @@ emit_output_reload_insns (chain, rl, j)
 
 		  gen_reload (reloadreg, second_reloadreg,
 			      rl->opnum, rl->when_needed);
-		  emit_insn ((GEN_FCN (tertiary_icode)
+		  emit_insn ((GEN_FCN3 (tertiary_icode)
 			      (real_old, reloadreg, third_reloadreg)));
 		  special = 1;
 		}

diff --git a/stor-layout.c b/stor-layout.c
index c330fb6..c6c9401 100644
--- a/stor-layout.c
+++ b/stor-layout.c
@@ -1,23 +1,23 @@
 /* C-compiler utilities for types and variables storage layout
-   Copyright (C) 1987, 1988, 1992, 1993, 1994, 1995, 1996, 1996, 1998,
-   1999, 2000, 2001, 2002 Free Software Foundation, Inc.
-
-This file is part of GCC.
-
-GCC is free software; you can redistribute it and/or modify it under
-the terms of the GNU General Public License as published by the Free
-Software Foundation; either version 2, or (at your option) any later
-version.
-
-GCC is distributed in the hope that it will be useful, but WITHOUT ANY
-WARRANTY; without even the implied warranty of MERCHANTABILITY or
-FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
-for more details.
-
-You should have received a copy of the GNU General Public License
-along with GCC; see the file COPYING.  If not, write to the Free
-Software Foundation, 59 Temple Place - Suite 330, Boston, MA
-02111-1307, USA.  */
+ Copyright (C) 1987, 1988, 1992, 1993, 1994, 1995, 1996, 1996, 1998,
+ 1999, 2000, 2001, 2002 Free Software Foundation, Inc.
+ 
+ This file is part of GCC.
+ 
+ GCC is free software; you can redistribute it and/or modify it under
+ the terms of the GNU General Public License as published by the Free
+ Software Foundation; either version 2, or (at your option) any later
+ version.
+ 
+ GCC is distributed in the hope that it will be useful, but WITHOUT ANY
+ WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ for more details.
+ 
+ You should have received a copy of the GNU General Public License
+ along with GCC; see the file COPYING.  If not, write to the Free
+ Software Foundation, 59 Temple Place - Suite 330, Boston, MA
+ 02111-1307, USA.  */
 
 
 #include "config.h"
@@ -33,50 +33,50 @@ Software Foundation, 59 Temple Place - Suite 330, Boston, MA
 #include "target.h"
 
 /* Set to one when set_sizetype has been called.  */
-static int sizetype_set;
+static int sizetype_set = 0;
 
 /* List of types created before set_sizetype has been called.  We do not
-   make this a GGC root since we want these nodes to be reclaimed.  */
+ make this a GGC root since we want these nodes to be reclaimed.  */
 static tree early_type_list;
 
 /* Data type for the expressions representing sizes of data types.
-   It is the first integer type laid out.  */
+ It is the first integer type laid out.  */
 tree sizetype_tab[(int) TYPE_KIND_LAST];
 
 /* If nonzero, this is an upper limit on alignment of structure fields.
-   The value is measured in bits.  */
+ The value is measured in bits.  */
 unsigned int maximum_field_alignment;
 
 /* If non-zero, the alignment of a bitstring or (power-)set value, in bits.
-   May be overridden by front-ends.  */
+ May be overridden by front-ends.  */
 unsigned int set_alignment = 0;
 
 /* Nonzero if all REFERENCE_TYPEs are internal and hence should be
-   allocated in Pmode, not ptr_mode.   Set only by internal_reference_types
-   called only by a front end.  */
+ allocated in Pmode, not ptr_mode.   Set only by internal_reference_types
+ called only by a front end.  */
 static int reference_types_internal = 0;
 
-static void finalize_record_size	PARAMS ((record_layout_info));
-static void finalize_type_size		PARAMS ((tree));
-static void place_union_field		PARAMS ((record_layout_info, tree));
-extern void debug_rli			PARAMS ((record_layout_info));
+static void finalize_record_size    PARAMS ((record_layout_info));
+static void finalize_type_size        PARAMS ((tree));
+static void place_union_field        PARAMS ((record_layout_info, tree));
+extern void debug_rli            PARAMS ((record_layout_info));
 
 /* SAVE_EXPRs for sizes of types and decls, waiting to be expanded.  */
 
 static tree pending_sizes;
 
 /* Nonzero means cannot safely call expand_expr now,
-   so put variable sizes onto `pending_sizes' instead.  */
+ so put variable sizes onto `pending_sizes' instead.  */
 
 int immediate_size_expand;
 
 /* Show that REFERENCE_TYPES are internal and should be Pmode.  Called only
-   by front end.  */
+ by front end.  */
 
 void
 internal_reference_types ()
 {
-  reference_types_internal = 1;
+    reference_types_internal = 1;
 }
 
 /* Get a list of all the objects put on the pending sizes list.  */
@@ -84,79 +84,79 @@ internal_reference_types ()
 tree
 get_pending_sizes ()
 {
-  tree chain = pending_sizes;
-  tree t;
-
-  /* Put each SAVE_EXPR into the current function.  */
-  for (t = chain; t; t = TREE_CHAIN (t))
+    tree chain = pending_sizes;
+    tree t;
+    
+    /* Put each SAVE_EXPR into the current function.  */
+    for (t = chain; t; t = TREE_CHAIN (t))
     SAVE_EXPR_CONTEXT (TREE_VALUE (t)) = current_function_decl;
-
-  pending_sizes = 0;
-  return chain;
+    
+    pending_sizes = 0;
+    return chain;
 }
 
 /* Return non-zero if EXPR is present on the pending sizes list.  */
 
 int
 is_pending_size (expr)
-     tree expr;
+tree expr;
 {
-  tree t;
-
-  for (t = pending_sizes; t; t = TREE_CHAIN (t))
+    tree t;
+    
+    for (t = pending_sizes; t; t = TREE_CHAIN (t))
     if (TREE_VALUE (t) == expr)
-      return 1;
-  return 0;
+        return 1;
+    return 0;
 }
 
 /* Add EXPR to the pending sizes list.  */
 
 void
 put_pending_size (expr)
-     tree expr;
+tree expr;
 {
-  /* Strip any simple arithmetic from EXPR to see if it has an underlying
+    /* Strip any simple arithmetic from EXPR to see if it has an underlying
      SAVE_EXPR.  */
-  while (TREE_CODE_CLASS (TREE_CODE (expr)) == '1'
-	 || (TREE_CODE_CLASS (TREE_CODE (expr)) == '2'
-	    && TREE_CONSTANT (TREE_OPERAND (expr, 1))))
-    expr = TREE_OPERAND (expr, 0);
-
-  if (TREE_CODE (expr) == SAVE_EXPR)
-    pending_sizes = tree_cons (NULL_TREE, expr, pending_sizes);
+    while (TREE_CODE_CLASS (TREE_CODE (expr)) == '1'
+           || (TREE_CODE_CLASS (TREE_CODE (expr)) == '2'
+               && TREE_CONSTANT (TREE_OPERAND (expr, 1))))
+        expr = TREE_OPERAND (expr, 0);
+    
+    if (TREE_CODE (expr) == SAVE_EXPR)
+        pending_sizes = tree_cons (NULL_TREE, expr, pending_sizes);
 }
 
 /* Put a chain of objects into the pending sizes list, which must be
-   empty.  */
+ empty.  */
 
 void
 put_pending_sizes (chain)
-     tree chain;
+tree chain;
 {
-  if (pending_sizes)
-    abort ();
-
-  pending_sizes = chain;
+    if (pending_sizes)
+        abort ();
+    
+    pending_sizes = chain;
 }
 
 /* Given a size SIZE that may not be a constant, return a SAVE_EXPR
-   to serve as the actual size-expression for a type or decl.  */
+ to serve as the actual size-expression for a type or decl.  */
 
 tree
 variable_size (size)
-     tree size;
+tree size;
 {
-  /* If the language-processor is to take responsibility for variable-sized
+    /* If the language-processor is to take responsibility for variable-sized
      items (e.g., languages which have elaboration procedures like Ada),
      just return SIZE unchanged.  Likewise for self-referential sizes and
      constant sizes.  */
-  if (TREE_CONSTANT (size)
-      || global_bindings_p () < 0 || contains_placeholder_p (size))
-    return size;
-
-  size = save_expr (size);
-
-  /* If an array with a variable number of elements is declared, and
+    if (TREE_CONSTANT (size)
+        || global_bindings_p () < 0 || contains_placeholder_p (size))
+        return size;
+    
+    size = save_expr (size);
+    
+    /* If an array with a variable number of elements is declared, and
      the elements require destruction, we will emit a cleanup for the
      array.  That cleanup is run both on normal exit from the block
      and in the exception-handler for the block.  Normally, when code
@@ -164,32 +164,32 @@ variable_size (size)
      `unsaved', i.e., all SAVE_EXPRs are recalculated.  However, we do
      not wish to do that here; the array-size is the same in both
      places.  */
-  if (TREE_CODE (size) == SAVE_EXPR)
-    SAVE_EXPR_PERSISTENT_P (size) = 1;
-
-  if (global_bindings_p ())
+    if (TREE_CODE (size) == SAVE_EXPR)
+        SAVE_EXPR_PERSISTENT_P (size) = 1;
+    
+    if (global_bindings_p ())
     {
-      if (TREE_CONSTANT (size))
-	error ("type size can't be explicitly evaluated");
-      else
-	error ("variable-size type declared outside of any function");
-
-      return size_one_node;
+        if (TREE_CONSTANT (size))
+            error ("type size can't be explicitly evaluated");
+        else
+            error ("variable-size type declared outside of any function");
+        
+        return size_one_node;
     }
-
-  if (immediate_size_expand)
-    /* NULL_RTX is not defined; neither is the rtx type. 
-       Also, we would like to pass const0_rtx here, but don't have it.  */
-    expand_expr (size, expand_expr (integer_zero_node, NULL_RTX, VOIDmode, 0),
-		 VOIDmode, 0);
-  else if (cfun != 0 && cfun->x_dont_save_pending_sizes_p)
+    
+    if (immediate_size_expand)
+    /* NULL_RTX is not defined; neither is the rtx type.
+     Also, we would like to pass const0_rtx here, but don't have it.  */
+        expand_expr (size, expand_expr (integer_zero_node, NULL_RTX, VOIDmode, 0),
+                     VOIDmode, 0);
+    else if (cfun != 0 && cfun->x_dont_save_pending_sizes_p)
     /* The front-end doesn't want us to keep a list of the expressions
-       that determine sizes for variable size objects.  */
-    ;
-  else
-    put_pending_size (size);
-
-  return size;
+     that determine sizes for variable size objects.  */
+        ;
+    else
+        put_pending_size (size);
+    
+    return size;
 }
 
 #ifndef MAX_FIXED_MODE_SIZE
@@ -197,158 +197,158 @@ variable_size (size)
 #endif
 
 /* Return the machine mode to use for a nonscalar of SIZE bits.
-   The mode must be in class CLASS, and have exactly that many bits.
-   If LIMIT is nonzero, modes of wider than MAX_FIXED_MODE_SIZE will not
-   be used.  */
+ The mode must be in class CLASS, and have exactly that many bits.
+ If LIMIT is nonzero, modes of wider than MAX_FIXED_MODE_SIZE will not
+ be used.  */
 
 enum machine_mode
 mode_for_size (size, class, limit)
-     unsigned int size;
-     enum mode_class class;
-     int limit;
+unsigned int size;
+enum mode_class class;
+int limit;
 {
-  enum machine_mode mode;
-
-  if (limit && size > MAX_FIXED_MODE_SIZE)
-    return BLKmode;
-
-  /* Get the first mode which has this size, in the specified class.  */
-  for (mode = GET_CLASS_NARROWEST_MODE (class); mode != VOIDmode;
-       mode = GET_MODE_WIDER_MODE (mode))
+    enum machine_mode mode;
+    
+    if (limit && size > MAX_FIXED_MODE_SIZE)
+        return BLKmode;
+    
+    /* Get the first mode which has this size, in the specified class.  */
+    for (mode = GET_CLASS_NARROWEST_MODE (class); mode != VOIDmode;
+         mode = GET_MODE_WIDER_MODE (mode))
     if (GET_MODE_BITSIZE (mode) == size)
-      return mode;
-
-  return BLKmode;
+        return mode;
+    
+    return BLKmode;
 }
 
 /* Similar, except passed a tree node.  */
 
 enum machine_mode
 mode_for_size_tree (size, class, limit)
-     tree size;
-     enum mode_class class;
-     int limit;
+tree size;
+enum mode_class class;
+int limit;
 {
-  if (TREE_CODE (size) != INTEGER_CST
-      /* What we really want to say here is that the size can fit in a
-	 host integer, but we know there's no way we'd find a mode for
-	 this many bits, so there's no point in doing the precise test.  */
-      || compare_tree_int (size, 1000) > 0)
-    return BLKmode;
-  else
-    return mode_for_size (TREE_INT_CST_LOW (size), class, limit);
+    if (TREE_CODE (size) != INTEGER_CST
+        /* What we really want to say here is that the size can fit in a
+         host integer, but we know there's no way we'd find a mode for
+         this many bits, so there's no point in doing the precise test.  */
+        || compare_tree_int (size, 1000) > 0)
+        return BLKmode;
+    else
+        return mode_for_size (TREE_INT_CST_LOW (size), class, limit);
 }
 
 /* Similar, but never return BLKmode; return the narrowest mode that
-   contains at least the requested number of bits.  */
+ contains at least the requested number of bits.  */
 
 enum machine_mode
 smallest_mode_for_size (size, class)
-     unsigned int size;
-     enum mode_class class;
+unsigned int size;
+enum mode_class class;
 {
-  enum machine_mode mode;
-
-  /* Get the first mode which has at least this size, in the
+    enum machine_mode mode;
+    
+    /* Get the first mode which has at least this size, in the
      specified class.  */
-  for (mode = GET_CLASS_NARROWEST_MODE (class); mode != VOIDmode;
-       mode = GET_MODE_WIDER_MODE (mode))
+    for (mode = GET_CLASS_NARROWEST_MODE (class); mode != VOIDmode;
+         mode = GET_MODE_WIDER_MODE (mode))
     if (GET_MODE_BITSIZE (mode) >= size)
-      return mode;
-
-  abort ();
+        return mode;
+    
+    abort ();
 }
 
 /* Find an integer mode of the exact same size, or BLKmode on failure.  */
 
 enum machine_mode
 int_mode_for_mode (mode)
-     enum machine_mode mode;
+enum machine_mode mode;
 {
-  switch (GET_MODE_CLASS (mode))
+    switch (GET_MODE_CLASS (mode))
     {
-    case MODE_INT:
-    case MODE_PARTIAL_INT:
-      break;
-
-    case MODE_COMPLEX_INT:
-    case MODE_COMPLEX_FLOAT:
-    case MODE_FLOAT:
-    case MODE_VECTOR_INT:
-    case MODE_VECTOR_FLOAT:
-      mode = mode_for_size (GET_MODE_BITSIZE (mode), MODE_INT, 0);
-      break;
-
-    case MODE_RANDOM:
-      if (mode == BLKmode)
-        break;
-
-      /* ... fall through ...  */
-
-    case MODE_CC:
-    default:
-      abort ();
+        case MODE_INT:
+        case MODE_PARTIAL_INT:
+            break;
+            
+        case MODE_COMPLEX_INT:
+        case MODE_COMPLEX_FLOAT:
+        case MODE_FLOAT:
+        case MODE_VECTOR_INT:
+        case MODE_VECTOR_FLOAT:
+            mode = mode_for_size (GET_MODE_BITSIZE (mode), MODE_INT, 0);
+            break;
+            
+        case MODE_RANDOM:
+            if (mode == BLKmode)
+                break;
+            
+            /* ... fall through ...  */
+            
+        case MODE_CC:
+        default:
+            abort ();
     }
-
-  return mode;
+    
+    return mode;
 }
 
 /* Return the value of VALUE, rounded up to a multiple of DIVISOR.
-   This can only be applied to objects of a sizetype.  */
+ This can only be applied to objects of a sizetype.  */
 
 tree
 round_up (value, divisor)
-     tree value;
-     int divisor;
+tree value;
+int divisor;
 {
-  tree arg = size_int_type (divisor, TREE_TYPE (value));
-
-  return size_binop (MULT_EXPR, size_binop (CEIL_DIV_EXPR, value, arg), arg);
+    tree arg = size_int_type (divisor, TREE_TYPE (value));
+    
+    return size_binop (MULT_EXPR, size_binop (CEIL_DIV_EXPR, value, arg), arg);
 }
 
 /* Likewise, but round down.  */
 
 tree
 round_down (value, divisor)
-     tree value;
-     int divisor;
+tree value;
+int divisor;
 {
-  tree arg = size_int_type (divisor, TREE_TYPE (value));
-
-  return size_binop (MULT_EXPR, size_binop (FLOOR_DIV_EXPR, value, arg), arg);
+    tree arg = size_int_type (divisor, TREE_TYPE (value));
+    
+    return size_binop (MULT_EXPR, size_binop (FLOOR_DIV_EXPR, value, arg), arg);
 }
 
 /* Set the size, mode and alignment of a ..._DECL node.
-   TYPE_DECL does need this for C++.
-   Note that LABEL_DECL and CONST_DECL nodes do not need this,
-   and FUNCTION_DECL nodes have them set up in a special (and simple) way.
-   Don't call layout_decl for them.
-
-   KNOWN_ALIGN is the amount of alignment we can assume this
-   decl has with no special effort.  It is relevant only for FIELD_DECLs
-   and depends on the previous fields.
-   All that matters about KNOWN_ALIGN is which powers of 2 divide it.
-   If KNOWN_ALIGN is 0, it means, "as much alignment as you like":
-   the record will be aligned to suit.  */
+ TYPE_DECL does need this for C++.
+ Note that LABEL_DECL and CONST_DECL nodes do not need this,
+ and FUNCTION_DECL nodes have them set up in a special (and simple) way.
+ Don't call layout_decl for them.
+ 
+ KNOWN_ALIGN is the amount of alignment we can assume this
+ decl has with no special effort.  It is relevant only for FIELD_DECLs
+ and depends on the previous fields.
+ All that matters about KNOWN_ALIGN is which powers of 2 divide it.
+ If KNOWN_ALIGN is 0, it means, "as much alignment as you like":
+ the record will be aligned to suit.  */
 
 void
 layout_decl (decl, known_align)
-     tree decl;
-     unsigned int known_align;
+tree decl;
+unsigned int known_align;
 {
-  tree type = TREE_TYPE (decl);
-  enum tree_code code = TREE_CODE (decl);
-
-  if (code == CONST_DECL)
-    return;
-  else if (code != VAR_DECL && code != PARM_DECL && code != RESULT_DECL
-	   && code != TYPE_DECL && code != FIELD_DECL)
-    abort ();
-
-  if (type == error_mark_node)
-    type = void_type_node;
-
-  /* Usually the size and mode come from the data type without change,
+    tree type = TREE_TYPE (decl);
+    enum tree_code code = TREE_CODE (decl);
+    
+    if (code == CONST_DECL)
+        return;
+    else if (code != VAR_DECL && code != PARM_DECL && code != RESULT_DECL
+             && code != TYPE_DECL && code != FIELD_DECL)
+        abort ();
+    
+    if (type == error_mark_node)
+        type = void_type_node;
+    
+    /* Usually the size and mode come from the data type without change,
      however, the front-end may set the explicit width of the field, so its
      size may not be the same as the size of its type.  This happens with
      bitfields, of course (an `int' bitfield may be only 2 bits, say), but it
@@ -357,237 +357,236 @@ layout_decl (decl, known_align)
      layout_type setting DECL_FIELD_BITPOS correctly for the field.  Set the
      size in bytes from the size in bits.  If we have already set the mode,
      don't set it again since we can be called twice for FIELD_DECLs.  */
-
-  TREE_UNSIGNED (decl) = TREE_UNSIGNED (type);
-  if (DECL_MODE (decl) == VOIDmode)
-    DECL_MODE (decl) = TYPE_MODE (type);
-
-  if (DECL_SIZE (decl) == 0)
+    
+    TREE_UNSIGNED (decl) = TREE_UNSIGNED (type);
+    if (DECL_MODE (decl) == VOIDmode)
+        DECL_MODE (decl) = TYPE_MODE (type);
+    
+    if (DECL_SIZE (decl) == 0)
     {
-      DECL_SIZE (decl) = TYPE_SIZE (type);
-      DECL_SIZE_UNIT (decl) = TYPE_SIZE_UNIT (type);
+        DECL_SIZE (decl) = TYPE_SIZE (type);
+        DECL_SIZE_UNIT (decl) = TYPE_SIZE_UNIT (type);
     }
-  else
-    DECL_SIZE_UNIT (decl)
-      = convert (sizetype, size_binop (CEIL_DIV_EXPR, DECL_SIZE (decl),
-				       bitsize_unit_node));
-
-  /* Force alignment required for the data type.
+    else
+        DECL_SIZE_UNIT (decl)
+        = convert (sizetype, size_binop (CEIL_DIV_EXPR, DECL_SIZE (decl),
+                                         bitsize_unit_node));
+    
+    /* Force alignment required for the data type.
      But if the decl itself wants greater alignment, don't override that.
      Likewise, if the decl is packed, don't override it.  */
-  if (! (code == FIELD_DECL && DECL_BIT_FIELD (decl))
-      && (DECL_ALIGN (decl) == 0
-	  || (! (code == FIELD_DECL && DECL_PACKED (decl))
-	      && TYPE_ALIGN (type) > DECL_ALIGN (decl))))
-    {	      
-      DECL_ALIGN (decl) = TYPE_ALIGN (type);
-      DECL_USER_ALIGN (decl) = 0;
+    if (! (code == FIELD_DECL && DECL_BIT_FIELD (decl))
+        && (DECL_ALIGN (decl) == 0
+            || (! (code == FIELD_DECL && DECL_PACKED (decl))
+                && TYPE_ALIGN (type) > DECL_ALIGN (decl))))
+    {
+        DECL_ALIGN (decl) = TYPE_ALIGN (type);
+        DECL_USER_ALIGN (decl) = 0;
     }
-
-  /* For fields, set the bit field type and update the alignment.  */
-  if (code == FIELD_DECL)
+    
+    /* For fields, set the bit field type and update the alignment.  */
+    if (code == FIELD_DECL)
     {
-      DECL_BIT_FIELD_TYPE (decl) = DECL_BIT_FIELD (decl) ? type : 0;
-      if (maximum_field_alignment != 0)
-	DECL_ALIGN (decl) = MIN (DECL_ALIGN (decl), maximum_field_alignment);
-
-      /* If the field is of variable size, we can't misalign it since we
-	 have no way to make a temporary to align the result.  But this
-	 isn't an issue if the decl is not addressable.  Likewise if it
-	 is of unknown size.  */
-      else if (DECL_PACKED (decl)
-	       && (DECL_NONADDRESSABLE_P (decl)
-		   || DECL_SIZE_UNIT (decl) == 0
-		   || TREE_CODE (DECL_SIZE_UNIT (decl)) == INTEGER_CST))
-	{
-	  DECL_ALIGN (decl) = MIN (DECL_ALIGN (decl), BITS_PER_UNIT);
-	  DECL_USER_ALIGN (decl) = 0;
-	}
+        DECL_BIT_FIELD_TYPE (decl) = DECL_BIT_FIELD (decl) ? type : 0;
+        if (maximum_field_alignment != 0)
+            DECL_ALIGN (decl) = MIN (DECL_ALIGN (decl), maximum_field_alignment);
+        
+        /* If the field is of variable size, we can't misalign it since we
+         have no way to make a temporary to align the result.  But this
+         isn't an issue if the decl is not addressable.  Likewise if it
+         is of unknown size.  */
+        else if (DECL_PACKED (decl)
+                 && (DECL_NONADDRESSABLE_P (decl)
+                     || DECL_SIZE_UNIT (decl) == 0
+                     || TREE_CODE (DECL_SIZE_UNIT (decl)) == INTEGER_CST))
+        {
+            DECL_ALIGN (decl) = MIN (DECL_ALIGN (decl), BITS_PER_UNIT);
+            DECL_USER_ALIGN (decl) = 0;
+        }
     }
-
-  /* See if we can use an ordinary integer mode for a bit-field. 
+    
+    /* See if we can use an ordinary integer mode for a bit-field.
      Conditions are: a fixed size that is correct for another mode
      and occupying a complete byte or bytes on proper boundary.  */
-  if (code == FIELD_DECL && DECL_BIT_FIELD (decl)
-      && TYPE_SIZE (type) != 0
-      && TREE_CODE (TYPE_SIZE (type)) == INTEGER_CST
-      && GET_MODE_CLASS (TYPE_MODE (type)) == MODE_INT)
+    if (code == FIELD_DECL && DECL_BIT_FIELD (decl)
+        && TYPE_SIZE (type) != 0
+        && TREE_CODE (TYPE_SIZE (type)) == INTEGER_CST
+        && GET_MODE_CLASS (TYPE_MODE (type)) == MODE_INT)
     {
-      enum machine_mode xmode
-	= mode_for_size_tree (DECL_SIZE (decl), MODE_INT, 1);
-
-      if (xmode != BLKmode && known_align >= GET_MODE_ALIGNMENT (xmode))
-	{
-	  DECL_ALIGN (decl) = MAX (GET_MODE_ALIGNMENT (xmode),
-				   DECL_ALIGN (decl));
-	  DECL_MODE (decl) = xmode;
-	  DECL_BIT_FIELD (decl) = 0;
-	}
+        enum machine_mode xmode
+        = mode_for_size_tree (DECL_SIZE (decl), MODE_INT, 1);
+        
+        if (xmode != BLKmode && known_align >= GET_MODE_ALIGNMENT (xmode))
+        {
+            DECL_ALIGN (decl) = MAX (GET_MODE_ALIGNMENT (xmode),
+                                     DECL_ALIGN (decl));
+            DECL_MODE (decl) = xmode;
+            DECL_BIT_FIELD (decl) = 0;
+        }
     }
-
-  /* Turn off DECL_BIT_FIELD if we won't need it set.  */
-  if (code == FIELD_DECL && DECL_BIT_FIELD (decl)
-      && TYPE_MODE (type) == BLKmode && DECL_MODE (decl) == BLKmode
-      && known_align >= TYPE_ALIGN (type)
-      && DECL_ALIGN (decl) >= TYPE_ALIGN (type)
-      && DECL_SIZE_UNIT (decl) != 0)
-    DECL_BIT_FIELD (decl) = 0;
-
-  /* Evaluate nonconstant size only once, either now or as soon as safe.  */
-  if (DECL_SIZE (decl) != 0 && TREE_CODE (DECL_SIZE (decl)) != INTEGER_CST)
-    DECL_SIZE (decl) = variable_size (DECL_SIZE (decl));
-  if (DECL_SIZE_UNIT (decl) != 0
-      && TREE_CODE (DECL_SIZE_UNIT (decl)) != INTEGER_CST)
-    DECL_SIZE_UNIT (decl) = variable_size (DECL_SIZE_UNIT (decl));
-
-  /* If requested, warn about definitions of large data objects.  */
-  if (warn_larger_than
-      && (code == VAR_DECL || code == PARM_DECL)
-      && ! DECL_EXTERNAL (decl))
+    
+    /* Turn off DECL_BIT_FIELD if we won't need it set.  */
+    if (code == FIELD_DECL && DECL_BIT_FIELD (decl)
+        && TYPE_MODE (type) == BLKmode && DECL_MODE (decl) == BLKmode
+        && known_align >= TYPE_ALIGN (type)
+        && DECL_ALIGN (decl) >= TYPE_ALIGN (type)
+        && DECL_SIZE_UNIT (decl) != 0)
+        DECL_BIT_FIELD (decl) = 0;
+    
+    /* Evaluate nonconstant size only once, either now or as soon as safe.  */
+    if (DECL_SIZE (decl) != 0 && TREE_CODE (DECL_SIZE (decl)) != INTEGER_CST)
+        DECL_SIZE (decl) = variable_size (DECL_SIZE (decl));
+    if (DECL_SIZE_UNIT (decl) != 0
+        && TREE_CODE (DECL_SIZE_UNIT (decl)) != INTEGER_CST)
+        DECL_SIZE_UNIT (decl) = variable_size (DECL_SIZE_UNIT (decl));
+    
+    /* If requested, warn about definitions of large data objects.  */
+    if (warn_larger_than
+        && (code == VAR_DECL || code == PARM_DECL)
+        && ! DECL_EXTERNAL (decl))
     {
-      tree size = DECL_SIZE_UNIT (decl);
-
-      if (size != 0 && TREE_CODE (size) == INTEGER_CST
-	  && compare_tree_int (size, larger_than_size) > 0)
-	{
-	  unsigned int size_as_int = TREE_INT_CST_LOW (size);
-
-	  if (compare_tree_int (size, size_as_int) == 0)
-	    warning_with_decl (decl, "size of `%s' is %d bytes", size_as_int);
-	  else
-	    warning_with_decl (decl, "size of `%s' is larger than %d bytes",
-			       larger_than_size);
-	}
+        tree size = DECL_SIZE_UNIT (decl);
+        
+        if (size != 0 && TREE_CODE (size) == INTEGER_CST
+            && compare_tree_int (size, larger_than_size) > 0)
+        {
+            unsigned int size_as_int = TREE_INT_CST_LOW (size);
+            
+            if (compare_tree_int (size, size_as_int) == 0)
+                warning_with_decl (decl, "size of `%s' is %d bytes", size_as_int);
+            else
+                warning_with_decl (decl, "size of `%s' is larger than %d bytes",
+                                   larger_than_size);
+        }
     }
 }
 
 /* Hook for a front-end function that can modify the record layout as needed
-   immediately before it is finalized.  */
+ immediately before it is finalized.  */
 
 void (*lang_adjust_rli) PARAMS ((record_layout_info)) = 0;
 
 void
 set_lang_adjust_rli (f)
-     void (*f) PARAMS ((record_layout_info));
+void (*f) PARAMS ((record_layout_info));
 {
-  lang_adjust_rli = f;
+    lang_adjust_rli = f;
 }
 
 /* Begin laying out type T, which may be a RECORD_TYPE, UNION_TYPE, or
-   QUAL_UNION_TYPE.  Return a pointer to a struct record_layout_info which
-   is to be passed to all other layout functions for this record.  It is the
-   responsibility of the caller to call `free' for the storage returned. 
-   Note that garbage collection is not permitted until we finish laying
-   out the record.  */
+ QUAL_UNION_TYPE.  Return a pointer to a struct record_layout_info which
+ is to be passed to all other layout functions for this record.  It is the
+ responsibility of the caller to call `free' for the storage returned.
+ Note that garbage collection is not permitted until we finish laying
+ out the record.  */
 
 record_layout_info
 start_record_layout (t)
-     tree t;
+tree t;
 {
-  record_layout_info rli 
+    record_layout_info rli
     = (record_layout_info) xmalloc (sizeof (struct record_layout_info_s));
-
-  rli->t = t;
-
-  /* If the type has a minimum specified alignment (via an attribute
+    
+    rli->t = t;
+    
+    /* If the type has a minimum specified alignment (via an attribute
      declaration, for example) use it -- otherwise, start with a
      one-byte alignment.  */
-  rli->record_align = MAX (BITS_PER_UNIT, TYPE_ALIGN (t));
-  rli->unpacked_align = rli->unpadded_align = rli->record_align;
-  rli->offset_align = MAX (rli->record_align, BIGGEST_ALIGNMENT);
-
+    rli->record_align = MAX (BITS_PER_UNIT, TYPE_ALIGN (t));
+    rli->unpacked_align = rli->unpadded_align = rli->record_align;
+    rli->offset_align = MAX (rli->record_align, BIGGEST_ALIGNMENT);
+    
 #ifdef STRUCTURE_SIZE_BOUNDARY
-  /* Packed structures don't need to have minimum size.  */
-  if (! TYPE_PACKED (t))
-    rli->record_align = MAX (rli->record_align, STRUCTURE_SIZE_BOUNDARY);
+    /* Packed structures don't need to have minimum size.  */
+    if (! TYPE_PACKED (t))
+        rli->record_align = MAX (rli->record_align, STRUCTURE_SIZE_BOUNDARY);
 #endif
-
-  rli->offset = size_zero_node;
-  rli->bitpos = bitsize_zero_node;
-  rli->prev_field = 0;
-  rli->pending_statics = 0;
-  rli->packed_maybe_necessary = 0;
-
-  return rli;
+    
+    rli->offset = size_zero_node;
+    rli->bitpos = bitsize_zero_node;
+    rli->prev_field = 0;
+    rli->pending_statics = 0;
+    rli->packed_maybe_necessary = 0;
+    
+    return rli;
 }
 
 /* These four routines perform computations that convert between
-   the offset/bitpos forms and byte and bit offsets.  */
+ the offset/bitpos forms and byte and bit offsets.  */
 
 tree
 bit_from_pos (offset, bitpos)
-     tree offset, bitpos;
+tree offset, bitpos;
 {
-  return size_binop (PLUS_EXPR, bitpos,
-		     size_binop (MULT_EXPR, convert (bitsizetype, offset),
-				 bitsize_unit_node));
+    return size_binop (PLUS_EXPR, bitpos,
+                       size_binop (MULT_EXPR, convert (bitsizetype, offset),
+                                   bitsize_unit_node));
 }
 
 tree
 byte_from_pos (offset, bitpos)
-     tree offset, bitpos;
+tree offset, bitpos;
 {
-  return size_binop (PLUS_EXPR, offset,
-		     convert (sizetype,
-			      size_binop (TRUNC_DIV_EXPR, bitpos,
-					  bitsize_unit_node)));
+    return size_binop (PLUS_EXPR, offset,
+                       convert (sizetype,
+                                size_binop (TRUNC_DIV_EXPR, bitpos,
+                                            bitsize_unit_node)));
 }
 
 void
 pos_from_byte (poffset, pbitpos, off_align, pos)
-     tree *poffset, *pbitpos;
-     unsigned int off_align;
-     tree pos;
+tree *poffset, *pbitpos;
+unsigned int off_align;
+tree pos;
 {
-  *poffset
+    *poffset
     = size_binop (MULT_EXPR,
-		  convert (sizetype,
-			   size_binop (FLOOR_DIV_EXPR, pos,
-				       bitsize_int (off_align
-						    / BITS_PER_UNIT))),
-		  size_int (off_align / BITS_PER_UNIT));
-  *pbitpos = size_binop (MULT_EXPR,
-			 size_binop (FLOOR_MOD_EXPR, pos,
-				     bitsize_int (off_align / BITS_PER_UNIT)),
-			 bitsize_unit_node);
+                  convert (sizetype,
+                           size_binop (FLOOR_DIV_EXPR, pos,
+                                       bitsize_int (off_align
+                                                    / BITS_PER_UNIT))),
+                  size_int (off_align / BITS_PER_UNIT));
+    *pbitpos = size_binop (MULT_EXPR,
+                           size_binop (FLOOR_MOD_EXPR, pos,
+                                       bitsize_int (off_align / BITS_PER_UNIT)),
+                           bitsize_unit_node);
 }
 
 void
 pos_from_bit (poffset, pbitpos, off_align, pos)
-     tree *poffset, *pbitpos;
-     unsigned int off_align;
-     tree pos;
+tree *poffset, *pbitpos;
+unsigned int off_align;
+tree pos;
 {
-  *poffset = size_binop (MULT_EXPR,
-			 convert (sizetype,
-				  size_binop (FLOOR_DIV_EXPR, pos,
-					      bitsize_int (off_align))),
-			 size_int (off_align / BITS_PER_UNIT));
-  *pbitpos = size_binop (FLOOR_MOD_EXPR, pos, bitsize_int (off_align));
+    *poffset = size_binop (MULT_EXPR,
+                           convert (sizetype,
+                                    size_binop (FLOOR_DIV_EXPR, pos,
+                                                bitsize_int (off_align))),
+                           size_int (off_align / BITS_PER_UNIT));
+    *pbitpos = size_binop (FLOOR_MOD_EXPR, pos, bitsize_int (off_align));
 }
 
 /* Given a pointer to bit and byte offsets and an offset alignment,
-   normalize the offsets so they are within the alignment.  */
+ normalize the offsets so they are within the alignment.  */
 
 void
 normalize_offset (poffset, pbitpos, off_align)
-     tree *poffset, *pbitpos;
-     unsigned int off_align;
+tree *poffset, *pbitpos;
+unsigned int off_align;
 {
-  /* If the bit position is now larger than it should be, adjust it
+    /* If the bit position is now larger than it should be, adjust it
      downwards.  */
-  if (compare_tree_int (*pbitpos, off_align) >= 0)
+    if (compare_tree_int (*pbitpos, off_align) >= 0)
     {
-      tree extra_aligns = size_binop (FLOOR_DIV_EXPR, *pbitpos,
-				      bitsize_int (off_align));
-
-      *poffset
-	= size_binop (PLUS_EXPR, *poffset,
-		      size_binop (MULT_EXPR, convert (sizetype, extra_aligns),
-				  size_int (off_align / BITS_PER_UNIT)));
-				
-      *pbitpos
-	= size_binop (FLOOR_MOD_EXPR, *pbitpos, bitsize_int (off_align));
+        tree extra_aligns = size_binop (FLOOR_DIV_EXPR, *pbitpos,
+                                        bitsize_int (off_align));
+        
+        // crash point
+        tree converted_tree = convert (sizetype, extra_aligns);
+        *poffset = size_binop (PLUS_EXPR, *poffset, size_binop (MULT_EXPR, converted_tree, size_int (off_align / BITS_PER_UNIT)));
+        
+        *pbitpos
+        = size_binop (FLOOR_MOD_EXPR, *pbitpos, bitsize_int (off_align));
     }
 }
 
@@ -595,604 +594,607 @@ normalize_offset (poffset, pbitpos, off_align)
 
 void
 debug_rli (rli)
-     record_layout_info rli;
+record_layout_info rli;
 {
-  print_node_brief (stderr, "type", rli->t, 0);
-  print_node_brief (stderr, "\noffset", rli->offset, 0);
-  print_node_brief (stderr, " bitpos", rli->bitpos, 0);
-
-  fprintf (stderr, "\naligns: rec = %u, unpack = %u, unpad = %u, off = %u\n",
-	   rli->record_align, rli->unpacked_align, rli->unpadded_align,
-	   rli->offset_align);
-  if (rli->packed_maybe_necessary)
-    fprintf (stderr, "packed may be necessary\n");
-
-  if (rli->pending_statics)
+    print_node_brief (stderr, "type", rli->t, 0);
+    print_node_brief (stderr, "\noffset", rli->offset, 0);
+    print_node_brief (stderr, " bitpos", rli->bitpos, 0);
+    
+    fprintf (stderr, "\naligns: rec = %u, unpack = %u, unpad = %u, off = %u\n",
+             rli->record_align, rli->unpacked_align, rli->unpadded_align,
+             rli->offset_align);
+    if (rli->packed_maybe_necessary)
+        fprintf (stderr, "packed may be necessary\n");
+    
+    if (rli->pending_statics)
     {
-      fprintf (stderr, "pending statics:\n");
-      debug_tree (rli->pending_statics);
+        fprintf (stderr, "pending statics:\n");
+        debug_tree (rli->pending_statics);
     }
 }
 
 /* Given an RLI with a possibly-incremented BITPOS, adjust OFFSET and
-   BITPOS if necessary to keep BITPOS below OFFSET_ALIGN.  */
+ BITPOS if necessary to keep BITPOS below OFFSET_ALIGN.  */
 
 void
 normalize_rli (rli)
-     record_layout_info rli;
+record_layout_info rli;
 {
-  normalize_offset (&rli->offset, &rli->bitpos, rli->offset_align);
+    normalize_offset (&rli->offset, &rli->bitpos, rli->offset_align);
 }
 
 /* Returns the size in bytes allocated so far.  */
 
 tree
 rli_size_unit_so_far (rli)
-     record_layout_info rli;
+record_layout_info rli;
 {
-  return byte_from_pos (rli->offset, rli->bitpos);
+    return byte_from_pos (rli->offset, rli->bitpos);
 }
 
 /* Returns the size in bits allocated so far.  */
 
 tree
 rli_size_so_far (rli)
-     record_layout_info rli;
+record_layout_info rli;
 {
-  return bit_from_pos (rli->offset, rli->bitpos);
+    return bit_from_pos (rli->offset, rli->bitpos);
 }
 
 /* Called from place_field to handle unions.  */
 
 static void
 place_union_field (rli, field)
-     record_layout_info rli;
-     tree field;
+record_layout_info rli;
+tree field;
 {
-  unsigned int desired_align;
-
-  layout_decl (field, 0);
-  
-  DECL_FIELD_OFFSET (field) = size_zero_node;
-  DECL_FIELD_BIT_OFFSET (field) = bitsize_zero_node;
-  SET_DECL_OFFSET_ALIGN (field, BIGGEST_ALIGNMENT);
-
-  desired_align = DECL_ALIGN (field);
-
+    unsigned int desired_align;
+    
+    layout_decl (field, 0);
+    
+    DECL_FIELD_OFFSET (field) = size_zero_node;
+    DECL_FIELD_BIT_OFFSET (field) = bitsize_zero_node;
+    SET_DECL_OFFSET_ALIGN (field, BIGGEST_ALIGNMENT);
+    
+    desired_align = DECL_ALIGN (field);
+    
 #ifdef BIGGEST_FIELD_ALIGNMENT
-  /* Some targets (i.e. i386) limit union field alignment
+    /* Some targets (i.e. i386) limit union field alignment
      to a lower boundary than alignment of variables unless
      it was overridden by attribute aligned.  */
-  if (! DECL_USER_ALIGN (field))
-    desired_align =
-      MIN (desired_align, (unsigned) BIGGEST_FIELD_ALIGNMENT);
+    if (! DECL_USER_ALIGN (field))
+        desired_align =
+        MIN (desired_align, (unsigned) BIGGEST_FIELD_ALIGNMENT);
 #endif
-
+    
 #ifdef ADJUST_FIELD_ALIGN
-  if (! DECL_USER_ALIGN (field))
-    desired_align = ADJUST_FIELD_ALIGN (field, desired_align);
+    if (! DECL_USER_ALIGN (field))
+        desired_align = ADJUST_FIELD_ALIGN (field, desired_align);
 #endif
-
-  TYPE_USER_ALIGN (rli->t) |= DECL_USER_ALIGN (field);
-
-  /* Union must be at least as aligned as any field requires.  */
-  rli->record_align = MAX (rli->record_align, desired_align);
-  rli->unpadded_align = MAX (rli->unpadded_align, desired_align);
-
+    
+    TYPE_USER_ALIGN (rli->t) |= DECL_USER_ALIGN (field);
+    
+    /* Union must be at least as aligned as any field requires.  */
+    rli->record_align = MAX (rli->record_align, desired_align);
+    rli->unpadded_align = MAX (rli->unpadded_align, desired_align);
+    
 #ifdef PCC_BITFIELD_TYPE_MATTERS
-  /* On the m88000, a bit field of declare type `int' forces the
+    /* On the m88000, a bit field of declare type `int' forces the
      entire union to have `int' alignment.  */
-  if (PCC_BITFIELD_TYPE_MATTERS && DECL_BIT_FIELD_TYPE (field))
+    if (PCC_BITFIELD_TYPE_MATTERS && DECL_BIT_FIELD_TYPE (field))
     {
-      unsigned int type_align = TYPE_ALIGN (TREE_TYPE (field));
-
+        unsigned int type_align = TYPE_ALIGN (TREE_TYPE (field));
+        
 #ifdef ADJUST_FIELD_ALIGN
-      if (! TYPE_USER_ALIGN (TREE_TYPE (field)))
-	type_align = ADJUST_FIELD_ALIGN (field, type_align);
+        if (! TYPE_USER_ALIGN (TREE_TYPE (field)))
+            type_align = ADJUST_FIELD_ALIGN (field, type_align);
 #endif
-      rli->record_align = MAX (rli->record_align, type_align);
-      rli->unpadded_align = MAX (rli->unpadded_align, type_align);
-      TYPE_USER_ALIGN (rli->t) |= TYPE_USER_ALIGN (TREE_TYPE (field));
+        rli->record_align = MAX (rli->record_align, type_align);
+        rli->unpadded_align = MAX (rli->unpadded_align, type_align);
+        TYPE_USER_ALIGN (rli->t) |= TYPE_USER_ALIGN (TREE_TYPE (field));
     }
 #endif
-
-  /* We assume the union's size will be a multiple of a byte so we don't
+    
+    /* We assume the union's size will be a multiple of a byte so we don't
      bother with BITPOS.  */
-  if (TREE_CODE (rli->t) == UNION_TYPE)
-    rli->offset = size_binop (MAX_EXPR, rli->offset, DECL_SIZE_UNIT (field));
-  else if (TREE_CODE (rli->t) == QUAL_UNION_TYPE)
-    rli->offset = fold (build (COND_EXPR, sizetype, 
-			       DECL_QUALIFIER (field),
-			       DECL_SIZE_UNIT (field), rli->offset));
+    if (TREE_CODE (rli->t) == UNION_TYPE)
+        rli->offset = size_binop (MAX_EXPR, rli->offset, DECL_SIZE_UNIT (field));
+    else if (TREE_CODE (rli->t) == QUAL_UNION_TYPE)
+        rli->offset = fold (build (COND_EXPR, sizetype,
+                                   DECL_QUALIFIER (field),
+                                   DECL_SIZE_UNIT (field), rli->offset));
 }
 
 /* RLI contains information about the layout of a RECORD_TYPE.  FIELD
-   is a FIELD_DECL to be added after those fields already present in
-   T.  (FIELD is not actually added to the TYPE_FIELDS list here;
-   callers that desire that behavior must manually perform that step.)  */
+ is a FIELD_DECL to be added after those fields already present in
+ T.  (FIELD is not actually added to the TYPE_FIELDS list here;
+ callers that desire that behavior must manually perform that step.)  */
 
 void
 place_field (rli, field)
-     record_layout_info rli;
-     tree field;
+record_layout_info rli;
+tree field;
 {
-  /* The alignment required for FIELD.  */
-  unsigned int desired_align;
-  /* The alignment FIELD would have if we just dropped it into the
+    /* The alignment required for FIELD.  */
+    unsigned int desired_align;
+    /* The alignment FIELD would have if we just dropped it into the
      record as it presently stands.  */
-  unsigned int known_align;
-  unsigned int actual_align;
-  unsigned int user_align;
-  /* The type of this field.  */
-  tree type = TREE_TYPE (field);
- 
-  if (TREE_CODE (field) == ERROR_MARK || TREE_CODE (type) == ERROR_MARK)
-      return;
-
-  /* If FIELD is static, then treat it like a separate variable, not
+    unsigned int known_align;
+    unsigned int actual_align;
+    unsigned int user_align;
+    /* The type of this field.  */
+    tree type = TREE_TYPE (field);
+    
+    if (TREE_CODE (field) == ERROR_MARK || TREE_CODE (type) == ERROR_MARK)
+        return;
+    
+    /* If FIELD is static, then treat it like a separate variable, not
      really like a structure field.  If it is a FUNCTION_DECL, it's a
      method.  In both cases, all we do is lay out the decl, and we do
      it *after* the record is laid out.  */
-  if (TREE_CODE (field) == VAR_DECL)
+    if (TREE_CODE (field) == VAR_DECL)
     {
-      rli->pending_statics = tree_cons (NULL_TREE, field,
-					rli->pending_statics);
-      return;
+        rli->pending_statics = tree_cons (NULL_TREE, field,
+                                          rli->pending_statics);
+        return;
     }
-
-  /* Enumerators and enum types which are local to this class need not
+    
+    /* Enumerators and enum types which are local to this class need not
      be laid out.  Likewise for initialized constant fields.  */
-  else if (TREE_CODE (field) != FIELD_DECL)
-    return;
-
-  /* Unions are laid out very differently than records, so split
+    else if (TREE_CODE (field) != FIELD_DECL)
+        return;
+    
+    /* Unions are laid out very differently than records, so split
      that code off to another function.  */
-  else if (TREE_CODE (rli->t) != RECORD_TYPE)
+    else if (TREE_CODE (rli->t) != RECORD_TYPE)
     {
-      place_union_field (rli, field);
-      return;
+        place_union_field (rli, field);
+        return;
     }
-
-  /* Work out the known alignment so far.  Note that A & (-A) is the
+    
+    /* Work out the known alignment so far.  Note that A & (-A) is the
      value of the least-significant bit in A that is one.  */
-  if (! integer_zerop (rli->bitpos))
-    known_align = (tree_low_cst (rli->bitpos, 1)
-		   & - tree_low_cst (rli->bitpos, 1));
-  else if (integer_zerop (rli->offset))
-    known_align = BIGGEST_ALIGNMENT;
-  else if (host_integerp (rli->offset, 1))
-    known_align = (BITS_PER_UNIT
-		   * (tree_low_cst (rli->offset, 1)
-		      & - tree_low_cst (rli->offset, 1)));
-  else
-    known_align = rli->offset_align;
-
-  /* Lay out the field so we know what alignment it needs.  For a
+    if (! integer_zerop (rli->bitpos))
+        known_align = (tree_low_cst (rli->bitpos, 1)
+                       & - tree_low_cst (rli->bitpos, 1));
+    else if (integer_zerop (rli->offset))
+        known_align = BIGGEST_ALIGNMENT;
+    else if (host_integerp (rli->offset, 1))
+        known_align = (BITS_PER_UNIT
+                       * (tree_low_cst (rli->offset, 1)
+                          & - tree_low_cst (rli->offset, 1)));
+    else
+        known_align = rli->offset_align;
+    
+    /* Lay out the field so we know what alignment it needs.  For a
      packed field, use the alignment as specified, disregarding what
      the type would want.  */
-  desired_align = DECL_ALIGN (field);
-  user_align = DECL_USER_ALIGN (field);
-  layout_decl (field, known_align);
-  if (! DECL_PACKED (field))
+    desired_align = DECL_ALIGN (field);
+    user_align = DECL_USER_ALIGN (field);
+    layout_decl (field, known_align);
+    if (! DECL_PACKED (field))
     {
-      desired_align = DECL_ALIGN (field);
-      user_align = DECL_USER_ALIGN (field);
+        desired_align = DECL_ALIGN (field);
+        user_align = DECL_USER_ALIGN (field);
     }
-
-  /* Some targets (i.e. i386, VMS) limit struct field alignment
+    
+    /* Some targets (i.e. i386, VMS) limit struct field alignment
      to a lower boundary than alignment of variables unless
      it was overridden by attribute aligned.  */
 #ifdef BIGGEST_FIELD_ALIGNMENT
-  if (! user_align)
-    desired_align
-      = MIN (desired_align, (unsigned) BIGGEST_FIELD_ALIGNMENT);
+    if (! user_align)
+        desired_align
+        = MIN (desired_align, (unsigned) BIGGEST_FIELD_ALIGNMENT);
 #endif
-
+    
 #ifdef ADJUST_FIELD_ALIGN
-  if (! user_align)
-    desired_align = ADJUST_FIELD_ALIGN (field, desired_align);
+    if (! user_align)
+        desired_align = ADJUST_FIELD_ALIGN (field, desired_align);
 #endif
-
-  /* Record must have at least as much alignment as any field.
+    
+    /* Record must have at least as much alignment as any field.
      Otherwise, the alignment of the field within the record is
      meaningless.  */
-  if ((* targetm.ms_bitfield_layout_p) (rli->t)
-      && type != error_mark_node
-      && DECL_BIT_FIELD_TYPE (field)
-      && ! integer_zerop (TYPE_SIZE (type))
-      && integer_zerop (DECL_SIZE (field)))
+    if ((* targetm.ms_bitfield_layout_p) (rli->t)
+        && type != error_mark_node
+        && DECL_BIT_FIELD_TYPE (field)
+        && ! integer_zerop (TYPE_SIZE (type))
+        && integer_zerop (DECL_SIZE (field)))
     {
-      if (rli->prev_field
-	  && DECL_BIT_FIELD_TYPE (rli->prev_field)
-	  && ! integer_zerop (DECL_SIZE (rli->prev_field)))
-	{
-	  rli->record_align = MAX (rli->record_align, desired_align);
-	  rli->unpacked_align = MAX (rli->unpacked_align, TYPE_ALIGN (type));
-	}
-      else
-	desired_align = 1;
-    }	
-  else
+        if (rli->prev_field
+            && DECL_BIT_FIELD_TYPE (rli->prev_field)
+            && ! integer_zerop (DECL_SIZE (rli->prev_field)))
+        {
+            rli->record_align = MAX (rli->record_align, desired_align);
+            rli->unpacked_align = MAX (rli->unpacked_align, TYPE_ALIGN (type));
+        }
+        else
+            desired_align = 1;
+    }
+    else
 #ifdef PCC_BITFIELD_TYPE_MATTERS
-  if (PCC_BITFIELD_TYPE_MATTERS && type != error_mark_node
-      && ! (* targetm.ms_bitfield_layout_p) (rli->t)
-      && DECL_BIT_FIELD_TYPE (field)
-      && ! integer_zerop (TYPE_SIZE (type)))
-    {
-      /* For these machines, a zero-length field does not
-	 affect the alignment of the structure as a whole.
-	 It does, however, affect the alignment of the next field
-	 within the structure.  */
-      if (! integer_zerop (DECL_SIZE (field)))
-	rli->record_align = MAX (rli->record_align, desired_align);
-      else if (! DECL_PACKED (field))
-	desired_align = TYPE_ALIGN (type);
-
-      /* A named bit field of declared type `int'
-	 forces the entire structure to have `int' alignment.  */
-      if (DECL_NAME (field) != 0)
-	{
-	  unsigned int type_align = TYPE_ALIGN (type);
-
+        if (PCC_BITFIELD_TYPE_MATTERS && type != error_mark_node
+            && ! (* targetm.ms_bitfield_layout_p) (rli->t)
+            && DECL_BIT_FIELD_TYPE (field)
+            && ! integer_zerop (TYPE_SIZE (type)))
+        {
+            /* For these machines, a zero-length field does not
+             affect the alignment of the structure as a whole.
+             It does, however, affect the alignment of the next field
+             within the structure.  */
+            if (! integer_zerop (DECL_SIZE (field)))
+                rli->record_align = MAX (rli->record_align, desired_align);
+            else if (! DECL_PACKED (field))
+                desired_align = TYPE_ALIGN (type);
+            
+            /* A named bit field of declared type `int'
+             forces the entire structure to have `int' alignment.  */
+            if (DECL_NAME (field) != 0)
+            {
+                unsigned int type_align = TYPE_ALIGN (type);
+                
 #ifdef ADJUST_FIELD_ALIGN
-	  if (! TYPE_USER_ALIGN (type))
-	    type_align = ADJUST_FIELD_ALIGN (field, type_align);
+                if (! TYPE_USER_ALIGN (type))
+                    type_align = ADJUST_FIELD_ALIGN (field, type_align);
 #endif
-
-	  if (maximum_field_alignment != 0)
-	    type_align = MIN (type_align, maximum_field_alignment);
-	  else if (DECL_PACKED (field))
-	    type_align = MIN (type_align, BITS_PER_UNIT);
-
-	  rli->record_align = MAX (rli->record_align, type_align);
-	  rli->unpadded_align = MAX (rli->unpadded_align, DECL_ALIGN (field));
-	  if (warn_packed)
-	    rli->unpacked_align = MAX (rli->unpacked_align, TYPE_ALIGN (type));
-	  user_align |= TYPE_USER_ALIGN (type);
-	}
-    }
-  else
+                
+                if (maximum_field_alignment != 0)
+                    type_align = MIN (type_align, maximum_field_alignment);
+                else if (DECL_PACKED (field))
+                    type_align = MIN (type_align, BITS_PER_UNIT);
+                
+                rli->record_align = MAX (rli->record_align, type_align);
+                rli->unpadded_align = MAX (rli->unpadded_align, DECL_ALIGN (field));
+                if (warn_packed)
+                    rli->unpacked_align = MAX (rli->unpacked_align, TYPE_ALIGN (type));
+                user_align |= TYPE_USER_ALIGN (type);
+            }
+        }
+        else
 #endif
+        {
+            rli->record_align = MAX (rli->record_align, desired_align);
+            rli->unpacked_align = MAX (rli->unpacked_align, TYPE_ALIGN (type));
+            rli->unpadded_align = MAX (rli->unpadded_align, DECL_ALIGN (field));
+        }
+    
+    if (warn_packed && DECL_PACKED (field))
     {
-      rli->record_align = MAX (rli->record_align, desired_align);
-      rli->unpacked_align = MAX (rli->unpacked_align, TYPE_ALIGN (type));
-      rli->unpadded_align = MAX (rli->unpadded_align, DECL_ALIGN (field));
-    }
-
-  if (warn_packed && DECL_PACKED (field))
-    {
-      if (known_align > TYPE_ALIGN (type))
-	{
-	  if (TYPE_ALIGN (type) > desired_align)
-	    {
-	      if (STRICT_ALIGNMENT)
-		warning_with_decl (field, "packed attribute causes inefficient alignment for `%s'");
-	      else
-		warning_with_decl (field, "packed attribute is unnecessary for `%s'");
-	    }
-	}
-      else
-	rli->packed_maybe_necessary = 1;
+        if (known_align > TYPE_ALIGN (type))
+        {
+            if (TYPE_ALIGN (type) > desired_align)
+            {
+                if (STRICT_ALIGNMENT)
+                    warning_with_decl (field, "packed attribute causes inefficient alignment for `%s'");
+                else
+                    warning_with_decl (field, "packed attribute is unnecessary for `%s'");
+            }
+        }
+        else
+            rli->packed_maybe_necessary = 1;
     }
-
-  /* Does this field automatically have alignment it needs by virtue
+    
+    /* Does this field automatically have alignment it needs by virtue
      of the fields that precede it and the record's own alignment?  */
-  if (known_align < desired_align)
+    if (known_align < desired_align)
     {
-      /* No, we need to skip space before this field.
-	 Bump the cumulative size to multiple of field alignment.  */
-
-      if (warn_padded)
-	warning_with_decl (field, "padding struct to align `%s'");
-
-      /* If the alignment is still within offset_align, just align
-	 the bit position.  */
-      if (desired_align < rli->offset_align)
-	rli->bitpos = round_up (rli->bitpos, desired_align);
-      else
-	{
-	  /* First adjust OFFSET by the partial bits, then align.  */
-	  rli->offset
-	    = size_binop (PLUS_EXPR, rli->offset,
-			  convert (sizetype,
-				   size_binop (CEIL_DIV_EXPR, rli->bitpos,
-					       bitsize_unit_node)));
-	  rli->bitpos = bitsize_zero_node;
-
-	  rli->offset = round_up (rli->offset, desired_align / BITS_PER_UNIT);
-	}
-
-      if (! TREE_CONSTANT (rli->offset))
-	rli->offset_align = desired_align;
-
+        /* No, we need to skip space before this field.
+         Bump the cumulative size to multiple of field alignment.  */
+        
+        if (warn_padded)
+            warning_with_decl (field, "padding struct to align `%s'");
+        
+        /* If the alignment is still within offset_align, just align
+         the bit position.  */
+        if (desired_align < rli->offset_align)
+            rli->bitpos = round_up (rli->bitpos, desired_align);
+        else
+        {
+            /* First adjust OFFSET by the partial bits, then align.  */
+            rli->offset
+            = size_binop (PLUS_EXPR, rli->offset,
+                          convert (sizetype,
+                                   size_binop (CEIL_DIV_EXPR, rli->bitpos,
+                                               bitsize_unit_node)));
+            rli->bitpos = bitsize_zero_node;
+            
+            rli->offset = round_up (rli->offset, desired_align / BITS_PER_UNIT);
+        }
+        
+        if (! TREE_CONSTANT (rli->offset))
+            rli->offset_align = desired_align;
+        
     }
-
-  /* Handle compatibility with PCC.  Note that if the record has any
+    
+    /* Handle compatibility with PCC.  Note that if the record has any
      variable-sized fields, we need not worry about compatibility.  */
 #ifdef PCC_BITFIELD_TYPE_MATTERS
-  if (PCC_BITFIELD_TYPE_MATTERS
-      && ! (* targetm.ms_bitfield_layout_p) (rli->t)
-      && TREE_CODE (field) == FIELD_DECL
-      && type != error_mark_node
-      && DECL_BIT_FIELD (field)
-      && ! DECL_PACKED (field)
-      && maximum_field_alignment == 0
-      && ! integer_zerop (DECL_SIZE (field))
-      && host_integerp (DECL_SIZE (field), 1)
-      && host_integerp (rli->offset, 1)
-      && host_integerp (TYPE_SIZE (type), 1))
+    if (PCC_BITFIELD_TYPE_MATTERS
+        && ! (* targetm.ms_bitfield_layout_p) (rli->t)
+        && TREE_CODE (field) == FIELD_DECL
+        && type != error_mark_node
+        && DECL_BIT_FIELD (field)
+        && ! DECL_PACKED (field)
+        && maximum_field_alignment == 0
+        && ! integer_zerop (DECL_SIZE (field))
+        && host_integerp (DECL_SIZE (field), 1)
+        && host_integerp (rli->offset, 1)
+        && host_integerp (TYPE_SIZE (type), 1))
     {
-      unsigned int type_align = TYPE_ALIGN (type);
-      tree dsize = DECL_SIZE (field);
-      HOST_WIDE_INT field_size = tree_low_cst (dsize, 1);
-      HOST_WIDE_INT offset = tree_low_cst (rli->offset, 0);
-      HOST_WIDE_INT bit_offset = tree_low_cst (rli->bitpos, 0);
-
+        unsigned int type_align = TYPE_ALIGN (type);
+        tree dsize = DECL_SIZE (field);
+        HOST_WIDE_INT field_size = tree_low_cst (dsize, 1);
+        HOST_WIDE_INT offset = tree_low_cst (rli->offset, 0);
+        HOST_WIDE_INT bit_offset = tree_low_cst (rli->bitpos, 0);
+        
 #ifdef ADJUST_FIELD_ALIGN
-      if (! TYPE_USER_ALIGN (type))
-	type_align = ADJUST_FIELD_ALIGN (field, type_align);
+        if (! TYPE_USER_ALIGN (type))
+            type_align = ADJUST_FIELD_ALIGN (field, type_align);
 #endif
-
-      /* A bit field may not span more units of alignment of its type
-	 than its type itself.  Advance to next boundary if necessary.  */
-      if ((((offset * BITS_PER_UNIT + bit_offset + field_size +
-	     type_align - 1)
-	    / type_align)
-	   - (offset * BITS_PER_UNIT + bit_offset) / type_align)
-	  > tree_low_cst (TYPE_SIZE (type), 1) / type_align)
-	rli->bitpos = round_up (rli->bitpos, type_align);
-
-      user_align |= TYPE_USER_ALIGN (type);
+        
+        /* A bit field may not span more units of alignment of its type
+         than its type itself.  Advance to next boundary if necessary.  */
+        if ((((offset * BITS_PER_UNIT + bit_offset + field_size +
+               type_align - 1)
+              / type_align)
+             - (offset * BITS_PER_UNIT + bit_offset) / type_align)
+            > tree_low_cst (TYPE_SIZE (type), 1) / type_align)
+            rli->bitpos = round_up (rli->bitpos, type_align);
+        
+        user_align |= TYPE_USER_ALIGN (type);
     }
 #endif
-
+    
 #ifdef BITFIELD_NBYTES_LIMITED
-  if (BITFIELD_NBYTES_LIMITED
-      && ! (* targetm.ms_bitfield_layout_p) (rli->t)
-      && TREE_CODE (field) == FIELD_DECL
-      && type != error_mark_node
-      && DECL_BIT_FIELD_TYPE (field)
-      && ! DECL_PACKED (field)
-      && ! integer_zerop (DECL_SIZE (field))
-      && host_integerp (DECL_SIZE (field), 1)
-      && host_integerp (rli->offset, 1)
-      && host_integerp (TYPE_SIZE (type), 1))
+    if (BITFIELD_NBYTES_LIMITED
+        && ! (* targetm.ms_bitfield_layout_p) (rli->t)
+        && TREE_CODE (field) == FIELD_DECL
+        && type != error_mark_node
+        && DECL_BIT_FIELD_TYPE (field)
+        && ! DECL_PACKED (field)
+        && ! integer_zerop (DECL_SIZE (field))
+        && host_integerp (DECL_SIZE (field), 1)
+        && host_integerp (rli->offset, 1)
+        && host_integerp (TYPE_SIZE (type), 1))
     {
-      unsigned int type_align = TYPE_ALIGN (type);
-      tree dsize = DECL_SIZE (field);
-      HOST_WIDE_INT field_size = tree_low_cst (dsize, 1);
-      HOST_WIDE_INT offset = tree_low_cst (rli->offset, 0);
-      HOST_WIDE_INT bit_offset = tree_low_cst (rli->bitpos, 0);
-
+        unsigned int type_align = TYPE_ALIGN (type);
+        tree dsize = DECL_SIZE (field);
+        HOST_WIDE_INT field_size = tree_low_cst (dsize, 1);
+        HOST_WIDE_INT offset = tree_low_cst (rli->offset, 0);
+        HOST_WIDE_INT bit_offset = tree_low_cst (rli->bitpos, 0);
+        
 #ifdef ADJUST_FIELD_ALIGN
-      if (! TYPE_USER_ALIGN (type))
-	type_align = ADJUST_FIELD_ALIGN (field, type_align);
+        if (! TYPE_USER_ALIGN (type))
+            type_align = ADJUST_FIELD_ALIGN (field, type_align);
 #endif
-
-      if (maximum_field_alignment != 0)
-	type_align = MIN (type_align, maximum_field_alignment);
-      /* ??? This test is opposite the test in the containing if
-	 statement, so this code is unreachable currently.  */
-      else if (DECL_PACKED (field))
-	type_align = MIN (type_align, BITS_PER_UNIT);
-
-      /* A bit field may not span the unit of alignment of its type.
-	 Advance to next boundary if necessary.  */
-      /* ??? This code should match the code above for the
-	 PCC_BITFIELD_TYPE_MATTERS case.  */
-      if ((offset * BITS_PER_UNIT + bit_offset) / type_align
-	  != ((offset * BITS_PER_UNIT + bit_offset + field_size - 1)
-	      / type_align))
-	rli->bitpos = round_up (rli->bitpos, type_align);
-
-      user_align |= TYPE_USER_ALIGN (type);
+        
+        if (maximum_field_alignment != 0)
+            type_align = MIN (type_align, maximum_field_alignment);
+        /* ??? This test is opposite the test in the containing if
+         statement, so this code is unreachable currently.  */
+        else if (DECL_PACKED (field))
+            type_align = MIN (type_align, BITS_PER_UNIT);
+        
+        /* A bit field may not span the unit of alignment of its type.
+         Advance to next boundary if necessary.  */
+        /* ??? This code should match the code above for the
+         PCC_BITFIELD_TYPE_MATTERS case.  */
+        if ((offset * BITS_PER_UNIT + bit_offset) / type_align
+            != ((offset * BITS_PER_UNIT + bit_offset + field_size - 1)
+                / type_align))
+            rli->bitpos = round_up (rli->bitpos, type_align);
+        
+        user_align |= TYPE_USER_ALIGN (type);
     }
 #endif
-
-  /* See the docs for TARGET_MS_BITFIELD_LAYOUT_P for details.  */
-  if ((* targetm.ms_bitfield_layout_p) (rli->t)
-      && TREE_CODE (field) == FIELD_DECL
-      && type != error_mark_node
-      && ! DECL_PACKED (field)
-      && rli->prev_field
-      && DECL_SIZE (field)
-      && host_integerp (DECL_SIZE (field), 1)
-      && DECL_SIZE (rli->prev_field)
-      && host_integerp (DECL_SIZE (rli->prev_field), 1)
-      && host_integerp (rli->offset, 1)
-      && host_integerp (TYPE_SIZE (type), 1)
-      && host_integerp (TYPE_SIZE (TREE_TYPE (rli->prev_field)), 1)
-      && ((DECL_BIT_FIELD_TYPE (rli->prev_field)
-	   && ! integer_zerop (DECL_SIZE (rli->prev_field)))
-	  || (DECL_BIT_FIELD_TYPE (field)
-	      && ! integer_zerop (DECL_SIZE (field))))
-      && (! simple_cst_equal (TYPE_SIZE (type),
-			      TYPE_SIZE (TREE_TYPE (rli->prev_field)))
-	  /* If the previous field was a zero-sized bit-field, either
-	     it was ignored, in which case we must ensure the proper
-	     alignment of this field here, or it already forced the
-	     alignment of this field, in which case forcing the
-	     alignment again is harmless.  So, do it in both cases.  */
-	  || (DECL_BIT_FIELD_TYPE (rli->prev_field)
-	      && integer_zerop (DECL_SIZE (rli->prev_field)))))
+    
+    /* See the docs for TARGET_MS_BITFIELD_LAYOUT_P for details.  */
+    if ((* targetm.ms_bitfield_layout_p) (rli->t)
+        && TREE_CODE (field) == FIELD_DECL
+        && type != error_mark_node
+        && ! DECL_PACKED (field)
+        && rli->prev_field
+        && DECL_SIZE (field)
+        && host_integerp (DECL_SIZE (field), 1)
+        && DECL_SIZE (rli->prev_field)
+        && host_integerp (DECL_SIZE (rli->prev_field), 1)
+        && host_integerp (rli->offset, 1)
+        && host_integerp (TYPE_SIZE (type), 1)
+        && host_integerp (TYPE_SIZE (TREE_TYPE (rli->prev_field)), 1)
+        && ((DECL_BIT_FIELD_TYPE (rli->prev_field)
+             && ! integer_zerop (DECL_SIZE (rli->prev_field)))
+            || (DECL_BIT_FIELD_TYPE (field)
+                && ! integer_zerop (DECL_SIZE (field))))
+        && (! simple_cst_equal (TYPE_SIZE (type),
+                                TYPE_SIZE (TREE_TYPE (rli->prev_field)))
+            /* If the previous field was a zero-sized bit-field, either
+             it was ignored, in which case we must ensure the proper
+             alignment of this field here, or it already forced the
+             alignment of this field, in which case forcing the
+             alignment again is harmless.  So, do it in both cases.  */
+            || (DECL_BIT_FIELD_TYPE (rli->prev_field)
+                && integer_zerop (DECL_SIZE (rli->prev_field)))))
     {
-      unsigned int type_align = TYPE_ALIGN (type);
-
-      if (rli->prev_field
-	  && DECL_BIT_FIELD_TYPE (rli->prev_field)
-	  /* If the previous bit-field is zero-sized, we've already
-	     accounted for its alignment needs (or ignored it, if
-	     appropriate) while placing it.  */
-	  && ! integer_zerop (DECL_SIZE (rli->prev_field)))
-	type_align = MAX (type_align,
-			  TYPE_ALIGN (TREE_TYPE (rli->prev_field)));
-
-      if (maximum_field_alignment != 0)
-	type_align = MIN (type_align, maximum_field_alignment);
-
-      rli->bitpos = round_up (rli->bitpos, type_align);
+        unsigned int type_align = TYPE_ALIGN (type);
+        
+        if (rli->prev_field
+            && DECL_BIT_FIELD_TYPE (rli->prev_field)
+            /* If the previous bit-field is zero-sized, we've already
+             accounted for its alignment needs (or ignored it, if
+             appropriate) while placing it.  */
+            && ! integer_zerop (DECL_SIZE (rli->prev_field)))
+            type_align = MAX (type_align,
+                              TYPE_ALIGN (TREE_TYPE (rli->prev_field)));
+        
+        if (maximum_field_alignment != 0)
+            type_align = MIN (type_align, maximum_field_alignment);
+        
+        rli->bitpos = round_up (rli->bitpos, type_align);
     }
-
-  /* Offset so far becomes the position of this field after normalizing.  */
-  normalize_rli (rli);
-  DECL_FIELD_OFFSET (field) = rli->offset;
-  DECL_FIELD_BIT_OFFSET (field) = rli->bitpos;
-  SET_DECL_OFFSET_ALIGN (field, rli->offset_align);
-
-  TYPE_USER_ALIGN (rli->t) |= user_align;
-
-  /* If this field ended up more aligned than we thought it would be (we
+    
+    /* Offset so far becomes the position of this field after normalizing.  */
+    normalize_rli (rli);
+    DECL_FIELD_OFFSET (field) = rli->offset;
+    DECL_FIELD_BIT_OFFSET (field) = rli->bitpos;
+    SET_DECL_OFFSET_ALIGN (field, rli->offset_align);
+    
+    TYPE_USER_ALIGN (rli->t) |= user_align;
+    
+    /* If this field ended up more aligned than we thought it would be (we
      approximate this by seeing if its position changed), lay out the field
      again; perhaps we can use an integral mode for it now.  */
-  if (! integer_zerop (DECL_FIELD_BIT_OFFSET (field)))
-    actual_align = (tree_low_cst (DECL_FIELD_BIT_OFFSET (field), 1)
-		    & - tree_low_cst (DECL_FIELD_BIT_OFFSET (field), 1));
-  else if (integer_zerop (DECL_FIELD_OFFSET (field)))
-    actual_align = BIGGEST_ALIGNMENT;
-  else if (host_integerp (DECL_FIELD_OFFSET (field), 1))
-    actual_align = (BITS_PER_UNIT
-		   * (tree_low_cst (DECL_FIELD_OFFSET (field), 1)
-		      & - tree_low_cst (DECL_FIELD_OFFSET (field), 1)));
-  else
-    actual_align = DECL_OFFSET_ALIGN (field);
-
-  if (known_align != actual_align)
-    layout_decl (field, actual_align);
-
-  rli->prev_field = field;
-
-  /* Now add size of this field to the size of the record.  If the size is
+    if (! integer_zerop (DECL_FIELD_BIT_OFFSET (field)))
+        actual_align = (tree_low_cst (DECL_FIELD_BIT_OFFSET (field), 1)
+                        & - tree_low_cst (DECL_FIELD_BIT_OFFSET (field), 1));
+    else if (integer_zerop (DECL_FIELD_OFFSET (field)))
+        actual_align = BIGGEST_ALIGNMENT;
+    else if (host_integerp (DECL_FIELD_OFFSET (field), 1))
+        actual_align = (BITS_PER_UNIT
+                        * (tree_low_cst (DECL_FIELD_OFFSET (field), 1)
+                           & - tree_low_cst (DECL_FIELD_OFFSET (field), 1)));
+    else
+        actual_align = DECL_OFFSET_ALIGN (field);
+    
+    if (known_align != actual_align)
+        layout_decl (field, actual_align);
+    
+    rli->prev_field = field;
+    
+    /* Now add size of this field to the size of the record.  If the size is
      not constant, treat the field as being a multiple of bytes and just
      adjust the offset, resetting the bit position.  Otherwise, apportion the
      size amongst the bit position and offset.  First handle the case of an
      unspecified size, which can happen when we have an invalid nested struct
      definition, such as struct j { struct j { int i; } }.  The error message
      is printed in finish_struct.  */
-  if (DECL_SIZE (field) == 0)
+    if (DECL_SIZE (field) == 0)
     /* Do nothing.  */;
-  else if (TREE_CODE (DECL_SIZE_UNIT (field)) != INTEGER_CST
-	   || TREE_CONSTANT_OVERFLOW (DECL_SIZE_UNIT (field)))
+    else if (TREE_CODE (DECL_SIZE_UNIT (field)) != INTEGER_CST
+             || TREE_CONSTANT_OVERFLOW (DECL_SIZE_UNIT (field)))
     {
-      rli->offset
-	= size_binop (PLUS_EXPR, rli->offset,
-		      convert (sizetype,
-			       size_binop (CEIL_DIV_EXPR, rli->bitpos,
-					   bitsize_unit_node)));
-      rli->offset
-	= size_binop (PLUS_EXPR, rli->offset, DECL_SIZE_UNIT (field));
-      rli->bitpos = bitsize_zero_node;
-      rli->offset_align = MIN (rli->offset_align, DECL_ALIGN (field));
+        rli->offset
+        = size_binop (PLUS_EXPR, rli->offset,
+                      convert (sizetype,
+                               size_binop (CEIL_DIV_EXPR, rli->bitpos,
+                                           bitsize_unit_node)));
+        rli->offset
+        = size_binop (PLUS_EXPR, rli->offset, DECL_SIZE_UNIT (field));
+        rli->bitpos = bitsize_zero_node;
+        rli->offset_align = MIN (rli->offset_align, DECL_ALIGN (field));
     }
-  else
+    else
     {
-      rli->bitpos = size_binop (PLUS_EXPR, rli->bitpos, DECL_SIZE (field));
-      normalize_rli (rli);
+        // Yoshi
+        // callee: normalize_offset (&rli->offset, &rli->bitpos, rli->offset_align);
+
+        rli->bitpos = size_binop (PLUS_EXPR, rli->bitpos, DECL_SIZE (field));
+        normalize_rli (rli);
     }
 }
 
 /* Assuming that all the fields have been laid out, this function uses
-   RLI to compute the final TYPE_SIZE, TYPE_ALIGN, etc. for the type
-   inidicated by RLI.  */
+ RLI to compute the final TYPE_SIZE, TYPE_ALIGN, etc. for the type
+ inidicated by RLI.  */
 
 static void
 finalize_record_size (rli)
-     record_layout_info rli;
+record_layout_info rli;
 {
-  tree unpadded_size, unpadded_size_unit;
-
-  /* Now we want just byte and bit offsets, so set the offset alignment
+    tree unpadded_size, unpadded_size_unit;
+    
+    /* Now we want just byte and bit offsets, so set the offset alignment
      to be a byte and then normalize.  */
-  rli->offset_align = BITS_PER_UNIT;
-  normalize_rli (rli);
-
-  /* Determine the desired alignment.  */
+    rli->offset_align = BITS_PER_UNIT;
+    normalize_rli (rli);
+    
+    /* Determine the desired alignment.  */
 #ifdef ROUND_TYPE_ALIGN
-  TYPE_ALIGN (rli->t) = ROUND_TYPE_ALIGN (rli->t, TYPE_ALIGN (rli->t),
-					  rli->record_align);
+    TYPE_ALIGN (rli->t) = ROUND_TYPE_ALIGN (rli->t, TYPE_ALIGN (rli->t),
+                                            rli->record_align);
 #else
-  TYPE_ALIGN (rli->t) = MAX (TYPE_ALIGN (rli->t), rli->record_align);
+    TYPE_ALIGN (rli->t) = MAX (TYPE_ALIGN (rli->t), rli->record_align);
 #endif
-
-  /* Compute the size so far.  Be sure to allow for extra bits in the
+    
+    /* Compute the size so far.  Be sure to allow for extra bits in the
      size in bytes.  We have guaranteed above that it will be no more
      than a single byte.  */
-  unpadded_size = rli_size_so_far (rli);
-  unpadded_size_unit = rli_size_unit_so_far (rli);
-  if (! integer_zerop (rli->bitpos))
-    unpadded_size_unit
-      = size_binop (PLUS_EXPR, unpadded_size_unit, size_one_node);
-
-  /* Record the un-rounded size in the binfo node.  But first we check
+    unpadded_size = rli_size_so_far (rli);
+    unpadded_size_unit = rli_size_unit_so_far (rli);
+    if (! integer_zerop (rli->bitpos))
+        unpadded_size_unit
+        = size_binop (PLUS_EXPR, unpadded_size_unit, size_one_node);
+    
+    /* Record the un-rounded size in the binfo node.  But first we check
      the size of TYPE_BINFO to make sure that BINFO_SIZE is available.  */
-  if (TYPE_BINFO (rli->t) && TREE_VEC_LENGTH (TYPE_BINFO (rli->t)) > 6)
+    if (TYPE_BINFO (rli->t) && TREE_VEC_LENGTH (TYPE_BINFO (rli->t)) > 6)
     {
-      TYPE_BINFO_SIZE (rli->t) = unpadded_size;
-      TYPE_BINFO_SIZE_UNIT (rli->t) = unpadded_size_unit;
+        TYPE_BINFO_SIZE (rli->t) = unpadded_size;
+        TYPE_BINFO_SIZE_UNIT (rli->t) = unpadded_size_unit;
     }
-
+    
     /* Round the size up to be a multiple of the required alignment */
 #ifdef ROUND_TYPE_SIZE
-  TYPE_SIZE (rli->t) = ROUND_TYPE_SIZE (rli->t, unpadded_size,
-					TYPE_ALIGN (rli->t));
-  TYPE_SIZE_UNIT (rli->t)
+    TYPE_SIZE (rli->t) = ROUND_TYPE_SIZE (rli->t, unpadded_size,
+                                          TYPE_ALIGN (rli->t));
+    TYPE_SIZE_UNIT (rli->t)
     = ROUND_TYPE_SIZE_UNIT (rli->t, unpadded_size_unit,
-			    TYPE_ALIGN (rli->t) / BITS_PER_UNIT);
+                            TYPE_ALIGN (rli->t) / BITS_PER_UNIT);
 #else
-  TYPE_SIZE (rli->t) = round_up (unpadded_size, TYPE_ALIGN (rli->t));
-  TYPE_SIZE_UNIT (rli->t) = round_up (unpadded_size_unit,
-				      TYPE_ALIGN (rli->t) / BITS_PER_UNIT);
+    TYPE_SIZE (rli->t) = round_up (unpadded_size, TYPE_ALIGN (rli->t));
+    TYPE_SIZE_UNIT (rli->t) = round_up (unpadded_size_unit,
+                                        TYPE_ALIGN (rli->t) / BITS_PER_UNIT);
 #endif
-
-  if (warn_padded && TREE_CONSTANT (unpadded_size)
-      && simple_cst_equal (unpadded_size, TYPE_SIZE (rli->t)) == 0)
-    warning ("padding struct size to alignment boundary");
-  
-  if (warn_packed && TREE_CODE (rli->t) == RECORD_TYPE
-      && TYPE_PACKED (rli->t) && ! rli->packed_maybe_necessary
-      && TREE_CONSTANT (unpadded_size))
+    
+    if (warn_padded && TREE_CONSTANT (unpadded_size)
+        && simple_cst_equal (unpadded_size, TYPE_SIZE (rli->t)) == 0)
+        warning ("padding struct size to alignment boundary");
+    
+    if (warn_packed && TREE_CODE (rli->t) == RECORD_TYPE
+        && TYPE_PACKED (rli->t) && ! rli->packed_maybe_necessary
+        && TREE_CONSTANT (unpadded_size))
     {
-      tree unpacked_size;
-
+        tree unpacked_size;
+        
 #ifdef ROUND_TYPE_ALIGN
-      rli->unpacked_align
-	= ROUND_TYPE_ALIGN (rli->t, TYPE_ALIGN (rli->t), rli->unpacked_align);
+        rli->unpacked_align
+        = ROUND_TYPE_ALIGN (rli->t, TYPE_ALIGN (rli->t), rli->unpacked_align);
 #else
-      rli->unpacked_align = MAX (TYPE_ALIGN (rli->t), rli->unpacked_align);
+        rli->unpacked_align = MAX (TYPE_ALIGN (rli->t), rli->unpacked_align);
 #endif
-
+        
 #ifdef ROUND_TYPE_SIZE
-      unpacked_size = ROUND_TYPE_SIZE (rli->t, TYPE_SIZE (rli->t),
-				       rli->unpacked_align);
+        unpacked_size = ROUND_TYPE_SIZE (rli->t, TYPE_SIZE (rli->t),
+                                         rli->unpacked_align);
 #else
-      unpacked_size = round_up (TYPE_SIZE (rli->t), rli->unpacked_align);
+        unpacked_size = round_up (TYPE_SIZE (rli->t), rli->unpacked_align);
 #endif
-
-      if (simple_cst_equal (unpacked_size, TYPE_SIZE (rli->t)))
-	{
-	  TYPE_PACKED (rli->t) = 0;
-
-	  if (TYPE_NAME (rli->t))
-	    {
-	      const char *name;
-
-	      if (TREE_CODE (TYPE_NAME (rli->t)) == IDENTIFIER_NODE)
-		name = IDENTIFIER_POINTER (TYPE_NAME (rli->t));
-	      else
-		name = IDENTIFIER_POINTER (DECL_NAME (TYPE_NAME (rli->t)));
-
-	      if (STRICT_ALIGNMENT)
-		warning ("packed attribute causes inefficient alignment for `%s'", name);
-	      else
-		warning ("packed attribute is unnecessary for `%s'", name);
-	    }
-	  else
-	    {
-	      if (STRICT_ALIGNMENT)
-		warning ("packed attribute causes inefficient alignment");
-	      else
-		warning ("packed attribute is unnecessary");
-	    }
-	}
+        
+        if (simple_cst_equal (unpacked_size, TYPE_SIZE (rli->t)))
+        {
+            TYPE_PACKED (rli->t) = 0;
+            
+            if (TYPE_NAME (rli->t))
+            {
+                const char *name;
+                
+                if (TREE_CODE (TYPE_NAME (rli->t)) == IDENTIFIER_NODE)
+                    name = IDENTIFIER_POINTER (TYPE_NAME (rli->t));
+                else
+                    name = IDENTIFIER_POINTER (DECL_NAME (TYPE_NAME (rli->t)));
+                
+                if (STRICT_ALIGNMENT)
+                    warning ("packed attribute causes inefficient alignment for `%s'", name);
+                else
+                    warning ("packed attribute is unnecessary for `%s'", name);
+            }
+            else
+            {
+                if (STRICT_ALIGNMENT)
+                    warning ("packed attribute causes inefficient alignment");
+                else
+                    warning ("packed attribute is unnecessary");
+            }
+        }
     }
 }
 
@@ -1200,810 +1202,810 @@ finalize_record_size (rli)
 
 void
 compute_record_mode (type)
-     tree type;
+tree type;
 {
-  tree field;
-  enum machine_mode mode = VOIDmode;
-
-  /* Most RECORD_TYPEs have BLKmode, so we start off assuming that.
+    tree field;
+    enum machine_mode mode = VOIDmode;
+    
+    /* Most RECORD_TYPEs have BLKmode, so we start off assuming that.
      However, if possible, we use a mode that fits in a register
      instead, in order to allow for better optimization down the
      line.  */
-  TYPE_MODE (type) = BLKmode;
-
-  if (! host_integerp (TYPE_SIZE (type), 1))
-    return;
-
-  /* A record which has any BLKmode members must itself be
+    TYPE_MODE (type) = BLKmode;
+    
+    if (! host_integerp (TYPE_SIZE (type), 1))
+        return;
+    
+    /* A record which has any BLKmode members must itself be
      BLKmode; it can't go in a register.  Unless the member is
      BLKmode only because it isn't aligned.  */
-  for (field = TYPE_FIELDS (type); field; field = TREE_CHAIN (field))
+    for (field = TYPE_FIELDS (type); field; field = TREE_CHAIN (field))
     {
-      unsigned HOST_WIDE_INT bitpos;
-
-      if (TREE_CODE (field) != FIELD_DECL)
-	continue;
-
-      if (TREE_CODE (TREE_TYPE (field)) == ERROR_MARK
-	  || (TYPE_MODE (TREE_TYPE (field)) == BLKmode
-	      && ! TYPE_NO_FORCE_BLK (TREE_TYPE (field)))
-	  || ! host_integerp (bit_position (field), 1)
-	  || DECL_SIZE (field) == 0
-	  || ! host_integerp (DECL_SIZE (field), 1))
-	return;
-
-      bitpos = int_bit_position (field);
-	  
-      /* Must be BLKmode if any field crosses a word boundary,
-	 since extract_bit_field can't handle that in registers.  */
-      if (bitpos / BITS_PER_WORD
-	  != ((tree_low_cst (DECL_SIZE (field), 1) + bitpos - 1)
-	      / BITS_PER_WORD)
-	  /* But there is no problem if the field is entire words.  */
-	  && tree_low_cst (DECL_SIZE (field), 1) % BITS_PER_WORD != 0)
-	return;
-
-      /* If this field is the whole struct, remember its mode so
-	 that, say, we can put a double in a class into a DF
-	 register instead of forcing it to live in the stack.  */
-      if (simple_cst_equal (TYPE_SIZE (type), DECL_SIZE (field)))
-	mode = DECL_MODE (field);
-
+        unsigned HOST_WIDE_INT bitpos;
+        
+        if (TREE_CODE (field) != FIELD_DECL)
+            continue;
+        
+        if (TREE_CODE (TREE_TYPE (field)) == ERROR_MARK
+            || (TYPE_MODE (TREE_TYPE (field)) == BLKmode
+                && ! TYPE_NO_FORCE_BLK (TREE_TYPE (field)))
+            || ! host_integerp (bit_position (field), 1)
+            || DECL_SIZE (field) == 0
+            || ! host_integerp (DECL_SIZE (field), 1))
+            return;
+        
+        bitpos = int_bit_position (field);
+        
+        /* Must be BLKmode if any field crosses a word boundary,
+         since extract_bit_field can't handle that in registers.  */
+        if (bitpos / BITS_PER_WORD
+            != ((tree_low_cst (DECL_SIZE (field), 1) + bitpos - 1)
+                / BITS_PER_WORD)
+            /* But there is no problem if the field is entire words.  */
+            && tree_low_cst (DECL_SIZE (field), 1) % BITS_PER_WORD != 0)
+            return;
+        
+        /* If this field is the whole struct, remember its mode so
+         that, say, we can put a double in a class into a DF
+         register instead of forcing it to live in the stack.  */
+        if (simple_cst_equal (TYPE_SIZE (type), DECL_SIZE (field)))
+            mode = DECL_MODE (field);
+        
 #ifdef MEMBER_TYPE_FORCES_BLK
-      /* With some targets, eg. c4x, it is sub-optimal
-	 to access an aligned BLKmode structure as a scalar.  */
-
-      /* On ia64-*-hpux we need to ensure that we don't change the
-	 mode of a structure containing a single field or else we
-	 will pass it incorrectly.  Since a structure with a single
-	 field causes mode to get set above we can't allow the
-	 check for mode == VOIDmode in this case.  Perhaps
-	 MEMBER_TYPE_FORCES_BLK should be extended to include mode
-	 as an argument and the check could be put in there for c4x.  */
-
-      if ((mode == VOIDmode || FUNCTION_ARG_REG_LITTLE_ENDIAN)
-	  && MEMBER_TYPE_FORCES_BLK (field))
-	return;
+        /* With some targets, eg. c4x, it is sub-optimal
+         to access an aligned BLKmode structure as a scalar.  */
+        
+        /* On ia64-*-hpux we need to ensure that we don't change the
+         mode of a structure containing a single field or else we
+         will pass it incorrectly.  Since a structure with a single
+         field causes mode to get set above we can't allow the
+         check for mode == VOIDmode in this case.  Perhaps
+         MEMBER_TYPE_FORCES_BLK should be extended to include mode
+         as an argument and the check could be put in there for c4x.  */
+        
+        if ((mode == VOIDmode || FUNCTION_ARG_REG_LITTLE_ENDIAN)
+            && MEMBER_TYPE_FORCES_BLK (field))
+            return;
 #endif /* MEMBER_TYPE_FORCES_BLK  */
     }
-
-  /* If we only have one real field; use its mode.  This only applies to
+    
+    /* If we only have one real field; use its mode.  This only applies to
      RECORD_TYPE.  This does not apply to unions.  */
-  if (TREE_CODE (type) == RECORD_TYPE && mode != VOIDmode)
-    TYPE_MODE (type) = mode;
-  else
-    TYPE_MODE (type) = mode_for_size_tree (TYPE_SIZE (type), MODE_INT, 1);
-
-  /* If structure's known alignment is less than what the scalar
+    if (TREE_CODE (type) == RECORD_TYPE && mode != VOIDmode)
+        TYPE_MODE (type) = mode;
+    else
+        TYPE_MODE (type) = mode_for_size_tree (TYPE_SIZE (type), MODE_INT, 1);
+    
+    /* If structure's known alignment is less than what the scalar
      mode would need, and it matters, then stick with BLKmode.  */
-  if (TYPE_MODE (type) != BLKmode
-      && STRICT_ALIGNMENT
-      && ! (TYPE_ALIGN (type) >= BIGGEST_ALIGNMENT
-	    || TYPE_ALIGN (type) >= GET_MODE_ALIGNMENT (TYPE_MODE (type))))
+    if (TYPE_MODE (type) != BLKmode
+        && STRICT_ALIGNMENT
+        && ! (TYPE_ALIGN (type) >= BIGGEST_ALIGNMENT
+              || TYPE_ALIGN (type) >= GET_MODE_ALIGNMENT (TYPE_MODE (type))))
     {
-      /* If this is the only reason this type is BLKmode, then
-	 don't force containing types to be BLKmode.  */
-      TYPE_NO_FORCE_BLK (type) = 1;
-      TYPE_MODE (type) = BLKmode;
+        /* If this is the only reason this type is BLKmode, then
+         don't force containing types to be BLKmode.  */
+        TYPE_NO_FORCE_BLK (type) = 1;
+        TYPE_MODE (type) = BLKmode;
     }
 }
 
 /* Compute TYPE_SIZE and TYPE_ALIGN for TYPE, once it has been laid
-   out.  */
+ out.  */
 
 static void
 finalize_type_size (type)
-     tree type;
+tree type;
 {
-  /* Normally, use the alignment corresponding to the mode chosen.
+    /* Normally, use the alignment corresponding to the mode chosen.
      However, where strict alignment is not required, avoid
      over-aligning structures, since most compilers do not do this
      alignment.  */
-
-  if (TYPE_MODE (type) != BLKmode && TYPE_MODE (type) != VOIDmode
-      && (STRICT_ALIGNMENT
-	  || (TREE_CODE (type) != RECORD_TYPE && TREE_CODE (type) != UNION_TYPE
-	      && TREE_CODE (type) != QUAL_UNION_TYPE
-	      && TREE_CODE (type) != ARRAY_TYPE)))
+    
+    if (TYPE_MODE (type) != BLKmode && TYPE_MODE (type) != VOIDmode
+        && (STRICT_ALIGNMENT
+            || (TREE_CODE (type) != RECORD_TYPE && TREE_CODE (type) != UNION_TYPE
+                && TREE_CODE (type) != QUAL_UNION_TYPE
+                && TREE_CODE (type) != ARRAY_TYPE)))
     {
-      TYPE_ALIGN (type) = GET_MODE_ALIGNMENT (TYPE_MODE (type));
-      TYPE_USER_ALIGN (type) = 0;
+        TYPE_ALIGN (type) = GET_MODE_ALIGNMENT (TYPE_MODE (type));
+        TYPE_USER_ALIGN (type) = 0;
     }
-
-  /* Do machine-dependent extra alignment.  */
+    
+    /* Do machine-dependent extra alignment.  */
 #ifdef ROUND_TYPE_ALIGN
-  TYPE_ALIGN (type)
+    TYPE_ALIGN (type)
     = ROUND_TYPE_ALIGN (type, TYPE_ALIGN (type), BITS_PER_UNIT);
 #endif
-
-  /* If we failed to find a simple way to calculate the unit size
+    
+    /* If we failed to find a simple way to calculate the unit size
      of the type, find it by division.  */
-  if (TYPE_SIZE_UNIT (type) == 0 && TYPE_SIZE (type) != 0)
+    if (TYPE_SIZE_UNIT (type) == 0 && TYPE_SIZE (type) != 0)
     /* TYPE_SIZE (type) is computed in bitsizetype.  After the division, the
-       result will fit in sizetype.  We will get more efficient code using
-       sizetype, so we force a conversion.  */
-    TYPE_SIZE_UNIT (type)
-      = convert (sizetype,
-		 size_binop (FLOOR_DIV_EXPR, TYPE_SIZE (type),
-			     bitsize_unit_node));
-
-  if (TYPE_SIZE (type) != 0)
+     result will fit in sizetype.  We will get more efficient code using
+     sizetype, so we force a conversion.  */
+        TYPE_SIZE_UNIT (type)
+        = convert (sizetype,
+                   size_binop (FLOOR_DIV_EXPR, TYPE_SIZE (type),
+                               bitsize_unit_node));
+    
+    if (TYPE_SIZE (type) != 0)
     {
 #ifdef ROUND_TYPE_SIZE
-      TYPE_SIZE (type)
-	= ROUND_TYPE_SIZE (type, TYPE_SIZE (type), TYPE_ALIGN (type));
-      TYPE_SIZE_UNIT (type)
-	= ROUND_TYPE_SIZE_UNIT (type, TYPE_SIZE_UNIT (type),
-				TYPE_ALIGN (type) / BITS_PER_UNIT);
+        TYPE_SIZE (type)
+        = ROUND_TYPE_SIZE (type, TYPE_SIZE (type), TYPE_ALIGN (type));
+        TYPE_SIZE_UNIT (type)
+        = ROUND_TYPE_SIZE_UNIT (type, TYPE_SIZE_UNIT (type),
+                                TYPE_ALIGN (type) / BITS_PER_UNIT);
 #else
-      TYPE_SIZE (type) = round_up (TYPE_SIZE (type), TYPE_ALIGN (type));
-      TYPE_SIZE_UNIT (type)
-	= round_up (TYPE_SIZE_UNIT (type), TYPE_ALIGN (type) / BITS_PER_UNIT);
+        TYPE_SIZE (type) = round_up (TYPE_SIZE (type), TYPE_ALIGN (type));
+        TYPE_SIZE_UNIT (type)
+        = round_up (TYPE_SIZE_UNIT (type), TYPE_ALIGN (type) / BITS_PER_UNIT);
 #endif
     }
-
-  /* Evaluate nonconstant sizes only once, either now or as soon as safe.  */
-  if (TYPE_SIZE (type) != 0 && TREE_CODE (TYPE_SIZE (type)) != INTEGER_CST)
-    TYPE_SIZE (type) = variable_size (TYPE_SIZE (type));
-  if (TYPE_SIZE_UNIT (type) != 0
-      && TREE_CODE (TYPE_SIZE_UNIT (type)) != INTEGER_CST)
-    TYPE_SIZE_UNIT (type) = variable_size (TYPE_SIZE_UNIT (type));
-
-  /* Also layout any other variants of the type.  */
-  if (TYPE_NEXT_VARIANT (type)
-      || type != TYPE_MAIN_VARIANT (type))
+    
+    /* Evaluate nonconstant sizes only once, either now or as soon as safe.  */
+    if (TYPE_SIZE (type) != 0 && TREE_CODE (TYPE_SIZE (type)) != INTEGER_CST)
+        TYPE_SIZE (type) = variable_size (TYPE_SIZE (type));
+    if (TYPE_SIZE_UNIT (type) != 0
+        && TREE_CODE (TYPE_SIZE_UNIT (type)) != INTEGER_CST)
+        TYPE_SIZE_UNIT (type) = variable_size (TYPE_SIZE_UNIT (type));
+    
+    /* Also layout any other variants of the type.  */
+    if (TYPE_NEXT_VARIANT (type)
+        || type != TYPE_MAIN_VARIANT (type))
     {
-      tree variant;
-      /* Record layout info of this variant.  */
-      tree size = TYPE_SIZE (type);
-      tree size_unit = TYPE_SIZE_UNIT (type);
-      unsigned int align = TYPE_ALIGN (type);
-      unsigned int user_align = TYPE_USER_ALIGN (type);
-      enum machine_mode mode = TYPE_MODE (type);
-
-      /* Copy it into all variants.  */
-      for (variant = TYPE_MAIN_VARIANT (type);
-	   variant != 0;
-	   variant = TYPE_NEXT_VARIANT (variant))
-	{
-	  TYPE_SIZE (variant) = size;
-	  TYPE_SIZE_UNIT (variant) = size_unit;
-	  TYPE_ALIGN (variant) = align;
-	  TYPE_USER_ALIGN (variant) = user_align;
-	  TYPE_MODE (variant) = mode;
-	}
+        tree variant;
+        /* Record layout info of this variant.  */
+        tree size = TYPE_SIZE (type);
+        tree size_unit = TYPE_SIZE_UNIT (type);
+        unsigned int align = TYPE_ALIGN (type);
+        unsigned int user_align = TYPE_USER_ALIGN (type);
+        enum machine_mode mode = TYPE_MODE (type);
+        
+        /* Copy it into all variants.  */
+        for (variant = TYPE_MAIN_VARIANT (type);
+             variant != 0;
+             variant = TYPE_NEXT_VARIANT (variant))
+        {
+            TYPE_SIZE (variant) = size;
+            TYPE_SIZE_UNIT (variant) = size_unit;
+            TYPE_ALIGN (variant) = align;
+            TYPE_USER_ALIGN (variant) = user_align;
+            TYPE_MODE (variant) = mode;
+        }
     }
 }
 
 /* Do all of the work required to layout the type indicated by RLI,
-   once the fields have been laid out.  This function will call `free'
-   for RLI.  */
+ once the fields have been laid out.  This function will call `free'
+ for RLI.  */
 
 void
 finish_record_layout (rli)
-     record_layout_info rli;
+record_layout_info rli;
 {
-  /* Compute the final size.  */
-  finalize_record_size (rli);
-
-  /* Compute the TYPE_MODE for the record.  */
-  compute_record_mode (rli->t);
-
-  /* Perform any last tweaks to the TYPE_SIZE, etc.  */
-  finalize_type_size (rli->t);
-
-  /* Lay out any static members.  This is done now because their type
+    /* Compute the final size.  */
+    finalize_record_size (rli);
+    
+    /* Compute the TYPE_MODE for the record.  */
+    compute_record_mode (rli->t);
+    
+    /* Perform any last tweaks to the TYPE_SIZE, etc.  */
+    finalize_type_size (rli->t);
+    
+    /* Lay out any static members.  This is done now because their type
      may use the record's type.  */
-  while (rli->pending_statics)
+    while (rli->pending_statics)
     {
-      layout_decl (TREE_VALUE (rli->pending_statics), 0);
-      rli->pending_statics = TREE_CHAIN (rli->pending_statics);
+        layout_decl (TREE_VALUE (rli->pending_statics), 0);
+        rli->pending_statics = TREE_CHAIN (rli->pending_statics);
     }
-
-  /* Clean up.  */
-  free (rli);
+    
+    /* Clean up.  */
+    free (rli);
 }
 
 /* Calculate the mode, size, and alignment for TYPE.
-   For an array type, calculate the element separation as well.
-   Record TYPE on the chain of permanent or temporary types
-   so that dbxout will find out about it.
-
-   TYPE_SIZE of a type is nonzero if the type has been laid out already.
-   layout_type does nothing on such a type.
-
-   If the type is incomplete, its TYPE_SIZE remains zero.  */
+ For an array type, calculate the element separation as well.
+ Record TYPE on the chain of permanent or temporary types
+ so that dbxout will find out about it.
+ 
+ TYPE_SIZE of a type is nonzero if the type has been laid out already.
+ layout_type does nothing on such a type.
+ 
+ If the type is incomplete, its TYPE_SIZE remains zero.  */
 
 void
 layout_type (type)
-     tree type;
+tree type;
 {
-  if (type == 0)
-    abort ();
-
-  /* Do nothing if type has been laid out before.  */
-  if (TYPE_SIZE (type))
-    return;
-
-  switch (TREE_CODE (type))
+    if (type == 0)
+        abort ();
+    
+    /* Do nothing if type has been laid out before.  */
+    if (TYPE_SIZE (type))
+        return;
+    
+    switch (TREE_CODE (type))
     {
-    case LANG_TYPE:
-      /* This kind of type is the responsibility
-	 of the language-specific code.  */
-      abort ();
-
-    case BOOLEAN_TYPE:  /* Used for Java, Pascal, and Chill.  */
-      if (TYPE_PRECISION (type) == 0)
-	TYPE_PRECISION (type) = 1; /* default to one byte/boolean.  */
-
-      /* ... fall through ...  */
-
-    case INTEGER_TYPE:
-    case ENUMERAL_TYPE:
-    case CHAR_TYPE:
-      if (TREE_CODE (TYPE_MIN_VALUE (type)) == INTEGER_CST
-	  && tree_int_cst_sgn (TYPE_MIN_VALUE (type)) >= 0)
-	TREE_UNSIGNED (type) = 1;
-
-      TYPE_MODE (type) = smallest_mode_for_size (TYPE_PRECISION (type),
-						 MODE_INT);
-      TYPE_SIZE (type) = bitsize_int (GET_MODE_BITSIZE (TYPE_MODE (type)));
-      TYPE_SIZE_UNIT (type) = size_int (GET_MODE_SIZE (TYPE_MODE (type)));
-      break;
-
-    case REAL_TYPE:
-      TYPE_MODE (type) = mode_for_size (TYPE_PRECISION (type), MODE_FLOAT, 0);
-      TYPE_SIZE (type) = bitsize_int (GET_MODE_BITSIZE (TYPE_MODE (type)));
-      TYPE_SIZE_UNIT (type) = size_int (GET_MODE_SIZE (TYPE_MODE (type)));
-      break;
-
-    case COMPLEX_TYPE:
-      TREE_UNSIGNED (type) = TREE_UNSIGNED (TREE_TYPE (type));
-      TYPE_MODE (type)
-	= mode_for_size (2 * TYPE_PRECISION (TREE_TYPE (type)),
-			 (TREE_CODE (TREE_TYPE (type)) == INTEGER_TYPE
-			  ? MODE_COMPLEX_INT : MODE_COMPLEX_FLOAT),
-			 0);
-      TYPE_SIZE (type) = bitsize_int (GET_MODE_BITSIZE (TYPE_MODE (type)));
-      TYPE_SIZE_UNIT (type) = size_int (GET_MODE_SIZE (TYPE_MODE (type)));
-      break;
-
-    case VECTOR_TYPE:
-      {
-	tree subtype;
-
-	subtype = TREE_TYPE (type);
-	TREE_UNSIGNED (type) = TREE_UNSIGNED (subtype);
-	TYPE_SIZE (type) = bitsize_int (GET_MODE_BITSIZE (TYPE_MODE (type)));
-	TYPE_SIZE_UNIT (type) = size_int (GET_MODE_SIZE (TYPE_MODE (type)));
-      }
-      break;
-
-    case VOID_TYPE:
-      /* This is an incomplete type and so doesn't have a size.  */
-      TYPE_ALIGN (type) = 1;
-      TYPE_USER_ALIGN (type) = 0;
-      TYPE_MODE (type) = VOIDmode;
-      break;
-
-    case OFFSET_TYPE:
-      TYPE_SIZE (type) = bitsize_int (POINTER_SIZE);
-      TYPE_SIZE_UNIT (type) = size_int (POINTER_SIZE / BITS_PER_UNIT);
-      /* A pointer might be MODE_PARTIAL_INT,
-	 but ptrdiff_t must be integral.  */
-      TYPE_MODE (type) = mode_for_size (POINTER_SIZE, MODE_INT, 0);
-      break;
-
-    case FUNCTION_TYPE:
-    case METHOD_TYPE:
-      TYPE_MODE (type) = mode_for_size (2 * POINTER_SIZE, MODE_INT, 0);
-      TYPE_SIZE (type) = bitsize_int (2 * POINTER_SIZE);
-      TYPE_SIZE_UNIT (type) = size_int ((2 * POINTER_SIZE) / BITS_PER_UNIT);
-      break;
-
-    case POINTER_TYPE:
-    case REFERENCE_TYPE:
-      {
-	int nbits = ((TREE_CODE (type) == REFERENCE_TYPE
-		      && reference_types_internal)
-		     ? GET_MODE_BITSIZE (Pmode) : POINTER_SIZE);
-
-	TYPE_MODE (type) = nbits == POINTER_SIZE ? ptr_mode : Pmode;
-	TYPE_SIZE (type) = bitsize_int (nbits);
-	TYPE_SIZE_UNIT (type) = size_int (nbits / BITS_PER_UNIT);
-	TREE_UNSIGNED (type) = 1;
-	TYPE_PRECISION (type) = nbits;
-      }
-      break;
-
-    case ARRAY_TYPE:
-      {
-	tree index = TYPE_DOMAIN (type);
-	tree element = TREE_TYPE (type);
-
-	build_pointer_type (element);
-
-	/* We need to know both bounds in order to compute the size.  */
-	if (index && TYPE_MAX_VALUE (index) && TYPE_MIN_VALUE (index)
-	    && TYPE_SIZE (element))
-	  {
-	    tree ub = TYPE_MAX_VALUE (index);
-	    tree lb = TYPE_MIN_VALUE (index);
-	    tree length;
-	    tree element_size;
-
-	    /* The initial subtraction should happen in the original type so
-	       that (possible) negative values are handled appropriately.  */
-	    length = size_binop (PLUS_EXPR, size_one_node,
-				 convert (sizetype,
-					  fold (build (MINUS_EXPR,
-						       TREE_TYPE (lb),
-						       ub, lb))));
-
-	    /* Special handling for arrays of bits (for Chill).  */
-	    element_size = TYPE_SIZE (element);
-	    if (TYPE_PACKED (type) && INTEGRAL_TYPE_P (element)
-		&& (integer_zerop (TYPE_MAX_VALUE (element))
-		    || integer_onep (TYPE_MAX_VALUE (element)))
-		&& host_integerp (TYPE_MIN_VALUE (element), 1))
-	      {
-		HOST_WIDE_INT maxvalue
-		  = tree_low_cst (TYPE_MAX_VALUE (element), 1);
-		HOST_WIDE_INT minvalue
-		  = tree_low_cst (TYPE_MIN_VALUE (element), 1);
-
-		if (maxvalue - minvalue == 1
-		    && (maxvalue == 1 || maxvalue == 0))
-		  element_size = integer_one_node;
-	      }
-
-	    TYPE_SIZE (type) = size_binop (MULT_EXPR, element_size,
-					   convert (bitsizetype, length));
-
-	    /* If we know the size of the element, calculate the total
-	       size directly, rather than do some division thing below.
-	       This optimization helps Fortran assumed-size arrays
-	       (where the size of the array is determined at runtime)
-	       substantially.
-	       Note that we can't do this in the case where the size of
-	       the elements is one bit since TYPE_SIZE_UNIT cannot be
-	       set correctly in that case.  */
-	    if (TYPE_SIZE_UNIT (element) != 0 && ! integer_onep (element_size))
-	      TYPE_SIZE_UNIT (type)
-		= size_binop (MULT_EXPR, TYPE_SIZE_UNIT (element), length);
-	  }
-
-	/* Now round the alignment and size,
-	   using machine-dependent criteria if any.  */
-
+        case LANG_TYPE:
+            /* This kind of type is the responsibility
+             of the language-specific code.  */
+            abort ();
+            
+        case BOOLEAN_TYPE:  /* Used for Java, Pascal, and Chill.  */
+            if (TYPE_PRECISION (type) == 0)
+                TYPE_PRECISION (type) = 1; /* default to one byte/boolean.  */
+            
+            /* ... fall through ...  */
+            
+        case INTEGER_TYPE:
+        case ENUMERAL_TYPE:
+        case CHAR_TYPE:
+            if (TREE_CODE (TYPE_MIN_VALUE (type)) == INTEGER_CST
+                && tree_int_cst_sgn (TYPE_MIN_VALUE (type)) >= 0)
+                TREE_UNSIGNED (type) = 1;
+            
+            TYPE_MODE (type) = smallest_mode_for_size (TYPE_PRECISION (type),
+                                                       MODE_INT);
+            TYPE_SIZE (type) = bitsize_int (GET_MODE_BITSIZE (TYPE_MODE (type)));
+            TYPE_SIZE_UNIT (type) = size_int (GET_MODE_SIZE (TYPE_MODE (type)));
+            break;
+            
+        case REAL_TYPE:
+            TYPE_MODE (type) = mode_for_size (TYPE_PRECISION (type), MODE_FLOAT, 0);
+            TYPE_SIZE (type) = bitsize_int (GET_MODE_BITSIZE (TYPE_MODE (type)));
+            TYPE_SIZE_UNIT (type) = size_int (GET_MODE_SIZE (TYPE_MODE (type)));
+            break;
+            
+        case COMPLEX_TYPE:
+            TREE_UNSIGNED (type) = TREE_UNSIGNED (TREE_TYPE (type));
+            TYPE_MODE (type)
+            = mode_for_size (2 * TYPE_PRECISION (TREE_TYPE (type)),
+                             (TREE_CODE (TREE_TYPE (type)) == INTEGER_TYPE
+                              ? MODE_COMPLEX_INT : MODE_COMPLEX_FLOAT),
+                             0);
+            TYPE_SIZE (type) = bitsize_int (GET_MODE_BITSIZE (TYPE_MODE (type)));
+            TYPE_SIZE_UNIT (type) = size_int (GET_MODE_SIZE (TYPE_MODE (type)));
+            break;
+            
+        case VECTOR_TYPE:
+        {
+            tree subtype;
+            
+            subtype = TREE_TYPE (type);
+            TREE_UNSIGNED (type) = TREE_UNSIGNED (subtype);
+            TYPE_SIZE (type) = bitsize_int (GET_MODE_BITSIZE (TYPE_MODE (type)));
+            TYPE_SIZE_UNIT (type) = size_int (GET_MODE_SIZE (TYPE_MODE (type)));
+        }
+            break;
+            
+        case VOID_TYPE:
+            /* This is an incomplete type and so doesn't have a size.  */
+            TYPE_ALIGN (type) = 1;
+            TYPE_USER_ALIGN (type) = 0;
+            TYPE_MODE (type) = VOIDmode;
+            break;
+            
+        case OFFSET_TYPE:
+            TYPE_SIZE (type) = bitsize_int (POINTER_SIZE);
+            TYPE_SIZE_UNIT (type) = size_int (POINTER_SIZE / BITS_PER_UNIT);
+            /* A pointer might be MODE_PARTIAL_INT,
+             but ptrdiff_t must be integral.  */
+            TYPE_MODE (type) = mode_for_size (POINTER_SIZE, MODE_INT, 0);
+            break;
+            
+        case FUNCTION_TYPE:
+        case METHOD_TYPE:
+            TYPE_MODE (type) = mode_for_size (2 * POINTER_SIZE, MODE_INT, 0);
+            TYPE_SIZE (type) = bitsize_int (2 * POINTER_SIZE);
+            TYPE_SIZE_UNIT (type) = size_int ((2 * POINTER_SIZE) / BITS_PER_UNIT);
+            break;
+            
+        case POINTER_TYPE:
+        case REFERENCE_TYPE:
+        {
+            int nbits = ((TREE_CODE (type) == REFERENCE_TYPE
+                          && reference_types_internal)
+                         ? GET_MODE_BITSIZE (Pmode) : POINTER_SIZE);
+            
+            TYPE_MODE (type) = nbits == POINTER_SIZE ? ptr_mode : Pmode;
+            TYPE_SIZE (type) = bitsize_int (nbits);
+            TYPE_SIZE_UNIT (type) = size_int (nbits / BITS_PER_UNIT);
+            TREE_UNSIGNED (type) = 1;
+            TYPE_PRECISION (type) = nbits;
+        }
+            break;
+            
+        case ARRAY_TYPE:
+        {
+            tree index = TYPE_DOMAIN (type);
+            tree element = TREE_TYPE (type);
+            
+            build_pointer_type (element);
+            
+            /* We need to know both bounds in order to compute the size.  */
+            if (index && TYPE_MAX_VALUE (index) && TYPE_MIN_VALUE (index)
+                && TYPE_SIZE (element))
+            {
+                tree ub = TYPE_MAX_VALUE (index);
+                tree lb = TYPE_MIN_VALUE (index);
+                tree length;
+                tree element_size;
+                
+                /* The initial subtraction should happen in the original type so
+                 that (possible) negative values are handled appropriately.  */
+                length = size_binop (PLUS_EXPR, size_one_node,
+                                     convert (sizetype,
+                                              fold (build (MINUS_EXPR,
+                                                           TREE_TYPE (lb),
+                                                           ub, lb))));
+                
+                /* Special handling for arrays of bits (for Chill).  */
+                element_size = TYPE_SIZE (element);
+                if (TYPE_PACKED (type) && INTEGRAL_TYPE_P (element)
+                    && (integer_zerop (TYPE_MAX_VALUE (element))
+                        || integer_onep (TYPE_MAX_VALUE (element)))
+                    && host_integerp (TYPE_MIN_VALUE (element), 1))
+                {
+                    HOST_WIDE_INT maxvalue
+                    = tree_low_cst (TYPE_MAX_VALUE (element), 1);
+                    HOST_WIDE_INT minvalue
+                    = tree_low_cst (TYPE_MIN_VALUE (element), 1);
+                    
+                    if (maxvalue - minvalue == 1
+                        && (maxvalue == 1 || maxvalue == 0))
+                        element_size = integer_one_node;
+                }
+                
+                TYPE_SIZE (type) = size_binop (MULT_EXPR, element_size,
+                                               convert (bitsizetype, length));
+                
+                /* If we know the size of the element, calculate the total
+                 size directly, rather than do some division thing below.
+                 This optimization helps Fortran assumed-size arrays
+                 (where the size of the array is determined at runtime)
+                 substantially.
+                 Note that we can't do this in the case where the size of
+                 the elements is one bit since TYPE_SIZE_UNIT cannot be
+                 set correctly in that case.  */
+                if (TYPE_SIZE_UNIT (element) != 0 && ! integer_onep (element_size))
+                    TYPE_SIZE_UNIT (type)
+                    = size_binop (MULT_EXPR, TYPE_SIZE_UNIT (element), length);
+            }
+            
+            /* Now round the alignment and size,
+             using machine-dependent criteria if any.  */
+            
 #ifdef ROUND_TYPE_ALIGN
-	TYPE_ALIGN (type)
-	  = ROUND_TYPE_ALIGN (type, TYPE_ALIGN (element), BITS_PER_UNIT);
+            TYPE_ALIGN (type)
+            = ROUND_TYPE_ALIGN (type, TYPE_ALIGN (element), BITS_PER_UNIT);
 #else
-	TYPE_ALIGN (type) = MAX (TYPE_ALIGN (element), BITS_PER_UNIT);
+            TYPE_ALIGN (type) = MAX (TYPE_ALIGN (element), BITS_PER_UNIT);
 #endif
-	TYPE_USER_ALIGN (type) = TYPE_USER_ALIGN (element);
-
+            TYPE_USER_ALIGN (type) = TYPE_USER_ALIGN (element);
+            
 #ifdef ROUND_TYPE_SIZE
-	if (TYPE_SIZE (type) != 0)
-	  {
-	    tree tmp
-	      = ROUND_TYPE_SIZE (type, TYPE_SIZE (type), TYPE_ALIGN (type));
-
-	    /* If the rounding changed the size of the type, remove any
-	       pre-calculated TYPE_SIZE_UNIT.  */
-	    if (simple_cst_equal (TYPE_SIZE (type), tmp) != 1)
-	      TYPE_SIZE_UNIT (type) = NULL;
-
-	    TYPE_SIZE (type) = tmp;
-	  }
+            if (TYPE_SIZE (type) != 0)
+            {
+                tree tmp
+                = ROUND_TYPE_SIZE (type, TYPE_SIZE (type), TYPE_ALIGN (type));
+                
+                /* If the rounding changed the size of the type, remove any
+                 pre-calculated TYPE_SIZE_UNIT.  */
+                if (simple_cst_equal (TYPE_SIZE (type), tmp) != 1)
+                    TYPE_SIZE_UNIT (type) = NULL;
+                
+                TYPE_SIZE (type) = tmp;
+            }
 #endif
-
-	TYPE_MODE (type) = BLKmode;
-	if (TYPE_SIZE (type) != 0
+            
+            TYPE_MODE (type) = BLKmode;
+            if (TYPE_SIZE (type) != 0
 #ifdef MEMBER_TYPE_FORCES_BLK
-	    && ! MEMBER_TYPE_FORCES_BLK (type)
+                && ! MEMBER_TYPE_FORCES_BLK (type)
 #endif
-	    /* BLKmode elements force BLKmode aggregate;
-	       else extract/store fields may lose.  */
-	    && (TYPE_MODE (TREE_TYPE (type)) != BLKmode
-		|| TYPE_NO_FORCE_BLK (TREE_TYPE (type))))
-	  {
-	    /* One-element arrays get the component type's mode.  */
-	    if (simple_cst_equal (TYPE_SIZE (type),
-				  TYPE_SIZE (TREE_TYPE (type))))
-	      TYPE_MODE (type) = TYPE_MODE (TREE_TYPE (type));
-	    else
-	      TYPE_MODE (type)
-		= mode_for_size_tree (TYPE_SIZE (type), MODE_INT, 1);
-
-	    if (TYPE_MODE (type) != BLKmode
-		&& STRICT_ALIGNMENT && TYPE_ALIGN (type) < BIGGEST_ALIGNMENT
-		&& TYPE_ALIGN (type) < GET_MODE_ALIGNMENT (TYPE_MODE (type))
-		&& TYPE_MODE (type) != BLKmode)
-	      {
-		TYPE_NO_FORCE_BLK (type) = 1;
-		TYPE_MODE (type) = BLKmode;
-	      }
-	  }
-	break;
-      }
-
-    case RECORD_TYPE:
-    case UNION_TYPE:
-    case QUAL_UNION_TYPE:
-      {
-	tree field;
-	record_layout_info rli;
-
-	/* Initialize the layout information.  */
-	rli = start_record_layout (type);
-
-	/* If this is a QUAL_UNION_TYPE, we want to process the fields
-	   in the reverse order in building the COND_EXPR that denotes
-	   its size.  We reverse them again later.  */
-	if (TREE_CODE (type) == QUAL_UNION_TYPE)
-	  TYPE_FIELDS (type) = nreverse (TYPE_FIELDS (type));
-
-	/* Place all the fields.  */
-	for (field = TYPE_FIELDS (type); field; field = TREE_CHAIN (field))
-	  place_field (rli, field);
-
-	if (TREE_CODE (type) == QUAL_UNION_TYPE)
-	  TYPE_FIELDS (type) = nreverse (TYPE_FIELDS (type));
-
-	if (lang_adjust_rli)
-	  (*lang_adjust_rli) (rli);
-
-	/* Finish laying out the record.  */
-	finish_record_layout (rli);
-      }
-      break;
-
-    case SET_TYPE:  /* Used by Chill and Pascal.  */
-      if (TREE_CODE (TYPE_MAX_VALUE (TYPE_DOMAIN (type))) != INTEGER_CST
-	  || TREE_CODE (TYPE_MIN_VALUE (TYPE_DOMAIN (type))) != INTEGER_CST)
-	abort ();
-      else
-	{
+                /* BLKmode elements force BLKmode aggregate;
+                 else extract/store fields may lose.  */
+                && (TYPE_MODE (TREE_TYPE (type)) != BLKmode
+                    || TYPE_NO_FORCE_BLK (TREE_TYPE (type))))
+            {
+                /* One-element arrays get the component type's mode.  */
+                if (simple_cst_equal (TYPE_SIZE (type),
+                                      TYPE_SIZE (TREE_TYPE (type))))
+                    TYPE_MODE (type) = TYPE_MODE (TREE_TYPE (type));
+                else
+                    TYPE_MODE (type)
+                    = mode_for_size_tree (TYPE_SIZE (type), MODE_INT, 1);
+                
+                if (TYPE_MODE (type) != BLKmode
+                    && STRICT_ALIGNMENT && TYPE_ALIGN (type) < BIGGEST_ALIGNMENT
+                    && TYPE_ALIGN (type) < GET_MODE_ALIGNMENT (TYPE_MODE (type))
+                    && TYPE_MODE (type) != BLKmode)
+                {
+                    TYPE_NO_FORCE_BLK (type) = 1;
+                    TYPE_MODE (type) = BLKmode;
+                }
+            }
+            break;
+        }
+            
+        case RECORD_TYPE:
+        case UNION_TYPE:
+        case QUAL_UNION_TYPE:
+        {
+            tree field;
+            record_layout_info rli;
+            
+            /* Initialize the layout information.  */
+            rli = start_record_layout (type);
+            
+            /* If this is a QUAL_UNION_TYPE, we want to process the fields
+             in the reverse order in building the COND_EXPR that denotes
+             its size.  We reverse them again later.  */
+            if (TREE_CODE (type) == QUAL_UNION_TYPE)
+                TYPE_FIELDS (type) = nreverse (TYPE_FIELDS (type));
+            
+            /* Place all the fields.  */
+            for (field = TYPE_FIELDS (type); field; field = TREE_CHAIN (field))
+            place_field (rli, field);
+            
+            if (TREE_CODE (type) == QUAL_UNION_TYPE)
+                TYPE_FIELDS (type) = nreverse (TYPE_FIELDS (type));
+            
+            if (lang_adjust_rli)
+                (*lang_adjust_rli) (rli);
+            
+            /* Finish laying out the record.  */
+            finish_record_layout (rli);
+        }
+            break;
+            
+        case SET_TYPE:  /* Used by Chill and Pascal.  */
+            if (TREE_CODE (TYPE_MAX_VALUE (TYPE_DOMAIN (type))) != INTEGER_CST
+                || TREE_CODE (TYPE_MIN_VALUE (TYPE_DOMAIN (type))) != INTEGER_CST)
+                abort ();
+            else
+            {
 #ifndef SET_WORD_SIZE
 #define SET_WORD_SIZE BITS_PER_WORD
 #endif
-	  unsigned int alignment
-	    = set_alignment ? set_alignment : SET_WORD_SIZE;
-	  int size_in_bits
-	    = (TREE_INT_CST_LOW (TYPE_MAX_VALUE (TYPE_DOMAIN (type)))
-	       - TREE_INT_CST_LOW (TYPE_MIN_VALUE (TYPE_DOMAIN (type))) + 1);
-	  int rounded_size
-	    = ((size_in_bits + alignment - 1) / alignment) * alignment;
-
-	  if (rounded_size > (int) alignment)
-	    TYPE_MODE (type) = BLKmode;
-	  else
-	    TYPE_MODE (type) = mode_for_size (alignment, MODE_INT, 1);
-
-	  TYPE_SIZE (type) = bitsize_int (rounded_size);
-	  TYPE_SIZE_UNIT (type) = size_int (rounded_size / BITS_PER_UNIT);
-	  TYPE_ALIGN (type) = alignment;
-	  TYPE_USER_ALIGN (type) = 0;
-	  TYPE_PRECISION (type) = size_in_bits;
-	}
-      break;
-
-    case FILE_TYPE:
-      /* The size may vary in different languages, so the language front end
-	 should fill in the size.  */
-      TYPE_ALIGN (type) = BIGGEST_ALIGNMENT;
-      TYPE_USER_ALIGN (type) = 0;
-      TYPE_MODE  (type) = BLKmode;
-      break;
-
-    default:
-      abort ();
+                unsigned int alignment
+                = set_alignment ? set_alignment : SET_WORD_SIZE;
+                int size_in_bits
+                = (TREE_INT_CST_LOW (TYPE_MAX_VALUE (TYPE_DOMAIN (type)))
+                   - TREE_INT_CST_LOW (TYPE_MIN_VALUE (TYPE_DOMAIN (type))) + 1);
+                int rounded_size
+                = ((size_in_bits + alignment - 1) / alignment) * alignment;
+                
+                if (rounded_size > (int) alignment)
+                    TYPE_MODE (type) = BLKmode;
+                else
+                    TYPE_MODE (type) = mode_for_size (alignment, MODE_INT, 1);
+                
+                TYPE_SIZE (type) = bitsize_int (rounded_size);
+                TYPE_SIZE_UNIT (type) = size_int (rounded_size / BITS_PER_UNIT);
+                TYPE_ALIGN (type) = alignment;
+                TYPE_USER_ALIGN (type) = 0;
+                TYPE_PRECISION (type) = size_in_bits;
+            }
+            break;
+            
+        case FILE_TYPE:
+            /* The size may vary in different languages, so the language front end
+             should fill in the size.  */
+            TYPE_ALIGN (type) = BIGGEST_ALIGNMENT;
+            TYPE_USER_ALIGN (type) = 0;
+            TYPE_MODE  (type) = BLKmode;
+            break;
+            
+        default:
+            abort ();
     }
-
-  /* Compute the final TYPE_SIZE, TYPE_ALIGN, etc. for TYPE.  For
+    
+    /* Compute the final TYPE_SIZE, TYPE_ALIGN, etc. for TYPE.  For
      records and unions, finish_record_layout already called this
      function.  */
-  if (TREE_CODE (type) != RECORD_TYPE 
-      && TREE_CODE (type) != UNION_TYPE
-      && TREE_CODE (type) != QUAL_UNION_TYPE)
-    finalize_type_size (type);
-
-  /* If this type is created before sizetype has been permanently set,
+    if (TREE_CODE (type) != RECORD_TYPE
+        && TREE_CODE (type) != UNION_TYPE
+        && TREE_CODE (type) != QUAL_UNION_TYPE)
+        finalize_type_size (type);
+    
+    /* If this type is created before sizetype has been permanently set,
      record it so set_sizetype can fix it up.  */
-  if (! sizetype_set)
-    early_type_list = tree_cons (NULL_TREE, type, early_type_list);
-
-  /* If an alias set has been set for this aggregate when it was incomplete,
+    if (! sizetype_set)
+        early_type_list = tree_cons (NULL_TREE, type, early_type_list);
+    
+    /* If an alias set has been set for this aggregate when it was incomplete,
      force it into alias set 0.
      This is too conservative, but we cannot call record_component_aliases
      here because some frontends still change the aggregates after
      layout_type.  */
-  if (AGGREGATE_TYPE_P (type) && TYPE_ALIAS_SET_KNOWN_P (type))
-    TYPE_ALIAS_SET (type) = 0;
+    if (AGGREGATE_TYPE_P (type) && TYPE_ALIAS_SET_KNOWN_P (type))
+        TYPE_ALIAS_SET (type) = 0;
 }
 
 /* Create and return a type for signed integers of PRECISION bits.  */
 
 tree
 make_signed_type (precision)
-     int precision;
+int precision;
 {
-  tree type = make_node (INTEGER_TYPE);
-
-  TYPE_PRECISION (type) = precision;
-
-  fixup_signed_type (type);
-  return type;
+    tree type = make_node (INTEGER_TYPE);
+    
+    TYPE_PRECISION (type) = precision;
+    
+    fixup_signed_type (type);
+    return type;
 }
 
 /* Create and return a type for unsigned integers of PRECISION bits.  */
 
 tree
 make_unsigned_type (precision)
-     int precision;
+int precision;
 {
-  tree type = make_node (INTEGER_TYPE);
-
-  TYPE_PRECISION (type) = precision;
-
-  fixup_unsigned_type (type);
-  return type;
+    tree type = make_node (INTEGER_TYPE);
+    
+    TYPE_PRECISION (type) = precision;
+    
+    fixup_unsigned_type (type);
+    return type;
 }
 
 /* Initialize sizetype and bitsizetype to a reasonable and temporary
-   value to enable integer types to be created.  */
+ value to enable integer types to be created.  */
 
 void
 initialize_sizetypes ()
 {
-  tree t = make_node (INTEGER_TYPE);
-
-  /* Set this so we do something reasonable for the build_int_2 calls
+    tree t = make_node (INTEGER_TYPE);
+    
+    /* Set this so we do something reasonable for the build_int_2 calls
      below.  */
-  integer_type_node = t;
-
-  TYPE_MODE (t) = SImode;
-  TYPE_ALIGN (t) = GET_MODE_ALIGNMENT (SImode);
-  TYPE_USER_ALIGN (t) = 0;
-  TYPE_SIZE (t) = build_int_2 (GET_MODE_BITSIZE (SImode), 0);
-  TYPE_SIZE_UNIT (t) = build_int_2 (GET_MODE_SIZE (SImode), 0);
-  TREE_UNSIGNED (t) = 1;
-  TYPE_PRECISION (t) = GET_MODE_BITSIZE (SImode);
-  TYPE_MIN_VALUE (t) = build_int_2 (0, 0);
-  TYPE_IS_SIZETYPE (t) = 1;
-
-  /* 1000 avoids problems with possible overflow and is certainly
+    integer_type_node = t;
+    
+    TYPE_MODE (t) = SImode;
+    TYPE_ALIGN (t) = GET_MODE_ALIGNMENT (SImode);
+    TYPE_USER_ALIGN (t) = 0;
+    TYPE_SIZE (t) = build_int_2 (GET_MODE_BITSIZE (SImode), 0);
+    TYPE_SIZE_UNIT (t) = build_int_2 (GET_MODE_SIZE (SImode), 0);
+    TREE_UNSIGNED (t) = 1;
+    TYPE_PRECISION (t) = GET_MODE_BITSIZE (SImode);
+    TYPE_MIN_VALUE (t) = build_int_2 (0, 0);
+    TYPE_IS_SIZETYPE (t) = 1;
+    
+    /* 1000 avoids problems with possible overflow and is certainly
      larger than any size value we'd want to be storing.  */
-  TYPE_MAX_VALUE (t) = build_int_2 (1000, 0);
-
-  /* These two must be different nodes because of the caching done in
+    TYPE_MAX_VALUE (t) = build_int_2 (1000, 0);
+    
+    /* These two must be different nodes because of the caching done in
      size_int_wide.  */
-  sizetype = t;
-  bitsizetype = copy_node (t);
-  integer_type_node = 0;
+    sizetype = t;
+    bitsizetype = copy_node (t);
+    integer_type_node = 0;
 }
 
 /* Set sizetype to TYPE, and initialize *sizetype accordingly.
-   Also update the type of any standard type's sizes made so far.  */
+ Also update the type of any standard type's sizes made so far.  */
 
 void
 set_sizetype (type)
-     tree type;
+tree type;
 {
-  int oprecision = TYPE_PRECISION (type);
-  /* The *bitsizetype types use a precision that avoids overflows when
+    int oprecision = TYPE_PRECISION (type);
+    /* The *bitsizetype types use a precision that avoids overflows when
      calculating signed sizes / offsets in bits.  However, when
      cross-compiling from a 32 bit to a 64 bit host, we are limited to 64 bit
      precision.  */
-  int precision = MIN (oprecision + BITS_PER_UNIT_LOG + 1,
-		       2 * HOST_BITS_PER_WIDE_INT);
-  unsigned int i;
-  tree t;
-
-  if (sizetype_set)
-    abort ();
-
-  /* Make copies of nodes since we'll be setting TYPE_IS_SIZETYPE.  */
-  sizetype = copy_node (type);
-  TYPE_DOMAIN (sizetype) = type;
-  TYPE_IS_SIZETYPE (sizetype) = 1;
-  bitsizetype = make_node (INTEGER_TYPE);
-  TYPE_NAME (bitsizetype) = TYPE_NAME (type);
-  TYPE_PRECISION (bitsizetype) = precision;
-  TYPE_IS_SIZETYPE (bitsizetype) = 1;
-
-  if (TREE_UNSIGNED (type))
-    fixup_unsigned_type (bitsizetype);
-  else
-    fixup_signed_type (bitsizetype);
-
-  layout_type (bitsizetype);
-
-  if (TREE_UNSIGNED (type))
+    int precision = MIN (oprecision + BITS_PER_UNIT_LOG + 1,
+                         2 * HOST_BITS_PER_WIDE_INT);
+    unsigned int i;
+    tree t;
+    
+    if (sizetype_set)
+        abort ();
+    
+    /* Make copies of nodes since we'll be setting TYPE_IS_SIZETYPE.  */
+    sizetype = copy_node (type);
+    TYPE_DOMAIN (sizetype) = type;
+    TYPE_IS_SIZETYPE (sizetype) = 1;
+    bitsizetype = make_node (INTEGER_TYPE);
+    TYPE_NAME (bitsizetype) = TYPE_NAME (type);
+    TYPE_PRECISION (bitsizetype) = precision;
+    TYPE_IS_SIZETYPE (bitsizetype) = 1;
+    
+    if (TREE_UNSIGNED (type))
+        fixup_unsigned_type (bitsizetype);
+    else
+        fixup_signed_type (bitsizetype);
+    
+    layout_type (bitsizetype);
+    
+    if (TREE_UNSIGNED (type))
     {
-      usizetype = sizetype;
-      ubitsizetype = bitsizetype;
-      ssizetype = copy_node (make_signed_type (oprecision));
-      sbitsizetype = copy_node (make_signed_type (precision));
+        usizetype = sizetype;
+        ubitsizetype = bitsizetype;
+        ssizetype = copy_node (make_signed_type (oprecision));
+        sbitsizetype = copy_node (make_signed_type (precision));
     }
-  else
+    else
     {
-      ssizetype = sizetype;
-      sbitsizetype = bitsizetype;
-      usizetype = copy_node (make_unsigned_type (oprecision));
-      ubitsizetype = copy_node (make_unsigned_type (precision));
+        ssizetype = sizetype;
+        sbitsizetype = bitsizetype;
+        usizetype = copy_node (make_unsigned_type (oprecision));
+        ubitsizetype = copy_node (make_unsigned_type (precision));
     }
-
-  TYPE_NAME (bitsizetype) = get_identifier ("bit_size_type");
-
-  /* Show is a sizetype, is a main type, and has no pointers to it.  */
-  for (i = 0; i < ARRAY_SIZE (sizetype_tab); i++)
+    
+    TYPE_NAME (bitsizetype) = get_identifier ("bit_size_type");
+    
+    /* Show is a sizetype, is a main type, and has no pointers to it.  */
+    for (i = 0; i < ARRAY_SIZE (sizetype_tab); i++)
     {
-      TYPE_IS_SIZETYPE (sizetype_tab[i]) = 1;
-      TYPE_MAIN_VARIANT (sizetype_tab[i]) = sizetype_tab[i];
-      TYPE_NEXT_VARIANT (sizetype_tab[i]) = 0;
-      TYPE_POINTER_TO (sizetype_tab[i]) = 0;
-      TYPE_REFERENCE_TO (sizetype_tab[i]) = 0;
+        TYPE_IS_SIZETYPE (sizetype_tab[i]) = 1;
+        TYPE_MAIN_VARIANT (sizetype_tab[i]) = sizetype_tab[i];
+        TYPE_NEXT_VARIANT (sizetype_tab[i]) = 0;
+        TYPE_POINTER_TO (sizetype_tab[i]) = 0;
+        TYPE_REFERENCE_TO (sizetype_tab[i]) = 0;
     }
-
-  ggc_add_tree_root ((tree *) &sizetype_tab,
-		     sizeof sizetype_tab / sizeof (tree));
-
-  /* Go down each of the types we already made and set the proper type
+    
+    ggc_add_tree_root ((tree *) &sizetype_tab,
+                       sizeof sizetype_tab / sizeof (tree));
+    
+    /* Go down each of the types we already made and set the proper type
      for the sizes in them.  */
-  for (t = early_type_list; t != 0; t = TREE_CHAIN (t))
+    for (t = early_type_list; t != 0; t = TREE_CHAIN (t))
     {
-      if (TREE_CODE (TREE_VALUE (t)) != INTEGER_TYPE)
-	abort ();
-
-      TREE_TYPE (TYPE_SIZE (TREE_VALUE (t))) = bitsizetype;
-      TREE_TYPE (TYPE_SIZE_UNIT (TREE_VALUE (t))) = sizetype;
+        if (TREE_CODE (TREE_VALUE (t)) != INTEGER_TYPE)
+            abort ();
+        
+        TREE_TYPE (TYPE_SIZE (TREE_VALUE (t))) = bitsizetype;
+        TREE_TYPE (TYPE_SIZE_UNIT (TREE_VALUE (t))) = sizetype;
     }
-
-  early_type_list = 0;
-  sizetype_set = 1;
+    
+    early_type_list = 0;
+    sizetype_set = 1;
 }
 
 /* Set the extreme values of TYPE based on its precision in bits,
-   then lay it out.  Used when make_signed_type won't do
-   because the tree code is not INTEGER_TYPE.
-   E.g. for Pascal, when the -fsigned-char option is given.  */
+ then lay it out.  Used when make_signed_type won't do
+ because the tree code is not INTEGER_TYPE.
+ E.g. for Pascal, when the -fsigned-char option is given.  */
 
 void
 fixup_signed_type (type)
-     tree type;
+tree type;
 {
-  int precision = TYPE_PRECISION (type);
-
-  /* We can not represent properly constants greater then
+    int precision = TYPE_PRECISION (type);
+    
+    /* We can not represent properly constants greater then
      2 * HOST_BITS_PER_WIDE_INT, still we need the types
      as they are used by i386 vector extensions and friends.  */
-  if (precision > HOST_BITS_PER_WIDE_INT * 2)
-    precision = HOST_BITS_PER_WIDE_INT * 2;
-
-  TYPE_MIN_VALUE (type)
+    if (precision > HOST_BITS_PER_WIDE_INT * 2)
+        precision = HOST_BITS_PER_WIDE_INT * 2;
+    
+    TYPE_MIN_VALUE (type)
     = build_int_2 ((precision - HOST_BITS_PER_WIDE_INT > 0
-		    ? 0 : (HOST_WIDE_INT) (-1) << (precision - 1)),
-		   (((HOST_WIDE_INT) (-1)
-		     << (precision - HOST_BITS_PER_WIDE_INT - 1 > 0
-			 ? precision - HOST_BITS_PER_WIDE_INT - 1
-			 : 0))));
-  TYPE_MAX_VALUE (type)
+                    ? 0 : (HOST_WIDE_INT) (-1) << (precision - 1)),
+                   (((HOST_WIDE_INT) (-1)
+                     << (precision - HOST_BITS_PER_WIDE_INT - 1 > 0
+                         ? precision - HOST_BITS_PER_WIDE_INT - 1
+                         : 0))));
+    TYPE_MAX_VALUE (type)
     = build_int_2 ((precision - HOST_BITS_PER_WIDE_INT > 0
-		    ? -1 : ((HOST_WIDE_INT) 1 << (precision - 1)) - 1),
-		   (precision - HOST_BITS_PER_WIDE_INT - 1 > 0
-		    ? (((HOST_WIDE_INT) 1
-			<< (precision - HOST_BITS_PER_WIDE_INT - 1))) - 1
-		    : 0));
-
-  TREE_TYPE (TYPE_MIN_VALUE (type)) = type;
-  TREE_TYPE (TYPE_MAX_VALUE (type)) = type;
-
-  /* Lay out the type: set its alignment, size, etc.  */
-  layout_type (type);
+                    ? -1 : ((HOST_WIDE_INT) 1 << (precision - 1)) - 1),
+                   (precision - HOST_BITS_PER_WIDE_INT - 1 > 0
+                    ? (((HOST_WIDE_INT) 1
+                        << (precision - HOST_BITS_PER_WIDE_INT - 1))) - 1
+                    : 0));
+    
+    TREE_TYPE (TYPE_MIN_VALUE (type)) = type;
+    TREE_TYPE (TYPE_MAX_VALUE (type)) = type;
+    
+    /* Lay out the type: set its alignment, size, etc.  */
+    layout_type (type);
 }
 
 /* Set the extreme values of TYPE based on its precision in bits,
-   then lay it out.  This is used both in `make_unsigned_type'
-   and for enumeral types.  */
+ then lay it out.  This is used both in `make_unsigned_type'
+ and for enumeral types.  */
 
 void
 fixup_unsigned_type (type)
-     tree type;
+tree type;
 {
-  int precision = TYPE_PRECISION (type);
-
-  /* We can not represent properly constants greater then
+    int precision = TYPE_PRECISION (type);
+    
+    /* We can not represent properly constants greater then
      2 * HOST_BITS_PER_WIDE_INT, still we need the types
      as they are used by i386 vector extensions and friends.  */
-  if (precision > HOST_BITS_PER_WIDE_INT * 2)
-    precision = HOST_BITS_PER_WIDE_INT * 2;
-
-  TYPE_MIN_VALUE (type) = build_int_2 (0, 0);
-  TYPE_MAX_VALUE (type)
+    if (precision > HOST_BITS_PER_WIDE_INT * 2)
+        precision = HOST_BITS_PER_WIDE_INT * 2;
+    
+    TYPE_MIN_VALUE (type) = build_int_2 (0, 0);
+    TYPE_MAX_VALUE (type)
     = build_int_2 (precision - HOST_BITS_PER_WIDE_INT >= 0
-		   ? -1 : ((HOST_WIDE_INT) 1 << precision) - 1,
-		   precision - HOST_BITS_PER_WIDE_INT > 0
-		   ? ((unsigned HOST_WIDE_INT) ~0
-		      >> (HOST_BITS_PER_WIDE_INT
-			  - (precision - HOST_BITS_PER_WIDE_INT)))
-		   : 0);
-  TREE_TYPE (TYPE_MIN_VALUE (type)) = type;
-  TREE_TYPE (TYPE_MAX_VALUE (type)) = type;
-
-  /* Lay out the type: set its alignment, size, etc.  */
-  layout_type (type);
+                   ? -1 : ((HOST_WIDE_INT) 1 << precision) - 1,
+                   precision - HOST_BITS_PER_WIDE_INT > 0
+                   ? ((unsigned HOST_WIDE_INT) ~0
+                      >> (HOST_BITS_PER_WIDE_INT
+                          - (precision - HOST_BITS_PER_WIDE_INT)))
+                   : 0);
+    TREE_TYPE (TYPE_MIN_VALUE (type)) = type;
+    TREE_TYPE (TYPE_MAX_VALUE (type)) = type;
+    
+    /* Lay out the type: set its alignment, size, etc.  */
+    layout_type (type);
 }
 
 /* Find the best machine mode to use when referencing a bit field of length
-   BITSIZE bits starting at BITPOS.
-
-   The underlying object is known to be aligned to a boundary of ALIGN bits.
-   If LARGEST_MODE is not VOIDmode, it means that we should not use a mode
-   larger than LARGEST_MODE (usually SImode).
-
-   If no mode meets all these conditions, we return VOIDmode.  Otherwise, if
-   VOLATILEP is true or SLOW_BYTE_ACCESS is false, we return the smallest
-   mode meeting these conditions.
-
-   Otherwise (VOLATILEP is false and SLOW_BYTE_ACCESS is true), we return
-   the largest mode (but a mode no wider than UNITS_PER_WORD) that meets
-   all the conditions.  */
+ BITSIZE bits starting at BITPOS.
+ 
+ The underlying object is known to be aligned to a boundary of ALIGN bits.
+ If LARGEST_MODE is not VOIDmode, it means that we should not use a mode
+ larger than LARGEST_MODE (usually SImode).
+ 
+ If no mode meets all these conditions, we return VOIDmode.  Otherwise, if
+ VOLATILEP is true or SLOW_BYTE_ACCESS is false, we return the smallest
+ mode meeting these conditions.
+ 
+ Otherwise (VOLATILEP is false and SLOW_BYTE_ACCESS is true), we return
+ the largest mode (but a mode no wider than UNITS_PER_WORD) that meets
+ all the conditions.  */
 
 enum machine_mode
 get_best_mode (bitsize, bitpos, align, largest_mode, volatilep)
-     int bitsize, bitpos;
-     unsigned int align;
-     enum machine_mode largest_mode;
-     int volatilep;
+int bitsize, bitpos;
+unsigned int align;
+enum machine_mode largest_mode;
+int volatilep;
 {
-  enum machine_mode mode;
-  unsigned int unit = 0;
-
-  /* Find the narrowest integer mode that contains the bit field.  */
-  for (mode = GET_CLASS_NARROWEST_MODE (MODE_INT); mode != VOIDmode;
-       mode = GET_MODE_WIDER_MODE (mode))
+    enum machine_mode mode;
+    unsigned int unit = 0;
+    
+    /* Find the narrowest integer mode that contains the bit field.  */
+    for (mode = GET_CLASS_NARROWEST_MODE (MODE_INT); mode != VOIDmode;
+         mode = GET_MODE_WIDER_MODE (mode))
     {
-      unit = GET_MODE_BITSIZE (mode);
-      if ((bitpos % unit) + bitsize <= unit)
-	break;
+        unit = GET_MODE_BITSIZE (mode);
+        if ((bitpos % unit) + bitsize <= unit)
+            break;
     }
-
-  if (mode == VOIDmode
-      /* It is tempting to omit the following line
-	 if STRICT_ALIGNMENT is true.
-	 But that is incorrect, since if the bitfield uses part of 3 bytes
-	 and we use a 4-byte mode, we could get a spurious segv
-	 if the extra 4th byte is past the end of memory.
-	 (Though at least one Unix compiler ignores this problem:
-	 that on the Sequent 386 machine.  */
-      || MIN (unit, BIGGEST_ALIGNMENT) > align
-      || (largest_mode != VOIDmode && unit > GET_MODE_BITSIZE (largest_mode)))
-    return VOIDmode;
-
-  if (SLOW_BYTE_ACCESS && ! volatilep)
+    
+    if (mode == VOIDmode
+        /* It is tempting to omit the following line
+         if STRICT_ALIGNMENT is true.
+         But that is incorrect, since if the bitfield uses part of 3 bytes
+         and we use a 4-byte mode, we could get a spurious segv
+         if the extra 4th byte is past the end of memory.
+         (Though at least one Unix compiler ignores this problem:
+         that on the Sequent 386 machine.  */
+        || MIN (unit, BIGGEST_ALIGNMENT) > align
+        || (largest_mode != VOIDmode && unit > GET_MODE_BITSIZE (largest_mode)))
+        return VOIDmode;
+    
+    if (SLOW_BYTE_ACCESS && ! volatilep)
     {
-      enum machine_mode wide_mode = VOIDmode, tmode;
-
-      for (tmode = GET_CLASS_NARROWEST_MODE (MODE_INT); tmode != VOIDmode;
-	   tmode = GET_MODE_WIDER_MODE (tmode))
-	{
-	  unit = GET_MODE_BITSIZE (tmode);
-	  if (bitpos / unit == (bitpos + bitsize - 1) / unit
-	      && unit <= BITS_PER_WORD
-	      && unit <= MIN (align, BIGGEST_ALIGNMENT)
-	      && (largest_mode == VOIDmode
-		  || unit <= GET_MODE_BITSIZE (largest_mode)))
-	    wide_mode = tmode;
-	}
-
-      if (wide_mode != VOIDmode)
-	return wide_mode;
+        enum machine_mode wide_mode = VOIDmode, tmode;
+        
+        for (tmode = GET_CLASS_NARROWEST_MODE (MODE_INT); tmode != VOIDmode;
+             tmode = GET_MODE_WIDER_MODE (tmode))
+        {
+            unit = GET_MODE_BITSIZE (tmode);
+            if (bitpos / unit == (bitpos + bitsize - 1) / unit
+                && unit <= BITS_PER_WORD
+                && unit <= MIN (align, BIGGEST_ALIGNMENT)
+                && (largest_mode == VOIDmode
+                    || unit <= GET_MODE_BITSIZE (largest_mode)))
+                wide_mode = tmode;
+        }
+        
+        if (wide_mode != VOIDmode)
+            return wide_mode;
     }
-
-  return mode;
+    
+    return mode;
 }
 
 /* This function is run once to initialize stor-layout.c.  */
@@ -2011,5 +2013,5 @@ get_best_mode (bitsize, bitpos, align, largest_mode, volatilep)
 void
 init_stor_layout_once ()
 {
-  ggc_add_tree_root (&pending_sizes, 1);
+    ggc_add_tree_root (&pending_sizes, 1);
 }


